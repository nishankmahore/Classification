OWNX	 waste not want not  expresses our culture's aversion to waste
OWNX	 i could have gotten the same thing for less  is a sentiment that can diminish pleasure in a transaction
MISC	we study people's willingness to  pay  to avoid this spoiler
MISC	in one scenario  participants imagined they were looking for a rental apartment  and had bought a subscription to an apartment listing
MISC	if a cheaper subscription had been declined  respondents preferred not to discover post hoc that it would have sufficed
MISC	specifically  they preferred ending their quest for the ideal apartment after seeing more  rather than fewer  apartments  so that the length of the search exceeds that available within the cheaper subscription
OWNX	other scenarios produced similar results
MISC	we conclude that people may sometimes prefer to be wasteful in order to avoid feeling wasteful
MISC	recently  one of our friends was upset
OWNX	she had just rented a perfect little apartment  advertised on a campus bulletin board
OWNX	 but   she said   i had just paid a non-refundable fee for an apartments listing
MISC	now i feel like a freier  a yiddish word  roughly meaning patsy  sucker  or pushover
MISC	spending more money than necessary is regarded as wasteful
MISC	when not intentional  and easily avoidable  it can make one feel like a freier
MISC	admittedly  sometimes people overspend deliberately
OWNX	people show off their wealth by shopping in wildly expensive places
MISC	others flaunt their disregard for money by lighting up cigars with   NUMBER  bills
MISC	people also choose to be generous  giving expensive gifts  throwing elaborate parties  tipping ostentatiously  etc
MISC	extravagance is not to be equated with waste
MISC	but when actions are self-defined as wasteful  the feeling of wastefulness can be as aversive  if not more  than the waste itself
OWNX	mental accounting  CITATION  provides a useful framework for understanding waste
MISC	if you want a new pair of jeans    NUMBER  is wasteful
MISC	but if you want prada jeans    NUMBER  may be a bargain
MISC	to please your hosts  a   NUMBER  wine may be adequate
MISC	but to impress them  you should lay out more
MISC	when you open a mental account  and enter a debit  you can judge for yourself whether the resulting outcome was  worth it 
OWNX	but mental accounting does not explain why the feeling of waste is so aversive
MISC	arkes  an expert on the psychology of waste  CITATION   has defined waste in two ways
MISC	first  as mentioned above  a person is said to be wasteful if she  spends more money on an item than is necessary 
MISC	second  the other side of waste is to  utilize the item that has been purchased  insufficiently  CITATION
OWNX	arkes identified several behaviors driven by waste aversion
MISC	waste is contrary to one's economic self-interest  and oftimes even considered immoral  so trying to avoid it is natural
MISC	arkes showed  moreover  that even  to avoid the appearance of wastefulness  italics ours  people may be motivated to make choices that compromise their own self-interest  CITATION  
OWNX	spending too much hurts the pocket
MISC	appearing to have spent too much hurts the ego
MISC	people may willingly overpay in economic currencies to reduce psychological costs
MISC	however  losses that are not one's  own fault  due  e g   to theft  accident  or market behavior are not accompanied by this second-order pain
MISC	thus  people may also prefer to tolerate additional expenditures of time  effort  pain  discomfort  etc
MISC	  if only to avoid the psychological costs of feeling that they wasted their money
MISC	the present study extends waste aversion to scenarios where not only self-interest is violated  but dominance is violated as well - provided that can save one from feeling like a freier
MISC	study  NUMBER  establishes the phenomenon  namely that  in order to avoid feeling that money was wasted people prefer an outcome that delivers the same result  but requires greater expenditure of effort  time or discomfort  and is therefore dominated
MISC	study  NUMBER  extends the results by introducing new dependent variables and manipulating the proximity of the protagonist
OWNX	This article considers constrained  SYMBOL  minimization methods for the recovery of high dimensional sparse signals in three settings: noiseless, bounded error and Gaussian noise
MISC	A unified and elementary treatment is given in these noise settings for two  SYMBOL  minimization methods: the Dantzig selector and  SYMBOL  minimization with an  SYMBOL  constraint
OWNX	The results of this paper improve the existing results in the literature by weakening the conditions and tightening the error bounds
MISC	The improvement on the conditions shows that signals with larger support can be recovered accurately
OWNX	This paper also establishes connections between restricted isometry property and the mutual incoherence property
OWNX	Some results of Candes, Romberg and Tao (2006) and Donoho, Elad, and Temlyakov (2006) are extended
MISC	The problem of recovering a high-dimensional sparse signal based on a small number of measurements, possibly corrupted by noise, has attracted much recent attention
MISC	This problem arises in many different settings, including model selection in linear regression, constructive approximation,  inverse problems, and compressive sensing
OWNX	Suppose we have  SYMBOL  observations of the form  y = F+ z where the matrix  SYMBOL  with  SYMBOL  is given and  SYMBOL  is a vector of measurement errors
OWNX	The goal is to reconstruct the unknown vector  SYMBOL
MISC	Depending on settings, the error vector  SYMBOL  can either be zero (in the noiseless case), bounded, or Gaussian where  SYMBOL
OWNX	It is now well understood that  SYMBOL  minimization provides an effective way for reconstructing a sparse signal in all three settings
MISC	A special case of particular interest is when no noise is present in () and  SYMBOL
MISC	This is an underdetermined system of linear equations with more variables than the number of equations
MISC	It is clear that the problem is ill-posed and there are generally infinite many solutions
OWNX	However, in many applications the vector  SYMBOL  is known to be sparse or nearly sparse in the sense that it contains only a small number of nonzero entries
OWNX	This sparsity assumption fundamentally changes the problem, making unique solution possible
OWNX	Indeed in many cases the unique sparse solution can be found exactly through  SYMBOL  minimization: (P) \min\|\|_1 \mbox{subject to} F= y
MISC	This  SYMBOL  minimization problem has been studied, for example, in Fuchs  CITATION , Candes and Tao  CITATION  and Donoho  CITATION
MISC	Understanding the noiseless case is not only of significant interest on its own right, it also provides deep insight into the problem of reconstructing sparse signals in the noisy case
MISC	See, for example, Candes and Tao  CITATION  and Donoho  CITATION
MISC	When  noise is present, there are two well known  SYMBOL  minimization methods
MISC	One is  SYMBOL  minimization under the  SYMBOL  constraint on the residuals: (P_1) \min\|\|_1 \mbox{subject to} \|y-F\gamma\|_2\epsilon
MISC	Writing in terms of the Lagrangian function of ( SYMBOL ), this is closely related to finding the solution to the  SYMBOL  regularized least squares:  \min_\left\{\|y-F\gamma\|_2^2 + \rho\|\|_1\right\}
OWNX	The latter is often called the Lasso in the statistics literature (Tibshirani  CITATION )
MISC	Tropp  CITATION  gave a detailed treatment of the  SYMBOL  regularized least squares problem
MISC	Another method, called the Dantzig selector, is recently proposed by Candes and Tao  CITATION
MISC	The Dantzig selector solves the sparse recovery problem through  SYMBOL -minimization with a constraint on the correlation between the residuals and the column vectors of  SYMBOL :  SYMBOL } Candes and Tao  CITATION  showed that the Dantzig selector can be computed by solving a linear program and it mimics the performance of an oracle procedure up to a logarithmic factor  SYMBOL
MISC	It is clear that regularity conditions are needed in order for these problems to be well behaved
MISC	Over the last few years, many interesting results for recovering sparse signals have been obtained in the framework of the  Restricted Isometry Property  (RIP)
OWNX	In their seminal work  CITATION , Candes and Tao considered sparse recovery problems in the RIP framework
MISC	They provided beautiful solutions to the problem under some conditions on the restricted isometry constant  and restricted orthogonality constant (defined in Section )
MISC	Several different conditions have been imposed in various settings
OWNX	In this paper, we consider  SYMBOL  minimization methods for the sparse recovery problem in three cases: noiseless, bounded error and Gaussian noise
MISC	Both the Dantzig selector (DS) and  SYMBOL  minimization under the  SYMBOL  constraint  SYMBOL  are considered
OWNX	We give a unified and elementary treatment for the two methods under the three noise settings
OWNX	Our results improve on the existing results in  CITATION  by weakening the conditions and tightening the error bounds
MISC	In all cases we solve the problems under the weaker condition  SYMBOL  where  SYMBOL  is the sparsity index and  SYMBOL  and  SYMBOL  are respectively the restricted isometry constant and restricted orthogonality constant defined in Section
MISC	The improvement on the condition shows that signals with larger support can be recovered
OWNX	Although our main interest is on recovering sparse signals, we state the results in the general setting of reconstructing an arbitrary signal
MISC	Another widely used condition for sparse recovery is the so called  Mutual Incoherence  Property  (MIP) which requires the pairwise correlations among the column vectors of  SYMBOL  to be small
OWNX	See  CITATION
OWNX	We establish connections between the concepts of RIP and MIP
OWNX	As an application, we present an improvement to a recent result of Donoho, Elad, and Temlyakov   CITATION
OWNX	The paper is organized as follows
OWNX	In Section , after basic notation and definitions are reviewed, two elementary inequalities, which allow us to make finer analysis of the sparse recovery problem, are introduced
OWNX	We begin the analysis of  SYMBOL  minimization methods for sparse recovery by considering the exact recovery in the noiseless case in Section
OWNX	Our result improves the main result in Candes and Tao  CITATION  by using weaker conditions and providing tighter error bounds
OWNX	The analysis of the noiseless case provides insight to the case when the observations are contaminated by noise
MISC	We then consider the case of bounded error in Section
MISC	The connections between the RIP and MIP are also explored
OWNX	The case of Gaussian noise is treated in Section
OWNX	The Appendix contains the proofs of some technical results
OWNX	Suppose we are given two probability measures on the set of one-way infinite finite-alphabet sequences and consider the question when one of the  measures predicts the other, that is, when conditional probabilities  converge (in a certain sense) when one of the measures is chosen to generate the sequence
MISC	This question may be considered a refinement of the problem of sequence prediction in its most general formulation: for a given  class of probability measures, does there exist a measure which predicts all of the measures in the class
MISC	To address this problem, we find some conditions on local absolute continuity which are sufficient for prediction and which generalize several different notions which are known to be sufficient for prediction
OWNX	We also formulate some open questions to outline a direction for finding the conditions on classes of measures for which prediction is possible
MISC	Let a sequence  SYMBOL ,  SYMBOL  of letters from some finite alphabet  SYMBOL  be generated by some probability measure  SYMBOL
OWNX	Having observed the first  SYMBOL  letters  SYMBOL  we want to predict what is the probability of the next letter being  SYMBOL , for each  SYMBOL
MISC	This task is motivated by numerous applications --- from weather forecasting and stock market prediction to data compression
OWNX	If the measure  SYMBOL  is known completely then the best forecasts one can make for the  SYMBOL st  outcome of a sequence  SYMBOL  is  SYMBOL -conditional probabilities of   SYMBOL  given  SYMBOL
MISC	On the other hand, it is immediately apparent that if nothing is known about the distribution  SYMBOL  generating the sequence then no prediction is possible, since for any predictor there is a measure on which it errs (gives inadequate probability forecasts) on every step
MISC	Thus one has to restrict the attention to some class of measures
MISC	Laplace was perhaps the first to address the question of sequence prediction, his motivation being as follows: Suppose that we know that the Sun has risen every day for 5000 years, what is the probability that it will rise tomorrow
MISC	He suggested to assume that the probability that the Sun rises is the same every day and the trials are independent of each other
MISC	Thus Laplace considered the task of sequence prediction when the true generating measure belongs to the family of Bernoulli  iid  \ measures  with binary alphabet  SYMBOL
MISC	The predicting measure suggested by Laplace was  SYMBOL  where  SYMBOL  is the number of 1s in  SYMBOL
OWNX	The conditional probabilities of Laplace's measure  SYMBOL  converge to the true conditional probabilities  SYMBOL -almost surely under any Bernoulli  iid  measure  SYMBOL
MISC	This approach generalizes to the problem of predicting any finite-memory (e g \ Markovian) measure
OWNX	Moreover, in  CITATION  a measure  SYMBOL  was constructed for predicting an arbitrary stationary measure
MISC	The conditional probabilities of  SYMBOL  converge to the true ones  on average , where average is taken over time steps (that is, in Cesaro sense),  SYMBOL -almost surely for any stationary measure  SYMBOL
MISC	However, as it was shown in the same work, there is no measure for which conditional probabilities converge to the true ones  SYMBOL -a s \ for every stationary  SYMBOL
OWNX	Thus we can see that already for the problem of predicting outcomes of a stationary measure two criteria of prediction arise: prediction in the average (or in Cesaro sense) and prediction on each step, and the solution exists only for the former problem
OWNX	But what if the measure generating the sequence is not stationary
MISC	A different assumption one can make is that the measure  SYMBOL  generating the sequence is computable
MISC	Solomonoff  CITATION  suggested a measure  SYMBOL  for predicting any computable probability measure
MISC	The key observation here is that the class of all computable probability measures is countable; let us denote it by  SYMBOL
MISC	A Bayesian predictor  SYMBOL  for a countable class of measures  SYMBOL   is constructed as follows:  SYMBOL  for any measurable set A, where the weights  SYMBOL  are positive  and sum to one
MISC	The best predictor for a measure  SYMBOL  is the measure  SYMBOL  itself
MISC	The Bayesian predictor simply takes the weighted average of the predictors for all measures in the class --- for countable classes this is possible
MISC	It was shown by Solomonoff  CITATION  that  SYMBOL -conditional probabilities converge to  SYMBOL -conditional probabilities almost surely for any computable measure  SYMBOL
OWNX	In fact this is a special case of a more general (though without convergence rate) result of Blackwell and Dubins  CITATION  which states that if a measure  SYMBOL  is absolutely continuous with respect to a measure  SYMBOL  then  SYMBOL  converges to  SYMBOL  in total variation  SYMBOL -almost surely
MISC	Convergence in total variation means prediction in a very strong sense~--- convergence of conditional probabilities of arbitrary events (not just the next outcome), or prediction with arbitrary fast growing horizon
MISC	Since for  SYMBOL  we have  SYMBOL  for every measurable set  SYMBOL  and for every  SYMBOL , each  SYMBOL  is absolutely continuous with respect to  SYMBOL
MISC	Thus the problem of sequence prediction for certain  classes of measures (such as the class of all stationary measures or the class of all computable measures) was often addressed in the literature
MISC	Although the mentioned classes of measures are sufficiently interesting, it is often hard to decide in applications with which assumptions does a problem at hand comply; not to mention such practical issues as that a predicting measure for all computable measures is necessarily non-computable itself
MISC	Moreover, to be able to generalize the solutions of the sequence prediction problem to such problems as active learning, where outcomes of a sequence may depend on actions of the predictor, one has to understand better under which conditions  the problem of sequence prediction is solvable
MISC	In particular, in active learning, the stationarity assumption does not seem to be applicable (since the predictions are non-stationary), although, say, the Markov assumption is often applicable and is extensively studied
OWNX	Thus, we formulate the following general questions which we start to address in the present work:   For which classes of measures is sequence prediction possible
OWNX	Under which conditions does a measure  SYMBOL  predict a measure  SYMBOL
MISC	As we have seen, these questions have many facets, and in particular there are many criteria of prediction to be considered, such as almost sure convergence of conditional probabilities, convergence in average, etc
MISC	Extensive as the literature on sequence prediction is, these questions in their full generality have not received much attention
OWNX	One line of research which exhibits this kind of generality consists in extending the result of Blackwell and Dubins mentioned above, which states that if  SYMBOL  is absolutely continuous with respect to  SYMBOL , then  SYMBOL  predicts  SYMBOL  in total variation distance
MISC	In  CITATION  a question of whether, given a class of measures  SYMBOL  and a prior (``meta''-measure)  SYMBOL  over this class of measures, the conditional probabilities of a Bayesian mixture of the class  SYMBOL  w r t
OWNX	SYMBOL  converge to the true  SYMBOL -probabilities (weakly merge, in terminology of  CITATION ) for  SYMBOL --almost any measure  SYMBOL  in  SYMBOL
MISC	This question can be considered solved, since the authors provide necessary and sufficient conditions on the measure given by the mixture of the class  SYMBOL  w r t
OWNX	SYMBOL  under which prediction is possible
MISC	The major difference from the general  questions we posed above is that we do not wish to assume that we have a measure on our class of measures
MISC	For large (non-parametric) classes of measures it may not be intuitive which measure over it is natural; rather, the question is  whether a ``natural'' measure which can be used for prediction exists
OWNX	To address the general questions posed, we start with the following observation
MISC	As it was mentioned, for a Bayesian mixture  SYMBOL  of a countable class of measures  SYMBOL ,  SYMBOL , we have  SYMBOL  for any  SYMBOL  and any measurable set  SYMBOL , where  SYMBOL  is a constant
MISC	This condition is stronger than the assumption of absolute continuity and is sufficient for prediction in a very strong sense
MISC	Since we are willing to be satisfied with prediction in a weaker sense (e g \ convergence of conditional probabilities), let us make a weaker assumption: Say that  a measure  SYMBOL  dominates a measure  SYMBOL  with coefficients  SYMBOL   if \rho(x_1,\dots,x_n) \;\geq\; c_n \mu(x_1,\dots,x_n) for all  SYMBOL \paranodot{The first concrete question} we pose is, under what conditions on  SYMBOL  does () imply that  SYMBOL  predicts  SYMBOL
MISC	Observe that if  SYMBOL  for any  SYMBOL  then any measure  SYMBOL  is  locally  absolutely continuous with respect to  SYMBOL  (that is, the measure  SYMBOL  restricted to the first  SYMBOL  trials  SYMBOL  is absolutely continuous w r t
MISC	SYMBOL  for each  SYMBOL ), and moreover, for any measure  SYMBOL  some constants  SYMBOL  can be found that satisfy ()
MISC	For example, if  SYMBOL  is Bernoulli  iid  \ measure with parameter  SYMBOL  and  SYMBOL  is any other measure, then () is (trivially) satisfied with  SYMBOL
OWNX	Thus we know that if  SYMBOL  then  SYMBOL  predicts  SYMBOL  in a very strong sense, whereas exponentially decreasing  SYMBOL  are not enough for prediction
OWNX	Perhaps somewhat surprisingly, we will show that dominance with any subexponentially decreasing coefficients is sufficient for prediction, in a weak sense of convergence of expected averages
MISC	Dominance with any polynomially decreasing coefficients, and also with coefficients decreasing (for example) as  SYMBOL , is sufficient for (almost sure) prediction on average (i e \ in Cesaro sense)
MISC	However, for prediction on every step we have a negative result: for any dominance coefficients that go to zero there exists a pair of measures  SYMBOL  and  SYMBOL  which satisfy~() but  SYMBOL  does not predict  SYMBOL  in the sense of almost sure convergence of probabilities
MISC	Thus the situation is similar to that for predicting any stationary measure: prediction is possible in the average but not on every step
MISC	Note also that for Laplace's measure  SYMBOL  it can be shown that  SYMBOL  dominates any  iid  \ measure  SYMBOL  with linearly decreasing coefficients  SYMBOL ; a generalization of  SYMBOL  for predicting all measures with memory  SYMBOL  (for a given  SYMBOL ) dominates them with polynomially  decreasing coefficients
MISC	Thus dominance with decreasing coefficients generalizes (in a sense) predicting countable classes of measures (where we have dominance with a constant), absolute continuity (via local absolute continuity), and predicting  iid  \ and finite-memory measures
MISC	Another way to look for generalizations  is as follows
MISC	The Bayes mixture  SYMBOL , being a sum of countably many measures (predictors), possesses some of their predicting properties
MISC	In general, which predictive properties are preserved under summation
OWNX	In particular, if we have two predictors  SYMBOL  and  SYMBOL  for two classes of measures, we are interested in the question whether  SYMBOL  is a predictor for the union of the two classes
MISC	An answer to this question would improve our understanding of how far a class of measures for which a predicting measure exists can be extended without losing this property \paranodot{{Thus,} the second question} we consider is the following: suppose that a measure  SYMBOL  predicts  SYMBOL  (in some weak sense), and let  SYMBOL  be some other measure (e g \ a predictor for a different class of measures)
OWNX	Does the measure  SYMBOL  still predict  SYMBOL
OWNX	That is, we ask to which prediction quality criteria does the idea of taking a Bayesian sum generalize
MISC	Absolute continuity is preserved under summation along with it's (strong) prediction ability
MISC	It was mentioned in  CITATION  that prediction in the (weak) sense of convergence of expected averages of conditional probabilities is preserved under summation
OWNX	Here we find that several stronger notions of prediction are not preserved under summation
OWNX	Thus we address the following two questions
MISC	Is dominance with decreasing coefficients sufficient for prediction in some sense, under some  conditions on the coefficients
MISC	And, if a measure  SYMBOL  predicts a measure  SYMBOL  in some sense, does the measure  SYMBOL  also predict  SYMBOL  in the same sense, where  SYMBOL  is an arbitrary measure
OWNX	Considering different criteria of prediction (a s \ convergence of conditional probabilities, a s \ convergence of averages, etc ) in the above two questions we obtain not two but many different questions, some of which we answer in the positive and some in the negative,   yet some are left open
OWNX	The paper is organized as follows
OWNX	Section~ introduces necessary notation and measures of divergence of probability measures
MISC	Section~ addresses the question of whether dominance with decreasing coefficients is sufficient for prediction, while in Section~ we consider the question of summing a predictor with an arbitrary measure
OWNX	Both sections~ and~ also propose some open questions and directions for future research
OWNX	In Section~ we discuss some interesting special cases of the questions considered, and also some related problems
MISC	Various characteristics of complex gene regulatory networks have been discovered during the last decade, e.g., redundancy, exponential indegree distributions, scale-free outdegree distributions, mutational robustness, and evolvability.
MISC	Although progress has been made in this field, it is not well understood whether these characteristics are the direct products of selection or those of other evolutionary forces such as mutational biases and biophysical constraints.
OWNX	To elucidate the causal factors that promoted the evolution of complex GRNs, we examined the effect of fluctuating environmental selection and some intrinsic constraining factors on GRN evolution by using an individual-based model.
MISC	We found that the evolution of complex GRNs is remarkably promoted by fixation of beneficial gene duplications under unpredictably fluctuating environmental conditions and that some internal factors inherent in organisms, such as mutational bias, gene expression costs, and constraints on expression dynamics, are also important for the evolution of GRNs.
MISC	The results indicate that various biological properties observed in GRNs could evolve as a result of not only adaptation to unpredictable environmental changes but also non-adaptive processes owing to the properties of the organisms themselves.
OWNX	Our study emphasizes that evolutionary models considering such intrinsic constraining factors should be used as null models to analyze the effect of selection on GRN evolution.
OWNX	The genetic basis of organismal evolution is one of the fundamental problems in biology CITATION CITATION.
MISC	The modes of selection for phenotypes would influence the fixation probabilities of the mutations that affect the phenotypes CITATION, and the profile of the mutations fixed during the course of evolution would determine the architecture of the genomes and the genetic systems underlying the phenotypes CITATION.
MISC	However, because genetic systems would modify the phenotypic effects of the mutations, the properties of the genetic system would influence the rates and directions of phenotypic evolution as well as the mutational robustness and evolvability CITATION CITATION.
OWNX	Therefore, both phenotypes and genetic systems have evolved by mutually influencing each other.
MISC	Gene regulatory networks constitute important parts of such genetic systems and are involved in various biological processes such as environmental responses in unicellular organisms and cell differentiation in multicellular organisms CITATION, CITATION, CITATION.
MISC	Recent theoretical and experimental studies have revealed that complex GRNs have evolved by successive gene duplication, changes in regulatory interactions, and particularly in prokaryotes, horizontal gene transfer CITATION CITATION.
MISC	In addition, recent studies have addressed the structural features of complex GRNs such as redundancy, scale-free outdegree distributions and exponential indegree distributions CITATION, CITATION CITATION and the contribution of these features to genetic characteristics such as mutational robustness and evolvability CITATION CITATION .
MISC	One important question with regard to the evolution of complex GRNs is the evolutionary origin of these structural and mutational properties.
MISC	Various evolutionary processes simultaneously influence GRN evolution and these properties are interrelated.
MISC	It is thus difficult to identify the factors that have promoted the evolution of these properties, which could evolve as a result of being directly influenced by selection and also incidentally as a result of other factors CITATION CITATION.
MISC	Thus, to identify the factors responsible for the evolution of the properties of complex GRNs, it is necessary to consider not only selection but also various mutational processes and constraining processes.
OWNX	Selection for phenotype is one of the most important driving forces of organismal evolution.
MISC	However, the impact of phenotypic selection on the evolution of GRNs is unclear.
MISC	The mode of selection strongly influences the fate of mutations and the profile of mutations fixed during the course of evolution ultimately determines the architecture of GRNs.
MISC	Thus, it is important to examine how different modes of phenotypic selection would affect the evolution of GRNs.
OWNX	However, there are significant limitations to our general understanding of the processes of adaptation in evolutionary biology.
MISC	Many previous studies on the evolution of mutational robustness with respect to GRNs have focused on the fixation of phenotypically neutral mutations under stabilizing selection with a constant optimal environment CITATION, CITATION.
MISC	On the other hand, the fixation of beneficial mutations for phenotypic adaptation under changing environments is limited CITATION .
MISC	Many studies have suggested that some examples of GRN architectures are related to mutational robustness and evolvability CITATION, CITATION, CITATION, CITATION.
MISC	Theoretical studies have proposed that these genetic properties appear to be evolvable traits CITATION, CITATION CITATION and that these genetic properties could play a significant role in organismal evolution CITATION.
MISC	However, it is unclear how mutational robustness and evolvability influences the process of GRN evolution.
MISC	Certain properties of GRN might have evolved through non-adaptive processes such as mutations and biophysical constraints on gene regulation CITATION, CITATION, CITATION CITATION.
OWNX	Mutations in particular is the ultimate source of genetic variation.
MISC	Thus, the biased properties of mutations can potentially influence the tendency of an organism to evolve.
OWNX	For example, the probability of a transcription factor binding site formation as a result of mutations could vary by several orders of magnitude mainly owing to the extensive variation in the size of potential cis-regulatory regions among organisms CITATION, CITATION, and the rate of gene deletion could be several times higher than the rate of gene duplication in certain organisms CITATION, CITATION.
MISC	Moreover, it has been suggested that the horizontal transfer of regulatory genes is observed to a lesser extent than that of phenotypic genes CITATION.
MISC	Several studies have suggested that certain characteristic features of complex GRNs, such as redundancy and scale-free degree distributions could evolve as an inevitable outcome of mutations CITATION, CITATION.
MISC	However, these previous studies have not considered certain essential evolutionary processes such as selection and gene duplication.
MISC	It is therefore unclear whether such characteristic features of complex GRNs evolved as a result of selection or as a result of the inherent properties of the mutations.
MISC	The purpose of this study was to identify the evolutionary causes of various structural and mutational properties of complex GRNs, such as redundancy, indegree and outdegree distributions, mutational robustness, and evolvability.
OWNX	For this purpose, we constructed an individual-based model of GRN that dynamically controls gene expression levels and allows populations to evolve under various fluctuating conditions of selection with various kinds of mutations such as gene duplication and deletion, cis-, trans-regulatory mutation and horizontal gene transfer.
OWNX	In this study, to explore selective conditions that promote the evolution of complex GRNs, we first examine the evolution of GRNs under various conditions of fluctuating selection.
OWNX	Second, for showing the adaptive mechanisms for the evolution of complex GRNs, we examine the fitness effect of all the mutations that arose during the evolution.
OWNX	Third, to explore whether internal factors of organisms promote or inhibit the evolution of GRNs, we examined the impact of gene expression cost, constraints on expression dynamics, and several types of mutational biases such as the relative rates of gene duplication and deletion, the possibility of formation of new transcription factor binding sites and horizontal gene transfers.
OWNX	Finally, on the basis of the results of the above analyses, we discuss the major evolutionary causes of various properties of complex GRNs, i.e., redundancy, scale-free out-degree distributions, exponential in-degree distributions, mutational robustness, and evolvability.
MISC	Previous modeling studies have identified the vaccination coverage level necessary for preventing influenza epidemics, but have not shown whether this critical coverage can be reached.
MISC	Here we use computational modeling to determine, for the first time, whether the critical coverage for influenza can be achieved by voluntary vaccination.
MISC	We construct a novel individual-level model of human cognition and behavior; individuals are characterized by two biological attributes that they use when making vaccination decisions.
OWNX	We couple this model with a population-level model of influenza that includes vaccination dynamics.
MISC	The coupled models allow individual-level decisions to influence influenza epidemiology and, conversely, influenza epidemiology to influence individual-level decisions.
OWNX	By including the effects of adaptive decision-making within an epidemic model, we can reproduce two essential characteristics of influenza epidemiology: annual variation in epidemic severity and sporadic occurrence of severe epidemics.
MISC	We suggest that individual-level adaptive decision-making may be an important causal factor in driving influenza epidemiology.
MISC	We find that severe epidemics cannot be prevented unless vaccination programs offer incentives.
MISC	Frequency of severe epidemics could be reduced if programs provide, as an incentive to be vaccinated, several years of free vaccines to individuals who pay for one year of vaccination.
MISC	Magnitude of epidemic amelioration will be determined by the number of years of free vaccination, an individuals' adaptability in decision-making, and their memory.
MISC	This type of incentive program could control epidemics if individuals are very adaptable and have long-term memories.
MISC	However, incentive-based programs that provide free vaccination for families could increase the frequency of severe epidemics.
MISC	We conclude that incentive-based vaccination programs are necessary to control influenza, but some may be detrimental.
MISC	Surprisingly, we find that individuals' memories and flexibility in adaptive decision-making can be extremely important factors in determining the success of influenza vaccination programs.
OWNX	Finally, we discuss the implication of our results for controlling pandemics.
MISC	Previously, both complex CITATION CITATION and simple models CITATION CITATION of influenza transmission dynamics have been analyzed to determine what proportion of the population would need to be vaccinated to prevent influenza epidemics and pandemics.
MISC	However, none of these modeling studies have shown whether this critical coverage can actually be reached.
MISC	Here we investigate, by modeling vaccination decisions made by individuals, whether the critical coverage can be achieved through voluntary vaccination.
MISC	We construct an individual-level model of human cognition and behavior and link it to an epidemic model of influenza that includes vaccination dynamics.
MISC	We assume that the decision of each individual is based upon self-interest such that s/he wishes to avoid catching influenza, preferably without having to be vaccinated.
MISC	Since protective immunity against influenza lasts less than one year CITATION, individuals must decide every year whether or not to participate in a voluntary vaccination program.
MISC	Individuals who get vaccinated protect themselves from infection, but if they do not get vaccinated they may still avoid infection if sufficient numbers of their peers get vaccinated.
MISC	This poses a yearly dilemma for the self-interested individual of whether vaccination is necessary.
MISC	We model each individual's strategy for making yearly vaccination decisions as an adaptive process of trial and error.
MISC	We track both individual-level decisions and population-level variables.
MISC	We use our model to address the following question: can influenza epidemics be prevented by voluntary vaccination?
MISC	Our individual-level adaptive decision-making model is inspired by Minority Game methodology.
MISC	A Minority Game models how noncommunicating selfish individuals reach a collective behavior with respect to a common dilemma under adaptation of each one's expectations.
MISC	In the past decade, Minority Games CITATION have been used to model inductive reasoning systems CITATION and financial markets CITATION.
MISC	Our constructed model consists of a population of N individuals acting in their own self-interest who do not communicate their vaccination decisions to each other.
MISC	Every year, these individuals independently decide whether or not to get vaccinated against influenza using a risk-free, highly effective vaccine CITATION.
MISC	We assumed that the vaccine presents no real risk and that individuals do not perceive any risk from vaccination.
MISC	Individuals in the model are characterized by two biological attributes that they use when making vaccination decisions.
MISC	Individuals can adapt their vaccination behavior for the current season on the basis of their memories of the consequences of their past vaccination decisions: i.e., they use cognition to make decisions.
OWNX	We couple our individual-level model of adaptive decision-making with a model of influenza vaccination dynamics.
OWNX	Our coupled models show the effect of individual-level vaccination decisions on influenza epidemiology and, conversely, the effect of influenza epidemiology on individual-level vaccination decisions.
OWNX	We first use our model to assess whether vaccination programs without incentives could achieve the critical coverage levels necessary to control influenza epidemics.
MISC	We then assess the potential epidemiological impact of two public heath programs that use incentives to encourage vaccination.
MISC	There are two major classes of incentive-based public health programs that can be investigated with our coupled models.
MISC	The first class uses incentives to correlate vaccination decisions for the same individual over many influenza seasons.
MISC	The second class uses incentives to correlate vaccination decisions amongst individuals in the population in one influenza season.
MISC	Many additional incentive-based vaccination programs can be formulated by combining the defining characteristics of these two classes.
MISC	The first public health program that we investigate is an example of the first class of incentive-based programs.
MISC	This program offers free vaccination for y number of years to an individual who pays for vaccination in the first year.
MISC	We assume that the individual gets vaccinated each year during the y years of free vaccination, but that s/he also evaluates the necessity of vaccination every year.
MISC	At the end of y years, each individual in the program then uses their evaluations to decide whether or not to re-enroll in the program.
MISC	If they choose to re-enroll, they pay for vaccination that season and receive free vaccinations for a further y years.
MISC	The second public health program that we analyze is an example of the second class of incentive-based programs.
MISC	This program vaccinates a family for free if the head of the family pays for her/his own vaccination.
MISC	We assume that the head of the family decides every year whether to re-enroll in the program depending upon how many of her/his family members were infected in the previous season.
OWNX	Allosteric proteins bind an effector molecule at one site resulting in a functional change at a second site.
MISC	We hypothesize that allosteric communication in proteins relies upon networks of quaternary and tertiary motions.
MISC	We argue that cyclic topology of these networks is necessary for allosteric communication.
MISC	An automated algorithm identifies rigid bodies from the displacement between the inactive and the active structures and constructs quaternary networks from these rigid bodies and the substrate and effector ligands.
MISC	We then integrate quaternary networks with a coarse-grained representation of contact rearrangements to form global communication networks.
MISC	The GCN reveals allosteric communication among all substrate and effector sites in 15 of 18 multidomain and multimeric proteins, while tertiary and quaternary networks exhibit such communication in only 4 and 3 of these proteins, respectively.
MISC	Furthermore, in 7 of the 15 proteins connected by the GCN, 50 percent or more of the substrate-effector paths via the GCN are interdependent paths that do not exist via either the tertiary or the quaternary network.
MISC	Substrate-effector pathways typically are not linear but rather consist of polycyclic networks of rigid bodies and clusters of rearranging residue contacts.
OWNX	These results argue for broad applicability of allosteric communication based on structural changes and demonstrate the utility of the GCN.
MISC	Global communication networks may inform a variety of experiments on allosteric proteins as well as the design of allostery into non-allosteric proteins.
MISC	The modern concept of allostery began with the models of Monod et al. CITATION and Koshland et al. CITATION, which sought to account for allostery based upon gross properties of the transition between two well-defined end-states.
CONT	More recent thermodynamic models of allostery characterize population shifts in conformational ensembles in more detail CITATION CITATION, and there is experimental evidence that alternate allosteric states are simultaneously populated in solution CITATION, CITATION.
MISC	Nonetheless, mechanical and chemical transitions in individual molecules underlie the thermodynamic properties of allosteric proteins.
MISC	That is, in individual molecules, energetic pathways of spatially contiguous, physically coupled structural changes and/or dynamic fluctuations must link substrate and effector sites CITATION CITATION .
MISC	Crystal structures have revealed that most allosteric proteins are complex systems with both tertiary and quaternary structural changes CITATION.
OWNX	Previously, we quantified allosteric communication through tertiary structure from graphs of residue-residue contacts that form, break, or rearrange in the transition between inactive and active state structures CITATION.
MISC	In such network representations of protein structure, putative paths between residues distant in three-dimensional space can be readily identified.
MISC	These tertiary networks or contact rearrangement networks identified substrate-effector paths in 6 of 15 proteins tested, which indicated that tertiary changes play a significant but incomplete role in allosteric communication.
OWNX	In this work, we broaden the CRN approach toward more completely quantifying allosteric coupling mechanisms from structure.
OWNX	Specifically, we develop a network representation of quaternary structural changes and integrate this representation with the CRN.
MISC	We seek to infer information about the allosteric coupling mechanism from gross properties of the differences between inactive and active structures.
CONT	In this, our work resembles the MWC CITATION and KNF CITATION approaches but differs from investigations of the kinetic mechanism, that is, the order of events in the transition between inactive and active structural regimes CITATION CITATION.
MISC	Most current computational approaches to large-scale protein dynamics predict motions and/or associated energetics by applying to the structure theoretical models like the elastic network CITATION and potential functions.
OWNX	While these predictions address important problems, most of these approaches do not predict allosteric pathways.
OWNX	By contrast to these problems, we will argue that allosteric pathway identification is facilitated by a network representation of a protein structural transition.
MISC	Network representations of protein structures have previously been used to illuminate dynamic and/or allosteric properties.
MISC	For example, large-scale fluctuations predicted from normal mode analysis of the elastic network correlate with known conformational changes CITATION, CITATION, CITATION.
MISC	In addition, rigid and flexible regions of protein structures have been predicted from the network of contact and hydrogen bond constraints in a single protein structure CITATION, CITATION.
MISC	Furthermore, residues important for maintaining short paths in a contact network are experimentally known to mediate signaling in proteins CITATION.
OWNX	However, allosteric communication pathways have not previously been derived from a network representation of the quaternary structural transition.
OWNX	In this paper, we develop a hypothesis for allosteric coupling via networks of quaternary motions.
MISC	We elucidate rigid bodies from the differences between inactive and active crystal structures with an automatic algorithm, and we form a quaternary network from the rigid bodies based on contacts between them.
MISC	Toward a broader representation of allosteric communication mechanisms, we assess how communication through these networks relates to that through contact rearrangement networks in tertiary structure.
MISC	We then integrate quaternary networks with a coarse-grained representation of CRNs to form global communication networks.
AIMX	We describe the range of topologies of GCNs in several representative proteins from the allosteric benchmark set CITATION, and then we assess substrate-effector communication via CRNs, the quaternary network, and the GCN in 18 DNA-binding proteins and enzymes and classify each protein based on the respective tertiary and quaternary contributions to connectivity.
MISC	GCN analysis provides the opportunity to advance the theory of mechanical allosteric coupling in proteins and may guide drug design and allosteric experiments and simulations.
OWNX	In this paper, we study the application of sparse principal component analysis (PCA) to clustering and feature selection problems
MISC	Sparse PCA seeks sparse factors, or linear combinations of the data variables, explaining a maximum amount of variance in the data while having only a limited number of nonzero coefficients
MISC	PCA is often used as a simple clustering technique and sparse factors allow us here to interpret the clusters in terms of a reduced set of variables
OWNX	We begin with a brief introduction and motivation on sparse PCA and detail our implementation of the algorithm in d'Aspremont et al (2005)
OWNX	We then apply these results to some classic clustering and feature selection problems arising in biology
OWNX	This paper focuses on applications of sparse principal component analysis to clustering and feature selection problems, with a particular focus on gene expression data analysis
MISC	Sparse methods have had a significant impact in many areas of statistics, in particular regression and classification (see  CITATION ,  CITATION  and  CITATION  among others)
OWNX	As in these areas, our motivation for developing sparse multivariate visualization tools is the potential of these methods for yielding statistical results that are both more interpretable and more robust than classical analyses, while giving up little statistical efficiency
OWNX	Principal component analysis (PCA) is a classic tool for analyzing large scale multivariate data
MISC	It seeks linear combinations of the data variables (often called factors or principal components) that capture a maximum amount of variance
MISC	Numerically, PCA only amounts to computing a few leading eigenvectors of the data's covariance matrix, so it can be applied to very large scale data sets
MISC	One of the key shortcomings of PCA however is that these factors are linear combinations of  all  variables; that is, all factor coefficients (or loadings) are non-zero
MISC	This means that while PCA facilitates model interpretation and visualization by concentrating the information in a few key factors, the factors themselves are still constructed using  all  observed variables
OWNX	In many applications of PCA, the coordinate axes have a direct physical interpretation; in finance or biology for example, each axis might correspond to a specific financial asset or gene
MISC	In such cases, having only a few nonzero coefficients in the principal components would greatly improve the relevance and interpretability of the factors
MISC	In sparse PCA, we seek a trade-off between the two goals of  expressive power  (explaining most of the variance or information in the data) and  interpretability  (making sure that the factors involve only a few coordinate axes or variables)
OWNX	When PCA is used as a clustering tool, sparse factors will allow us to identify the clusters with the action of only a few variables
MISC	Earlier methods to produce sparse factors include Cadima and Jolliffe  CITATION  where the loadings with smallest absolute value are thresholded to zero and nonconvex algorithms called SCoTLASS by  CITATION , SLRA  CITATION  and SPCA by  CITATION
MISC	This last method works by writing PCA as a regression-type optimization problem and applies LASSO  CITATION , a penalization technique based on the  SYMBOL  norm
MISC	Very recently,  CITATION  and  CITATION  also proposed a greedy approach which seeks globally optimal solutions on small problems and uses a greedy method to approximate the solution of larger ones
AIMX	In what follows, we give a brief introduction to the relaxation of this problem in  CITATION  and describe how this smooth optimization algorithm was implemented
AIMX	The most expensive numerical step in this algorithm is the computation of the gradient as a matrix exponential and our key numerical contribution here is to show that using only a partial eigenvalue decomposition of the current iterate can produce a sufficiently precise gradient approximation while drastically improving computational efficiency
OWNX	We then show on classic gene expression data sets that using sparse PCA as a simple clustering tool isolates very relevant genes compared to other techniques such as recursive feature elimination or ranking
OWNX	The paper is organized as follows
OWNX	In Section , we begin with a brief introduction and motivation on sparse PCA and detail our implementation of the algorithm in a numerical toolbox called DSPCA, which is available for download on the authors' websites
OWNX	In Section , we describe the application of sparse PCA to clustering and feature selection on gene expression data
MISC	Learning machines that have  hierarchical structures or hidden variables  are singular statistical models because they are nonidentifiable and  their Fisher information matrices are singular
MISC	In singular statistical models, neither  does the Bayes  a posteriori  distribution converge to the normal distribution nor does the maximum likelihood estimator satisfy asymptotic normality
MISC	This is the main reason that it has been difficult to  predict their generalization performance from trained states
OWNX	In this paper, we study four errors,  (1) the Bayes generalization error, (2) the Bayes training error, (3) the Gibbs generalization error, and (4) the Gibbs training error, and prove that there are universal mathematical relations among  these errors
OWNX	The formulas proved in this paper are equations of states in statistical estimation because they hold for any true distribution, any parametric model, and any  a priori  distribution
AIMX	Also we show that the Bayes and Gibbs generalization errors can be  estimated by Bayes and Gibbs training errors, and we propose  widely applicable information criteria that can be applied to both regular and singular statistical models
MISC	Recently, many learning machines are being used in information processing systems
MISC	For  example, layered neural networks, normal mixtures, binomial mixtures, Bayes networks, Boltzmann machines, reduced rank regressions, hidden Markov models, and stochastic context-free grammars  are being employed in pattern recognition, time series  prediction, robotic control, human modeling,  and biostatistics
MISC	Although their generalization performances determine the accuracy of the information systems,  it has been difficult to estimate generalization  errors based on training errors, because such  learning machines are singular statistical models
MISC	A parametric model is called regular if the mapping from the parameter to the  probability distribution is one-to-one and if its Fisher information matrix is always positive definite
MISC	If a statistical model is regular, then  the Bayes  a posteriori  distribution converges to the normal distribution,  and the maximum likelihood estimator satisfies  asymptotic normality
MISC	Based on such properties,  the relation between the generalization error and the training error was clarified, on which some information criteria  were proposed
MISC	On the other hand, if the mapping from the  parameter to the probability distribution is not one-to-one or if the Fisher information matrix is  singular, then the parametric model is called singular
MISC	In general, if a learning machine has hierarchical structure or hidden variables, then it is singular
OWNX	Therefore, almost all learning machines are singular
MISC	For singular learning machines, the log likelihood  function can not be approximated by any quadratic form of the parameter, with the result that the conventional relationship between generalization errors and  training errors does not hold either for the maximum likelihood method  CITATION   CITATION  CITATION  or  Bayes estimation  CITATION
OWNX	Singularities strongly affect generalization performances  CITATION  and learning dynamics  CITATION
MISC	Therefore, in order to establish the mathematical foundation of singular learning theory, it is necessary  to construct the formulas which hold even in singular learning machines
OWNX	Recently, we proved  CITATION  CITATION  that the  generalization error in Bayes estimation is asymptotically equal to  SYMBOL , where  SYMBOL  is the rational number  determined by the zeta function of a learning machine and  SYMBOL  is the number of training samples
MISC	In regular statistical models,  SYMBOL ,  where  SYMBOL  is the dimension of the parameter space, whereas in singular statistical models,  SYMBOL   depends strongly on the learning machine, the true distribution, and the  a priori  probability distribution
MISC	In practical applications, the true distribution is often unknown, hence it has been difficult to estimate the generalization error from the training error
MISC	To estimate the generalization error when we do not have any information about the true distribution, we need a general formula which holds independently of singularities
OWNX	In this paper, we study four errors,  (1) the Bayes generalization error  SYMBOL , (2) the Bayes training error  SYMBOL , (3) the Gibbs generalization error  SYMBOL , and (4) the Gibbs training error  SYMBOL , and prove the formulas  SYMBOL *} where  SYMBOL  denotes the expectation value and   SYMBOL  is the inverse temperature  of the  a posteriori  distribution
MISC	These equations assert that the increased error from training to  generalization is in proportion to  the difference between the Bayes and Gibbs training errors
MISC	It should be emphasized that these formulas hold for any true distribution, any learning machine,  any  a priori  probability distribution, and any singularities, therefore they reflect the universal laws of statistical estimation
AIMX	Also,  based on the formula, we propose widely applicable information  criteria (WAIC) which can be applied to both regular and singular learning machines
OWNX	In other words, we can apply WAIC without  any knowledge about the true distribution
OWNX	This paper consists of six parts
OWNX	In Section 2, we  describe the main results of this paper
OWNX	In Section 3,  we propose widely applicable information criteria  and show how to apply them to statistical estimation
OWNX	In Section 4, we prove the main results in the mathematically rigorous way
OWNX	In Sections 5 and 6, we discuss and conclude of this paper
MISC	The proofs of lemmas are quite technical hence they are presented in Appendix
OWNX	The Bayesian framework is a well-studied and successful framework for inductive reasoning, which includes hypothesis testing and confirmation, parameter estimation, sequence prediction, classification, and regression
MISC	But standard statistical guidelines for choosing the model class and prior are not always available or can fail, in particular in complex situations
OWNX	Solomonoff completed the Bayesian framework by providing a rigorous, unique, formal, and universal choice for the model class and the prior
MISC	I discuss in breadth how and in which sense universal (non- iid  )\ sequence prediction solves various (philosophical) problems of traditional Bayesian sequence prediction
MISC	I show that Solomonoff's model possesses many desirable properties: Strong total and future bounds, and weak instantaneous bounds, and in contrast to most classical continuous prior densities has no zero p(oste)rior problem, ie \ can confirm universal hypotheses, is reparametrization and regrouping invariant, and avoids the old-evidence and updating problem
MISC	It even performs well (actually better) in non-computable environments \ifjournal
MISC	Given the weather in the past, what is the probability of rain tomorrow
OWNX	What is the correct answer in an IQ test asking to continue the sequence 1,4,9,16,
OWNX	Given historic stock-charts, can one predict the quotes of tomorrow
MISC	Assuming the sun rose 5000 years every day, how likely is doomsday (that the sun does not rise) tomorrow
MISC	These are instances of the important problem of induction or time-series forecasting or sequence prediction
MISC	Finding prediction rules for every particular (new) problem is possible but cumbersome and prone to disagreement or contradiction
MISC	What is desirable is a formal general theory for prediction
OWNX	The Bayesian framework is the most consistent and successful framework developed thus far  CITATION
OWNX	A Bayesian considers a set of environments\eqbr=hypotheses\eqbr=models  SYMBOL  which includes the true data generating probability distribution  SYMBOL
OWNX	From one's prior belief  SYMBOL  in environment  SYMBOL  and the observed data sequence  SYMBOL , Bayes' rule yields one's posterior confidence in  SYMBOL
MISC	In a prequential  CITATION  or transductive  CITATION  setting, one directly determines the predictive probability of the next symbol  SYMBOL  without the intermediate step of identifying a (true or good or causal or useful) model
OWNX	With the exception of Section , this paper concentrates on  prediction  rather than model identification
OWNX	The ultimate goal is to make ``good'' predictions in the sense of maximizing one's profit or minimizing one's loss
MISC	Note that classification and regression can be regarded as special sequence prediction problems, where the sequence  SYMBOL  of  SYMBOL -pairs is given and the class label or function value  SYMBOL  shall be predicted
OWNX	The Bayesian framework leaves open how to choose the model class  SYMBOL  and prior  SYMBOL
MISC	General guidelines are that  SYMBOL  should be small but large enough to contain the true environment  SYMBOL , and  SYMBOL  should reflect one's prior (subjective) belief in  SYMBOL  or should be non-informative or neutral or objective if no prior knowledge is available
OWNX	But these are informal and ambiguous considerations outside the formal Bayesian framework
OWNX	Solomonoff's  CITATION  rigorous, essentially unique, formal, and universal solution to this problem is to consider a single large universal class  SYMBOL  suitable for  all  induction problems
MISC	The corresponding universal prior  SYMBOL  is biased towards simple environments in such a way that it dominates (=superior to) all other priors
MISC	This leads to an a priori probability  SYMBOL  which is equivalent to the probability that a universal Turing machine with random input tape outputs  SYMBOL , and the shortest program computing  SYMBOL  produces the most likely continuation (prediction) of  SYMBOL
MISC	Many interesting, important, and deep results have been proven for Solomonoff's universal distribution  SYMBOL   CITATION
OWNX	The motivation and goal of this paper is % to provide a broad discussion of how and in which sense universal sequence prediction solves all kinds of (philosophical) problems of Bayesian sequence prediction, and to % present some recent results
MISC	% Many arguments and ideas could be further developed
MISC	I hope that the exposition stimulates such a future, more detailed, investigation
OWNX	In Section , I review the excellent predictive and decision-theoretic performance results of Bayesian sequence prediction for generic (non- iid  )\ countable and continuous model classes
OWNX	Section  critically reviews the classical principles (indifference, symmetry, minimax) for obtaining objective priors, introduces the universal prior inspired by Occam's razor and quantified in terms of Kolmogorov complexity
MISC	In Section  (for  iid  \  SYMBOL ) and Section  (for universal  SYMBOL ) I show various desirable properties of the universal prior and class (non-zero p(oste)rior, confirmation of universal hypotheses, reparametrization and regrouping invariance, no old-evidence and updating problem) in contrast to (most) classical continuous prior densities
OWNX	I also complement the general total bounds of Section  with some universal and some  iid 
OWNX	-specific instantaneous and future bounds
MISC	Finally, I show that the universal mixture performs better than classical continuous mixtures, even in uncomputable environments
OWNX	Section  contains critique, summary, and conclusions
MISC	The reparametrization and regrouping invariance, the (weak) instantaneous bounds, the good performance of  SYMBOL  in non-computable environments, and most of the discussion (zero prior and universal hypotheses, old evidence) are new or new in the light of universal sequence prediction
OWNX	Technical and mathematical non-trivial new results are the Hellinger-like loss bound \req{lbnd} and the instantaneous bounds \req{iIIDbnd} and \req{iMbnd}
OWNX	We propose a randomized algorithm for   training Support vector machines(SVMs) on large datasets
OWNX	By using ideas from Random projections we show that  the combinatorial dimension of SVMs is  SYMBOL  with high probability
MISC	This estimate of combinatorial dimension is used  to derive an iterative algorithm, called RandSVM,  which at each step calls an existing solver to train SVMs on  a randomly chosen subset of size  SYMBOL
OWNX	The algorithm has probabilistic guarantees and is  capable of training SVMs  with Kernels for both classification and regression problems
OWNX	Experiments done on synthetic and real life data sets demonstrate that the algorithm scales up  existing SVM learners, without loss of accuracy \keywords{Support Vector Machines,  Randomized Algorithms, Random Projections} \subclass{68W20 90C25 90C06 90C90 }
MISC	Consider a training data set  SYMBOL  where  SYMBOL  are data points and  SYMBOL  are labels
MISC	The problem of learning a linear classifier,  SYMBOL ,  where  SYMBOL  or a linear function  SYMBOL  when  SYMBOL  is a scalar  can be understood as estimating  SYMBOL  from  SYMBOL
MISC	Over the years Support Vector Machines(SVMs) have emerged as powerful tools for estimating such functions
OWNX	In this paper we concentrate on developing  randomized algorithms for learning SVMs on large datasets
OWNX	For a  detailed review of SVM classification and SVM regression please see  CITATION
OWNX	To develop notation we briefly discuss the problem of training linear classifiers
MISC	The SVM formulation for linearly separable datasets is given by  CITATION    SYMBOL }  where  SYMBOL , is the euclidean norm of  SYMBOL
MISC	The formulation has very interesting geometric underpinnings  ~ CITATION
MISC	It can be understood as computing the distance between convex  hulls of the sets  SYMBOL  and  SYMBOL
OWNX	For linearly non-separable datasets the following formulation \\     C-SVM-1:  \\  SYMBOL } which will be called  SYMBOL , again due to  CITATION , can be used
MISC	This  formulation do not have an elegant geometric interpretation like the separable  case,  but one can consider C-SVMs as computing the distance between two  reduced convex hulls ~ CITATION
MISC	Both the formulations are instances of  Abstract Optimization Problem(AOP) ~ CITATION
MISC	An AOP is defined as follows:  Every AOP has a  combinatorial dimension associated  with it; the combinatorial dimension captures the notion of number of free variables for that AOP
MISC	An AOP can be solved by a randomized algorithm by selecting subsets of size greater than the combinatorial dimension of the problem~ CITATION
MISC	We wish to exploit this property  of AOPs to design randomized algorithms for SVMs
MISC	The idea is to develop an iterative algorithm where in each step one needs  to solve a SVM formulation on a small subset of the training data
MISC	Crucial  to this idea is the size of the subset which is tied to the combinatorial  dimension of the SVM formulation
OWNX	To this end note that at optimality  SYMBOL  is given by  SYMBOL } for both the separable and non-separable case
MISC	Using the  SYMBOL  variables one can define the set of Support vectors~(SVs),  SYMBOL } which defines  SYMBOL
OWNX	The set  SYMBOL  may not be unique, though  SYMBOL  is
MISC	The combinatorial dimension of SVMs is given by the minimum number of SVs   required to define  SYMBOL
OWNX	More formally  SYMBOL } where  SYMBOL  is the cardinality of the set  SYMBOL
MISC	The parameter  SYMBOL  does not change with number of examples  SYMBOL , and is often much less than  SYMBOL
MISC	Apriori the value of  SYMBOL  is not known, but for linearly separable classification problems the following holds:  SYMBOL
OWNX	This follows from the observation that  it computes the distance between 2 non-overlapping convex hulls~ CITATION
MISC	When the problem is not linearly separable, the reduced convex hull interpretation leads to a very crude upper bound, which is much larger than  SYMBOL
MISC	The idea of iterating over randomly sampled subsets of size greater than   SYMBOL , for training SVMs was first explored by  ~ CITATION , and  the resulting algorithm was called RandSVM
MISC	The  RandSVM procedure iterates over subsets of size proportional to  SYMBOL  , as shown in Algorithm~
MISC	However as the authors noted that RandSVM is not practical because of the following reasons
OWNX	For linear classifiers the sample size is too large in case of high dimensional data sets
MISC	For non-linear SVMs ~ CITATION   the dimension of feature space is usually unknown when using kernels
CONT	Even in this case one can obtain a very crude  upper-bound on  SYMBOL  by the reduced convex hull approach but  is not really useful as the number obtained is very large \end{algorithm}  This work overcomes the above problems using ideas from random projections~ CITATION  and randomized algorithms~ CITATION
MISC	As mentioned by the authors of RandSVM, the biggest bottleneck in their algorithm is the value of  SYMBOL  as it is too large
OWNX	The main contribution of this work is, using ideas from random projections, the conjecture that if RandSVM is solved using  SYMBOL  equal to  SYMBOL , then the solution obtained is close to optimal with high probability(Theorem~, particularly for linearly separable and almost separable data sets
MISC	Almost separable data sets are those which become linearly separable when a small number of properly chosen data points are deleted from them
MISC	The second contribution is an algorithm which, using ideas from randomized algorithms for Linear Programming(LP), solves the SVM problem by using samples of size linear in  SYMBOL
MISC	This work also shows that the theory can be applied to non-linear kernels
OWNX	The formulation naturally applies to regression problems
OWNX	The paper is organized as follows: Section~ introduces the previous work, Section~ presents the improved algorithm for classification for almost linearly  separable data
OWNX	Section~ presents the improved algorithm for the  SYMBOL tube regression formulation
OWNX	We present our results  and conclusions in Section~ and ~
MISC	The extent to which self-adopted or intervention-related changes in behaviors affect the course of epidemics remains a key issue for outbreak control.
MISC	This study attempted to quantify the effect of such changes on the risk of infection in different settings, i.e., the community and hospitals.
MISC	The 2002 2003 severe acute respiratory syndrome outbreak in Hong Kong, where 27 percent of cases were healthcare workers, was used as an example.
OWNX	A stochastic compartmental SEIR model was used: the population was split into healthcare workers, hospitalized people and general population.
OWNX	Super spreading events were taken into account in the model.
MISC	The temporal evolutions of the daily effective contact rates in the community and hospitals were modeled with smooth functions.
OWNX	Data augmentation techniques and Markov chain Monte Carlo methods were applied to estimate SARS epidemiological parameters.
OWNX	In particular, estimates of daily reproduction numbers were provided for each subpopulation.
OWNX	The average duration of the SARS infectious period was estimated to be 9.3 days.
MISC	The model was able to disentangle the impact of the two SSEs from background transmission rates.
MISC	The effective contact rates, which were estimated on a daily basis, decreased with time, reaching zero inside hospitals.
MISC	This observation suggests that public health measures and possible changes in individual behaviors effectively reduced transmission, especially in hospitals.
MISC	The temporal patterns of reproduction numbers were similar for healthcare workers and the general population, indicating that on average, an infectious healthcare worker did not infect more people than any other infectious person.
MISC	We provide a general method to estimate time dependence of parameters in structured epidemic models, which enables investigation of the impact of control measures and behavioral changes in different settings.
MISC	Emerging infectious diseases have been defined as, infections that have newly appeared in a population or have existed previously but are rapidly increasing in incidence or geographic range.
MISC	CITATION Several features may make them particularly threatening.
MISC	First, recognizing the disease can be difficult when the first cases appear, especially when the symptoms are non-specific.
MISC	Second, no vaccine or specific treatment may be known initially.
MISC	Moreover, heterogeneities in disease transmission may create high-risk groups, such as healthcare workers CITATION CITATION and high-risk geographical areas, thereby dramatically enhancing the impact of the outbreak CITATION .
MISC	The 2003 severe acute respiratory syndrome outbreak in Hong Kong is remarkably illustrative of the above issues: symptoms were similar to pneumonia CITATION ; the incubation period was long enough for local and international transmission to occur CITATION ; no vaccine or treatment was available; as much as 21 percent of cases worldwide were healthcare workers CITATION.
MISC	The outbreak also demonstrated the possible existence of super-spreading events CITATION, during which a few infectious individuals contaminated a high number of secondary cases.
MISC	Hong Kong had two SSEs: the first occurred in Hospital X around March 3 and led to about 125 cases CITATION ; the second occurred in Housing Estate Y on March 19, and led to over 300 cases CITATION, CITATION.
MISC	Despite its particularly threatening features, the outbreak was brought under control.
MISC	In this context, once the epidemic is detected, spontaneous changes in behavior will occur, and non-pharmacological measures are usually initiated to control the outbreak.
MISC	The resulting effects of these two phenomena on disease transmission is not easily quantified.
MISC	The effective contact rate, which reflects the combined influences of social proximity and the probability of infection through each contact, is an essential determinant of disease spread.
OWNX	Our aim was to estimate the temporal variation of this parameter in the community and hospitals, over the course of the outbreak.
MISC	Previously published mathematical models of parameter estimation addressed the issues of temporal variability CITATION, CITATION or social heterogeneity CITATION, CITATION.
OWNX	Here we present an approach that deals with both issues, together with the occurrence of SSEs.
OWNX	Then the method is applied to the 2003 SARS epidemic in Hong Kong .
MISC	In the presence of exogenous mortality risks, future reproduction by an individual is worth less than present reproduction to its fitness.
OWNX	Senescent aging thus results inevitably from transferring net fertility into younger ages.
MISC	Some long-lived organisms appear to defy theory, however, presenting negligible senescence and extended lifespans.
MISC	Here, we investigate the possibility that the onset of vitality loss can be delayed indefinitely, even accepting the abundant evidence that reproduction is intrinsically costly to survival.
MISC	For an environment with constant hazard, we establish that natural selection itself contributes to increasing density-dependent recruitment losses.
MISC	We then develop a generalized model of accelerating vitality loss for analyzing fitness optima as a tradeoff between compression and spread in the age profile of net fertility.
MISC	Across a realistic spectrum of senescent age profiles, density regulation of recruitment can trigger runaway selection for ever-reducing senescence.
MISC	This novel prediction applies without requirement for special life-history characteristics such as indeterminate somatic growth or increasing fecundity with age.
MISC	The evolution of nonsenescence from senescence is robust to the presence of exogenous adult mortality, which tends instead to increase the age-independent component of vitality loss.
MISC	We simulate examples of runaway selection leading to negligible senescence and even intrinsic immortality.
MISC	Senescence, usually treated as synonymous with aging, refers to a deterioration in physiological condition with age, manifest as an increase in mortality and a decline in fertility.
MISC	Since this phenomenon is detrimental to reproductive success, natural selection might be expected to cause its postponement or elimination from the life history of organisms.
MISC	Its apparent ubiquity in the natural world, therefore, has been treated as a challenge for evolutionary theory CITATION.
MISC	There is a general acceptance that this challenge has, in principle, been met, and modern understanding of the widespread occurrence of senescence in nature has been hailed as one of the great triumphs of evolutionary thinking CITATION .
OWNX	Discussions of the evolution of senescence broadly follow one of two paradigms, based either in classical population genetics or in physiological ecology CITATION.
OWNX	The first emphasizes the accumulation of late-acting deleterious mutations on hypothesized genes with age-specific expression CITATION, CITATION.
MISC	More generally, this paradigm hypothesizes an antagonistic pleiotropy of age-specific genes in which mutations confer a fitness benefit early in life at the cost of some deleterious effect later CITATION CITATION.
MISC	The key insight of this perspective is that the force of selection on the additive component of genetic variance necessarily declines with age, so that an early-age cost is more strongly selected against than an equivalent late-age cost, and, a fortiori, an early-age benefit more than compensates for a late-age cost CITATION.
MISC	Hamilton concludes: ...for organisms that reproduce repeatedly, senescence is to be expected as an inevitable consequence of the working of natural selection CITATION .
MISC	This population genetic analysis has been challenged recently both theoretically and empirically.
MISC	First, a declining force of selection is only guaranteed for mutations with additive effects, and it has been suggested that mutations with proportional effects for which the force of selection need not decline with age may be more relevant CITATION.
MISC	Second, Hamilton himself concedes: To what extent and in exactly what way life schedules will be moulded by natural selection depends on what sort of genetical variation is available CITATION.
MISC	Thus, the more such genes there are, the more evolutionary pressure there will be toward compressed life histories.
MISC	However, despite much empirical work over several decades, evidence for the availability of genes with the necessary age-specific effects appears to be thin .
MISC	In contrast to the classical population genetic approach, the disposable soma theory CITATION, CITATION CITATION is based firmly within physiological ecology.
OWNX	Thus, it is claimed that birth and death schedules are the result of the action of integrated physiological processes concerned with the optimal partitioning of available resources between reproduction and somatic maintenance or growth.
MISC	In particular, there is an inherent cost of reproduction in which an early-age reproductive benefit incurs a late-age cost in decreased survival, possibly in the form of latent damage that is only unmasked later in life CITATION.
MISC	Relevant genetic mutations must have effects that are manifest at this physiological level.
MISC	This is potentially a much more constraining paradigm, though apparently more strongly supported by current evidence CITATION, CITATION.
MISC	Nevertheless, given this tradeoff between early fecundity and longevity, it has again generally been concluded that senescence is inevitable CITATION.
MISC	In particular, immortality has long been considered theoretically impossible because of the inevitability of senescent aging CITATION CITATION .
MISC	Yet this understanding of the evolution of senescence fails to account for organisms showing negligible or even negative senescence CITATION, CITATION.
MISC	These are species such as the freshwater Hydra vulgaris CITATION with period survival that remains constant or increases with adult age.
MISC	They include some organisms with apparently indefinite lifespans such as the Great Basin Bristlecone Pine Pinus longaeva CITATION, CITATION, which continues producing viable cones at well over 4,000 y old, the Quaking Aspen Populus tremuloides CITATION, and the Creosote Bush Larrea tridentata CITATION, both of which have clonal clusters at least 10,000 y old.
MISC	These and other examples CITATION have recently led to a reversal of the traditional perspective in which the problem was to explain the evolution of senescence from nonsenescence.
MISC	On the contrary, given the ubiquity of senescence in nature, and the abundance of explanations for its presence, it seems very unlikely that the majority of today's organisms are descended from nonsenescent ancestors.
MISC	Rather, an important issue now is to provide an evolutionary account for those organisms that appear to exhibit little or no senescence, but which almost certainly have evolved from ancestors that did exhibit senescence.
MISC	Rising to this challenge, a theoretical analysis of the costs of senescent aging CITATION has shown that, although senescence is often favored by a high and sustained early vitality, nonsenescing strategies are locally optimal if vitality loss in the presence of senescence would otherwise be sufficiently fast.
MISC	Similarly, an optimization model CITATION has shown how negative senescence can evolve for species that grow in body size throughout their lives, if this growth carries proportionate benefits in increasing reproductive output and decreasing mortality.
MISC	Both these analyses are concerned with the optimal tradeoff between fecundity and mortality, and so lie within the disposable soma paradigm.
MISC	These analyses have not modeled density dependence, except implicitly as a limiting case in which population growth is set to zero.
OWNX	In this paper, we construct explicit models, within the disposable soma paradigm, for a very general class of organisms including those without indefinite somatic growth.
MISC	These reveal density dependence in recruitment as a sufficient driver for the evolution of nonsenescent life histories from senescent ancestors.
MISC	Density-limited recruitment sets up a balance of opposing selective forces that underpins the direction of evolution toward either compressed or spread reproductive life.
MISC	Thus, on the one hand, future reproduction is worth less than present reproduction to an individual's fitness, given a future extrinsic mortality risk CITATION.
MISC	On the other hand, future reproduction by an individual's mature offspring may be worth more to its inclusive fitness than its own present reproduction, if otherwise viable offspring face an extrinsic mortality risk before recruitment.
OWNX	The crucial advance that we make is prefigured by Abrams CITATION, who showed that faster senescence is favored by positive or zero density-independent growth, and also by density-dependent adult mortality, whereas slower senescence requires density-dependent fecundity.
OWNX	Our advance on his analysis is to show how the slower senescence can take the form of a runaway selection to negligible senescence, and even intrinsic immortality.
MISC	Indeed, density-dependent recruitment reflects the widely prevailing ecological condition of bottom-up regulation in crowded habitats.
MISC	We show that it is unwise either to ignore it, or to represent it only implicitly as zero population growth, because of its ubiquity in nature and its significant consequences for the evolution of senescence.
OWNX	Here, we perform an optimization analysis of vitality evolution as a fitness tradeoff between compression into earlier life and spread into later life in the context of density-dependent recruitment, which accords with the abundant evidence that reproduction is intrinsically costly to survival CITATION, CITATION, CITATION, CITATION CITATION.
OWNX	For populations at recruitment-regulated equilibrium, we demonstrate generic conditions under which natural selection itself increases the extrinsic recruitment losses, by successive genomic invasions increasing the level of crowding within the population.
MISC	Stronger density dependence means fewer recruitment opportunities into the adult population and, therefore, a natural selection that is weighted toward maximizing generation length over early-age vitality.
OWNX	This positive feedback leads to the novel result that density regulation can trigger selection for ever-reducing senescence.
MISC	We develop a model that shows the potential for runaway selection of reduced senescence to arise across a wide range of age-specific vitality profiles, including accelerating loss from an early or late onset, and constant aging.
MISC	We find that natural selection can favor evolution of nonsenescence, and even immortality, from senescence in the presence of exogenous mortality, without a requirement for special life-history characteristics such as increasing intrinsic fecundity with age.
OWNX	Simulations of this process are given for various scenarios, including stochastic environments.
OWNX	The first four Results sections develop our analytical framework.
OWNX	Section 1 outlines the assumptions we make about the action of density-dependent recruitment.
OWNX	Section 2 specifies precisely the relation between the concepts that we use of vitality and senescent and nonsenescent aging.
MISC	Our approach is to define these concepts in terms of instantaneous rates, rather than on the rate of change of age-specific reproductive value.
OWNX	The section Model: Invasion of Mutations outlines our assumptions concerning the effects of mutations on the key life-history parameter controlling the rate of senescence, and states our main result concerning the possibility of evolution from a highly compressed life history to a highly spread life history.
OWNX	The section Example describes a specific example of evolution from positive senescence to non- senescence.
OWNX	Finally, the section Simulations outlines stochastic simulations of the model.
OWNX	Supporting material is provided in the Methods section and in Text S1.
OWNX	We conclude with a discussion of the model predictions for life-history conditions and biotic environments that favor negligible senescence.
MISC	labeling a food as  organic  entails a claim about its production but is silent on its calorie content
MISC	nevertheless  people infer that organic cookies are lower in calories and can be eaten more often than conventional cookies study  NUMBER 
OWNX	these inferences are observed even when the nutrition label conveys identical calorie content and are more pronounced among perceivers high on pro-environmentalism
MISC	moreover  when evaluating a person with a weight-loss goal  forgoing exercise is deemed more acceptable when the person has just chosen organic rather than conventional dessert study  NUMBER 
OWNX	these results reflect an  organic natural - healthy  association that is capable of biasing everyday judgments about diet and exercise
MISC	as americans' waistlines have grown  so has their appetite for organic foods u s
MISC	sales of organics rose from approximately   NUMBER  billion in  NUMBER  to   NUMBER  billion in  NUMBER   CITATION   meanwhile  roughly one-third of u s adults now qualify as obese  CITATION
MISC	yet  scant research has explored the implications of  organic  production claims for judgments and decisions related to weight gain
MISC	although organic claims license inferences about lower levels of conventional pesticides and synthetic additives in foods  CITATION   they are silent on calorie content
MISC	might consumers nevertheless assume that organics contain fewer calories as well
MISC	the tendency to overgeneralize health claims suggests this possibility
MISC	previous research has demonstrated that margarine advertised as  no cholesterol  and  healthy  is judged as lower in fat  CITATION  and that nutrient-based claims can promote calorie underestimation  thought to be an important factor in the obesity crisis  CITATION
MISC	it is not clear  however  whether such effects would extend to organic claims  which speak to production process and not nutrient content per se  CITATION
MISC	consistent with activation theory  CITATION   specific nutrient claims e g    no cholesterol  have been shown to affect judgments of closely associated nutrients e g   fat but not of more general  distal concepts e g   cancer risk  CITATION
MISC	from this perspective   organic  and other production-related claims may not be expected to activate  calories  and other nutrient-related concepts
MISC	on the other hand  a number of different theories suggest that organic claims might indeed bias - and specifically  reduce - calorie judgments
MISC	first  strong associations exist between the concepts  organic  and  healthy  in contemporary america  associations that are promoted by marketers and reflected in survey data in which most americans endorse organics as healthier  CITATION
MISC	moreover  natural foods as opposed to those altered by humans in some significant way tend to be seen as inherently good and healthy  CITATION   further supporting associations between organic production and healthy attributes
MISC	given that calorie restriction is nearly synonymous with  healthy  in the u s CITATION   these associations might lead consumers to assume that foods produced organically contain fewer calories than their conventional counterparts  despite the fact that the  organic  designation entails no such claim  CITATION
MISC	second  because calorie estimation is a cognitively demanding task  CITATION   consumers might even substitute the associatively related attribute  healthy  for  organic  as a means for simplifying complex calorie judgments  CITATION
MISC	third  consumers might go beyond the literal meaning of the producer's utterance  CITATION  and infer that a producer who adheres to organic production standards might also care about other health-related aspects of the product  again supporting more general inferences about the product's healthy attributes  CITATION
MISC	fourth  the logic of halo effects  CITATION  more generally suggests that consumers might judge products with one positive attribute more favorably on other attributes  even when they are not substantively related  if so  organics might be judged as lower-calorie to the extent that perceivers hold favorable attitudes toward organic production
MISC	because natural foods tend to be seen as inherently good and healthy  CITATION    organic  halos seem plausible given the back-to-nature connotations of organic production
OWNX	although the above considerations all point to generalized positive effects of organic claims  the strength of these effects might be moderated by perceivers' general attitudes toward organic foods
MISC	these attitudes are likely to show more variation than attitudes toward health-related nutrient claims e g    no cholesterol    low-fat  and might vary partly as a function of individual differences in pro-environmentalism  CITATION
MISC	if so  people high on pro-environmentalism might be more affected by organic claims  reflecting that positive halo effects should increase with the positivity of the attitude toward the initial attribute here  organic production
MISC	despite different underlying assumptions  all of these considerations converge on the same core prediction  organic claims might reduce calorie judgments  making the consumption of organic foods seem more compatible with a weight-loss goal
MISC	the present studies test this prediction by assessing the effect of organic claims on perceived calorie content and consumption recommendations as well as the impact of organic consumption on the perceived need to exercise
OWNX	we also explore whether individuals high on pro-environmentalism are especially likely to show this effect  consistent with the halo logic outlined above
OWNX	note  however  that an alternative prediction is also plausible  those high on pro-environmentalism may know more about organics  rendering them less susceptible to unwarranted inferences from organic claims
MISC	Finding functional DNA binding sites of transcription factors throughout the genome is a crucial step in understanding transcriptional regulation.
MISC	Unfortunately, these binding sites are typically short and degenerate, posing a significant statistical challenge: many more matches to known TF motifs occur in the genome than are actually functional.
MISC	However, information about chromatin structure may help to identify the functional sites.
MISC	In particular, it has been shown that active regulatory regions are usually depleted of nucleosomes, thereby enabling TFs to bind DNA in those regions.
OWNX	Here, we describe a novel motif discovery algorithm that employs an informative prior over DNA sequence positions based on a discriminative view of nucleosome occupancy.
OWNX	When a Gibbs sampling algorithm is applied to yeast sequence-sets identified by ChIP-chip, the correct motif is found in 52 percent more cases with our informative prior than with the commonly used uniform prior.
MISC	This is the first demonstration that nucleosome occupancy information can be used to improve motif discovery.
OWNX	The improvement is dramatic, even though we are using only a statistical model to predict nucleosome occupancy; we expect our results to improve further as high-resolution genome-wide experimental nucleosome occupancy data becomes increasingly available.
OWNX	Finding functional DNA binding sites of transcription factors throughout the genome is a necessary step in understanding transcriptional regulation.
MISC	However, despite an explosion of TF binding data from high-throughput technologies like ChIP-chip, DIP-chip CITATION, PBM CITATION, and gene expression arrays, finding functional occurrences of binding sites of TFs remains a difficult problem because the binding sites of most TFs are short, degenerate sequences that occur frequently in the genome by chance.
MISC	In particular, matches to known TF motifs in the genome often do not appear to be bound by the respective TFs in vivo.
MISC	One popular explanation for this is that when the DNA is in the form of chromatin, not all parts of the DNA are equally accessible to TFs.
OWNX	In this state, DNA is wrapped around histone octamers, forming nucleosomes.
MISC	The positioning of these nucleosomes along the DNA is believed to provide a mechanism for differential access to TFs at potential binding sites.
MISC	Indeed, it has been shown that functional binding sites of TFs at regulatory regions are typically depleted of nucleosomes in vivo CITATION CITATION .
MISC	If we knew the precise positions of nucleosomes throughout the genome under various conditions, we could increase the specificity of motif finders by restricting the search for functional binding sites to nucleosome-free areas.
OWNX	Here, we describe a method for incorporating nucleosome positioning information into motif discovery algorithms by constructing informative priors biased toward less-occupied promoter positions.
MISC	Our method should improve motif discovery most when it has access to high-resolution nucleosome occupancy data gathered under various in vivo conditions.
MISC	Unfortunately, this data is not currently available for any organism at a whole-genome scale, let alone under a variety of conditions.
OWNX	Nevertheless, because our method is probabilistic, even noisy evidence regarding nucleosome positioning can be effectively exploited.
MISC	For example, Segal et al. CITATION recently published a computational model based on high-quality experimental nucleosome binding data that predicts the probability of each nucleotide position in the yeast genome being bound by a nucleosome; these predictions are intrinsic to the DNA sequence and thus independent of condition, but were purported to explain around half of nucleosome positions observed in vivo.
MISC	In addition, Lee et al. CITATION have used ChIP-chip to profile the average nucleosome occupancy of each yeast intergenic region.
MISC	We show that informative positional priors, whether learned from computational occupancy predictions or low-resolution average occupancy data, significantly outperform not only the commonly used uniform positional prior, but also state-of-the-art motif discovery programs.
MISC	Many databases store data in relational format, with different types of entities and information about links between the entities
MISC	The field of statistical-relational learning (SRL) has developed a number of new statistical models for such data
OWNX	In this paper we focus on learning class-level or first-order dependencies, which model the general database statistics over attributes of linked objects and links (e g , the percentage of A grades given in computer science classes)
MISC	Class-level statistical relationships are important in themselves, and they support applications like policy making, strategic planning, and query optimization
OWNX	Most current SRL methods find class-level dependencies, but their main task is to support instance-level predictions about the attributes or links of specific entities
MISC	We focus only on class-level prediction, and describe algorithms for learning class-level models that are orders of magnitude faster for this task
MISC	Our algorithms learn Bayes nets with relational structure, leveraging the efficiency of single-table nonrelational Bayes net learners
MISC	An evaluation of our methods on three data sets shows that they are computationally feasible for realistic table sizes, and that the learned structures represent the statistical information in the databases well
MISC	After learning compiles the database statistics into a Bayes net, querying these statistics via Bayes net inference is faster than with SQL queries, and does not depend on the size of the database
MISC	Many real-world applications store data in relational format, with different tables for entities and their links
MISC	Standard machine learning techniques are applied to data stored in a single table, that is, in nonrelational, propositional or ``flat" format  CITATION
OWNX	The field of statistical-relational learning (SRL) aims to extend machine learning algorithms to relational data  CITATION
MISC	One of the major machine learning tasks is to use data to build a  generative statistical model  for the variables in an application domain  CITATION
MISC	In the single-table learning setting, the goal is often to represent predictive dependencies between the attributes of a single individual (e g , between the intelligence and ranking of a student)
MISC	In the SRL setting, the goal is often to represent, in addition, dependencies between attributes of different individuals that are related or linked to each other (e g , between the intelligence of a student and the difficulty of a course given that the student is registered in the course)
OWNX	Spectro-temporal receptive fields have been widely used as linear approximations to the signal transform from sound spectrograms to neural responses along the auditory pathway.
OWNX	Their dependence on statistical attributes of the stimuli, such as sound intensity, is usually explained by nonlinear mechanisms and models.
OWNX	Here, we apply an efficient coding principle which has been successfully used to understand receptive fields in early stages of visual processing, in order to provide a computational understanding of the STRFs.
OWNX	According to this principle, STRFs result from an optimal tradeoff between maximizing the sensory information the brain receives, and minimizing the cost of the neural activities required to represent and transmit this information.
MISC	Both terms depend on the statistical properties of the sensory inputs and the noise that corrupts them.
MISC	The STRFs should therefore depend on the input power spectrum and the signal-to-noise ratio, which is assumed to increase with input intensity.
OWNX	We analytically derive the optimal STRFs when signal and noise are approximated as Gaussians.
MISC	Under the constraint that they should be spectro-temporally local, the STRFs are predicted to adapt from being band-pass to low-pass filters as the input intensity reduces, or the input correlation becomes longer range in sound frequency or time.
OWNX	These predictions qualitatively match physiological observations.
MISC	Our prediction as to how the STRFs should be determined by the input power spectrum could readily be tested, since this spectrum depends on the stimulus ensemble.
OWNX	The potentials and limitations of the efficient coding principle are discussed.
MISC	In response to acoustic input signals, neurons in the auditory pathway are typically selective to sound frequency FORMULA and have particular response latencies.
OWNX	At least ignoring cases with FORMULA kHz, in which neuronal responses often phase lock to the sound waves, a spectro-temporal receptive field is often used to describe the tuning properties of a neuron CITATION, CITATION, CITATION, CITATION.
MISC	This is a two-dimensional function FORMULA that reports the sensitivity of the neuron at response latency FORMULA to acoustic inputs of frequency FORMULA for a given stimulus ensemble.
MISC	More specifically, in a stimulus ensemble, the power FORMULA of the acoustic input at frequency FORMULA at time FORMULA fluctuates around an average level denoted by FORMULA.
OWNX	If we let FORMULA denote the neuron's response at time FORMULA, then FORMULA best approximates the linear relationship between FORMULA and FORMULA in this stimulus ensemble asFORMULANote that in this paper, we refer to FORMULA as the input spectrogram, although some authors also include the average input power FORMULA.
MISC	Though FORMULA is not a full description of acoustic input, since it ignores features such as the phase of the oscillation in the sound wave, it is the only relevant aspect of the auditory input as far as the STRF is concerned.
OWNX	Note that if we use FORMULA to denote the deviation of the neural response from its spontaneous activity level, then both FORMULA and FORMULA have zero mean.
OWNX	We will use this simplification throughout the paper.
MISC	In studies in which the temporal dimension is omitted, the STRF is called the spectral receptive field .
OWNX	Figure 1 cartoons a typical STRF.
MISC	This has excitatory and inhibitory regions, reflecting its preferred frequency and response latency.
MISC	For example, if FORMULA peaks at frequency FORMULA and time FORMULA, then this neuron prefers frequency FORMULA and should respond to an input impulse FORMULA of this frequency with latency FORMULA.
OWNX	We will also refer to FORMULA as the receptive field, the filter kernel, or the transfer function from input to neural responses, as these all convey the same or similar meanings.
MISC	A neuron's STRF is typically estimated using reverse correlation methods CITATION, CITATION .
MISC	However, there are extensive nonlinearities in the signal transformation along the auditory pathway.
OWNX	Indeed, the STRF formulation of neural responses, though linear in spectral power, is already a second-order nonlinear function of the auditory sound wave.
MISC	There are two kinds of nonlinearities when inputs are represented as spectrograms.
MISC	The simpler one is a static nonlinearity FORMULA, which when applied to the linear approximation FORMULA of equation enables better predictions of the neural responses CITATION, CITATION.
OWNX	This static nonlinearity however does not alter the spectro-temporal selectivity of the neuron seen in the linear STRF.
OWNX	This paper is interested in the more complex nonlinearity that the STRFs are dependent on the stimulus ensemble used to estimate them CITATION, CITATION, CITATION, CITATION.
MISC	For example, the STRFs are wider when the stimuli are narrow-band rather than wide-band CITATION, or when the stimuli are animal vocalizations rather than noise CITATION.
OWNX	The STRF also becomes more band-pass when sound intensity increases.
MISC	The dependence of the STRFs on the stimulus ensemble holds, for example, for type IV neurons in the cochlear nucleus of cats CITATION, CITATION, the inferior colliculus of the frog CITATION and the gerbil CITATION, and field L region of the songbird CITATION.
MISC	Nonlinearities in the auditory system become progressively stronger further from the periphery.
MISC	Despite the nonlinearities, the concept of the STRF is still widely used, not only because it provides a meaningful description of the spectro-temporal selectivity of the neurons in a given stimulus ensemble, but also because it can predict neural responses to novel stimuli reasonably well, as long as the stimuli are drawn from the same stimulus ensemble as that used to estimate the STRF in the first place.
OWNX	Reasonable predictions from the STRFs have been obtained for the responses of auditory nerves and auditory midbrain neurons CITATION, CITATION, CITATION.
MISC	They have also been obtained for responses of the auditory cortical neurons when the stimulus ensemble is composed of biologically more meaningful static or dynamic ripples.
OWNX	If the linear neural filter is augmented to include the filtering performed by the head and ears, it is also possible to predict the preferred locations of sound sources of auditory cortical neurons based on the linear neural filter for input spectrograms CITATION.
MISC	Meanwhile, linear STRF models fail to capture many complex phenomena, particularly in the auditory cortex, and nonlinearities are not limited to being just static or monotonic.
MISC	It has been suggested that some auditory cortical neurons process auditory objects in a highly non-linear manner, by selectively responding to a weak object component while ignoring loud components that occupy the same region in frequency space in auditory mixtures of these object components CITATION, and some prefer low over high spectral contrast sounds CITATION.
MISC	Strong nonlinearities in the auditory processes have long since motivated nonlinear models of auditory responses .
OWNX	This paper aims to understand from a computational, rather than a mechanistic, perspective why the auditory encoding transform should depend on the stimulus ensemble in the ways observed.
AIMX	More specifically, the paper focuses on cases in which STRFs can reasonably capture neural responses, and aims to identify and understand the computational goal of the STRFs for a given stimulus ensemble finding a metric according to which the STRFs are optimal for the ensemble.
MISC	This would provide a rationale for how the physiologically measured STRFs should depend on or adapt to the stimulus ensemble.
AIMX	This paper does not address what linear or nonlinear mechanisms could build the optimal STRFs, or whether or how nonlinear auditory processes enable the adaptation of the STRFs to the stimulus ensemble.
MISC	Existing computational models of auditory neurons, including ones with the notion that cochlear hair cells perform independent component analysis to provide an efficient code for inputs using spikes in the auditory nerves CITATION, CITATION, cannot explain the observed dependence of the STRFs on the stimulus ensemble .
OWNX	Restricting attention to the temporal properties of STRF, Lesica and Grothe CITATION observed that the temporal filter in STRF adapted to the level of ambient noise in the input environment.
MISC	In particular, the temporal receptive field in the STRF changed from being bandpass to being low pass with the increase of ambient noise.
OWNX	They argued using a simple model that such adaptation in the STRF enables more efficient coding of the input information.
OWNX	This study applies the principles of efficient coding to understand the auditory STRF and its variations with sound intensities and other input characteristics.
OWNX	It generalizes the work of Lesica and Grothe CITATION to understand the temporal and spectral filtering characteristics of STRF adaptation to changes in noise, signal and correlations in input statistics.
MISC	Explicitly, the principle of efficient coding states that the neural receptive fields should enable the neural responses to transmit as much sensory information as possible to the central nervous system, subject to the limitation in neural cost in representing and transmitting information.
MISC	This principle has been proposed CITATION and successfully applied to the visual system to understand the receptive fields in the early visual pathway CITATION, CITATION, CITATION, CITATION, CITATION, CITATION.
OWNX	We will borrow heavily techniques and intuitions from vision to derive and explain the results in this paper.
MISC	To make initial progress, it is necessary to start with some simplifying assumptions.
MISC	First, we assume that the statistical characteristics of the stimulus ensemble do not change more rapidly than the speed at which the sensory encoding adapts, so that the stimulus ensemble can be approximated as being stationary as far as optimal encoding is concerned.
OWNX	Knowing when this assumption does not hold tells us when the encoding is not optimal, e.g., when one sees poorly for a brief moment before the visual encoding adapts to a sudden change from a dark room to a bright garden.
MISC	Second, for mathematical convenience, we assume that the linear STRF model as in equation can approximate adapted auditory neural responses reasonably well.
MISC	As we know from above, this assumption often does not hold, particularly for auditory cortical neurons.
OWNX	This paper leaves the extension of the optimal encoding to nonlinear cases for future studies.
MISC	Third, to derive a closed-form, analytical, solution to the optimal STRF, we assume that the input statistics in the stimulus ensemble can be approximated as being Gaussian, with higher order correlations in the input contributing only negligibly to the inefficiency of the representation in the original sensory inputs.
MISC	Although it is known that the natural auditory inputs are far from Gaussian CITATION, as for the case of vision, the discrepancy may have only a limited impact on the input inefficiency, as measured by the amount of information redundancy in the original sensory input CITATION, CITATION, CITATION .
OWNX	To understand how sensory inputs should be recoded to increase coding efficiency, we start with visual encoding to draw insights and made analogies with auditory encoding.
MISC	In vision, large amounts of raw data about the visual world are transduced by photoreceptors.
MISC	However, the optic nerve, which transmits the input data to the visual cortex via thalamus, can only accommodate a dramatically smaller data rate.
MISC	It has thus been proposed that early visual processes use an efficient coding strategy to encode as much information as possible given the limited bandwidth CITATION, CITATION, in other words, to recode the data such that the redundancy in the data is reduced and consequently the data can be transmitted by the limited bandwidth.
MISC	Compression is possible since images are very redundant CITATION, CITATION, CITATION, CITATION, e.g., with strong correlations between visual inputs at nearby points in time and space.
OWNX	Removing such correlations can cut down the data rate substantially CITATION .
MISC	One way to remove the correlations is to transform the raw input FORMULA into a different representation FORMULA in neural responses that would then have a much smaller data rate than FORMULA, yet preserving essential input information.
MISC	This transform is often approximated by the visual receptive field, analogous to the auditory STRFs.
MISC	For instance, the center-surround receptive fields of the retinal ganglion cells help remove spatial redundancy CITATION, CITATION, CITATION.
MISC	They do this by making the ganglion cells preferentially respond to spatial contrast in the input, and so eliminating responses to visual locations whose input is redundant with that of their neighbors.
MISC	Consequently, the responses of retinal ganglion cells are much less correlated than those of the photoreceptors, making their representation much more efficient.
OWNX	One facet of this efficient encoding hypothesis is that the optimal receptive field transform should depend on the statistical properties, such as the correlation structure and intensity, of the input.
OWNX	This dependence has been used to explain adaptation, to changes in input statistics, of visual receptive field characteristics, such as the sizes of center-surround regions and the color tuning of retinal neurons, or the ocular dominance properties of striate cortical neurons CITATION, CITATION, CITATION, CITATION, CITATION, CITATION.
MISC	In the auditory system, information redundancy is also reduced along the auditory pathway CITATION.
MISC	Although this redundancy reduction was only investigated in the neural responses to sensory inputs rather than in the coding transform leading to the neural responses, it suggested that coding efficiency is one of the goals of early auditory processes.
OWNX	More formally, the efficient coding scheme is depicted in Figure 2A.
OWNX	The input contains sensory signal FORMULA and noise FORMULA.
OWNX	The net input FORMULA is encoded by a linear transfer function FORMULA into output.FORMULAwhich also contains additional noise FORMULA introduced in the encoding process.
MISC	When the input has multiple channels, e.g., many different photoreceptors or hair cells, FORMULA is a vector with many components, as indeed is FORMULA.
OWNX	Output FORMULA is a vector representing the neural population responses from many neurons.
OWNX	For output neuron FORMULA, we have FORMULA.
OWNX	Therefore FORMULA is a matrix, and its FORMULA row FORMULA models the receptive field for output neuron FORMULA as the array of effective weights from input receptors FORMULA to output neuron FORMULA.
OWNX	In the particular example when input neurons are photoreceptors and output neurons are retinal ganglion cells, FORMULA is the effective connection from photoreceptor FORMULA to ganglion cell FORMULA, and collectively, FORMULA describe the linear receptive field of this ganglion cell.
MISC	We consider the problem of finding an optimal FORMULA that maximizes the information extracted by FORMULA about FORMULA, i.e., the mutual information FORMULA CITATION between FORMULA and FORMULA subject to a given cost of the neural encoding, which depends on the responses in a way we will describe shortly.
MISC	Therefore, the optimal FORMULA should minimize the objective function:FORMULAwhere FORMULA is a parameter whose value specifies a particular balance between the needs to minimize costs and to maximize extracted information.
MISC	Neural costs can arise from various sources, such as the metabolic energy cost for generating neural activities or spikes CITATION and the cost of thicker axons to transmit higher rates of neural firing.
MISC	We follow a formulation that has been productive in vision CITATION, CITATION, and model the neural cost asFORMULAwhere FORMULA indicates the average over the stimulus ensemble.
MISC	This givesFORMULAIt has been shown CITATION, CITATION, CITATION, CITATION that the FORMULA that provides the most efficient coding according to FORMULA has the following properties.
MISC	At high signal-to-noise ratio, FORMULA is such that FORMULA extracts the difference between correlated channels, and thus avoids transmitting redundant information.
MISC	Hence, for example, in photopic conditions, retinal ganglion cells have center-surround spatial receptive fields which extract the spatial contrast of the input.
OWNX	By contrast, at low SNR, FORMULA is a smoothing filter that averages out input noise instead of reducing redundancy.
OWNX	This avoids spending neural cost on transmitting noise.
MISC	Hence, for example, in scotopic conditions, when SNR can be considered as being low, the receptive fields of retinal ganglion cells expand the sizes of their center regions and weaken their suppressive surrounds CITATION.
OWNX	We will apply this framework to the auditory encoding to understand STRFs and their adaptation to stimulus ensembles.
OWNX	Given a time series of multicomponent measurements  SYMBOL , the usual objective of nonlinear blind source separation (BSS) is to find a ``source" time series  SYMBOL , comprised of statistically independent combinations of the measured components
OWNX	In this paper, the source time series is required to have a density function in  SYMBOL  that is equal to the product of density functions of individual components
OWNX	This formulation of the BSS problem has a solution that is unique, up to permutations and component-wise transformations
MISC	Separability is shown to impose constraints on certain locally invariant (scalar) functions of  SYMBOL , which are derived from local higher-order correlations of the data's velocity  SYMBOL
MISC	The data are separable if and only if they satisfy these constraints, and, if the constraints are satisfied, the sources can be explicitly constructed from the data
MISC	The method is illustrated by using it to separate two speech-like sounds recorded with a single microphone
MISC	Sensory devices often receive signals from multiple physical stimuli that evolve simultaneously but are unrelated to one another
MISC	In many of these situations, it is necessary to create separate representations of one or more of these stimuli by blindly processing the observed signals (i e , by processing them without prior knowledge of the nature of the stimuli)
MISC	In recent years, there has be considerable progress in the solution of this ``blind source separation" (BSS) problem for the special case in which the signals and source variables are linearly related
MISC	However, although nonlinear BSS is often performed effortlessly by humans, computational methods for doing this are quite limited~ CITATION
MISC	Consider a time series of data  SYMBOL , where  SYMBOL  is a multiplet of  SYMBOL  measurements ( SYMBOL )
OWNX	The usual objectives of nonlinear BSS are: 1) determine if these data are instantaneous mixtures of  SYMBOL  statistically independent source components  SYMBOL   SYMBOL } where  SYMBOL  is a possibly nonlinear, invertible  SYMBOL  mixing function; 2) if this is the case, compute the mixing function
MISC	In other words, the problem is to find a coordinate transformation  SYMBOL  that transforms the observed data  SYMBOL  from the measurement-defined coordinate system ( SYMBOL ) on state space to a special source coordinate system ( SYMBOL ) in which the components of the transformed data are statistically independent
OWNX	Let  SYMBOL  be the state space probability density function (PDF) in the source coordinate system, defined so that  SYMBOL  is the fraction of total time that the source trajectory  SYMBOL  is located within the volume element  SYMBOL  at location  SYMBOL
CONT	In the usual formulation of the BSS problem, the source components are required to be statistically independent in the sense that their state space PDF is the product of the density functions of the individual components  SYMBOL } In every formulation of BSS, multiple solutions can be created by permutations and component-wise transformations of any one solution
MISC	However, it is well known that the criterion in () is so weak that it suffers from a much worse non-uniqueness problem: namely, in this form of the BSS problem, multiple solutions can be created by transformations that mix the source variables (see~ CITATION  and references therein)
OWNX	The issue of non-uniqueness can be circumvented by considering the data's trajectory in  SYMBOL  ( SYMBOL ) instead of  SYMBOL  (i e , state space)
MISC	First, let  SYMBOL  be the PDF in this space, defined so that  SYMBOL  is the fraction of total time that the location and velocity of the source trajectory are within the volume element  SYMBOL  at location  SYMBOL
OWNX	An earlier paper~ CITATION  described a formulation of the BSS problem in which this PDF was required to be the product of the density functions of the individual components  SYMBOL } Separability in  SYMBOL  is a stronger requirement than separability in state space
MISC	To see this, note that () can be recovered by integrating both sides of () over all velocities, but the latter equation cannot be deduced from the former one
OWNX	In fact, it can be shown that () is strong enough to guarantee that the BSS problem in  SYMBOL  has a unique solution, up to permutations and component-wise transformations~ CITATION
MISC	Furthermore, this type of statistical independence has the virtue of being satisfied by almost all classical physical systems that are composed of non-interacting subsystems, which are the generators of most signals of interest
OWNX	The author previously demonstrated~ CITATION  that the  SYMBOL  PDF of a time series induces a Riemannian geometry on the state space, with the metric equal to the local second-order correlation matrix of the data's velocity
OWNX	Nonlinear BSS can be performed by computing this metric in the  SYMBOL  coordinate system (i e , by computing the second-order correlation of  SYMBOL  at each point  SYMBOL ), as well as its first and second derivatives with respect to  SYMBOL
OWNX	However, although this is a mathematically correct and complete method of solving the nonlinear BSS problem, it suffers from a practical difficulty: namely, if the dimensionality of state space is high, a great deal of data is required to cover it densely enough in order to calculate these derivatives accurately
OWNX	The current paper~ CITATION  shows how to perform nonlinear BSS by computing higher-order local correlations of the data's velocity, instead of computing derivatives of its second-order correlation
MISC	This approach is advantageous because it requires much less data for an accurate computation
OWNX	For example, in the synthetic speech separation experiment in Section III, the new method can separate two synthetic utterances recorded with a single microphone after minutes of observation, rather than the hours of observation required by the differential geometric method
OWNX	The method described in this paper differs significantly from the methods proposed by other investigators because it uses a criterion of statistical independence in  SYMBOL , instead of state space
MISC	In addition, there are technical differences between the proposed method and conventional ones
OWNX	First of all, the technique in this paper exploits statistical constraints on the data that are  locally  defined in state space, in contrast to the usual criteria for statistical independence that are  global  conditions on the data time series or its time derivatives~ CITATION
OWNX	Furthermore, unlike many other methods~ CITATION , the mixing function is derived in a constructive, deterministic, and non-parametric manner, without employing iterative algorithms, without using probabilistic learning methods, and without parameterizing it with a neural network architecture or other means
OWNX	In addition, the proposed method can handle any differentiable mixing function, unlike some other techniques that only apply to a restricted class of mixing functions~ CITATION
OWNX	The next section describes how to separate two-dimensional data into two one-dimensional source variables
MISC	Section III illustrates the method by using it to separate two simultaneous speech-like sounds that are recorded with a single microphone
OWNX	The implications of this work are discussed in the last section
MISC	The appendix describes how the method can be generalized to separate data of arbitrary dimensionality into possibly multidimensional source variables
OWNX	% Sparse coding---that is, modelling data vectors as sparse linear combinations of basis elements---is widely used in machine learning, neuroscience, signal processing, and statistics
OWNX	This paper focuses on the large-scale matrix factorization problem that consists of  learning  the basis set in order to adapt it to specific data
OWNX	Variations of this problem include dictionary learning in signal processing, non-negative matrix factorization and sparse principal component analysis
AIMX	In this paper, we propose to address these tasks with a new online optimization algorithm, based on stochastic approximations, which scales up gracefully to large data sets with millions of training samples, and extends naturally to various  matrix factorization formulations, making it suitable for a wide range of learning problems
MISC	A proof of convergence is presented, along with experiments with natural images and genomic data demonstrating that it leads to state-of-the-art performance in terms of speed and optimization for both small and large data sets
MISC	The linear decomposition of a signal using a few atoms of a  learned  dictionary instead of a predefined one---based on wavelets  CITATION  for example---has recently led to state-of-the-art results in numerous low-level signal processing tasks such as image denoising  CITATION , texture synthesis  CITATION  and audio processing  CITATION , as well as higher-level tasks such as image classification  CITATION , showing that sparse learned models are well adapted to natural signals
MISC	Unlike decompositions based on principal component analysis and its variants, these models do not impose that the basis vectors be orthogonal, allowing more flexibility to adapt the representation to the data
OWNX	In machine learning and statistics, slightly different matrix factorization problems are formulated  in order to obtain a few  interpretable  basis elements from a set of data vectors
OWNX	This includes non-negative matrix factorization and its variants  CITATION , and sparse principal component analysis  CITATION
OWNX	As shown in this paper, these problems have strong similarities; even though we first focus on the problem of dictionary learning, the algorithm we propose is able to address all of them
MISC	While learning the dictionary has proven to be critical to achieve (or improve upon) state-of-the-art results in signal and image processing, effectively solving the corresponding optimization problem is a significant computational challenge, particularly in the context of large-scale data sets that may include millions of training samples
OWNX	Addressing this challenge and designing a generic algorithm which is  capable of efficiently handling various matrix factorization problems, is the topic of this paper
OWNX	Concretely, consider a signal  SYMBOL  in  SYMBOL
MISC	We say that it admits a sparse approximation over a \mbox{ dictionary }  SYMBOL  in  SYMBOL , with  SYMBOL  columns referred to as  atoms , when one can find a linear combination of a ``few'' atoms from  SYMBOL  that is ``close'' to the signal  SYMBOL
MISC	Experiments have shown that modelling a signal with such a sparse decomposition ( sparse coding ) is very effective in many signal processing applications  CITATION
MISC	For natural images, predefined dictionaries based on various types of wavelets  CITATION  have also been used for this task
MISC	However, learning the dictionary instead of using off-the-shelf bases has been shown to dramatically improve signal reconstruction  CITATION
MISC	Although some of the learned dictionary elements may sometimes ``look like'' wavelets (or Gabor filters), they are tuned to the input images or signals, leading to much better results in practice
MISC	Most recent algorithms for dictionary learning  CITATION  are iterative  batch  procedures, accessing the whole training set at each iteration in order to minimize a cost function under some constraints, and cannot efficiently deal with very large training sets  CITATION , or dynamic training data changing over time, such as video sequences
AIMX	To address these issues, we propose an  online  approach that processes the signals, one at a time, or in mini-batches
MISC	This is particularly important in the context of image and video processing  CITATION , where it is common to learn dictionaries adapted to small patches, with training data that may include several millions of these patches (roughly one per pixel and per frame)
OWNX	In this setting, online techniques based on stochastic approximations are an attractive alternative to batch methods~(see, eg ,  CITATION )
MISC	For example, first-order stochastic gradient descent with projections on the constraint set  CITATION  is sometimes used for dictionary learning (see  CITATION  for instance)
OWNX	We show in this paper that it is possible to go further and exploit the specific structure of sparse coding in the design of an optimization procedure tuned to this problem, with low memory consumption and lower computational cost than classical batch algorithms
MISC	As demonstrated by our experiments, it scales up gracefully to large data sets with millions of training samples, is easy to use, and is faster than competitive methods
OWNX	The paper is structured as follows: Section~ presents the dictionary learning problem
OWNX	The proposed method is introduced in Section , with a proof of convergence in Section~
OWNX	Section~ extends our algorithm to various matrix factorization problems that generalize dictionary learning, and Section  is devoted to experimental results, demonstrating that our algorithm is suited to a wide class of learning problems
MISC	This correspondence studies an estimator of the conditional  support of a distribution underlying a set of  iid 
OWNX	observations
OWNX	The relation with mutual information is shown via an extension of  Fano's theorem in combination with a generalization bound based on a compression argument
MISC	Extensions to estimating the conditional quantile interval, and  statistical guarantees on the minimal convex hull are given {Keywords}: -  Statistical Learning, Fano's inequality, Mutual Information, Support Vector Machines
OWNX	Given a set of paired observations   SYMBOL   which are  iid 
MISC	copies of a random vector  SYMBOL  possessing a fixed but unknown joint distribution  SYMBOL ,  this letter concerns the question which values the random variable  SYMBOL  can  possibly/likely take given a covariate  SYMBOL
MISC	This investigation on predictive tolerance intervals  is motivated as one is often interested in other characteristics of the joint distribution than the conditional expectation (regression): eg in econometrics one is often more interested in the volatility of a market than in its precise prediction
MISC	In environmental sciences  one is typically concerned with the extremal behavior  (i e the min or max value) of a magnitude, and its respective conditioning  on related environmental variables
MISC	The main contribution of this letter is the extension to Fano's classical inequality (see eg CITATION , p 38) which gives a lower-bound to the mutual information of two random variables
MISC	This classical result is extended towards a setting of learning theory where random variables have an arbitrary fixed distribution
OWNX	The derivation yields a non-parametric estimator of the mutual information possessing  a probabilistic guarantee which is derived using a classical compression argument
OWNX	The described relationship differs from other results relating  estimators and mutual information as eg using Fisher's information matrix  CITATION  or based on Gaussian assumptions as eg in  CITATION , as a distribution free context is adopted
MISC	As an aside,  (i) an estimator of the conditional support is derived  and is extended to the setting of conditional quantiles,  (ii) its theoretical properties are derived,  (iii) the relation to the method of the minimal convex hull is made explicit, and (iv) it is shown how the estimate can be computed efficiently by  solving a linear program
MISC	While studied in the literature eg on quantile regression   CITATION , we argue that this question can be approached   naturally from a setting of statistical learning theory, pattern recognition and Support Vector Machines (SVM), see  CITATION  for an overview
CONT	A main conceptual difference with the existing literature on classical regression and  other predictor methods is that no attempt is made whatsoever to reveal an underlying  conditional mean (as in regression), conditional quantile (as in quantile regression), or minimal risk point prediction of the dependent variable (as in pattern recognition)
OWNX	Here we target instead (the change of) the rough contour of the conditional distribution
OWNX	This implies that one becomes interested in  (i) to what extent the estimated conditional support of the tube is conservative  (i e does it overestimate the actual conditional support ), and  (ii) what is the probability of covering the actual conditional support (i e to what probability a new sample can occur outside the estimated interval) }   Section II proofs the main result, and explores the relation with the convex hull
OWNX	From a practical perspective, Section III provides further insight in  how the optimal estimate can be found efficiently by solving a linear program
MISC	We study the problem of partitioning a small sample of  SYMBOL  individuals  from a mixture of  SYMBOL  product distributions over a Boolean cube  SYMBOL   according to their distributions
MISC	Each distribution is described by a  vector of allele frequencies in  SYMBOL
OWNX	Given two distributions, we use  SYMBOL  to denote the average  SYMBOL   distance in frequencies across  SYMBOL  dimensions,  which measures the statistical divergence  between them
OWNX	We study the case assuming that bits are independently distributed  across  SYMBOL  dimensions
OWNX	This work demonstrates that, for a balanced input instance for  SYMBOL , a certain graph-based optimization function returns the correct partition with  high probability, where a weighted graph  SYMBOL  is formed over  SYMBOL  individuals,  whose pairwise hamming distances between their corresponding bit vectors define the edge weights, so long as  SYMBOL  and   SYMBOL
MISC	The function computes a maximum-weight balanced cut of  SYMBOL ,  where the weight of a cut is the sum of the weights across all edges in the cut
OWNX	This result demonstrates a nice property in the high-dimensional feature space: one can trade off the number of features that are required with the size  of the sample to accomplish certain tasks like clustering
OWNX	We explore a type of classification problem that arises in the context of computational biology
MISC	The problem is that we are given a small sample of size  SYMBOL , eg , DNA of  SYMBOL  individuals, each described by the values  of  SYMBOL   features  or  markers , eg , SNPs (Single Nucleotide Polymorphisms),  where  SYMBOL
MISC	Features have slightly different frequencies depending on which population the  individual belongs to, and are assumed to be independent of each other
AIMX	Given the population of origin of an individual, the genotype (represented as a bit vector in this paper) can be reasonably assumed to be generated by drawing  alleles independently from the appropriate distribution
OWNX	The objective we consider is to minimize the number of features  SYMBOL , and thus total data size  SYMBOL , to correctly  classify the individuals in the sample according to their population of origin,  given any  SYMBOL
OWNX	We describe  SYMBOL  and  SYMBOL  as a function of the ``average quality''   SYMBOL  of the features
OWNX	Throughout the paper, we use  SYMBOL  and  SYMBOL  as  shorthands for  SYMBOL  and  SYMBOL  respectively
OWNX	We first describe a general mixture model that we use in this paper
OWNX	The same model was previously used  in~ CITATION  and ~ CITATION  {Statistical Model:} We have   SYMBOL  probability spaces  SYMBOL  over the set  SYMBOL
MISC	Further, the components ( features ) of  SYMBOL  are independent and  SYMBOL   ( SYMBOL ,  SYMBOL )
OWNX	Hence, the probability spaces  SYMBOL  comprise the distribution of the features for each of the  SYMBOL  populations
MISC	Moreover, the input of the algorithm consists of  a collection ( mixture ) of  SYMBOL  unlabeled samples,  SYMBOL  points  from  SYMBOL , and the algorithm is to determine for each data point from which of  SYMBOL  it was chosen
MISC	In general we do  not  assume that  SYMBOL  are revealed to the algorithm; but we do require some bounds on their relative sizes
MISC	An important parameter of the probability ensemble  SYMBOL  is the  measure of divergence   between any two distributions
OWNX	Note that  SYMBOL  provides a lower bound on the Euclidean distance  between the means of any two distributions and represents their separation
OWNX	Further, let  SYMBOL  (so if the populations were balanced we would have  SYMBOL  of each type)
OWNX	This paper proves the following theorem which gives a sufficient condition for a  balanced ( SYMBOL ) input instance when  SYMBOL
MISC	Variants of the above theorem, based on a model that allows two random draws at each dimension for all points, are given in~ CITATION  and ~ CITATION
MISC	The cleverness there is the construction of a diploid score at each dimension,  given any  pair of individuals , under the assumption that two random bits can be  drawn from the same distribution at each dimension
OWNX	In expectation, diploid scores are higher among pairs from different groups  than for pairs in the same group across all  SYMBOL  dimensions
CONT	In addition,~ CITATION  shows that when  SYMBOL ,  given two bits from each dimension, one can always classify for any size of  SYMBOL ,  for unbalanced cases with any number of mixtures, using essentially connected  component based algorithms, given the weighted graph as in described in  Theorem~
AIMX	The key contribution of this paper is to show new ideas that we use to  accomplish the goal of clustering with the same amount of features,  while requiring only one random bit at each dimension
MISC	While some ideas and proofs for Theorem~  in Section~ have appeared in~ CITATION , modifications for  handling a single bit at each dimension are ubiquitous throughout the proof
OWNX	Hence we contain the complete proof in this paper nonetheless to give a  complete exposition
OWNX	Finding a max-cut is computationally intractable;  a hill-climbing algorithm was given in~ CITATION  to partition a balanced  mixture, with a stronger requirement on  SYMBOL , given any  SYMBOL ,  as the middle green curve in Figure~ shows
OWNX	Two simpler algorithms using spectral techniques were constructed  in~ CITATION , attempting to reproduce conditions above
MISC	Both spectral algorithms in~ CITATION  achieve the bound established by Theorem~ without requiring the input instances being balanced, and work for cases when  SYMBOL  is a constant; However, they require  SYMBOL , even when  SYMBOL  and the input instance  is balanced, as the vertical line in Figure~ shows
OWNX	Note that when  SYMBOL , i e , when we have enough sample from  each distribution,  SYMBOL  becomes the only requirement  in Theorem~
MISC	Exploring the tradeoffs between  SYMBOL  and  SYMBOL , when  SYMBOL  is small, as in  Theorem~ in algorithmic design is both of  theoretical interests and practical value }                                                                                                                                                                                                                                                                                                                                                                                                                                           long-lemma
MISC	 very small but cumulated decreases in food intake may be sufficient to have significant effects  even erasing obesity over a period of years   CITATION
OWNX	in two studies  one a lab study and the other a real-world study  we examine the effect of manipulating the position of different foods on a restaurant menu
MISC	items placed at the beginning or the end of the list of their category options were up to twice as popular as when they were placed in the center of the list
MISC	given this effect  placing healthier menu items at the top or bottom of item lists and less healthy ones in their center e g   sugared drinks vs calorie-free drinks should result in some increase in favor of healthier food choices
MISC	obesity is a growing problem throughout the world
OWNX	fighting it via dieting is apparently ineffective  CITATION
OWNX	in a companion paper  rozin et al CITATION  present arguments and facts to substantiate these two claims  which we shall not repeat here
MISC	they then suggest that the war on obesity could benefit from nudges  CITATION   not only from heavy efforts and investments in resources
MISC	nudges are small  cheap  easily implementable and often hardly noticed changes in the choice architecture i e   the manner or setting in which the choice set is presented that do not affect the choice set itself  yet affect the appeal of different options in it
MISC	rozin et al 's nudge to nobesity is very simple  if you want to increase or decrease the popularity of a food item  make it easier or harder to access  respectively
OWNX	in the same spirit  the present paper explores another possible nudge to nobesity
OWNX	we show that placing a food item on a menu at the beginning or the end of its category increases its popularity compared to placing it in the middle
MISC	restaurants present customers with lists of their offerings
MISC	when the menu is displayed in writing  items are presented simultaneously
MISC	when a waiter recites the day's specials  items are presented sequentially
OWNX	our study involved only printed menus
MISC	menu items may be organized in various ways  such as by type e g   soups  salads  etc
MISC	  or according to main ingredients fish dishes  vegetarian dishes  etc
OWNX	
MISC	within each category they are typically listed in vertical ordering
MISC	when designing menus  does this order matter
MISC	one may seek answers from two kinds of sources-the  how to  literature on menu design  and the psychological literature on position effects
MISC	familiar position effects such as primacy and recency refer to stimuli presented sequentially  and their dependent variable is not usually choice
MISC	but the effect called  edge avoidance   CITATION    centrality preferences   CITATION    middle bias   CITATION   or  center-stage effect   CITATION  refers to choice from among simultaneously presented options-and the various names indicate the typical findings   people choosing from an array of identical options reliably prefer the middle ones   CITATION
MISC	when items are not identical  the effect's manifestation is that when options are presented in the middle of an array they are chosen more often than when they are presented on its edges
MISC	these studies do not  of course  apply to options for which position may be inherently important  such as theater or airplane seats  skyscraper floors  restaurant tables  or place in queues
MISC	rather they use options for which it is hard to imagine why position would matter  such as  i
MISC	in which of  NUMBER  opaque boxes people choose to hide  or seek  a  treasure   CITATION   ii
MISC	similarly  in what position people place  or guess  answers in multiple-choice tests  CITATION   iii
MISC	which good they choose from a set of identical  CITATION  or non-identical  CITATION  goods offered  iv
MISC	what stall they head for in a public bathroom  CITATION   etc
OWNX	all these studies found that placing an item in the middle  rather than the edges  of the choice set enhanced its popularity
MISC	we are aware of only three exceptions in which there seems to be an advantage to being first or last in a simultaneously presented choice set rather than in its middle
MISC	nisbett and wilson  CITATION  asked their subjects to consider a linear array of  NUMBER  identical pairs of stockings a fact of which their subjects were not aware  and serendipitously found a  pronounced left-to-right position effect  such that the right-most object in the array  which was also the last perused  was heavily over-chosen  p  NUMBER -namely   last-is-best 
MISC	in contrast  koppell and steen  CITATION  analyzed real ballot-voting data that was almost like a controlled study  inasmuch as  the order of candidates' names was rotated by precinct  p  NUMBER   and found that  candidates received a greater proportion of the vote when listed first than when listed in any other position  p  NUMBER -namely   first-is-best 
OWNX	finally  christenfeld  CITATION  asked respondents to choose a route between two points  either on hypothetical maps or for real
MISC	the destination point could not be reached by walking a straight line  but the paths to be chosen from had the same total length and number of turns
OWNX	respondents showed a preference for the path reached by making the first turn as late as possible
OWNX	the paths cannot be classified into first  last  or middle  but the possible points of taking the first turn can  and in that sense  respondents preferred the last
MISC	in contrast to all the above-mentioned findings  the restaurant trade publications on menus advocate both edges namely  the first and last as the positions where one should place the items whose popularity one wants to enhance  CITATION
MISC	these recommendations  however  were never backed by research  and none  to the best of our knowledge  exists panitz's claim is certainly valid  but it is not clear why one needs to rely much on memory when choosing from a menu
MISC	moreover  when kincaid and corsun  CITATION  attempted to put other accepted truths regarding  the impact of menu layout on item sales  to an empirical test  their title question   are consultants blowing smoke
MISC	  p  NUMBER   was answered in the affirmative
OWNX	however  since they did not study  edge bias  specifically  we have no direct menu results to either contrast with or add to the  edge avoidance  we reported above
OWNX	in the present study  therefore  we did not hypothesize a bias either in favor of or against middle positioned items  but rather checked whether one exists  using  NUMBER -tailed significance testing
OWNX	across many real-world domains  men engage in more risky behaviors than do women
MISC	to examine some of the beliefs and preferences that underlie this difference   NUMBER  participants assessed their likelihood of engaging in various risky activities relating to four different domains gambling  health  recreation  and social  and reported their perceptions of  NUMBER  probability of negative outcomes   NUMBER  severity of potential negative outcomes  and  NUMBER  enjoyment expected from the risky activities
MISC	women's greater perceived likelihood of negative outcomes and lesser expectation of enjoyment partially mediated their lower propensity toward risky choices in gambling  recreation  and health domains
MISC	perceptions of severity of potential outcomes was a partial mediator in the gambling and health domains
MISC	the genders did not differ in their propensity towards taking social risks
MISC	a fifth domain of activities associated with high potential payoffs and fixed minor costs was also assessed
MISC	in contrast to other domains  women reported being more likely to engage in behaviors in this domain
MISC	this gender difference was partially mediated by women's more optimistic judgments of the probability of good outcomes and of outcomes being more intensely positive
MISC	accidents are a very frequent cause of death  particularly among young adults and teenagers u s center for disease control  cdc    CITATION   and men are more often the victims of accidents than are women  CITATION
OWNX	for example  for every  NUMBER   NUMBER  us drivers  men are three times as likely as women to be involved in fatal car accidents  CITATION
MISC	while some of this well-known difference in automobile death rates probably reflects differences in the average amount of time men and women spend driving  it seems likely that another important cause is that males voluntarily engage in risky behaviors more often than do females
MISC	for example  us women report usually using seat belts substantially more often than men  CITATION   and men have been shown to run yellow lights more often than women  CITATION
MISC	furthermore  similar differences are seen in a wide variety of other forms of accident statistics
MISC	male pedestrians in the uk are involved in accidents about  NUMBER  percent  more often than female pedestrians  and men die much more often from drowning or accidental poisoning throughout the western world  CITATION
MISC	thus  there seems little doubt that men must be engaging in more risky behaviors across a broad range of domains
MISC	despite its obvious practical importance  some key aspects of the psychological underpinnings of gender differences in risk taking have not been examined
AIMX	the present article seeks to shed new light on these underpinnings  by asking a substantial sample of college men and women to report various perceptions and preferences related to a wide range of risk-taking scenarios
MISC	the existence of gender differences in propensity to take risks has been documented in a large number of questionnaire and experimental studies
MISC	for example  a meta-analysis by byrnes  miller  and schafer  CITATION  reviewed over  NUMBER  papers on gender differences in risk perception
MISC	they concluded that the literature  clearly  indicated that  male participants are more likely to take risks than female participants  p  NUMBER 
MISC	recent work has begun to examine the generality and cognitive underpinnings of these differences in greater detail  CITATION
AIMX	in one important study that provides a backdrop for the present investigation  weber  blais  and betz  CITATION  assessed the risks that men and women perceived in behaviors spanning five different content domains financial  health safety  recreational  ethical  and social decisions
MISC	gender differences were found in four of the five domainssocial decision-making being the exceptionwith males perceiving less risk and indicating a greater likelihood of engaging in risky behaviors
MISC	similar gender differences have been found in these domains in a large german sample  CITATION
MISC	across studies  the social domain is unique in that either no gender differences are found or when they are found  it is women who report greater propensity to engage in risky behaviors and perceive overall greater benefit and less risk in doing so  CITATION
MISC	of interest  these authors also found great variability in an individual's willingness to engage in risk across domains  suggesting that risk taking is not simply the product of some general personality trait that promotes risk seeking
MISC	instead  individual and group differences are substantially due to differing perceptions of risk in different domains
MISC	for the most part  previous research has relied on a unitary and subject-defined notion of  risk  e g    how risky is the behavior or situation
OWNX	 
MISC	a number of researchers have examined the role of various affect dimensions in determining overall perceptions of riskiness
MISC	slovic  CITATION  proposes that several psychological risk dimensions including dread  control  and knowledge contribute to perceived riskiness
MISC	follow-up research has shown the material as well as emotional factors also impact overall risk judgments  CITATION
MISC	any global assessment of perceived risk combines elements of a belief  how likely is it that something bad will happen
OWNX	  and a subjective valuation of that outcome  how bad would that be
OWNX	 
MISC	thus  in common parlance a given behavior might be said to be riskier than another behavior if the former has more severe potential consequences  or if it has a higher risk of potential negative consequences  or both
MISC	for example  leaving one's bike unattended for a day in a busy city  and bungie jumping could both be described as risky behaviors  and yet the probabilities and potential bad outcomes are enormously different in the two cases
MISC	past research shows that decomposing these elements can shed important light on individual and group differences in responses to risky situations
MISC	gurmankin levy and baron  CITATION  had subjects assess badness of unfortunate medical outcomes associated with a defined probability e g    NUMBER  percent  chance of loss of a big toe
OWNX	different groups men vs women  physicians vs non-physicians were differentially sensitive to probability as against severity
OWNX	the present article pursues a similar approach to explore the determinants of men's and women's willingness to engage in different risky activities
MISC	note that in the field of finance  where distribution of potential outcomes is obviously continuous  risk is often conceptualized as the variability of the returns offered by a choice
MISC	following that approach  some theorists have found it useful to conceive of people's generalized risk preferences in terms of how this variability affects an individual's disposition to choose an option  CITATION
MISC	while this seems quite reasonable  in many real world risky choice scenarios e g   riding motorcycle without helmet  not using sunscreen  etc
MISC	  it would seem to be a reasonable simplification to view the potential negative outcomes as a unitary event  having a probability and some degree of un-desirability
OWNX	this approach will be followed here  although in the general discussion we will point out the potential for follow-up work that would consider risks involving more than a single discrete negative outcome
MISC	remarkably  the literature with adults does not seem to contain any studies that seek to decompose the perceptions of risk involved in real-world risky behaviors  in order to determine whether the genders differ in their evaluations of the likelihoods and costs of negative outcomes
OWNX	a number of plausible hypotheses immediately present themselves
MISC	one such hypothesis is that women do not evaluate the probability of negative outcomes differently than men  they simply assume perhaps rightly  perhaps not that they would be more emotionally upset or harmed by negative outcomes  should these occur
OWNX	alternatively  one may hypothesize that women assess as greater the probability of unfavorable outcomes  without projecting any stronger negative reactions to these outcomes than do men
MISC	while studies of gender effects in adult risk preferenceswith the exception of gurmankin levy and baron  CITATION have not addressed this issue  there is one study within the developmental literature that explored this question
OWNX	hillier and morrongiello  CITATION  examined gender differences in perceptions involved in physical risk taking in children
MISC	using pictorial descriptions e g   riding bicycle with no helmet in street and an interview to determine how children assessed risks  they found that girls appraised more general risk i e   judged the situations as more unsafe than boys
MISC	the genders also differed in the factors that contributed to their overall risk judgments
MISC	boys' risk judgments were significantly predicted by their ratings of injury severity while girls' risk judgments were better predicted by their ratings of vulnerability to any type of injury
MISC	this suggests that girls may avoid risky situations with any likelihood of perceived injury and boys may avoid risky situations only if the possible perceived injuries are judged as being severe
MISC	as noted above  the literature with adults has not examined whether the genders differ in their evaluations of  NUMBER  the likelihood of potential negative outcomes and  NUMBER  their appraisals of the severity of these potential outcomes
MISC	in adults  either or both of these aspects of risk may mediate gender differences in engaging in  risky  behaviors
MISC	a third factor may also be responsible for the gender differences in propensity to engage in risky behaviors  the genders may differ in their estimates of the enjoyment offered by the activity  assuming that negative outcomes do not take place
MISC	this last possibility finds some support from weber et al CITATION  and johnson et al  NUMBER   who found that relative to women  men judged they would obtain greater benefits from engaging in risky behaviors in all domains except social
MISC	using a risk-return framework  weber and colleagues have suggested that risky decision making can be seen as a trade-off between fear risk and hope expected returns
OWNX	the present study had two major goals
OWNX	the first was to separately assess gender differences in the three kinds of assessments just mentioned
OWNX	to put it in simple terms  the present study asks  do women tend  for example  to engage in dangerous recreational activities less often because a they think the likelihood of injury is greater  b they think the severity of an injury  were it to occur  would be greater  and or c because they simply do not find the positive aspects of such activities as attractive as men do
MISC	in addition  we examined whether such assessments vary depending upon the domain of behavior and compared patterns of risk perception with individuals' reports of engaging in risky behaviors in the past
MISC	a second aim was to explore an important category of choices popularly referred to as  taking a chance  that have not  to our knowledge  been examined in previous studies of individual differences in risk  decisions to engage or not engage in behaviors that offer a small probability of a large positive reward in return for some small but certain cost
MISC	an example is trying to be the  NUMBER th caller to a radio station in order to win a large sum of money
MISC	this type of scenario will be referred to as the  positive domain 
MISC	one possible explanation for why women engage in fewer risky activities is that they are relatively pessimistic and feel themselves relatively  unlucky  i e   prone to experience the least desirable possible outcome more often than would be expected based on overall frequencies
OWNX	if this is so  then women should also show less interest than men in options offering a low probability of positive reward
MISC	another possibility is that women see low-frequency outcomes whether good or bad as more likely to occur  in which cases they should show greater attraction to choices in the positive domain
MISC	-Actinin is an actin crosslinking molecule that can serve as a scaffold and maintain dynamic actin filament networks.
OWNX	As a crosslinker in the stressed cytoskeleton, -actinin can retain conformation, function, and strength.
MISC	-Actinin has an actin binding domain and a calmodulin homology domain separated by a long rod domain.
MISC	Using molecular dynamics and normal mode analysis, we suggest that the -actinin rod domain has flexible terminal regions which can twist and extend under mechanical stress, yet has a highly rigid interior region stabilized by aromatic packing within each spectrin repeat, by electrostatic interactions between the spectrin repeats, and by strong salt bridges between its two anti-parallel monomers.
OWNX	By exploring the natural vibrations of the -actinin rod domain and by conducting bending molecular dynamics simulations we also predict that bending of the rod domain is possible with minimal force.
AIMX	We introduce computational methods for analyzing the torsional strain of molecules using rotating constraints.
MISC	Molecular dynamics extension of the -actinin rod is also performed, demonstrating transduction of the unfolding forces across salt bridges to the associated monomer of the -actinin rod domain.
MISC	Cytoskeletal microfilament networks contribute to the mechanical stability of the cell by dynamically arranging and rearranging actin filaments for reinforcement.
MISC	The dynamic arrangement of actin filament requires actin filament crosslinking molecules such as -actinin.
MISC	-Actinin is a 200 kDa homodimer with three major structural motifs: the actin binding domain, the calmodulin homology domain, and the central rod domain CITATION.
OWNX	Each monomer contains all three structural domains but the two monomers are arranged anti-parallel so that the two ABDs are at opposite ends of -actinin.
OWNX	The arrangement of the two ABDs at opposite ends allows for -actinin to crosslink parallel actin filaments CITATION.
MISC	Actin filaments in the parallel arrangement are very dynamic; the actin filaments move laterally and horizontally in relationship to each other, and continuously bind and unbind -actinin crosslinking molecules CITATION.
OWNX	Several cellular processes involving actin filament dynamic rearrangement and scaffolding by -actinin include: focal adhesion formation near membrane bound integrin molecules CITATION, cytokinesis and cytoplasmic dumping in the final stages of mitosis CITATION, CITATION, and z-disk formation and stabilization in muscle cells CITATION.
MISC	In order for -actinin to maintain its function as an actin filament scaffold in such a dynamic environment, the -actinin molecule must be partially flexible, meaning it must simultaneously be rigid and stable at some regions to resist external stress and be flexible at other regions to maintain binding in a dynamic environment CITATION CITATION .
MISC	Structure of the -actinin rod domain underlies the function of -actinin as a partially flexible actin filament crosslinker.
MISC	Each central rod domain monomer is 240 long and made up of 4 spectrin repeats connected by helical linkers CITATION, CITATION.
MISC	Other molecules with spectrin repeats include dystophin and utrophin.
OWNX	The -actinin rod domain differs from the other spectrin family molecules by its shorter length, its more rigid helical linkers, and its dimerization CITATION.
MISC	The spectrin repeats structure of the rod domain contributes several vital characteristics to the -actinin rod domain: aromatic packing and hydrophobic residues within each repeat stabilize secondary structure CITATION ; acidic and basic surfaces on R1 and R4 confer strong dimerization interactions CITATION, Kd of 10 pM between monomers CITATION ; interaction of hydrophobic residues between R2 and R3 on both monomers and electrostatic interactions produce a coiled-coil homodimer conformation with a 12 degree bend and a 90 degree left handed twist CITATION.
MISC	Together these characteristics account for the rod domain maintaining both structural rigidity and flexibility.
OWNX	The goal of this investigation is to understand the structural mechanisms of the partial flexibility of the -actinin rod domain.
MISC	The coiled-coil nature of the rod domain is an essential component of the rod domain structure.
MISC	Coiled-coils are the dominant conformation for fibrous proteins CITATION.
MISC	Most coiled-coils have a heptad conformation, with hydrophobic residues every seventh residue CITATION, CITATION.
MISC	The heptad conformation allows for hydrophobic insertion of one linker region into that of the other monomers by a knobs-into-holes mechanism CITATION.
OWNX	The presence of heptad hydrophobic residues is common in coiled-coil structure but neither necessary nor sufficient CITATION, CITATION.
MISC	Coiled-coils with antiparallel dimers like the -actinin rod domain are stabilized mainly by electrostatic interactions between the monomers, and within the monomers CITATION.
MISC	In general the knobs-into-holes mechanism of coiled-coil conformation exists only when stabilized by electrostatic interactions CITATION.
MISC	The tendency of electrostatic interactions to play a key role in stabilizing coiled-coil dimers like -actinin is in contrast to globular proteins, where hydrophobic, VDW, and electrostatic interactions are equally significant to molecular stability CITATION.
OWNX	The coiled-coil conformation of the rod domain is a significant structural feature, and the significance of electrostatic interactions to coiled-coil structure stability suggests a significant role of electrostatic interactions in mechanical properties of the -actinin rod domain.
MISC	Several studies have examined the mechanical properties of other molecules with rod-like coiled-coil conformations.
MISC	These studies on DNA CITATION CITATION, myosin CITATION CITATION, and keratin CITATION, CITATION together suggest the coiled-coil rod like structure contributes extensible rigidity and torsional and bending flexibility.
MISC	The tertiary structure of DNA is referred to as coiled-coil, and more commonly as a double-helix, because it consists of two intertwined -helices.
MISC	In contrast, -actinin and other fibrous proteins are referred to as coiled-coil due to intertwining in their quaternary structures.
OWNX	The difference between the DNA coiled-coil conformation and the protein coiled-coil conformation is significant, but the mechanical properties can still be compared.
MISC	DNA is the most studied of the coiled-coil conformations and has been described as an elastic rod CITATION.
MISC	Its global mechanical behavior has been described as like a thin isotropic homogeneous rod, but its local mechanical behavior has been described as like an anisotropic heterogeneous rod with bending and torsional flexibility CITATION CITATION.
MISC	Myosin has an S2 region that functions as a lever arm in muscle sarcomeres.
MISC	Using a single molecule assay in a total internal reflection microscopy experiment CITATION, it has been shown that the S2 region has significant torsional flexibility underlying its lever arm function.
MISC	Keratin, the first coiled-coil structure to be discovered CITATION, is the major molecule in hair fibers, and investigation of its mechanical behavior with molecular dynamics has shown that it has strong stretching rigidity, over 1 nN of force is needed to stretch keratin 90 percent CITATION.
MISC	Removing the electrostatic interactions underlying the coiled-coil conformation of keratin significantly reduces its rigidity CITATION.
MISC	These studies suggest that the coiled-coil conformation in -actinin contributes extension rigidity but torsional and bending flexibility.
MISC	Studies of -actinin and other spectrin repeat molecules have similarly demonstrated extension rigidity of the coiled-coil rod domain CITATION CITATION.
MISC	Experimental investigation using atomic force microscopy of spectrin unfolding demonstrated that spectrin repeats unfold in a cooperative mechanism CITATION.
MISC	Several molecular dynamics investigations further characterize the extension rigidity of the -actinin rod domain as resulting from the strength of the helical linker between the spectrin repeats, and electrostatic and hydrogen bonding within each repeat CITATION CITATION.
MISC	There has been no investigation of the bending or torsional flexibility of the -actinin rod domain or other spectrin repeats, but investigation of -actinin structure using cryoelectron microscopy has shown that there must be some structural flexibility since -actinin molecules form stable actin filaments crosslinks in a range of crosslinking angles CITATION.
MISC	Is the flexibility of -actinin in crosslinking actin filaments due to torsional and bending flexibility of the rod domain?
OWNX	What features of the coiled-coil structure of -actinin underlie its partial flexibility?
OWNX	Using molecular dynamics and normal mode analysis this study investigates the mechanical partial flexibility of the -actinin rod domain.
MISC	Bending, torsion and extension simulations demonstrate that, as with other coiled-coil molecules, the -actinin rod domain has bending and torsional flexibility and extensional rigidity.
MISC	Normal mode analysis shows that the rod-like structure of -actinin contributes towards its bending and torsional flexibility.
MISC	Our simulations suggest that aromatic packing interactions determine the trajectory of torsion on the rod domain, and that electrostatic interaction between the monomers contributes extension rigidity to the rod domain.
MISC	Experimental work has shown that T cells of the immune system rapidly and specifically respond to antigenic molecules presented on the surface of antigen-presenting-cells and are able to discriminate between potential stimuli based on the kinetic parameters of the T cell receptor-antigen bond.
MISC	These antigenic molecules are presented among thousands of chemically similar endogenous peptides, raising the question of how T cells can reliably make a decision to respond to certain antigens but not others within minutes of encountering an antigen presenting cell.
OWNX	In this theoretical study, we investigate the role of localized rebinding between a T cell receptor and an antigen.
MISC	We show that by allowing the signaling state of individual receptors to persist during brief unbinding events, T cells are able to discriminate antigens based on both their unbinding and rebinding rates.
MISC	We demonstrate that T cell receptor coreceptors, but not receptor clustering, are important in promoting localized rebinding, and show that requiring rebinding for productive signaling reduces signals from a high concentration of endogenous pMHC.
OWNX	In developing our main results, we use a relatively simple model based on kinetic proofreading.
OWNX	However, we additionally show that all our results are recapitulated when we use a detailed T cell receptor signaling model.
OWNX	We discuss our results in the context of existing models and recent experimental work and propose new experiments to test our findings.
MISC	T cells of the adaptive immune system use their T cell receptors to scan the surfaces of antigen-presenting-cells for antigen in the form of specific peptides bound to major-histocompatibility complexes.
MISC	Scanning of APCs by T cells is rapid, with estimates suggesting that an individual T cell spends only 1 5 minutes interacting with a single APC if it lacks specific pMHC CITATION.
MISC	Experiments have demonstrated that T cells are extremely sensitive to specific pMHC, responding to as few as 1 10 pMHC in a sea of thousands of chemically similar self pMHC CITATION, CITATION, CITATION, CITATION.
MISC	It has also been demonstrated that a single amino acid substitution on a presented peptide can dramatically alter the T cell response CITATION.
MISC	Speed, sensitivity, and specificity have been dubbed the S 3 characteristics of antigen detection by T cells CITATION .
MISC	The observation that T cells transiently interact with APCs that do not express specific pMHC suggests that the decision to respond occurs within seconds of an encounter.
MISC	Rapid turnover of T cell-APC contacts in vivo accelerates the search for specific pMHC by allowing numerous unique T cell-APC interactions.
OWNX	The decision to respond gives rise to a stop signal CITATION and is commonly followed by the formation of the immune synapse CITATION, a stable adhesion between the T cell and APC that persists for upwards of 30 minutes and facilitates a second, sustained phase of signaling.
MISC	Experiments and mathematical modeling have been extensively used to understand the efficiency of T cell activation.
MISC	During the sustained signaling phase, the serial binding of many TCR by a single pMHC has been postulated to increase T cell sensitivity CITATION.
MISC	Serial binding is expected because the bonds formed between TCR and agonist pMHC are transient, with half-lives in the range of 1 100 s CITATION, CITATION, CITATION.
MISC	On the other hand, T cell specificity has been addressed by the kinetic proofreading model CITATION, CITATION.
MISC	This model postulates that a series of TCR-proximal steps, such as the binding and subsequent phosphorylation of the TCR associated immunoreceptor tyrosine-based activation motifs by signaling molecules, occur upon pMHC binding, and that these signaling events require continued TCR engagement to proceed.
MISC	A productive signal is transduced only after several such transformations have taken place.
MISC	In this model, T cells are able to discriminate between different pMHC by imposing a threshold on the TCR-pMHC dissociation rate constant .
OWNX	Combining serial binding and kinetic proofreading reveals that a balance between sensitivity and specificity gives rise to an optimal FORMULA for efficient T cell activation CITATION, CITATION, CITATION, an effect which has been experimentally observed CITATION, CITATION, CITATION.
MISC	The efficiency of T cell activation in these models, and others CITATION, CITATION, is usually quantified by the number of activated TCRs integrated over the whole cell, and after a relatively long period of interaction with an APC.
MISC	Additionally, several studies have reported correlations between the TCR/pMHC bond dissociation constant, but not FORMULA, and the efficiency of T cell activation as measured after FORMULA hour by cytoxicity and/or cytokine assays CITATION, CITATION, CITATION .
MISC	However, T cells have been observed to respond to stimulatory pMHC in less than a minute CITATION and, at least for cytotoxic T cells, a stable contact interface is not required for pMHC detection CITATION.
MISC	Serial binding/kinetic proofreading models do not predict specificity on these short time scales, in part because signals generated by high concentrations of weakly binding self pMHC are found to be comparable to signals generated by low concentrations of high affinity agonist pMHC CITATION, CITATION.
MISC	Moreover, the early T cell response is unlikely to be determined by an equilibrium parameter, such as FORMULA, as it is quite unlikely that the T cell-APC interface attains equilibrium at such short times.
MISC	It is more likely that FORMULA is an important determinant of the efficiency of T cell activation during the sustained phase of signaling, well after the initial decision to respond.
OWNX	In this paper we investigate a putative mechanism for antigen discrimination during the early phase of TCR signaling.
MISC	Specifically, we examine the role of TCR/pMHC rebinding in allowing T cells to make rapid and reliable decisions to respond.
MISC	By explicitly accounting for TCR/pMHC rebinding within existing formulations of diffusion-limited membrane reactions, we find that rebinding has very little effect in canonical proofreading models.
OWNX	A simple modification that accounts for signal persistence at the TCR allows individual TCR to integrate the duration of multiple rebinding events.
OWNX	The consequence of this scheme is that discrimination in this sum-of-binding model is now sensitive to both the association and dissociation rate constants of the TCR-pMHC bond.
MISC	This enhanced sensitivity leads to the finding that a T cell can discriminate between a wider spectrum of antigens than would be predicted by a traditional serial binding/kinetic proofreading model.
OWNX	We further show that coreceptors, but not TCR clustering, are important to achieve these rapid rebinding events.
OWNX	In addition, we show that signal persistence at the TCR does not allow high concentrations of endogenous pMHC to generate spurious signals.
OWNX	Finally, we show that our general conclusions are unchanged when our cartoon kinetic proofreading model is replaced by a detailed model of TCR-proximal signaling.
OWNX	We propose that T cells discriminate antigen based on FORMULA and FORMULA via a threshold in the sum-of-binding which allows for rapid and reliable T cell responses to specific pMHC.
MISC	We report a new optimal resolution for the statistical stratification problem under proportional sampling allocation among strata
MISC	Consider a finite population of  N  units, a random sample of  n  units selected from this population and a number  L  of strata
MISC	Thus, we have to define which units belong to each stratum so as to minimize the variance of a total estimator for one desired variable of interest in each stratum, and consequently reduce the overall variance for such quantity
OWNX	In order to solve this problem, an exact algorithm based on the concept of minimal path in a graph is proposed and assessed
OWNX	Computational results using real data from IBGE (Brazilian Central Statistical Office) are provided \\ [0 7em] {Keywords:} Stratification; Proportional Allocation; Variance; Minimal Path
MISC	A common procedure in sampling surveys is partitioning the elements of a population, before distributing the sample on it, in such a way to obtain most useful information from the data to be collected
MISC	This procedure is called stratification
MISC	It may have different aims, such as to guarantee obtaining information for some or all the geopolitical regions of a country, or to provide more precision in estimating population quantities by identifying strata with more homogeneous elements into them, according to one or more variables
OWNX	In this latter case, the stratification is also called statistical stratification
CONT	A principal use of statistical stratification, in order to obtain a better precision, is in defining what percentage of the sample must be taken from each stratum once we have chosen a non-uniform allocation scheme, that is, a non-trivial functional relation between the size of each stratum and the number of sample units to be collected in it
OWNX	Thus, it is important to consider the allocation scheme itself in order to do a suitable statistical stratification
OWNX	In this paper, we propose an exact algorithm to solve the statistical stratification problem, that we call simply stratification problem, considering a simple non-uniform allocation scheme
OWNX	Specifically, this method intends to solve the problem of optimal stratification with stratified simple random sampling without replacement  CITATION  using proportional allocation
MISC	In this problem, we must divide a population of size  SYMBOL  into  SYMBOL  strata considering an auxiliary variable  SYMBOL , also called the size variable, whose values are known for all units in the population
MISC	The first stratum is defined as the set of units in the population whose  SYMBOL   values are lower than or equal to a constant value  SYMBOL  , the second one as the set of units whose  SYMBOL  values are greater than  SYMBOL   and lower than or equal  to  SYMBOL   and so on
MISC	Based on this definition the stratum  SYMBOL   SYMBOL  is defined as the set of units in population with values of  SYMBOL  belonging to the interval  SYMBOL , where   SYMBOL  are the boundaries of each stratum, and the stratum  SYMBOL  corresponds to the set of observations which values are greater than  SYMBOL
MISC	The problem of optimal stratification consists in to find boundaries  SYMBOL  which minimize the variance of the estimator of total for one or more variables  SYMBOL  of study that are supposed to have some correlation with the  SYMBOL  variable, or even the  SYMBOL  variable properly
OWNX	Aiming to solve this problem, a new algorithm, when proportional allocation is used, is proposed using the idea of minimal path in graphs  CITATION
OWNX	This paper is organized in five sections
OWNX	In section 2, we present some basic concepts about stratified simple random sampling
OWNX	In section 3, we define the problem of stratification to be tackled in this work and offer a brief discussion about different approaches to this topic
OWNX	We propose, in section 4, an algorithm based on Graph Theory in order to provide exact solutions to the stratification problem defined in section 3
OWNX	Finally, we present some computational results and considerations about the new algorithm
MISC	Given a finite set of words  SYMBOL  independently drawn according to a fixed unknown distribution law  SYMBOL  called a  stochastic language , an usual goal in Grammatical Inference is to infer an estimate of  SYMBOL  in some class of probabilistic models, such as  Probabilistic Automata  (PA)
OWNX	Here, we study the class  SYMBOL  of  rational stochastic languages , which consists in stochastic languages that can be generated by  Multiplicity Automata  (MA) and which strictly includes the class of stochastic languages generated by PA
OWNX	Rational stochastic languages have minimal normal representation which may be very concise, and whose parameters can be efficiently estimated from stochastic samples
OWNX	We design an efficient inference algorithm DEES which aims at building a minimal normal representation of the target
OWNX	Despite the fact that no recursively enumerable class of MA computes exactly  SYMBOL , we show that DEES strongly identifies  SYMBOL  in the limit
OWNX	We study the intermediary MA output by DEES and show that they compute rational series which converge absolutely to one and which can be used to provide stochastic languages which closely estimate the target
MISC	In probabilistic grammatical inference, it is supposed that data arise in the form of a finite set of words  SYMBOL , built on a predefinite alphabet  SYMBOL , and independently drawn according to a fixed unknown distribution law on  SYMBOL  called a  stochastic language
OWNX	Then, an usual goal is to try to infer an estimate of this distribution law in some class of probabilistic models, such as  Probabilistic Automata  (PA), which have the same expressivity as Hidden Markov Models (HMM)
MISC	PA are identifiable in the limit~ CITATION
OWNX	However, to our knowledge, there exists no efficient inference algorithm able to deal with the whole class of stochastic languages that can be generated from PA
MISC	Most of the previous works use restricted subclasses of PA such as Probabilistic Deterministic Automata (PDA)~ CITATION
OWNX	In the other hand, Probabilistic Automata are particular cases of  Multiplicity Automata , and stochastic languages which can be generated by multiplicity automata are special cases of  rational languages  that we call  rational stochastic languages
OWNX	MA have been used in grammatical inference in a variant of the exact learning model of Angluin  CITATION  but not in probabilistic grammatical inference
MISC	Let us design by  SYMBOL , the class of rational stochastic languages over the semiring  SYMBOL
MISC	When  SYMBOL  or  SYMBOL ,  SYMBOL  is exactly the class of stochastic languages generated by PA with parameters in  SYMBOL
CONT	But, when  SYMBOL  or  SYMBOL , we obtain strictly greater classes which provide several advantages and at least one drawback: elements of  SYMBOL  may have significantly smaller representation in  SYMBOL  which is clearly an advantage from a learning perspective; elements of  SYMBOL  have a minimal normal representation while such normal representations do not exist for PA; parameters of these minimal representations are directly related to probabilities of some natural events of the form  SYMBOL , which can be efficiently estimated from stochastic samples; lastly, when  SYMBOL  is a field, rational series over  SYMBOL  form a vector space and efficient linear algebra techniques can be used to deal with rational stochastic languages
OWNX	However, the class  SYMBOL  presents a serious drawback : there exists no recursively enumerable subset of MA which exactly generates it~ CITATION
MISC	Moreover, this class of representations is unstable: arbitrarily close to an MA which generates a stochastic language, we may find MA whose associated rational series  SYMBOL  takes negative values and is not absolutely convergent: the global weight  SYMBOL  may be unbounded or not (absolutely) defined
OWNX	However, we show that  SYMBOL  is strongly identifiable in the limit: we design an algorithm DEES such that, for any target  SYMBOL  and given access to an infinite sample  SYMBOL  drawn according to  SYMBOL , will converge in a finite but unbounded number of steps to a minimal normal representation of  SYMBOL
MISC	Moreover, DEES is efficient: it runs within polynomial time in the size of the input and it computes a minimal number of parameters with classical statistical rates of convergence
OWNX	However, before converging to the target, DEES output MA which are close to the target but which do not compute stochastic languages
OWNX	The question is: what kind of guarantees do we have on these intermediary hypotheses and how can we use them for a probabilistic inference purpose
OWNX	We show that, since the algorithm aims at building a minimal normal representation of the target, the intermediary hypotheses  SYMBOL  output by DEES have a nice property: they absolutely converge to 1, i e SYMBOL  and  SYMBOL
MISC	As a consequence,  SYMBOL  is defined without ambiguity for any  SYMBOL , and it can be shown that  SYMBOL  tends to 0 as the learning proceeds
MISC	Given any such series  SYMBOL , we can efficiently compute a stochastic language  SYMBOL , which is not rational, but has the property that  SYMBOL  for any word  SYMBOL  such that  SYMBOL
MISC	Our conclusion is that, despite the fact that no recursively enumerable class of MA represents the class of rational stochastic languages, MA can be used efficiently to infer such stochastic languages
MISC	Classical notions on stochastic languages, rational series, and multiplicity automata are recalled in Section~
OWNX	We study an example which shows that the representation of rational stochastic languages by MA with real parameters may be very concise
OWNX	We introduce our inference algorithm DEES in Section~ and we show that  SYMBOL  is strongly indentifiable in the limit
OWNX	We study the properties of the MA output by DEES in Section~ and we show that they define absolutely convergent rational series which can be used to compute stochastic languages which are estimates of the target
MISC	Several researchers have recently investigated the connection between reinforcement learning and classification
AIMX	We are motivated by proposals of approximate policy iteration schemes without value functions, which focus on policy representation using classifiers and address policy learning as a supervised learning problem
OWNX	This paper proposes variants of an improved policy iteration scheme which addresses the core sampling problem in evaluating a policy through simulation as a multi-armed bandit machine
MISC	The resulting algorithm offers comparable performance to the previous algorithm achieved, however, with significantly less computational effort
MISC	An order of magnitude improvement is demonstrated experimentally in two standard reinforcement learning domains: inverted pendulum and mountain-car
MISC	Supervised and reinforcement learning are two well-known learning paradigms, which have been researched mostly independently
MISC	Recent studies have investigated the use of supervised learning methods for reinforcement learning, either for value function~\mycite{lagoudakis2003lsp,riedmiller2005nfq} or policy representation~\mycite{lagoudakisICML03,fern2004api,langfordICML05}
MISC	Initial results have shown that policies can be approximately represented using either multi-class classifiers or combinations of binary classifiers~\mycite{rexakis+lagoudakis:ewrl2008} and, therefore, it is possible to incorporate classification algorithms within the inner loops of several reinforcement learning algorithms~\mycite{lagoudakisICML03,fern2004api}
OWNX	This viewpoint allows the quantification of the performance of reinforcement learning algorithms in terms of the performance of classification algorithms~\mycite{langfordICML05}
MISC	While a variety of promising combinations become possible through this synergy, heretofore there have been limited practical and widely-applicable algorithms
MISC	Our work builds on the work of Lagoudakis and Parr~\mycite{lagoudakisICML03} who suggested an approximate policy iteration algorithm for learning a good policy represented as a classifier, avoiding representations of any kind of value function
MISC	At each iteration, a new policy/classifier is produced using training data obtained through extensive simulation (rollouts) of the previous policy on a generative model of the process
OWNX	These rollouts aim at identifying better action choices over a subset of states in order to form a set of data for training the classifier representing the improved policy
MISC	A similar algorithm was proposed by Fern et al ~\mycite{fern2004api} at around the same time
OWNX	The key differences between the two algorithms are related to the types of learning problems they are suitable for, the choice of the underlying classifier type, and the exact form of classifier training
OWNX	Nevertheless, the main ideas of producing training data using rollouts and iterating over policies remain the same
MISC	Even though both of these studies look carefully into the distribution of training states over the state space, their major limitation remains the large amount of sampling employed at each training state
MISC	It is hinted~\mycite{lagoudakisPhD03}, however, that great improvement could be achieved with sophisticated management of rollout sampling
OWNX	Our paper suggests managing the rollout sampling procedure within the above algorithm with the goal of obtaining comparable training sets (and therefore policies of similar quality), but with significantly less effort in terms of number of rollouts and computation effort
MISC	This is done by viewing the setting as akin to a bandit problem over the rollout states (states sampled using rollouts)
MISC	Well-known algorithms for bandit problems, such as Upper Confidence Bounds~\mycite{auerMLJ02} and Successive Elimination~\mycite{evendarJMLR06}, allow optimal allocation of resources (rollouts) to trials (states)
OWNX	Our contribution is two-fold: (a) we suitably adapt bandit techniques for rollout management, and (b) we suggest an improved statistical test for identifying early with high confidence states with dominating actions
OWNX	In return, we obtain up to an order of magnitude improvement over the original algorithm in terms of the effort needed to collect the training data for each classifier
MISC	This makes the resulting algorithm attractive to practitioners who need to address large real-world problems
OWNX	The remainder of the paper is organized as follows
OWNX	Section~ provides the necessary background and Section~ reviews the original algorithm we are based on
OWNX	Subsequently, our approach is presented in detail in Section~
MISC	Finally, Section~ includes experimental results obtained from well-known learning domains
MISC	ADP-glucose pyrophosphorylase, a key allosteric enzyme involved in higher plant starch biosynthesis, is composed of pairs of large and small subunits.
MISC	Current evidence indicates that the two subunit types play distinct roles in enzyme function.
MISC	Recently the heterotetrameric structure of potato AGPase has been modeled.
MISC	In the current study, we have applied the molecular mechanics generalized born surface area method and identified critical amino acids of the potato AGPase LS and SS subunits that interact with each other during the native heterotetrameric structure formation.
MISC	We have further shown the role of the LS amino acids in subunit-subunit interaction by yeast two-hybrid, bacterial complementation assay and native gel.
MISC	Comparison of the computational results with the experiments has indicated that the backbone energy contribution of the interface residues is more important in identifying critical residues.
MISC	We have found that lateral interaction of the LS-SS is much stronger than the longitudinal one, and it is mainly mediated by hydrophobic interactions.
OWNX	This study will not only enhance our understanding of the interaction between the SS and the LS of AGPase, but will also enable us to engineer proteins to obtain better assembled variants of AGPase which can be used for the improvement of plant yield.
OWNX	ADP-glucose pyrophosphorylase is a key regulatory allosteric enzyme involved in starch biosynthesis in higher plants.
OWNX	It catalyzes the rate limiting reversible reaction and controls the carbon-flux in the -glucan pathway by converting Glucose-1-phosphate and ATP to ADP-glucose and pyrophosphate using Mg 2 as the cofactor CITATION CITATION.
MISC	Regulation of almost all AGPases depends on the 3-phosphoglyceric acid to inorganic phosphate ratio.
OWNX	While 3-PGA functions as the main stimulator, Pi inhibits the activity of enzyme CITATION CITATION.
MISC	Plant AGPases consist of pairs of small and large subunits thereby constituting a heterotetrameric structure.
MISC	These two subunits are encoded by two distinct genes CITATION.
OWNX	In potato tuber AGPase the sequence identity between the different subunits is 53 percent suggesting a common ancestral gene CITATION, CITATION.
MISC	The molecular weights of tetrameric AGPases range from 200 to 240 kDa depending on the tissue and plant species.
MISC	Specifically, molecular weights of LS and SS in potato tuber AGPase are 51 kDa and 50 kDa, respectively CITATION.
OWNX	It was found that SS and LS have different roles in the enzyme functionality.
MISC	SS was shown to have both catalytic and regulatory functions whereas LS is mainly responsible for regulating the allosteric properties of SS CITATION CITATION.
MISC	These results were also supported by the studies that showed LS was incapable of assembling into a catalytically active oligomeric structure, whereas SS was able to form a homotetramer with catalytic properties CITATION, CITATION.
MISC	However, this SS homotetramer showed defective properties in terms of catalysis and regulation.
MISC	It required higher concentrations of 3-PGA for activation and was more sensitive to Pi inhibition.
OWNX	These results suggested that LS was essential for the enzyme to function efficiently CITATION, CITATION, CITATION.
MISC	Alternatively, recent studies have indicated that the LS may bind to substrates glucose-1 phosphate and ATP.
MISC	The binding of the LS to substrates may allow the LS to interact cooperatively with the catalytic SS in binding substrates and effectors and, in turn, influence net catalysis CITATION, CITATION CITATION.
OWNX	In addition, specific regions from both the LS and the SS were found to be important for subunit association and enzyme stability CITATION.
OWNX	Also, using chimeric maize/potato small subunits, Cross et al. CITATION found a polymorphic motif in the SS which is critical for subunit interaction.
MISC	They have concluded that a 55-amino acid region between the residues 322 376 directly interacts with LS and significantly contributes to the overall enzyme stability.
MISC	Recently crystal structure of SS was found in a homotetrameric form by Jin et al. CITATION.
MISC	Neither the LS nor the heterotetrameric AGPase structure have been solved yet.
OWNX	This is due to the difficulty of obtaining AGPase in stable form.
MISC	However, it is critical to elucidate the native heterotetrameric AGPase structure and identify the key residues taking place in subunit-subunit interactions to obtain a more detailed picture of the enzyme.
MISC	Understanding the structure and the hot spot residues in the subunit interface will enable us to manipulate the native enzyme to get a stable form which can be utilized for improving the yield of crops.
MISC	The feasibility of such an approach has been shown previously CITATION, CITATION.
MISC	We modeled the LS structure of potato tuber AGPase and proposed a model for the heterotetrameric AGPase CITATION.
OWNX	In this study, we extended our previous work by examining our AGPase model to identify important residues mediating the interactions between the LS and the SS both by computational and experimental techniques.
OWNX	Based on Molecular mechanics generalized born surface area method, two distinct LS domains are involved in LS-SS subunit interaction.
MISC	The residues of the potato AGPase LS Asn 97, Pro 327, Ile 330, Ile 335, Ile 339, Ile 340, and His 342 are involved in lateral interaction with the potato AGPase SS whereas residues Arg 45, Arg 88, Arg 92, and Trp 135 are involved in longitudinal interaction with the potato AGPase SS.
MISC	The effect of these mutations on the interactions of the LS and the SS of potato AGPase were further characterized in vivo using the bacterial complementation and the yeast two-hybrid methods.
MISC	Also, experimental results indicated that the backbone G binding energy of the interface amino acids is a decisive parameter for the subunit-subunit interaction rather than side chain G binding or total G binding energies.
OWNX	This study will highlight the important structural aspects of AGPase structure and provide insights for further attempts to engineer a more functional form of the enzyme.
OWNX	The purpose of this note is to show how the method of maximum entropy in the mean (MEM) may be used to improve parametric estimation when the measurements are corrupted by large level of noise
OWNX	The method is developed in the context on a concrete example: that of estimation of the parameter in an exponential distribution
OWNX	We compare the performance of our method with the bayesian and maximum likelihood approaches
MISC	Suppose that you want to measure the half-life of a decaying nucleus or the life-time of some elementary particle, or some other random variable modeled by an exponential distribution describing, say a decay time or the life time of a process
MISC	Assume as well that the noise in the measurement process can be modeled by a centered gaussian random variable whose variance may be of the same order of magnitude as that of the decay rate to be measured
MISC	To make things worse, assume that you can only collect very few measurements
MISC	That is if  SYMBOL  denotes the realized value of the variable, one can only measure  SYMBOL , for  SYMBOL , where  SYMBOL  is a small mumbler, say  SYMBOL  or  SYMBOL  and  SYMBOL  denotes the additive measurement noise
MISC	In other words, assume that you know that the sample comes from a specific parametric distribution but is contaminated by additive noise
MISC	What to do
MISC	One possible approach is to apply small sample statistical estimation procedures
CONT	But these are designed for problems where the variability is due only to the random nature of the quantity measured,and there is no other noise in the measurement  Still another possibility, the one we that to explore here, is to apply a maxentropic filtering method,  to estimate both the unknown variable and the noise level
OWNX	For this we recast the problem as a typical inverse problem consisting of solving for  SYMBOL  in  SYMBOL }   where  SYMBOL  is a convex set in  SYMBOL ,  SYMBOL  and for some  SYMBOL  and  SYMBOL , and  SYMBOL  is an  SYMBOL -matrix which depends on how we rephrase the our problem
MISC	We could, for example, consider the following problem: Find  SYMBOL  such that   SYMBOL }  In our case  SYMBOL , and we set  SYMBOL  Or we could consider a collection of  SYMBOL  such problems, one for every measurement, and then proceed to carry on the estimation
MISC	Once we have solved the generic problem (), the variations on the theme are easy to write down
OWNX	What is important to keep in mind here, is that the output of the method is a filtered estimator  SYMBOL  of  SYMBOL  which itself is an estimator of the unknown parameter
OWNX	The novelty then is to filter out the noise in ()
OWNX	The method of maximum entropy in the mean is rather well suited for solving problems like (1)
OWNX	See Navaza (1986) for an early development and Dacunha-Castele and Camboa (1990) for full mathematical treatment
OWNX	Below we shall briefly review what the method is about and then apply it to  obtain an estimator  SYMBOL  from ()
OWNX	In section 3  obtain the maxentropic estimator and in section 4 we examine some of its properties, in particular we examine what the results would be if either the noise level were small or the number of measurements were large
OWNX	We devote section 4 to some simulations in which the method is compared with a bayesian and a maximum likelihood approaches
OWNX	The role that mechanistic mathematical modeling and systems biology will play in molecular medicine and clinical development remains uncertain.
MISC	In this study, mathematical modeling and sensitivity analysis were used to explore the working hypothesis that mechanistic models of human cascades, despite model uncertainty, can be computationally screened for points of fragility, and that these sensitive mechanisms could serve as therapeutic targets.
MISC	We tested our working hypothesis by screening a model of the well-studied coagulation cascade, developed and validated from literature.
OWNX	The predicted sensitive mechanisms were then compared with the treatment literature.
MISC	The model, composed of 92 proteins and 148 protein protein interactions, was validated using 21 published datasets generated from two different quiescent in vitro coagulation models.
MISC	Simulated platelet activation and thrombin generation profiles in the presence and absence of natural anticoagulants were consistent with measured values, with a mean correlation of 0.87 across all trials.
OWNX	Overall state sensitivity coefficients, which measure the robustness or fragility of a given mechanism, were calculated using a Monte Carlo strategy.
OWNX	In the absence of anticoagulants, fluid and surface phase factor X/activated factor X activity and thrombin-mediated platelet activation were found to be fragile, while fIX/FIXa and fVIII/FVIIIa activation and activity were robust.
MISC	Both anti-fX/FXa and direct thrombin inhibitors are important classes of anticoagulants; for example, anti-fX/FXa inhibitors have FDA approval for the prevention of venous thromboembolism following surgical intervention and as an initial treatment for deep venous thrombosis and pulmonary embolism.
MISC	Both in vitro and in vivo experimental evidence is reviewed supporting the prediction that fIX/FIXa activity is robust.
MISC	When taken together, these results support our working hypothesis that computationally derived points of fragility of human relevant cascades could be used as a rational basis for target selection despite model uncertainty.
OWNX	The role that mechanistic mathematical modeling and systems biology will play in molecular medicine and clinical development remains uncertain.
OWNX	Kitano suggested that understanding of critical questions in biology required the integration of experimental and computational research CITATION.
MISC	Assmus et al. and others maintained that analysis of the dynamics of human relevant networks using predictive computer models and high-throughput data generation would play an increasingly important role in medical research and the elucidation of disease mechanisms CITATION, CITATION.
MISC	However, parametric and structural uncertainty remains an open challenge to mechanistic modeling in medicine.
MISC	Strategies that integrate experimental and computational techniques have had success at elucidating network structures.
MISC	Arm and Arkin reviewed experimental and computational techniques to uncover molecular interaction networks CITATION.
MISC	The central experimental advancements in the area of protein protein network identification have been the yeast two-hybrid system CITATION, CITATION and quantitative mass spectrometry proteomic techniques to determine protein complexes CITATION, CITATION.
MISC	Young and coworkers explored protein DNA interactions using the chromatin immunoprecipitation technique CITATION where likely transcription factor binding sites were determined using a combination of chromatin immunoprecipitation chips and DNA microarrays.
MISC	Time-lagged correlation matrices CITATION, CITATION, genetic programming techniques CITATION, and network decomposition strategies have also been used with time-series concentration measurements to estimate reaction network structures CITATION .
MISC	Sensitivity analysis has been used to integrate model identification and discrimination with optimal experimental design and knowledge discovery.
MISC	Cho et al. used sensitivity analysis to study TNF- mediated NF B signalling where parametric uncertainty was addressed using Monte Carlo sensitivity analysis; using the best-guess parameter set, a family of random parameter sets was generated where sensitivity coefficients were calculated for each member of the random family CITATION.
MISC	Cho et al. went on to develop a unifying framework, building upon the earlier work of Kholodenko et al. and Sontag et al. to unravel the functional interactions in biomolecular networks using a stimulus response strategy and metabolic control analysis CITATION CITATION.
MISC	Kremling et al. investigated the benchmark problem of growth of a microorganism in a continuous bioreactor subject to feed shifts using sensitivity-based model identification and discrimination strategies; they determined optimal experimental design and perturbation strategies to identify and discriminate between rival model formulations CITATION.
OWNX	Gadkar et al. identified signal transduction models from time-course measurements using a nonlinear scheme to estimate missing protein measurements from measured values CITATION.
MISC	They went further and proposed strategies to calculate D-optimal experimental designs that maximized the experimental information used to identify signal transduction models as well as an iterative strategy to explore model structure CITATION, CITATION.
MISC	Sensitivity analysis has also been used to explore the robustness and fragility of metabolic and signaling networks.
MISC	Robustness, the ability to maintain system performance in the face of perturbation and uncertainty, is a desirable feature in both biological as well as man-made networks, machines, and systems CITATION.
MISC	Conversely, fragility, i.e., extreme sensitivity to small perturbations, is a very undesirable trait that could lead to catastrophic system failure following seemingly innocuous perturbations, e.g., a Boeing 777 crashing because of minor software failures or microscopic alterations in a few integrated chips CITATION.
MISC	Stelling et al. reviewed several examples of robustness in biological networks CITATION, while Leibler first computationally predicted and later experimentally verified robust features of chemotaxis control networks CITATION, CITATION.
MISC	Bullinger and coworkers explored the robustness of models of programmed cell death or apoptosis CITATION, while Stelling et al. computationally identified points of robustness and fragility, using Monte Carlo sensitivity analysis and overall state sensitivity coefficients, in models of circadian rhythm CITATION .
AIMX	In this study, we use tools from systems biology, namely mathematical modeling and sensitivity analysis, to explore the working hypothesis that mechanistic models of human relevant cascades, despite model uncertainty, can be computationally screened for points of fragility, i.e., sensitive mechanisms, and that these mechanisms could serve as a rational basis for therapeutic target selection.
MISC	We test our working hypothesis by computationally screening a mechanistic model of the well-studied coagulation cascade developed and validated from literature sources.
MISC	After model validation, using 21 published datasets generated from two different quiescent in vitro coagulation models, we use Monte Carlo sensitivity analysis to computationally screen the model for sensitive mechanisms in the presence and absence of natural anticoagulants.
MISC	We then contrast the predicted fragile mechanisms with literature to determine if they are consistent with experimental investigation, thereby proving or disproving our working hypothesis.
MISC	While the current development is restricted to coagulation, the broader strategy is general and could be applied to an arbitrary network.
MISC	Coagulation, mediated by a family of serine proteases and a key group of blood cells, both of which are normally inactive in the circulation, is directly relevant to human health and has been suggested by Somogyi and Greller to be an ideal candidate for in silico drug discovery CITATION.
MISC	Insufficient coagulation is manifested in disorders such as haemophilia A, haemophilia B, or von Willebrand disease CITATION, CITATION.
MISC	Conversely, unwanted clotting can be a serious complication following surgical intervention and is directly involved in coronary artery diseases, which collectively account for 38 percent of all deaths in North America CITATION .
OWNX	The salient features of the coagulation cascade included in our model, shown schematically in Figure 1 and presented in detail in Table 1, are reviewed here.
OWNX	Several extensive reviews of the underlying biochemistry and cell biology of coagulation can be found elsewhere CITATION CITATION.
OWNX	There are two pathways that lead to activation of the master protease thrombin and eventually to a clot the intrinsic and extrinsic cascades.
MISC	It is generally believed that the extrinsic cascade is the main mechanism of thrombinogenesis in the blood CITATION CITATION.
OWNX	Upstream coagulation factors are activated by materials exposed because of vessel injury chief among these tissue factors CITATION ; TF and activated factor VIIa present in the blood form a complex that activates factor X and fIX.
OWNX	FXa activates downstream factors, including fV, fVIII, and fIX.
OWNX	FXa can also, along with FVa, form a complex on the surface of activated platelets that converts prothrombin to thrombin.
MISC	TF FVIIa is not the only mechanism to activate fX; FIXa and FVIIIa can complex on the surface of activated platelets and catalyze the formation of FXa.
CONT	Platelet localization at the wound site occurs through specific interactions between the platelet and the subendothelium, primarily through recognition of exposed materials such as collagen, fibronectin, and von Willebrand factor.
MISC	Localized platelets are activated by external signals such as adenosine diphosphate and thrombin.
MISC	Thrombin irreversibly activates platelets through a family of transmembrane receptors on the platelet surface called protease-activated receptors CITATION, CITATION.
MISC	Thrombin, in addition to playing a key role in platelet activation, catalyzes the conversion of fibrinogen to fibrin.
MISC	Fibrin, with the help of FVIIIa, forms a cross-linked mesh inside the platelet plug that stops blood flow.
OWNX	Thrombin also activates upstream coagulation factors, thereby forming a strong positive feedback that ensures rapid activation.
MISC	Three control points that inhibit thrombin formation are considered in the model.
OWNX	TF pathway inhibitor downregulates FXa formation and activity by sequestering free FXa and TF FVIIa in an FXa-dependent manner.
MISC	Antithrombin III neutralizes all serine proteases generated during the coagulation response, making it perhaps the most powerful control element in the cascade.
MISC	Thrombin itself plays an inadvertent role in its own inhibition by binding the surface protein thrombomodulin, expressed on normal vasculature CITATION.
MISC	The FIIa TM complex catalyzes the conversion of protein C to activated PC ; APC attenuates the coagulation response by the proteolytic cleavage of fV/FVa and fVIII/FVIIIa CITATION .
OWNX	Minimizing the rank of a matrix subject to affine constraints is a fundamental problem with many important applications in machine learning and statistics
AIMX	In this paper we propose a simple and fast algorithm  SYMBOL  (Singular Value Projection) for rank minimization with affine constraints ( SYMBOL ) and show that SVP recovers the minimum rank solution for affine constraints that satisfy the {restricted isometry property}
OWNX	We show robustness of our method to noise with a strong geometric convergence rate even for noisy measurements
OWNX	Our results improve upon a recent breakthrough by Recht, Fazel and Parillo  CITATION  and Lee and Bresler  CITATION  in three significant ways: 1) our method ( SYMBOL ) is significantly simpler to analyze and easier to implement, 2) we give recovery guarantees under strictly weaker isometry assumptions 3) we give geometric convergence guarantees for   SYMBOL  and, as demonstrated empirically,  SYMBOL  is significantly faster on real-world and synthetic problems
OWNX	In addition, we address the practically important problem of low-rank matrix completion, which can be seen as a special case of  SYMBOL
MISC	However, the affine constraints defining the matrix-completion problem do not obey the {restricted isometry property} in general
OWNX	We empirically demonstrate that our algorithm recovers low-rank {incoherent} matrices from an almost optimal number of uniformly sampled entries
OWNX	We make partial progress towards proving exact recovery and provide some intuition for the performance of  SYMBOL  applied to matrix completion by showing a more restricted isometry property
MISC	Our algorithm outperforms existing methods, such as those of  CITATION , for  SYMBOL  and the matrix-completion problem by an order of magnitude and is also significantly more robust to noise
AIMX	In this paper we study the general affine rank minimization problem (ARMP), \renewcommand{\theequation}{ARMP}  SYMBOL } \renewcommand{\theequation}{\arabic{equation}} \addtocounter{equation}{-1} where  SYMBOL   is an affine transformation from  SYMBOL  to  SYMBOL
OWNX	The general affine rank minimization problem is of considerable practical interest and many important machine learning problems such as matrix completion, low-dimensional metric embedding, low-rank kernel learning can be viewed as instances of the above problem
MISC	Unfortunately, ARMP is NP-hard in general and is also NP-hard to approximate ( CITATION )
MISC	Until recently, most known methods for  SYMBOL  were heuristic in nature with few known rigorous guarantees
MISC	The most commonly used heuristic for the problem is to assume a factorization of  SYMBOL  and optimize the resulting non-convex problem by alternating minimization  CITATION , alternative projections  CITATION  or alternating LMIs  CITATION
MISC	Another common approach is to relax the rank constraint to a convex function such as the trace-norm or the log determinant  CITATION ,  CITATION
MISC	However, most of these methods do not have any optimality guarantees
MISC	Recently, Meka et al CITATION  proposed online learning based methods for ARMP
MISC	However, their methods can only guarantee at best a logarithmic approximation for the minimum rank
MISC	In a recent breakthrough, Recht et al ~ CITATION  obtained the first nontrivial exact-recovery results for  SYMBOL  obtaining guaranteed rank minimization for affine transformations  SYMBOL  that satisfy a {restricted isometry property} ( SYMBOL )
MISC	Define the isometry constant of  SYMBOL ,  SYMBOL  to be the smallest number such that for all  SYMBOL  of rank at most  SYMBOL ,   SYMBOL }  Recht et al ~show that for affine constraints with bounded isometry constants (specifically,  SYMBOL ), finding the minimum trace-norm solution recovers the minimum rank solution
MISC	Their results were later extended to noisy measurements and isometry constants up to  SYMBOL  by Lee and Bresler  CITATION
MISC	However, even the best existing optimization algorithms for the trace-norm relaxation are relatively inefficient in practice and their results are hard to analyze
MISC	In another recent work, Lee and Bresler  CITATION  obtained exact-recovery guarantees for  SYMBOL  satisfying  SYMBOL  using a different approach
MISC	Lee and Bresler propose an algorithm (ADMiRA) motivated by the {orthogonal matching pursuit} line of work in compressed sensing, and show that for affine constraints with isometry constant  SYMBOL  their algorithm recovers the optimal solution
MISC	They also prove similar guarantees for noisy measurements and provide a geometric convergence rate for their algorithm
OWNX	However, their method is not very efficient for large datasets and is hard to analyze
OWNX	In this paper we propose a simple and fast algorithm  SYMBOL  (Singular Value Projection) based on the classical projected gradient algorithm
OWNX	We present a simple analysis showing that  SYMBOL  recovers the minimum rank solution for affine constraints that satisfy  SYMBOL  even in the presence of noise and prove the following guarantees
OWNX	Independent of our work, Goldfarb and Ma  CITATION  proposed an algorithm similar to our algorithm
MISC	However, their analysis and formulation is different from ours
MISC	In particular, their analysis builds on the analysis of Lee and Bresler and they require stronger isometry assumptions,  SYMBOL , than we do
OWNX	In addition, we make partial progress on analyzing  SYMBOL  for the matrix completion problem and proving exact recovery
MISC	Our analysis of  SYMBOL  is motivated by the recent work in the field of compressed sensing by Blumensath and Davies  CITATION , Garg and Khandekar  CITATION
MISC	Our results improve the results of Recht et al ~and Lee and Bresler as follows
MISC	SYMBOL  is considerably simpler to analyze than the methods of Recht et al ~and Lee and Bresler
MISC	Further, we need weaker isometry assumptions on  SYMBOL : we only require  SYMBOL  as opposed to  SYMBOL  required by Recht et al ,  SYMBOL  required by Lee and Bresler  CITATION  and  SYMBOL  required by Lee and Bresler  CITATION
MISC	SYMBOL  has a strong geometric convergence rate and is faster than using the best trace-norm optimization algorithms and the methods of Lee and Bresler by an order of magnitude
MISC	Although restricted isometry property is natural in settings where the affine constraints contain information about all the entries of the unknown matrix, in several cases of considerable practical interest the affine constraints only contain {local information} and may not satisfy  SYMBOL  directly
OWNX	One such important problem where  SYMBOL  does not hold directly is the low-rank matrix completion problem
OWNX	In the matrix completion problem we are given the entries of an unknown low-rank matrix  SYMBOL  for ordered pairs  SYMBOL  and the goal is to complete the missing entries of  SYMBOL
OWNX	A highly popular application of the matrix completion problem is in the field of collaborative filtering, where typically the task is to predict user ratings given past ratings of the users
MISC	Recently, a lot of attention has been given to the problem  due to the Netflix Challenge  CITATION
MISC	Other applications of matrix completion include triangulation from incomplete data, link prediction in social networks etc
MISC	Similar to  SYMBOL , the low-rank matrix completion is also NP-hard in general and most methods are heuristic in nature with no theoretical guarantees
MISC	The alternating least squares minimization heuristic and its variants  CITATION  perform the best in practice but are notoriously hard to analyze
MISC	Recently, Candes and Recht  CITATION , Candes and Tao  CITATION  and Keshavan et al ~ CITATION  obtained the first non-trivial results for low-rank matrix completion under a few additional assumptions
MISC	Broadly, these papers give exact-recovery guarantees when the optimal solution  SYMBOL  is  SYMBOL -{incoherent} (see Definition ), and the entries  SYMBOL  are chosen uniformly at random with  SYMBOL , where  SYMBOL  depends only on  SYMBOL
CONT	However, the algorithms of the above papers, even when using methods tailored specifically for matrix-completion such as those of Cai et al ~ CITATION , are quite expensive in practice and not very tolerant to noise
OWNX	As low-rank matrix completion is a special case of  SYMBOL , we can naturally adapt our algorithm  SYMBOL  for matrix completion
OWNX	We demonstrate empirically that for a suitable step-size,  SYMBOL  significantly outperforms the methods of  CITATION ,  CITATION ,  CITATION ,  CITATION  in accuracy, computational time and tolerance to noise
MISC	Furthermore, our experiments strongly suggest (see Figure~) that guarantees similar to those of  CITATION ,  CITATION  hold for  SYMBOL , achieving exact recovery for incoherent matrices from an almost optimal number of entries
OWNX	Although we do not provide a rigorous proof of exact-recovery for  SYMBOL  applied to matrix completion, we make partial progress in this direction and give strong intuition for the performance of  SYMBOL
MISC	We prove that though the affine constraints defining the matrix-completion problems do not obey the restricted isometry property, they obey the restricted isometry property over incoherent matrices
OWNX	This weaker  SYMBOL  condition along with a hypothesis bounding the incoherence of the iterates of  SYMBOL  imply exact-recovery of a low-rank incoherent matrix from an almost optimal number of entries
OWNX	We also provide strong empirical evidence supporting our hypothesis bounding the incoherence of the iterates of  SYMBOL  (see Figure ) }  We first present our algorithm  SYMBOL  in Section~ and present its analysis for affine constraints satisfying  SYMBOL  in Section~
OWNX	In Section~, we specialize our algorithm  SYMBOL  to the task of low-rank matrix completion and prove a more restricted isometry property for the matrix completion problem
OWNX	In Section~, we give empirical results for  SYMBOL  applied to  SYMBOL  and matrix-completion on real-world and synthetic problems
AIMX	In this paper, we consider the coherent theory of (epistemic) uncertainty of Walley, in which beliefs are represented through sets of probability distributions, and we focus on the problem of modeling prior ignorance about a categorical random variable
OWNX	In this setting, it is a known result that a state of prior ignorance is not compatible with learning
MISC	To overcome this problem, another state of beliefs, called  near-ignorance , has been proposed
MISC	Near-ignorance resembles ignorance very closely, by satisfying some principles that can arguably be regarded as necessary in a state of ignorance, and allows learning to take place
MISC	What this paper does, is to provide new and substantial evidence that also near-ignorance cannot be really regarded as a way out of the problem of starting statistical inference in conditions of very weak beliefs
MISC	The key to this result is focusing on a setting characterized by a variable of interest that is  latent
MISC	We argue that such a setting is by far the most common case in practice, and we provide, for the case of categorical latent variables (and general  manifest  variables) a condition that, if satisfied, prevents learning to take place under prior near-ignorance
MISC	This condition is shown to be easily satisfied even in the most common statistical problems
OWNX	We regard these results as a strong form of evidence against the possibility to adopt a condition of prior near-ignorance in real statistical problems
MISC	Epistemic theories of statistics are often confronted with the question of  prior ignorance
MISC	Prior ignorance means that a subject, who is about to perform a statistical analysis, is missing substantial beliefs about the underlying data-generating process
MISC	Yet, the subject would like to exploit the available sample to draw some statistical conclusion, i e , the subject would like to use the data to learn, moving away from the initial condition of ignorance
MISC	This situation is very important as it is often desirable to start a statistical analysis with weak assumptions about the problem of interest, thus trying to implement an objective-minded approach to statistics
MISC	A fundamental question is whether prior ignorance is compatible with learning or not
OWNX	Walley gives a negative answer for the case of his self-consistent (or  coherent ) theory of statistics based on the modeling of beliefs through sets of probability distributions
OWNX	He shows, in a very general sense, that  vacuous  prior beliefs, i e , beliefs that a priori are maximally imprecise, lead to vacuous posterior beliefs, irrespective of the type and amount of observed data  CITATION
MISC	At the same time, he proposes focusing on a slightly different state of beliefs, called  near-ignorance , that does enable learning to take place  CITATION
MISC	Loosely speaking, near-ignorant beliefs are beliefs that are vacuous for a proper subset of the functions of the random variables under consideration (see Section~)
MISC	In this way, a near-ignorance prior still gives one the possibility to express vacuous beliefs for some functions of interest, and at the same time it maintains the possibility to learn from data
MISC	The fact that learning is possible under prior near-ignorance is shown, for instance, in the special case of the  imprecise Dirichlet model  (IDM)  CITATION
MISC	This is a popular model, based on a near-ignorance set of priors, used in the case of inference from categorical data generated by a multinomial process
MISC	Our aim in this paper is to investigate whether near-ignorance can be really regarded as a possible way out of the problem of starting statistical inference in conditions of very weak beliefs
MISC	We carry out this investigation in a setting made of categorical data generated by a multinomial process, like in the IDM, but we consider near-ignorance sets of priors in general, not only that used in the IDM
MISC	The interest in this investigation is motivated by the fact that near-ignorance sets of priors appear to play a crucially important role in the question of modeling prior ignorance about a categorical random variable
MISC	The key point is that near-ignorance sets of priors can be made to satisfy two principles: the  symmetry  and the  embedding principles
OWNX	The first is well known and is equivalent to Laplace's  indifference principle ; the second states, loosely speaking, that if we are ignorant a priori, our prior beliefs on an event of interest should not depend on the space of possibilities in which the event is embedded (see Section~ for a discussion about these two principles)
MISC	Walley  CITATION , and later de Cooman and Miranda  CITATION , have argued extensively on the necessity of both the symmetry and the embedding principles in order to characterize a condition of ignorance about a categorical random variable
MISC	This implies, if we agree that the symmetry and the embedding principles are necessary for ignorance, that near-ignorance sets of priors should be regarded as an especially important avenue for a subject who wishes to learn starting in a condition of ignorance
MISC	Our investigation starts by focusing on a setting where the categorical variable  SYMBOL  under consideration is  latent
MISC	This means that we cannot observe the realizations of  SYMBOL , so that we can learn about it only by means of another, not necessarily categorical, variable  SYMBOL , related to  SYMBOL  through a known conditional probability distribution  SYMBOL
MISC	Variable  SYMBOL  is assumed to be  manifest , in the sense that its realizations can be observed (see Section~)
MISC	The intuition behind the setup considered, made of  SYMBOL  and  SYMBOL , is that in many real cases it is not possible to directly observe the value of a random variable in which we are interested, for instance when this variable represents a patient's health and we are observing the result of a diagnostic test
MISC	In these cases, we need to use a manifest variable (the medical test) in order to obtain information about the original latent variable (the patient's health)
OWNX	In this paper, we regard the passage from the latent to the manifest variable as made by a process that we call the  observational process
OWNX	Using the introduced setup, we give a condition in Section~, related to the likelihood function, that is shown to be sufficient to prevent learning about  SYMBOL  under prior near-ignorance
OWNX	The condition is very general as it is developed for any set of priors that models near-ignorance (thus including the case of the IDM), and for very general kinds of probabilistic relations between  SYMBOL  and  SYMBOL
MISC	We show then, by simple examples, that such a condition is easily satisfied, even in the most elementary and common statistical problems
MISC	In order to fully appreciate this result, it is important to realize that latent variables are ubiquitous in problems of uncertainty
AIMX	The key point here is that the scope of observational processes greatly extends if we consider that even when we directly obtain the value of a variable of interest, what we actually obtain is the observation of the value rather than the value itself
MISC	Doing this distinction makes sense because in practice an observational process is usually imperfect, i e , there is very often (it could be argued that there is always) a positive probability of confounding the realized value of  SYMBOL  with another possible value committing thus an observation error
MISC	Of course, if the probability of an observation error is very small and we consider one of the common Bayesian model proposed to learn under prior ignorance, then there is little difference between the results provided by a latent variable model modeling correctly the observational process, and the results provided by a model where the observations are assumed to be perfect
MISC	For this reason, the observational process is often neglected in practice and the distinction between the latent variable and the manifest one is not enforced
MISC	But, on the other hand, if we consider sets of probability distributions to model our prior beliefs, instead of a single probability distribution, and in particular if we consider near-ignorance sets of priors, then there can be an extreme difference between a latent variable model and a model where the observations are considered to be perfect, so that learning may be impossible in the first model and possible in the second
MISC	As a consequence, when dealing with sets of probability distributions, neglecting the observational process may be no longer justified even if the probability of observation error is tiny
OWNX	This is shown in a definite sense in Example~ of Section~, where we analyze the relevance of our results for the special case of the IDM
OWNX	From the proofs in this paper, it follows that this kind of behavior is mainly determined by the presence, in the near-ignorance set of priors, of extreme, almost-deterministic, distributions
MISC	And the question is that these problematic distributions, which are usually not considered when dealing with Bayesian models with a single prior, cannot be ruled out without dropping near-ignorance
OWNX	These considerations highlight the quite general applicability of the present results and raise hence serious doubts about the possibility to adopt a condition of prior near-ignorance in real, as opposed to idealized, applications of statistics
MISC	As a consequence, it may make sense to consider re-focusing the research about this subject on developing models of very weak states of belief that are, however, stronger than near-ignorance
MISC	This might also involve dropping the idea that both the symmetry and the embedding principles can be realistically met in practice
MISC	Computational efforts to identify functional elements within genomes leverage comparative sequence information by looking for regions that exhibit evidence of selective constraint.
MISC	One way of detecting constrained elements is to follow a bottom-up approach by computing constraint scores for individual positions of a multiple alignment and then defining constrained elements as segments of contiguous, highly scoring nucleotide positions.
AIMX	Here we present GERP, a new tool that uses maximum likelihood evolutionary rate estimation for position-specific scoring and, in contrast to previous bottom-up methods, a novel dynamic programming approach to subsequently define constrained elements.
MISC	GERP evaluates a richer set of candidate element breakpoints and ranks them based on statistical significance, eliminating the need for biased heuristic extension techniques.
OWNX	Using GERP we identify over 1.3 million constrained elements spanning over 7 percent of the human genome.
MISC	We predict a higher fraction than earlier estimates largely due to the annotation of longer constrained elements, which improves one to one correspondence between predicted elements with known functional sequences.
OWNX	GERP is an efficient and effective tool to provide both nucleotide- and element-level constraint scores within deep multiple sequence alignments.
MISC	The identification and annotation of all functional elements in the human genome is one of the main goals of contemporary genetics in general, and the ENCODE project in particular CITATION, CITATION, CITATION.
MISC	Comparative sequence analysis, enabled by multiple sequence alignments of the human genome to dozens of mammalian species, has become a powerful tool in the pursuit of this goal, as sequence conservation due to negative selection is often a strong signal of biological function.
OWNX	After constructing a multiple sequence alignment, one can quantify evolutionary rates at the level of individual positions and identify segments of the alignment that show significantly elevated levels of conservation.
CONT	Several computational methods for constrained element detection have been developed, with most falling into one of two broad categories: generative model-based approaches, which attempt to explicitly model the quantity and distribution of constraint within an alignment, and bottom-up approaches, which first estimate constraint at individual positions and then look for clusters of highly constrained positions.
MISC	A widely used generative approach, phastCons CITATION, uses a phylo-Hidden Markov Model to find the most likely parse of the alignment into constrained and neutral hidden states.
MISC	While HMMs are widely used in modeling biological sequences, they have known drawbacks: transition probabilities imply a specific geometric state duration distribution, which in the context of phastCons means predicted constrained and neutral segment length.
MISC	This may bias the resulting estimates of element length and total genomic fraction under constraint.
MISC	One of the leading bottom-up approaches is GERP CITATION, which quantifies position-specific constraint in terms of rejected substitutions, the difference between the neutral rate of substitution and the observed rate as estimated by maximum likelihood, and heuristically extends contiguous segments of constrained positions in a BLAST-like CITATION manner.
CONT	However, GERP is computationally slow because its maximum likelihood computation uses the Expectation Maximization algorithm CITATION to estimate a new set of branch lengths for each position of the alignment; this step is also undesirable methodologically because it involves estimating k real-valued parameters from k nucleotides of data.
MISC	Furthermore, the extension heuristic used by GERP may induce biases in the length of predicted CEs.
OWNX	In this work we present GERP, a novel bottom-up method for constrained element detection that like GERP uses rejected substitutions as a metric of constraint.
MISC	GERP uses a significantly faster and more statistically robust maximum likelihood estimation procedure to compute expected rates of evolution that results in a more than 100-fold reduction in computation time.
OWNX	In addition, we introduce a novel criterion of grouping constrained positions into constrained elements using statistical significance as a guide and assigning p-values to our predictions.
MISC	We apply a dynamic programming approach to globally predict a set of constrained elements ranked by their p-values and a concomitant false positive rate estimate.
OWNX	Using GERP we analyzed an alignment of the human genome and 33 other mammalian species, identifying over 1.3 million constrained elements spanning over 7 percent of the human genome with high confidence.
MISC	Compared to previous methods, we predict a larger fraction of the human genome to be contained in constrained elements due to the annotation of many fewer but longer elements, with a very low false positive rate.
MISC	In many fields where human understanding plays a crucial role, such as bioprocesses, the capacity of extracting knowledge from data is of critical importance
MISC	Within this framework, fuzzy learning methods, if properly used, can greatly help human experts
MISC	Amongst these methods, the aim of orthogonal transformations, which have been proven to be mathematically robust, is to build rules from a set of training data and to select the most important ones by linear regression or rank revealing techniques
MISC	The OLS algorithm is a good representative of those methods
MISC	However, it was originally designed so that it only cared about numerical performance
OWNX	Thus, we propose some modifications of the original method to take interpretability into account
OWNX	After recalling the original algorithm, this paper presents the changes made to the original method, then discusses some results obtained from benchmark problems
OWNX	Finally, the algorithm is applied to a real-world fault detection depollution problem
MISC	Fuzzy learning methods, unlike ``black-box'' models such as neural networks, are likely to give interpretable results, provided that some constraints are respected
MISC	While this ability is somewhat meaningless in some applications such as stock market prediction, it becomes essential when human experts want to gain insight into a complex problem (e g industrial  CITATION  and biological  CITATION  processes, climate evolution  CITATION )
MISC	These considerations explain why interpretability issues in Fuzzy Modeling have become an important research topic, as shown in recent literature  CITATION
OWNX	Even so, the meaning given to interpretability in Fuzzy Modeling is not always the same
MISC	By interpretability, some authors mean mathematical interpretability, as in  CITATION  where a structure is developed in Takagi-Sugeno systems, that leads to the interpretation of every consequent polynomial as a Taylor series expansion about the rule center
MISC	Others mean linguistic interpretability, as in  CITATION ,  CITATION
OWNX	The present paper is focused on the latter approach
MISC	Commonly admitted requirements for interpretability are a small number of consistent membership functions and a reasonable number of rules in the fuzzy system
MISC	Orthogonal transformation methods provide a set of tools for building rules from data and selecting a limited subset of rules
OWNX	Those methods were originally designed for linear optimization, but subject to some conditions they can be used in fuzzy models
MISC	For instance, a zero order Takagi Sugeno model can be written as a set of r fuzzy rules, the  SYMBOL  rule being:   SYMBOL }  where  SYMBOL  are the fuzzy sets associated to the  SYMBOL  variables for that given rule, and  SYMBOL  is the corresponding crisp rule conclusion
MISC	Let  SYMBOL  be  SYMBOL  input-output pairs of a data set, where  SYMBOL  and  SYMBOL
MISC	For the  SYMBOL  pair, the above Takagi Sugeno model output is calculated as follows:  SYMBOL } In equation ,  SYMBOL  is the conjunction operator used to combine elements in the rule premise,  SYMBOL  represents, within the  SYMBOL  rule, the membership function value for  SYMBOL
OWNX	Let us introduce the rule firing strength  SYMBOL
OWNX	Thus equation  can be rewritten as:  SYMBOL }  Once the fuzzy partitions have been set, and provided a given data set, the  SYMBOL  can be computed for all  SYMBOL  in the data set
OWNX	Then equation  allows to reformulate the fuzzy model as a linear regression problem, written in matrix form as:  SYMBOL
OWNX	In that matrix form, y is the sample output vector, P is the firing strength matrix,  SYMBOL  is the rule consequent vector and E is an error term
MISC	Orthogonal transformation methods can then be used to determine the  SYMBOL  to be kept, and to assign them optimal values in order to design a zero order Takagi Sugeno model from the data set
MISC	A thorough review of the use of orthogonal transformation methods (SVD, QR, OLS) to select fuzzy rules  can be found in  CITATION
OWNX	They can be divided into two main families: the methods that select rules using the  SYMBOL  matrix decomposition only, and others that also use the output  SYMBOL  to do a best fit
MISC	The first family of methods (rank revealing techniques) is particularly interesting when the input fuzzy partitions include redundant or quasi redundant fuzzy sets
OWNX	The orthogonal least squares (OLS) technique belongs to the second family and allows a rule selection based on the rule respective contribution to the output inertia or variance
MISC	With respect to this criterion, it gives a good summary of the system to be modeled, which explains why it has been widely used in Statistics, and also why it is particularly suited for rule induction, as shown for instance in  CITATION
OWNX	The aim of the present paper is to establish, by using the OLS method as an example, that orthogonal transformation results can be made interpretable, without suffering too much loss of accuracy
OWNX	This is achieved by building interpretable fuzzy partitions  and by reducing the number of rule conclusions
OWNX	This turns orthogonal transformations into useful tools for modeling regression problems and extracting knowledge from data
OWNX	Thus they are worth a careful study as there are few available techniques for achieving this double objective, contrary to knowledge induction in classification problems
OWNX	In section , we recall how the original OLS works
OWNX	Section  introduces the learning criteria that will be used in our modified OLS algorithm
MISC	Section  presents the modifications necessary to respect the interpretability constraints
OWNX	In the next section, the modified algorithm is applied to benchmark problems, compared to the original one and to reference results found in the literature
OWNX	A real-world application is presented and analyzed in section
OWNX	Finally we give some conclusions and perspectives for future work
MISC	Reinforcement learning means learning a policy---a mapping of observations into actions---based on feedback from the environment
MISC	The learning can be viewed as browsing a set of policies while evaluating them by trial through interaction with the environment
MISC	We present an application of gradient ascent algorithm for reinforcement learning to a complex domain of packet routing in network communication and compare the performance of this algorithm to other routing methods on a benchmark problem
MISC	Successful telecommunication requires efficient resource allocation that can be achieved by developing adaptive control policies
MISC	Reinforcement learning ({rl})~ CITATION  presents a natural framework for the development of such policies by trial and error in the process of interaction with the environment
OWNX	In this work we apply the {rl} algorithm to network routing
OWNX	Effective network routing means selecting the optimal communication paths
MISC	It can be modeled as a multi-agent {rl} problem
MISC	In a sense, learning the optimal control for network routing could be thought of as learning in some traditional for {rl} episodic task, like maze searching or pole balancing, but repeating trials many times in parallel with interaction among trials
MISC	Under this interpretation, an individual router is an agent which makes its routing decisions according to an individual policy
MISC	The parameters of this policy are adjusted according to some measure of the global performance of the network, while control is determined by local observations
MISC	Nodes do not have any information regarding the topology of network or their position in it
MISC	The initialization of each node, as well as the learning algorithm it follows, are identical to that of every other node and independent of the structure of the network
MISC	There is no notion of orientation in space or other semantics of actions
MISC	Our approach allows us to update the local policies while avoiding the necessity for centralized control or global knowledge of the networks structure
MISC	The only global information required by the learning algorithm is the network utility expressed as a reward signal distributed once in an epoch and dependent on the average routing time
OWNX	This learning multi-agent system is biologically plausible and could be thought of as neural network in which each neuron only performs simple computations based on locally available quantities~ CITATION
OWNX	Many reinforcement learning exploration techniques are overly optimistic and try to explore every state
MISC	Such exploration is impossible in environments with the unlimited number of states
OWNX	I propose to use simulated exploration with an optimistic model to discover promising paths for real exploration
OWNX	This reduces the needs for the real exploration
MISC	In reinforcement learning CITATION  an agent collects rewards in an environment
MISC	The environment is not known in advance
MISC	The agent has to explore it to learn where to go
MISC	A reward could be received when taking an action in a state
MISC	The agent aims to maximize her long-term reward in the environment
MISC	She should not miss any state with an important reward or a shorter path to it
MISC	There are many existing exploration techniques CITATION  that are optimistic in the face of uncertainty
OWNX	Their optimism assumes that a greater reward will be obtained when taking an unknown action
MISC	The problem is how to do exploration in environments with the unlimited number of states
MISC	In these environments, it is not possible to try every action in every possible state
OWNX	I study a new way to do exploration in environments with the unlimited number of states
OWNX	I use simulated exploration as an incentive for real exploration
OWNX	The simulated exploration proposes promising paths to explore
OWNX	I describe how to use this kind of exploration in section
OWNX	My experiments in section  demonstrate how simulated exploration reduced the needed amount of real exploration
OWNX	I also discuss when it is possible
OWNX	Many works touched related problems
OWNX	They inspired me and I discuss them in section
OWNX	Walley's Imprecise Dirichlet Model (IDM) for categorical  iid  \ data extends the classical Dirichlet model to a set of priors
MISC	It overcomes several fundamental problems which other approaches to uncertainty suffer from
MISC	Yet, to be useful in practice, one needs efficient ways for computing the imprecise=robust sets or intervals
OWNX	The main objective of this work is to derive exact, conservative, and approximate, robust and credible interval estimates under the IDM for a large class of statistical estimators, including the entropy and mutual information
MISC	This work derives interval estimates under the Imprecise Dirichlet Model (IDM)  CITATION  for a large class of statistical estimators
OWNX	In the IDM one considers an  iid  \ process with unknown chances  SYMBOL  for outcome  SYMBOL
MISC	The prior uncertainty about  SYMBOL  is modeled by a set of Dirichlet priors  SYMBOL , where%  %  SYMBOL , and  SYMBOL  is a hyper-parameter, typically chosen between 1 and 2
MISC	Sets of probability distributions are often called Imprecise probabilities, hence the name IDM for this model
MISC	We avoid the term  imprecise  and use  robust  instead, or capitalize  Imprecise
MISC	The IDM overcomes several fundamental problems which other approaches to uncertainty suffer from  CITATION
MISC	For instance, the IDM satisfies the representation invariance principle and the symmetry principle, which are mutually exclusive in a pure Bayesian treatment with proper prior  CITATION
OWNX	SYMBOL  The counts  SYMBOL  for  SYMBOL  form a minimal sufficient statistic of the data of size  SYMBOL
MISC	Statistical estimators  SYMBOL  usually also depend on the chosen prior: so a set of priors leads to a set of estimators  SYMBOL
MISC	For instance, the expected chances  SYMBOL  lead to a robust interval estimate  SYMBOL
MISC	Robust intervals for the variance  SYMBOL   CITATION  and for the mean and variance of linear-combinations  SYMBOL  have also been derived  CITATION
OWNX	Bayesian estimators (like expectations) depend on  SYMBOL  and  SYMBOL  only through  SYMBOL  (and  SYMBOL  which we suppress), i e \  SYMBOL
OWNX	The main objective of this work is to derive approximate, conservative, and exact intervals  SYMBOL  for general  SYMBOL , and for the expected (also called predictive) entropy and the expected mutual information in particular
OWNX	These results are key building blocks for applying the IDM
MISC	Walley suggests, for instance, to use  SYMBOL  for inference problems and  SYMBOL  for decision problems  CITATION , where  SYMBOL  is some function of  SYMBOL
MISC	One application is the inference of robust tree-dependency structures  CITATION , in which edges are partially ordered based on Imprecise mutual information
OWNX	Section  gives a brief introduction to the IDM and describes our problem setup
OWNX	In Section  we derive exact robust intervals for concave functions  SYMBOL , such as the entropy
MISC	Section  derives approximate robust intervals for arbitrary  SYMBOL
OWNX	In Section  we show how bounds of elementary functions can be used to get bounds for composite function, especially for sums and products of functions
MISC	The results are used in Section  for deriving robust intervals for the mutual information
MISC	The issue of how to set up IDM models on product spaces is discussed in Section
MISC	Section  addresses the problem of how to combine Bayesian credible intervals with the robust intervals of the IDM
MISC	Conclusions are given in Section
OWNX	Appendix  lists properties of the  SYMBOL  function, which occurs in the expressions for the expected entropy and mutual information
OWNX	Appendix  contains a table of used notation
MISC	To maintain a stable intracellular environment, cells utilize complex and specialized defense systems against a variety of external perturbations, such as electrophilic stress, heat shock, and hypoxia, etc. Irrespective of the type of stress, many adaptive mechanisms contributing to cellular homeostasis appear to operate through gene regulatory networks that are organized into negative feedback loops.
MISC	In general, the degree of deviation of the controlled variables, such as electrophiles, misfolded proteins, and O 2, is first detected by specialized sensor molecules, then the signal is transduced to specific transcription factors.
MISC	Transcription factors can regulate the expression of a suite of anti-stress genes, many of which encode enzymes functioning to counteract the perturbed variables.
AIMX	The objective of this study was to explore, using control theory and computational approaches, the theoretical basis that underlies the steady-state dose response relationship between cellular stressors and intracellular biochemical species in these gene regulatory networks.
MISC	Our work indicated that the shape of dose response curves depends on changes in the specific values of local response coefficients distributed in the feedback loop.
MISC	Multimerization of anti-stress enzymes and transcription factors into homodimers, homotrimers, or even higher-order multimers, play a significant role in maintaining robust homeostasis.
MISC	Moreover, our simulation noted that dose response curves for the controlled variables can transition sequentially through four distinct phases as stressor level increases: initial superlinear with lesser control, superlinear more highly controlled, linear uncontrolled, and sublinear catastrophic.
MISC	Each phase relies on specific gain-changing events that come into play as stressor level increases.
MISC	The low-dose region is intrinsically nonlinear, and depending on the level of local gains, presence of gain-changing events, and degree of feedforward gene activation, this region can appear as superlinear, sublinear, or even J-shaped.
OWNX	The general dose response transition proposed here was further examined in a complex anti-electrophilic stress pathway, which involves multiple genes, enzymes, and metabolic reactions.
MISC	This work would help biologists and especially toxicologists to better assess and predict the cellular impact brought about by biological stressors.
MISC	Cells in vivo must maintain a relatively stable intracellular milieu in an extracellular environment that is constantly changing and is potentially unpredictable.
MISC	Notably, many intracellular biomolecules need to be held within closely regulated ranges of concentrations for normal cell functions.
MISC	Examples of these biochemical species, which could be detrimental and/or beneficial to cellular health, are electrophiles, reactive oxygen species, DNA adducts, misfolded proteins, O 2, and glucose.
MISC	When external stressors cause these molecules to deviate from their basal operating concentrations for an extended period of time, normal cell functions become disrupted, and cell cycle arrest and apoptosis may ensue CITATION.
MISC	Homeostatic regulation of vital intracellular biochemical species appears to operate primarily via gene regulatory networks that respond specifically to particular types of physical/chemical insults, such as electrophilic chemicals, heat shock, hypoxia, and hyperosmolarity CITATION CITATION.
MISC	As with many manmade control devices, such as thermostats and automobile cruise controls, these homeostatic gene regulatory networks are usually organized into negative feedback circuits that can be generalized into a common control scheme.
MISC	The output of the system, referred to as controlled variable, is the biochemical species that is perturbed by external stressors and therefore needs to be tightly controlled.
OWNX	The system contains specific transcription factors that serve as transducers to either directly or indirectly sense the level of the controlled variable.
OWNX	In this fashion, alterations in the concentration of the controlled variable affect the activity or abundance of the transcription factor.
MISC	Activated transcription factors then upregulate expression of individual or suites of anti-stress genes, many of which encode enzymes that participate in an array of interconnected biochemical reactions to counteract the perturbation of the controlled variable.
MISC	Control and dynamic system theory has benefited applied fields such as electronic and mechanical engineering for many decades, and in recent years increasing efforts have been made to apply similar concepts to biological systems including adaptive responses CITATION CITATION.
MISC	Our goal is to understand nature's design principle for anti-stress cellular homeostasis and to improve prediction of the disrupting effects of biological stressors.
OWNX	Of practical importance for risk assessment at the cellular level is the steady-state dose response relationship between stressor levels and various measurable biochemical endpoints including the controlled variables, transcription factors, and gene expression.
MISC	Cell responses in the low-dose region are particularly relevant to human health risk assessment, and it is traditionally difficult to explain and predict dose response behaviors in this region due to uncertainty and subtlety of the curvature.
MISC	To accurately describe and fully understand complex dose response behaviors, the underlying biochemical networks will have to be examined through quantitative models.
MISC	With respect to the mathematical approaches involved, theoretical development in quantitative analysis of controls in biochemical networks, including metabolic control analysis and biochemical systems theory, has proven to be of great value CITATION CITATION.
OWNX	Using numerical simulation and concepts from MCA, BST, and classical control theory, the present study focused on understanding the quantitative basis for the steady-state dose response in an anti-stress gene regulatory network.
MISC	While some of the conclusions presented in this paper may seem implicitly familiar, or even obvious, to engineers, they nonetheless provide an important framework by which biologists and especially toxicologists can improve the accuracy with which they evaluate the influence of biological stressors on intracellular control processes under different exposure conditions.
MISC	it has been proposed that recognition can form the basis of simple but ecologically rational decision strategies CITATION
MISC	borges  goldstein  ortmann  and gigerenzer CITATION found that constructing share portfolios based on simple name recognition alone often yielded better returns than the market index
MISC	we describe four studies with seven samples of participants from three countries total n    NUMBER  in which the returns of recognized and unrecognized shares from several stock markets were tracked over various periods of time
OWNX	we find no support for the claim that a simple strategy of name recognition can be used as a general strategy to select stocks that yield better-than-average returns
MISC	however  there was some suggestion in the data that recognition performs better when the market is falling and worse when it is rising
MISC	a follow-up study indicated that the absence of an overall recognition effect could not easily be attributed to our reliance on student participants or smaller samples than borges et al CITATION had used
MISC	we conclude that  with respect to changes in value  selecting stocks on the basis of name recognition is a near-random method of portfolio construction that offers little  if any  benefit to the personal investor
OWNX	can quick-and-dirty decisions reasonably be expected to result in satisfactory outcomes  or do complex problems demand complex strategies
MISC	the extent to which the array of difficult choices that we face can be adequately tackled by simple strategies has been a recurring theme in five decades of decision research  CITATION
MISC	one of the simplest choice or inference strategies imaginable is the recognition heuristic
MISC	quite simply   if one of two objects is recognized and the other is not  then infer that the recognized object has the higher value   CITATION
MISC	thus  when asked to pick which movie yielded the greater gross takings  sin city or steget efter  the person who recognizes only one of these titles can use the recognition heuristic though the person who recognises neither or both of these movies must make their choice some other way
MISC	when the rate or frequency of exposure correlates positively with value  the heuristic will lead to choice or inference accuracy above chance levels  CITATION
MISC	thus  in our example  the positive association between media coverage such as advertising and movie attendances means that the recognition heuristic should have some ecological validity for the choice in question
MISC	recent analysis by schooler and hertwig  CITATION  shows that the effectiveness of recognition may even be enhanced by forgettingeven though this leads to a failure to recognize some previously seen objects
MISC	if remembered objects are more likely to be associated with the relevant characteristics of the environment than forgotten ones  this will enhance the predictive or inferential power of recognition
MISC	in this paper we examine the application of the recognition heuristic to investment decisions  where one of many possible investments can be made
MISC	here the recognition heuristic demands that   when choosing a set of objects from a larger set  choose the subset of recognized objects   CITATION
MISC	why might people use such a heuristic
MISC	first  in some situations  they may consciously accept the logic expressed in the previous paragraph
MISC	it probably makes sense to many people that the consumer products  movies  sports teams  and sports personalities that they have heard of are more successful than those they have notand they will be happy to make inferences accordingly
MISC	there are occasions when failure generates notoriety  ford's edsell car  the movie flop waterworld  the  NUMBER  jamaican bobsleigh team  or  eddie the eagle  whose olympic ski-jumping preparation lacked only a ski-jump
MISC	nonetheless  generally speaking  people know that it is success that breeds the personal exposure or column inches that will encourage recognition
MISC	alternatively  there may be other occasions when  in the absence of deliberative reasoning about recognition  more intuitive processes may drive recognition-based choices
MISC	people reliably prefer familiar stimuli  CITATION more so when they fail to recognise previously presented stimuli at better than chance levels and are presumably not conscious of prior exposure  CITATION
MISC	bornstein  CITATION  suggests that a preference for the familiar may be adaptive  as unfamiliar stimuli and situations have greater potential for risk than familiar ones do
MISC	people also judge more fluent i e   more easily processed stimuli positively  CITATION   and often base their judgements on how easily objects or events can be recalled  CITATION
MISC	although not necessarily easy to distinguish empirically  such accounts are conceptually distinct from the recognition heuristicstimuli may be more or less familiar  fluent or available  but are simply recognised or not recognised
MISC	nonetheless  recognised stimuli are inevitably more familiar and more available than unrecognised ones  and possibly  on average  more fluent too  CITATION
OWNX	these features could explain why recognition-based choice may occur  even when the conditions that make it an effective strategy in certain circumstances are unknown or absent
MISC	the use of the recognition heuristic has been the subject of several empirical investigations
MISC	gigerenzer and goldstein  CITATION  reported that this heuristic helped people to make correct inferences when faced with the task of assessing which of two foreign cities had the greater population
MISC	with some modified experimental designs  this observation has also been replicated for additional samples of cities  CITATION   for rivers and for mountains  CITATION
MISC	assessing such geographical objects is associated with stable characteristics  the true answer has rarely changed in living memory  and will usually not change for many years to come  CITATION
MISC	for example  the correct answer to the question  which city is larger  colchester or stockholm
MISC	  has been the same for centuries and is unlikely to be different in the foreseeable future
MISC	this contrasts with dynamic domains such as sports events  where the accuracy of inferences varies over time
MISC	for instance  tennis ace roger federer is likely  though not certain  to beat the lowly-ranked ezequiel krivulin
MISC	furthermore  there may eventually come a time when this highly recognized superstar will begin to lose on a regular basis to younger unknown players
MISC	nonetheless  it has been shown that recognition can  to some extent  predict the outcome of sports events  CITATION
MISC	in this paper we re-examine the effectiveness of the recognition heuristic using an important  but notoriously difficult  taskstock picking
MISC	this task is also associated with variable characteristics  and so provides a tough test for the recognition heuristic
MISC	borges et al CITATION  found name recognition to be a surprisingly successful basis for stock investment
MISC	lay people and business graduates in the usa and germany indicated which company names they recognized among the largest companies listed on the new york and frankfurt stock exchanges
MISC	portfolios of shares consisting of the most frequently recognized shares outperformed portfolios consisting of shares recognized by fewer than  NUMBER  percent  of participants over a six-month period beginning december  NUMBER 
MISC	these portfolios of frequently recognised shares outperformed the market index in six of eight possible comparisons treating recognition data from the four pools of participants across each of the two stock markets as distinct comparisons
MISC	only for americans' recognition of u s stocks did recognition-based investment under-perform the market index
MISC	this was symptomatic of a general trend in which the advantage for highly recognised stocks was greatest when people were apparently most ignoranti e   using the recognition data for foreign stock markets where recognition rates were  unsurprisingly  lower than for domestic stocks
MISC	that such a simple strategy should prove to be effective was surprisingand therefore grabbed attention among the financial press as it runs counter to the efficient market hypothesis  which anticipates that the index cannot consistently be beaten by simple investment strategies
MISC	borges et al CITATION  provide some speculation on the reasons for their results  for instance the possibility that features such as market share  company size and prestige may all be associated with both recognition and profitability  and that limited recognition best exploits the ability of the recognition heuristic to discriminate profitable and unprofitable shares
MISC	put simply  the suggestion is that company success and other features that foster recognition also tend to drive up share value
MISC	hence recognized shares will yield higher average returns than unrecognized ones
MISC	if an individual recognizes few shares  they probably only recognize the elite companies whose size and success has made them household names with good prospects for share return
MISC	however  an important question is whether such a mechanism could be sustainable in a market
MISC	boyd failed to replicate borges et al 's  CITATION  results in a falling  bear  market with a sample of american students providing recognition data on us stocks
MISC	both boyd  CITATION  and borges et al CITATION  discuss the possibility that recognition may not be a good strategy in such markets when  big  firms are often observed to perform poorly
MISC	merton's  CITATION  model of capital market equilibrium predicts that attempts to replicate borges et al 's  CITATION  finding are more likely to fail than to succeed
MISC	merton  CITATION  points out that investors can acquire only those shares that they recognize
MISC	consequently  demand and value will tend to be higher for company shares that are widely recognized
MISC	however  merton's theory predicts that investment returns will correlate negatively with recognitionmore highly recognized firms will yield lower returns  implying that the recognition heuristic should under-perform the market index
MISC	this is consistent with the  neglected firms effect  whereby the shares of firms with narrow investor bases outperform more widely held shares  CITATION
MISC	the effect persists even when company size is controlled  and may be interpreted as an informational effect
MISC	for obvious reasons  investors need information in order to predict future profits  dividends  and stock returns
MISC	the less information investors have  the greater the chance that important information that predicts extreme changes in value is missing
OWNX	however  investment-relevant information e g   earnings releases will be less abundant  and therefore more expensive  for obscure firms than for  high-profile  corporations that enjoy high levels of recognition and that release detailed reports on a regular basis
MISC	therefore  in order to invest in unfamiliar companies  investors require a risk premium on their investment  which roughly corresponds to their increased effort in searching for information about those companies
OWNX	risk aversion would make investing in the potentially risky shares of relatively unknown firms comparatively unappealing  unless better-than-average returns can be expected from such shares
MISC	in contrast  the market will sustain share returns from well-known companies that are more modest  as investors feel that they have  or can obtain  sufficient information on these shares to be able to guard against the risk of severe losses
MISC	several studies have examined factors that ought to affect recognition  CITATION  such as analyst coverage  advertising expenditure or exchange listing
MISC	many of these have found an effect upon security value consistent with merton  CITATION
MISC	for instance  barber and odean  CITATION  showed that private investors tended to purchase  high-profile  stocks that had previously experienced high volumes or returns  or had been in recent news reports
MISC	this strategy was shown to under-perform the market index
OWNX	weber  siebenmorgen and weber  CITATION  provide some insight into why investors might follow an unprofitable investment strategy driven by the  attention-grabbing  features of shares
MISC	they found that people tend to perceive shares that they recognize as less risky than those that they fail to recognize
MISC	more direct tests of merton's  theory have tended to focus on breadth of ownership among institutions with holdings in excess of   NUMBER  million as a proxy for recognition
OWNX	contrary to the predictions of merton  CITATION   chen et al CITATION  found that low levels of recognition predicted low returns
MISC	however  lehavy and sloan  CITATION  showed that changes in the breadth of ownership do indeed positively predict current share value and negatively predict future returns when autocorrelations for value or return over time are controlled
MISC	lehavy and sloan  CITATION  and others who have examined breadth of ownership recognize its limitations as a proxy for recognition
OWNX	whilst it is plausible that increases in recognition will often result in increases in the breadth of ownership  it is illogical that decreases in the breadth of ownership might imply that some investors no longer recognize a particular company that they previously knew of
AIMX	the studies reported here employ a direct measure of recognition  we simply ask a sample of people whether they recognize the name of a companies listed on the stock exchange
MISC	thus share recognition is considered at the level of the individual potential investor  rather than at the level of the large corporate investor
OWNX	we use these data to re-examine whether simple recognition alone can form the basis of a viable investment strategy
MISC	in particular  two questions that relate to how well borges et al 's  CITATION  findings generalize are considered
MISC	firstly  were their results simply a function of random variation in prices or applicable only to a particular period of time
OWNX	to this end our studies commence at different time points  and we track share value over differing periods of time
MISC	readers will see that  despite being at the mercy of the markets  this allowed us to test the effectiveness of the recognition heuristic in markets that fell and rose to differing degreespermitting a detailed re-evaluation of borges et al 's  CITATION  and boyd's  CITATION  findings under a variety of conditions
MISC	secondly  are borges et al 's findings restricted only to particular combinations of populations of participants and stock markets
MISC	thus  can one say that  recognition is an ecologically valid strategy for stock selection  or simply that  recognition data from germans and americans selects better than average german stocks
OWNX	  in considering this issue  we examine recognition data on stocks from five countries for participants from three countries
OWNX	in all   NUMBER  of the  NUMBER  possible combinations that this could yield are availableand some combinations can be examined for more than one study with recognition data from different samples of participants collected at different points in time
MISC	this permits us to test the recognition heuristic over a range of recognition rates typically high for domestic or  home  shares  and low for overseas or  away  shares
MISC	examination of many such participant-market combinations is important in order to determine whether there might be any general effect that favours or penalizes recognized over unrecognized shares
MISC	although borges et al CITATION  report eight comparisons between portfolios of recognized and unrecognized shares  these are not independent comparisons
MISC	for instance  there was some overlap in which shares are always recognized by laypeople and business graduates from a given country  CITATION
MISC	in summary  we re-examine the two key findings of the borges et al CITATION  data   NUMBER  the overall validity of recognition as a method of stock selection  and  NUMBER  the increased effectiveness of recognition for  more ignorant  participants with lower levels of recognition
MISC	note that we are not interested in whether personal or professional investors actually use the recognition heuristicsimply in whether  if they did  it would be effective
MISC	Accurate modelling of biological systems requires a deeper and more complete knowledge about the molecular components and their functional associations than we currently have.
MISC	Traditionally, new knowledge on protein associations generated by experiments has played a central role in systems modelling, in contrast to generally less trusted bio-computational predictions.
MISC	However, we will not achieve realistic modelling of complex molecular systems if the current experimental designs lead to biased screenings of real protein networks and leave large, functionally important areas poorly characterised.
OWNX	To assess the likelihood of this, we have built comprehensive network models of the yeast and human proteomes by using a meta-statistical integration of diverse computationally predicted protein association datasets.
MISC	We have compared these predicted networks against combined experimental datasets from seven biological resources at different level of statistical significance.
MISC	These eukaryotic predicted networks resemble all the topological and noise features of the experimentally inferred networks in both species, and we also show that this observation is not due to random behaviour.
MISC	In addition, the topology of the predicted networks contains information on true protein associations, beyond the constitutive first order binary predictions.
MISC	We also observe that most of the reliable predicted protein associations are experimentally uncharacterised in our models, constituting the hidden or dark matter of networks by analogy to astronomical systems.
MISC	Some of this dark matter shows enrichment of particular functions and contains key functional elements of protein networks, such as hubs associated with important functional areas like the regulation of Ras protein signal transduction in human cells.
MISC	Thus, characterising this large and functionally important dark matter, elusive to established experimental designs, may be crucial for modelling biological systems.
MISC	In any case, these predictions provide a valuable guide to these experimentally elusive regions.
MISC	Many features of biological systems cannot be inferred from a simple sum of their components but rather emerge as network properties CITATION.
MISC	Organisms comprise systems of highly integrated networks or accelerating networks CITATION in which all components are integrated and coordinated in time and space.
MISC	Given such complexity, the gaps in our current knowledge prevent us from modelling complete living organisms CITATION, CITATION.
MISC	Therefore, the development of bio-computational approaches for identifying new protein functions and protein-protein functional associations can play an important role in systems biology CITATION .
MISC	The scarce knowledge of biological systems is further compounded by experimental error.
MISC	It is common for different high-throughput experimental approaches, applied to the same biological system, to yield different outcomes, resulting in protein networks with different topological and biological properties CITATION.
MISC	However, errors are not restricted to high-throughput analysis.
MISC	For example, it has been demonstrated that high-throughput yeast two-hybrid interactions for human proteins are more precise than literature-curated interactions supported by a single publication CITATION .
MISC	There has been a great deal of work analysing biological networks across different species, giving insights into how networks evolve.
OWNX	However, many of these publications have yielded disparate and sometimes contradictory conclusions.
MISC	Observation of poor overlap in protein networks across species CITATION and divergence amongst organisms CITATION suggest fast evolution.
MISC	Significant variation in subunit compositions of the functional modules has also been observed in protein networks across species CITATION.
OWNX	However, in contrast to these observations, recent work using combined protein-protein interaction data suggests high conservation of the protein networks between yeast and human CITATION.
MISC	This approach, based on data combination, stresses the importance of integrating different data sources to reduce the bias associated with errors in functional prediction, and to increase the coverage in network modelling, and has been demonstrated in numerous studies CITATION CITATION .
MISC	Increasing the accuracy of networks by integrating different protein interaction data relies on the intuitive principle that combining multiple independent sources of evidence gives greater confidence than a single source.
MISC	For any genome wide computational analyses, we expect the prediction errors to be randomly distributed amongst a large sample of true negative interactions.
MISC	Hence, it is unlikely that two independent prediction methods will both identify the same false positive data in large interactomes like yeast or human.
OWNX	In general, we expect the precision to increase proportionally to the number of independent approaches supporting the same evidence.
OWNX	From the available list of well-known integration methods specifically designed to integrate diverse protein-protein interaction -PPI- datasets, we chose the Fisher method CITATION in order to have a predictor that is independent from the experimental data used to validate it.
MISC	Fisher integration method is not a trained or supervised method as, for example, Naive Bayes or SVM methods.
OWNX	The Fisher method presumes a Gaussian random distribution of the prediction datasets' scores as a null hypothesis and the Fisher integrated score calculation is based on Information Theory statistics CITATION, CITATION.
OWNX	Therefore, the Fisher integration score is completely independent of the experimental datasets used in this study to validate and compare the predictions.
OWNX	In this work, we significantly increase the prediction power of binary protein functional associations in yeast and human proteomes by integrating different individual prediction methods using the Fisher integration method.
OWNX	Three different untrained methods are implemented: GECO ; hiPPI ; and CODA run with two protein domain classifications, CATH CITATION and PFAM CITATION.
OWNX	The four different prediction datasets obtained by these methods, were integrated using simple integration and Fisher's method as examples of untrained methods.
OWNX	Similarly ab-initio prediction datasets from STRING CITATION were also integrated using Fisher integration and compared against the integrated prediction datasets from our methods.
OWNX	Results from the Fisher integration of our prediction datasets were benchmarked and compared against the individual prediction methods and the results from the integrated STRING methods.
OWNX	In all cases we demonstrate increased performance for the integrated approach with the Fisher integration of GECO, hiPPI, CODAcath and CODApfam datasets yielding the best results.
OWNX	Protein pairs identified by significant Fisher integration p-values were used to build a protein network model for yeast and human proteomes referred to as the Predictogram.
MISC	Additionally, all the protein-protein associations from several major biological databases, including Reactome CITATION, Kegg CITATION, GO CITATION, FunCat CITATION, Intact CITATION, MINT CITATION and HRPD CITATION were retrieved and combined into a network referred to as a Knowledgegram.
OWNX	As implemented in other pioneering studies CITATION, we built predicted and experimental models for further comparison.
MISC	Different network topology parameters were calculated and compared between KG and PG models for two test species Homo sapiens and Sacharomyces cerevisae.
MISC	We observe how the networks change as the cut-off on the confidence score of the predictions is varied.
MISC	Results of this PG and KG network comparison demonstrate that PG networks resemble KG networks in many of the major topological features and model a substantial fraction of real protein network associations, as previously observed in some bacterial predicted networks CITATION, CITATION .
MISC	There have been frequent observations of low overlaps between different experimental high-throughput approaches CITATION.
OWNX	Our comparison of the PG and KG models also show that the intersection between the two models is small and that the majority of predictions in the PG are novel predictions.
MISC	However, the overlap between PG and KG is significantly higher than expected by random in both species supporting a correspondence between the PG and KG screenings of PPI space.
MISC	This PG and KG data overlap is significantly larger in yeast than in human, pointing to a better functional characterization of the yeast PPI network and the presence of larger dark areas in the human PPI network still hidden from current experimental knowledge.
OWNX	We suggest that this novel prediction set may be a valuable estimation of the relative differences in dark matter of uncharacterised protein-protein associations between both specie, and we show that this dark matter contains key elements, such as hubs, with important functional roles in the cell.
MISC	By analogy CITATION, dark matter in protein network models refers to predicted protein-protein associations, whose existence has not yet been experimentally verified.
MISC	In this study, we suggest that dark matter involves functional associations difficult to characterise by current experimental assays making any network modelling of organisms highly incomplete and therefore inaccurate.
OWNX	The results are divided into four main sections in which the predicted and experimental PPI models of human and yeast are compared.
CONT	The first section analyses the performance of the single and integrated methods predicting the protein associations and determines the correlation between the prediction scores and the degree of accuracy and noise in the predictions.
OWNX	The second chapter compares the topological network features of the predicted and experimental PPI models at equivalent levels of accuracy and noise.
MISC	The third section searches for functional differences between the predicted and experimental models looking for specific functional areas which appear to be illuminated by the prediction methods but elusive to the experimental approaches.
MISC	Whilst the final fourth section explores whether the predicted PPI network graphs contain additional context-based information on protein associations beyond the sets of predicted protein pairs used to build the networks.
MISC	Understanding the computations performed by neuronal circuits requires characterizing the strength and dynamics of the connections between individual neurons.
MISC	This characterization is typically achieved by measuring the correlation in the activity of two neurons.
MISC	We have developed a new measure for studying connectivity in neuronal circuits based on information theory, the incremental mutual information.
CONT	By conditioning out the temporal dependencies in the responses of individual neurons before measuring the dependency between them, IMI improves on standard correlation-based measures in several important ways: it has the potential to disambiguate statistical dependencies that reflect the connection between neurons from those caused by other sources provided that the dependencies have appropriate timescales, for the study of early sensory systems, it does not require responses to repeated trials of identical stimulation, and it does not assume that the connection between neurons is linear.
OWNX	We describe the theory and implementation of IMI in detail and demonstrate its utility on experimental recordings from the primate visual system.
MISC	To understand the function of neuronal circuits and systems, it is essential to characterize the connections between individual neurons.
MISC	The major connections between and within many brain areas have been mapped through anatomical studies, but these maps specify only the existence of connections, not their strength or dynamics.
OWNX	Measuring the strength and dynamics of the connection between two neurons requires physiological experiments in which the activity of both neurons is measured.
OWNX	The most direct of these experiments involves intracellular recordings, which allow the connection between the two neurons to be directly investigated.
MISC	However, intracellular recordings are difficult to perform in vivo and impossible to obtain from more than a few cells at a time.
MISC	Instead, most physiological studies of connectivity rely on extracellular recordings from multi-electrode arrays.
MISC	In these experiments, it is not usually possible to explicitly verify anatomical connectivity, nor to directly characterize the connections.
MISC	Instead, the strength and dynamics of functional connectivity must be inferred through statistical methods.
MISC	The traditional method for characterizing the strength and dynamics of the connection between two neurons is the cross correlation function, which measures the linear correlation between two signals over a range of specified delays CITATION.
MISC	While C XY and its variants have been used successfully in a number of studies, it has limitations that must be considered when studying the connection between neurons CITATION CITATION.
MISC	The limitations of C XY arise from the fact that it is a measure of the total dependency between two signals and, thus, implicitly assumes that all dependencies between them are due to their connection.
MISC	In the case of neurons, there are in fact many potential sources of dependency shared external stimuli, intrinsic cellular and network properties, etc. and C XY cannot disambiguate these dependencies from those due to the actual connection.
MISC	Several modified versions of C XY have been proposed to address these drawbacks.
MISC	For example, if neuronal activity in response to repeated trials of the same external stimulus is available for analysis, as is often the case in early sensory systems, the shift-predictor can be used to remove some of the correlations due to the stimulus CITATION.
MISC	Further modifications to C XY have also been proposed to remove the correlations due to stimulus-driven covariations in activity CITATION and background activity CITATION.
MISC	While these modified approaches have certainly improved upon the standard C XY, the confound of dependencies due to the connection and those arising from other sources remains a general problem.
MISC	In addition to correlation-based methods, there are several other approaches to characterizing the dependency between two signals that can be used to study the connection between two neurons.
OWNX	These methods can be generally divided into two classes: model-based and model-free.
MISC	The most common model-based approach to characterizing dependency is Granger causality CITATION.
OWNX	With GC, one signal is predicted in two different ways: using an autoregressive model based on its own past and using a multivariate autoregressive model based on its own past and the past of the second signal.
MISC	The strength of the dependency is given by the difference in the predictive power of the two models and the dynamics of the dependency are reflected in the regression parameters that correspond to the influence of the second signal.
MISC	The power of model-based approaches such as GC is dependent on the validity of the underlying model; if the dependency between the two signals is approximately linear, then the characterization provided by GC will be accurate, but in situations where the properties of the dependency are complex or unknown, as is often the case with neurons, a model-free approach may be more appropriate.
MISC	The most common model-free approach to characterizing dependency is transfer entropy, the information-theoretic analog of GC CITATION.
MISC	TE measures the reduction in the entropy of one signal that is achieved by conditioning on its own past and the past of the second signal relative to the reduction in entropy achieved by conditioning on its own past alone.
OWNX	TE is a powerful tool for measuring the overall strength of a dependency, but is not suitable for characterizing its dynamics.
AIMX	In this paper, we detail a new model-free approach for characterizing both the strength and dynamics of a dependency by conditioning out the temporal correlations in both signals before assessing the strength of the dependency at different delays.
MISC	This approach can overcome some of the confounds that are common in studies of neuronal connectivity CITATION CITATION, as it has the potential to disambiguate statistical dependencies that reflect the connection between neurons from those caused by other sources provided that the dependencies have appropriate timescales.
OWNX	In the following sections, we outline the theory behind our measure, which we call incremental mutual information, illustrate its usage on simulated neuronal activity and experimental recordings from the primate visual system, and consider its relationship to other common measures of dependence.
MISC	Matlab code for measuring incremental mutual information is available for download at LINK
MISC	Natural proteins often partake in several highly specific protein-protein interactions.
MISC	They are thus subject to multiple opposing forces during evolutionary selection.
MISC	To be functional, such multispecific proteins need to be stable in complex with each interaction partner, and, at the same time, to maintain affinity toward all partners.
MISC	How is this multispecificity acquired through natural evolution?
OWNX	To answer this compelling question, we study a prototypical multispecific protein, calmodulin, which has evolved to interact with hundreds of target proteins.
OWNX	Starting from high-resolution structures of sixteen CaM-target complexes, we employ state-of-the-art computational methods to predict a hundred CaM sequences best suited for interaction with each individual CaM target.
OWNX	Then, we design CaM sequences most compatible with each possible combination of two, three, and all sixteen targets simultaneously, producing almost 70,000 low energy CaM sequences.
MISC	By comparing these sequences and their energies, we gain insight into how nature has managed to find the compromise between the need for favorable interaction energies and the need for multispecificity.
MISC	We observe that designing for more partners simultaneously yields CaM sequences that better match natural sequence profiles, thus emphasizing the importance of such strategies in nature.
OWNX	Furthermore, we show that the CaM binding interface can be nicely partitioned into positions that are critical for the affinity of all CaM-target complexes and those that are molded to provide interaction specificity.
MISC	We reveal several basic categories of sequence-level tradeoffs that enable the compromise necessary for the promiscuity of this protein.
OWNX	We also thoroughly quantify the tradeoff between interaction energetics and multispecificity and find that facilitating seemingly competing interactions requires only a small deviation from optimal energies.
MISC	We conclude that multispecific proteins have been subjected to a rigorous optimization process that has fine-tuned their sequences for interactions with a precise set of targets, thus conferring their multiple cellular functions.
MISC	Proteins engage in numerous protein-protein interactions, which together regulate the outcome of all biological processes in the cell.
MISC	By some estimates, over a third of all mammalian proteins participate in two or more highly specific protein-protein interactions CITATION.
MISC	Proteins that can interact with a large number of partners play a central role in the modular organization of protein interaction networks CITATION.
MISC	Such proteins, usually referred to as protein hubs, tend to be more essential than others for cell survival CITATION and usually exhibit slower rates of evolution CITATION.
MISC	Moreover, the comprehensive biological activity of these proteins typically requires them to recognize a precise set of targets in a specific way.
OWNX	For example, each subfamily of G protein regulators interacts with only a specific subset of G proteins CITATION.
MISC	Proteins with diverse binding capacity have also been termed multispecific proteins CITATION, CITATION .
MISC	The central function of multispecific proteins within interaction networks imposes constraints on their amino acid sequences, especially in their protein-protein interfaces, i.e., the regions that are used to mediate intermolecular interactions with various targets.
MISC	There exist only a few studies that have characterized in great detail the molecular and structural features of multispecific protein interfaces CITATION ; this is mostly due to sparse representation of such protein-protein complexes in the Protein Data Bank.
MISC	A thorough understanding of atomic-level principles governing multispecific interactions is extremely important not only for the advancement of basic science but also for the design of new pharmaceuticals that modify protein-protein interactions.
OWNX	Furthermore, such molecular insights will provide critical feedback for systems biology research, which views protein-protein interactions from a high-level network approach CITATION .
MISC	Calmodulin is a paradigm of a multispecific protein, with more than three hundred CaM targets identified to date CITATION.
OWNX	CaM is the central player in the FORMULA signaling pathways that control gene transcription, protein phosphorylation, nucleotide metabolism, and ion transport.
OWNX	This FORMULA sensor protein translates the changes in FORMULA concentration into activity of many downstream targets, including kinases, phosphatases, enzymes, and ion channels CITATION.
MISC	Remarkably, CaM targets display considerable variability in sequence and structure.
MISC	CaM-binding regions within target proteins are generally rich in hydrophobic and positively charged residues.
OWNX	Nevertheless, no consensus CaM-binding sequence exists for all CaM target proteins.
MISC	Recent structural studies have revealed that there are several binding modes accessible to CaM, allowing this protein to interact with its targets in a FORMULA-saturated state CITATION, CITATION, in a partially-saturated FORMULA state CITATION, and in a FORMULA-free state CITATION, CITATION.
MISC	In the FORMULA-saturated form, CaM usually binds to a stretch of FORMULA amino acids that is unfolded in the absence of CaM and becomes helical upon interaction with the protein CITATION.
CONT	In this conventional binding mode, CaM undergoes a conformational change and embraces the target helix with its two globular domains, burying a substantial hydrophobic surface area and providing favorable hydrogen bond and salt bridge interactions with the target.
MISC	FORMULA-saturated CaM binds to its targets with high affinity, displaying FORMULA values in the FORMULA to FORMULA M range CITATION.
MISC	This affinity is reduced at least 1000-fold in the absence of FORMULA, allowing for quick dissociation of CaM from its targets when FORMULA is depleted.
MISC	The multitude of binding constraints placed on CaM during evolution is likely to have produced a sequence that may not be optimal for binding to any particular CaM target, but rather presents a compromise essential for interaction with a large number of partners.
AIMX	In this study, we employ a computational design approach CITATION to understand how the compromises required for functional promiscuity CITATION are achieved both on the level of amino acid sequences and on the level of binding energetics.
MISC	First, we computationally evolve CaM to interact with single targets; second, we evolve this protein to bind to multiple partners simultaneously.
MISC	Recently, a similar analysis was performed on twenty multispecific proteins, whose interactions with two to seven targets were considered CITATION, CITATION.
OWNX	In contrast to those works, we report a much more comprehensive investigation of a single multispecific protein, CaM.
MISC	We examine interactions in sixteen different CaM-target complexes that exhibit the conventional binding mode.
MISC	Using the structures of these complexes, we perform 697 separate CaM design calculations to obtain FORMULA low energy CaM sequences optimal for either a single target or some combination of the targets.
OWNX	Rigorous quantitative and statistical comparisons of the designed CaM sequences and their energies allows us to draw conclusions regarding CaM evolution and to suggest strategies for the design of binders that are both promiscuous yet highly specific.
MISC	In particular, we characterize the CaM binding interface by partitioning its residues into those that are critical for binding affinity and those that are important for multispecificity.
OWNX	Furthermore, we analyze the sorts of sequence compromises required to yield proteins with promiscuous interactions and show how this fits with past explanations for the ability of CaM to accommodate many targets.
OWNX	Finally, we examine the energetic compromises inherently crucial for multispecificity CITATION, and we find that our results also shed light on the unexpected findings of previous experimental protein design research.
OWNX	Support vector machines (SVMs) are an extremely successful type of classification and regression algorithms
MISC	Building an SVM entails solving a constrained convex quadratic programming problem, which is quadratic in the number of training samples
OWNX	We introduce an efficient parallel implementation of an support vector regression solver, based on the Gaussian Belief Propagation algorithm (GaBP)
AIMX	In this paper, we demonstrate that methods from the complex system domain could be utilized for performing efficient distributed computation
OWNX	We compare the proposed algorithm to previously proposed distributed and single-node SVM solvers
MISC	Our comparison shows that the proposed algorithm is just as accurate as these solvers, while being significantly faster, especially for large datasets
OWNX	We demonstrate scalability of the proposed algorithm to up to 1,024 computing nodes and hundreds of thousands of data points using an IBM Blue Gene supercomputer
OWNX	As far as we know, our work is the largest parallel implementation of belief propagation ever done, demonstrating the applicability of this algorithm for large scale distributed computing systems
MISC	Support-vector machines (SVMs) are a class of algorithms that have, in recent years, exhibited superior performance compared to other pattern classification algorithms
MISC	There are several formulations of the SVM problem, depending on the specific application of the SVM (e g , classification, regression, etc )
MISC	One of the difficulties in using SVMs is that building an SVM requires solving a constrained quadratic programming problem, whose size is quadratic in the number of training examples
MISC	This fact has led to extensive research on efficient SVM solvers
MISC	Recently, several researchers have suggested using multiple computing nodes in order to increase the computational power available for solving SVMs
OWNX	In this article, we introduce a distributed SVM solver based on the Gaussian Belief Propagation (GaBP) algorithm
MISC	We improve on the original GaBP algorithm by reducing the communication load, as represented by the number of messages sent in each optimization iteration, from  SYMBOL  to  SYMBOL  aggregated messages, where  SYMBOL  is the number of data points
OWNX	Previously, it was known that the GaBP algorithm is very efficient for sparse matrices
OWNX	Using our novel construction, we demonstrate that the algorithm exhibits very good performance for dense matrices as well
OWNX	We also show that the GaBP algorithm can be used with kernels, thus making the algorithm more powerful than what was considered previously thought possible
OWNX	Using extensive simulation we demonstrate the applicability of our protocol vs the state-of-the-art existing parallel SVM solvers
MISC	Using a Linux cluster of up to a hundred machines and the IBM Blue Gene supercomputer we managed to solve very large data sets up to hundreds of thousands data point, using up to 1,024 CPUs working in parallel
MISC	Our comparison shows that the proposed algorithm is just as accurate as these previous solvers, while being significantly faster
OWNX	A preliminary version of this paper appeared as a poster in~ CITATION
MISC	As a fundamental problem in pattern recognition, graph matching has applications in a variety of fields, from computer vision to computational biology
MISC	In graph matching, patterns are modeled as graphs and pattern recognition amounts to finding a correspondence between the nodes of different graphs
OWNX	Many formulations of this problem can be cast in general as a quadratic assignment problem, where a linear term in the objective function encodes node compatibility and a quadratic term encodes edge compatibility
OWNX	The main research focus in this theme is about designing efficient algorithms for approximately solving the quadratic assignment problem, since it is NP-hard
OWNX	In this paper we turn our attention to a different question: how to  estimate  compatibility functions such that the solution of the resulting graph matching problem best matches the expected solution that a human would manually provide
MISC	We present a method for  learning graph matching : the training examples are pairs of graphs and the `labels' are matches between them
OWNX	Our experimental results reveal that learning can substantially improve the performance of standard graph matching algorithms
OWNX	In particular, we find that simple linear assignment with such a learning scheme outperforms Graduated Assignment with bistochastic normalisation, a state-of-the-art quadratic assignment relaxation algorithm
MISC	Graphs are commonly used as abstract representations for complex structures, including DNA sequences, documents, text, and images
MISC	In particular they are extensively used in the field of computer vision, where many problems can be formulated as an attributed graph matching problem
MISC	Here the nodes of the graphs correspond to local features of the image and edges correspond to relational aspects between features (both nodes and edges can be attributed, i e ~they can encode feature vectors)
MISC	Graph matching then consists of finding a correspondence between nodes of the two graphs such that they 'look most similar' when the vertices are labeled according to such a correspondence
MISC	Typically, the problem is mathematically formulated as a quadratic assignment problem, which consists of finding the assignment that maximizes an objective function encoding local compatibilities (a linear term) and structural compatibilities (a quadratic term)
MISC	The main body of research in graph matching has then been focused on devising more accurate and/or faster algorithms to solve the problem approximately (since it is NP-hard); the compatibility functions used in graph matching are typically handcrafted
OWNX	An interesting question arises in this context: If we are given two attributed graphs to match,  SYMBOL  and  SYMBOL , should the optimal match be uniquely determined
MISC	For example, assume first that  SYMBOL  and  SYMBOL  come from two images acquired by a surveillance camera in an airport's lounge; now, assume the same  SYMBOL  and  SYMBOL  instead come from two images in a photographer's image database; should the optimal match be the same in both situations
MISC	If the algorithm takes into account exclusively the graphs to be matched, the optimal solutions will be the same since the graph pair is the same in both cases
MISC	This is the standard way graph matching is approached today
AIMX	In this paper we address what we believe to be a limitation of this approach
MISC	We argue that if we know the `conditions' under which a pair of graphs has been extracted, then we should take into account  how graphs arising in those conditions are typically matched
OWNX	However, we do not take the information on the conditions explicitly into account, since this would obviously be impractical
OWNX	Instead, we approach the problem purely from a statistical inference perspective
OWNX	First, we extract graphs from a number of images acquired under the same conditions as those for which we want to solve, whatever the word `conditions' means (e g ~from the surveillance camera or the photographer's database)
OWNX	We then  manually  provide what we understand to be the optimal matches between the resulting graphs
MISC	This information is then used in a  learning  algorithm which learns a map from the space of pairs of graphs to the space of matches
MISC	In terms of the quadratic assignment problem, this learning algorithm amounts to (in loose language) adjusting the node and edge compatibility functions such that the expected optimal match in a test pair of graphs agrees with the expected match they would have had, had they been in the training set
MISC	In this formulation, the learning problem consists of a convex, quadratic program which is readily solvable by means of a column generation procedure
MISC	We provide experimental evidence that applying learning to standard graph matching algorithms significantly improves their performance
OWNX	In fact, we show that learning improves upon non-learning results so dramatically that linear assignment  with learning  outperforms Graduated Assignment with bistochastic normalisation, a state-of-the-art quadratic assignment relaxation algorithm
OWNX	Also, by introducing learning in Graduated Assignment itself, we obtain results that improve both in accuracy and speed over the best existing quadratic assignment relaxations
OWNX	A preliminary version of this paper appeared in  CITATION
MISC	In the past few years powerful generalizations to the Euclidean k-means problem have been made, such as Bregman clustering~ CITATION , co-clustering (i e , simultaneous clustering of rows and columns of an input matrix)~ CITATION , and tensor clustering~ CITATION
OWNX	Like k-means, these more general problems also suffer from the NP-hardness of the associated optimization
MISC	Researchers have developed approximation algorithms of varying degrees of sophistication for k-means, k-medians, and more recently also for Bregman clustering~ CITATION
MISC	However, there seem to be no approximation algorithms for Bregman co- and tensor clustering
OWNX	In this paper we derive the first (to our knowledge) guaranteed methods for these increasingly important clustering settings
OWNX	Going beyond Bregman divergences, we also prove an approximation factor for tensor clustering with arbitrary separable metrics
OWNX	Through extensive experiments we evaluate the characteristics of our method, and show that it also has practical impact
OWNX	Partitioning data points into clusters is a fundamentally hard problem
OWNX	The well-known Euclidean k-means problem that partitions the input data points (vectors in  SYMBOL ) into  SYMBOL  clusters while minimizing sums of their squared distances to corresponding cluster centroids, is an NP hard problem~ CITATION  (exponential in  SYMBOL )
MISC	However, simple and frequently used procedures that rapidly obtain local minima exist since a long time~ CITATION
MISC	Because of its wide applicability and importance, the Euclidean k-means problem has been generalized in several directions
CONT	Specific examples relevant to this paper include:  \setlength{sep}{-1pt}   Bregman clustering ~ CITATION , where instead of minimizing squared Euclidean distances one minimizes Bregman divergences (which are generalized distance functions, see~() or~ CITATION  for details),   Bregman co-clustering ~ CITATION  (which includes both Euclidean~ CITATION  and information-theoretic co-clustering~ CITATION  as special cases), where the set of input vectors is viewed as a matrix and one  simultaneously  clusters rows and columns to obtain coherent submatrices (co-clusters), while minimizing a Bregman divergence, and   Tensor clustering  or multiway clustering~ CITATION , especially the version based on Bregman divergences~ CITATION , where one simultaneously clusters along various dimensions of the input tensor
MISC	For these problems too, the commonly used heuristics perform well, but do not provide theoretical guarantees (or at best assure local optimality)
OWNX	For k-means type clustering problems---i e , problems that group together input vectors into clusters while minimizing ``distance'' to cluster centroids---there exist several algorithms that approximate a globally optimal solution
MISC	We refer the reader to~ CITATION , and the numerous references therein for more details
MISC	In stark contrast, approximation algorithms for tensor clustering are much less studied
MISC	We are aware of only two very recent attempts (both papers are from 2008) for the two-dimensional special case of co-clustering, namely,~ CITATION  and  CITATION ---and both of the papers  follow similar approaches to obtain their approximation guarantees
MISC	Both prove a  SYMBOL -approximation for Euclidean co-clustering,  CITATION  an additional factor of  SYMBOL  for binary matrices and an  SYMBOL  norm objective, and  CITATION  a factor of  SYMBOL  for co-clustering real matrices with  SYMBOL  norms
MISC	In all factors  SYMBOL  is an approximation guarantee for clustering either rows or columns
OWNX	In this paper, we build upon~ CITATION  and obtain approximation algorithms for tensor clustering with Bregman divergences and arbitrary separable metrics such as  SYMBOL -norms
OWNX	The latter result is of particular interest for  SYMBOL -norm based tensor clustering, which may be viewed as a generalization of k-medians to tensors
OWNX	In the terminology of~ CITATION , we focus on the ``block average'' versions of co- and tensor clustering
OWNX	Additional discussion and relevant references for co-clustering can be found in~ CITATION , while for the lesser known problem of tensor clustering more background can be gained by referring to~ CITATION
MISC	Position determination in biological systems is often achieved through protein concentration gradients.
MISC	Measuring the local concentration of such a protein with a spatially varying distribution allows the measurement of position within the system.
MISC	For these systems to work effectively, position determination must be robust to noise.
MISC	Here, we calculate fundamental limits to the precision of position determination by concentration gradients due to unavoidable biochemical noise perturbing the gradients.
OWNX	We focus on gradient proteins with first-order reaction kinetics.
MISC	Systems of this type have been experimentally characterised in both developmental and cell biology settings.
OWNX	For a single gradient we show that, through time-averaging, great precision potentially can be achieved even with very low protein copy numbers.
MISC	As a second example, we investigate the ability of a system with oppositely directed gradients to find its centre.
OWNX	With this mechanism, positional precision close to the centre improves more slowly with increasing averaging time, and so longer averaging times or higher copy numbers are required for high precision.
OWNX	For both single and double gradients, we demonstrate the existence of optimal length scales for the gradients for which precision is maximized, as well as analyze how precision depends on the size of the concentration-measuring apparatus.
MISC	These results provide fundamental constraints on the positional precision supplied by concentration gradients in various contexts, including both in developmental biology and also within a single cell.
MISC	To determine position in a biological system, some component within the system must have a nonuniform spatial distribution.
MISC	Often, this is achieved through the formation of gradients of protein concentration.
MISC	Typically, a gradient forms when a protein is manufactured/injected within a small region and subsequently spreads and decays CITATION.
OWNX	By measuring the local concentration, position relative to the source can be determined.
OWNX	In developmental biology, where such gradients are used to control patterns of gene expression, gradient proteins are called morphogens.
MISC	However, intracellular concentration gradients are also thought to be important for organisation inside single cells.
MISC	For a gradient mechanism to be biologically viable, position determination must be precise and therefore robust to noise.
MISC	Variability from one copy of the system to another will certainly compromise positional precision.
OWNX	Production and degradation rates can vary.
MISC	The physical size of the system will also vary, and this may affect proper positioning.
MISC	Most previous analyses of morphogen gradients have focused on robustness to changes in these extrinsic factors CITATION CITATION between different copies of the system.
MISC	However, there will also be intrinsic noise affecting the gradient within a single copy of the system, for example due to the unavoidably noisy nature of the biochemical reactions involved.
OWNX	This dissection of the fluctuations into extrinsic or intrinsic components mirrors that introduced into the analysis of stochastic gene expression CITATION CITATION.
OWNX	However, here, intrinsic noise alters not only the overall protein copy numbers, but also crucially the spatiotemporal protein distribution.
MISC	Even if all extrinsic variation could be eliminated, intrinsic biochemical noise would still lead to a fundamental limit to the precision of position determination, in a similar way to limits on the precision of protein concentration measurement CITATION, CITATION.
OWNX	In this paper, we therefore address the question of how precisely a concentration gradient can specify positional information, and calculate the limits on positional precision for a simple, but biologically relevant, gradient formation mechanism with first-order reaction kinetics.
MISC	Quantitative measurements, for example on the Bicoid Hunchback system in Drosophila CITATION, have shown that remarkable positional precision can sometimes be obtained.
MISC	For this reason, understanding the fundamental limits to the precision of concentration gradients is clearly an important issue in developmental biology.
MISC	Our results will be equally relevant to gradients that form within single cells, where protein copy numbers of a few thousand CITATION CITATION will lead to large density fluctuations.
MISC	The properties of intracellular protein gradients have been studied by Brown and Kholodenko CITATION.
MISC	Recently, a number of these gradients have been observed experimentally in both prokaryotic and eukaryotic systems.
MISC	The bacterial virulence factor IcsA forms a polar gradient on the cell membrane of Shigella flexneri CITATION.
MISC	MipZ in Caulobacter crescentus forms polar gradients to aid division site selection CITATION.
MISC	In Bacillus subtilis, the MinCD complex also forms polar gradients in order to direct division site selection to the mid-plane of the cell CITATION, CITATION.
OWNX	In Escherichia coli, the oscillatory dynamics of the Min proteins creates a time-averaged gradient that directs cell division placement CITATION CITATION.
OWNX	Using mechanisms of this sort, division site placement in bacteria can achieve an impressive precision of 1 percent of the cell length CITATION, CITATION.
MISC	Cell division in eukaryotic cells is also believed to be regulated by concentration gradients.
MISC	For example, in fission yeast, the protein Pom1p forms a cortical concentration gradient emanating from a cell tip, thereby restricting the cell division protein Mid1p to the cell centre CITATION, CITATION.
MISC	In eukaryotic cells, gradients of the Ran and HURP proteins aid the formation of the mitotic spindle by biasing microtubule growth toward the chromosomes CITATION CITATION.
MISC	Gradients may also play a role in the localization of Cdc42 activation, thereby permitting a coupling between cell shape and protein activation CITATION, CITATION .
MISC	Suppose that a biological system needs to identify a particular position along its length, such as the mid-plane to ensure symmetrical cell division.
MISC	As concrete examples, MipZ and the MinCD complex act by displacing the essential cell division protein FtsZ from the cell membrane.
MISC	Since the concentrations of MipZ/MinCD are higher near the cell poles, FtsZ accumulates near the cell centre.
MISC	Below some critical threshold of MinCD or MipZ concentration, enough FtsZ will presumably accumulate to form the division apparatus.
MISC	The locations where the concentration gradient crosses these thresholds mark positions within the cell.
OWNX	In our analysis, we simply postulate the existence of such well-defined critical thresholds, where the gradient sharply switches a downstream signal from on to off.
MISC	Clearly, any real gradient cannot act as such a sharp switch in reality, a certain amount of smearing is inevitable.
OWNX	Furthermore, there will be additional noise in the process of actually measuring the concentration due both to the binding of the gradient proteins to the receptor molecules CITATION, CITATION, and also to the downstream reactions that process this incoming signal CITATION CITATION, CITATION CITATION.
OWNX	In general, the noise of the output signal of a processing network can be written as the sum of a contribution from the noise in the input signal plus a contribution from the reactions that constitute the processing network.
OWNX	We assume here that the detector and the processing network are ideal and do not add any noise to the gradient input signal.
OWNX	As a result, our calculated variation constitutes a lower bound; any real gradient-signalling system will inevitably have a lower precision.
MISC	We first considered a system with a single planar morphogen source and linear degradation, thereby producing an exponentially decaying average concentration profile.
MISC	While this model is very simple, it remains biologically relevant in both developmental and intracellular contexts.
OWNX	Gradients of Bicoid in Drosophila and IcsA in Shigella have been quantitatively measured and shown to fit this exponential decay profile on average to high accuracy CITATION, CITATION.
MISC	We then calculated the expected distribution of positions where a noisy gradient crosses a concentration threshold.
OWNX	With typical cellular copy numbers of a few thousand proteins, the system would be unable to identify the correct threshold position from a single measurement.
MISC	To achieve reliable position determination, the concentration must be averaged over time.
MISC	We show that by averaging measurements, a biological system is able to achieve precision in position determination of a few percent of the system size even with hundreds of protein copies, a result we verified with computer simulations.
MISC	Furthermore, we find that the precision of position determination is maximised when a particular choice of the gradient decay length is made.
OWNX	We also show how the precision depends on the detector size.
MISC	For a 2-D gradient, the precision possible after a certain averaging time depends only very weakly on the detector size.
OWNX	We relate all these results to experimental measurements of gradients in Shigella and fission yeast.
MISC	We also considered the ability of gradients from two poles to identify the centre of the system, as in the MipZ and Pom1p gradients discussed above.
MISC	Related designs have also been proposed for the control of hunchback positioning in Drosophila CITATION, CITATION, CITATION.
MISC	As before, we find that the precision of the system can be optimised by a particular choice of the decay length.
MISC	However, if the threshold position is set at the system centre, time-averaging improves precision more slowly than in the single-source model.
MISC	For subcellular gradients, we find that a few thousand copies of the gradient proteins may therefore be required for high precision.
MISC	Our results strongly constrain the possible concentrations of gradient proteins in two gradient systems.
MISC	many natural decisions contain an element of skill
MISC	modern conceptions of the skill component include control CITATION and competence CITATION
MISC	the control hypothesis states that a task's skill component the sensitivity of the task to skill affects decision making  the competence hypothesis states decision making is affected only if the participant possesses the skill
OWNX	three experiments compared risk taking patterns between two groups
MISC	one group faced bets on random events  and another group faced bets on their answers to general knowledge questions  which is a task characterized by control
MISC	in experiment  NUMBER   control increased risk taking markedly with all statistical properties held constant
MISC	in experiment  NUMBER   decisions made in domains of varying difficulty  and by individuals of varying ability  yielded further qualified support for the role of competence
OWNX	in experiment  NUMBER   the role of control was replicated  and participants' perceptions of the differences in group treatments aligned more with the implications of the control hypothesis than with the competence hypothesis
MISC	results offered support for the control hypothesis across a range of competence
MISC	decision researchers know a great deal about the terms of risk that people will accept and reject on random events such as the drawing of a lottery number  rolling a die  or pulling a poker chip from a bookbag
MISC	less is known about how individuals accept or reject risk when they are betting on their own golf putts  stock picks  organizational decisions or answers to trivia questions
MISC	researchers readily build models of decision making around risky decisions based on random events
MISC	much decision research is analogous to psychophysical perception research  relating psychological events to objective criteria
MISC	a bookbag with  NUMBER  percent white and  NUMBER  percent red poker chips presents a clear objective criterion to which subjective perceptions may readily be compared
MISC	sinking a free throw does not present such a clear criterion with regard to its associated probabilities
MISC	for this reason  researchers have difficulty in evaluating performance relative to a normative criterion when the task is assessing the probability of a made free throw  as well as in establishing valid lawful relationships between relevant probabilities and decisions
MISC	ellsberg  CITATION  and many others have found that people are generally ambiguity averse  in the domain of gains  people prefer a prospect in which probabilities of possible outcomes are known to a prospect in which probabilities of the same outcomes are not stated ambiguous but have the same average value
MISC	the major exception to this is at very low probabilities  where ambiguity is preferred
MISC	in the domain of losses  these preferences are reversed
OWNX	examination of the effect of a skill element constitutes a special case of ambiguity
MISC	what is shaquille o'neal's probability of making his next free throw
OWNX	at the conclusion of the  NUMBERNUMBER  season  his career free throw rate was  NUMBER   NUMBER  percent   but his free throw rate for the season was only  NUMBER   NUMBER  percent 
MISC	at his next free throw opportunity  he may be suffering from the flu  or coming off a terrible game  or on a hot streak  or he may merely believe he's on a hot streak  CITATION
CONT	unlike a lottery draw  in which it is easier to construct a reasonable estimate of the probability of winning for example  by reading the ticket  the sample space for a successful free throw is not clearly defined
MISC	in other words  the prediction of performance is variable over time in a skilled task  hence it is more difficult to predict on the basis of past performance
MISC	in fact  most definitions of skill state or imply that the person exerting skill can change the probability of success
MISC	the existing evidence suggests that a skilled task that determines an uncertain outcome has an effect on probability assessment and decision making that is distinct from that of ambiguity alone
MISC	for example  in demonstrating the illusion of control  langer  CITATION  showed that people responded differently to vague likelihoods when certain superficial characteristics of the prospects were distorted  for example when the familiar symbols of a deck of cards were replaced by unfamiliar symbols  or when participants were permitted to practice on a random mechanism similar to a roulette wheel
MISC	langer argued that the changes in the appearance of a skill component caused changes in responses
MISC	confidence ratings  bet acceptance and bet amounts were all affected by apparent control  although the illusion of control is not robust to multi-shot gambles  CITATION
MISC	participants bet more when given skill-relevant manipulations such as being able to choose whether to receive more cards in a simulated blackjack game  but not when given skill-irrelevant manipulations such as choosing a different dealer  CITATION
MISC	also  participants high in desire for control bet more than those low in desire for control on events over which they had falsely perceived control
MISC	those high in desire for control bet less than others on events over which they did not have illusory control  CITATION
MISC	recent research has advanced two major conceptions of the role of skill in decision making  competence  CITATION  and control  CITATION
MISC	these conceptions have important commonalities  sharing an emphasis on the role that the skill component of a task plays in shaping decision making under uncertainty apart from the probability and magnitude of possible outcomes
MISC	the control hypothesis claims that people bet more when skill makes a difference  the competence hypothesis claims the same effect but only when an individual possesses the relevant skill
MISC	control is a property of the task  if the task requires actions that can be learned  then it is characterized by control  even if a participant has not yet learned the skill
MISC	competence  on the other hand  is an interactive characteristic of both the task and the person  competence exists only if the task both can be learned the task component and has been learned the person component
MISC	heath and tversky  CITATION  argued that people prefer to bet on questions about knowledge topics in which they feel competent rather than incompetent
MISC	in their studies  participants chose to bet on either the correctness of their answer to a general knowledge question or a random event whose probability matched their previously stated confidence  with identical payoffs in each bet offer
MISC	across an assortment of situations  when betting on questions drawn from intermixed domains  the proportion of times that participants chose to bet on their knowledge was a steeply increasing function of the probability of winning experiments  NUMBER  and  NUMBER 
MISC	because confidence consistently exceeded accuracy in these experiments  betting on a random event whose probability of winning was equal to confidence was more likely to win than betting on the belief itself  and heath and tversky  CITATION  noted that the acceptance of knowledge-based bets over random bets resulted in a  NUMBER  percent  loss of expected earnings
MISC	heath and tversky then experiment  NUMBER  tested the competence hypothesis by drawing questions from discrete domains in which participants believed themselves to be either competent or incompetent
MISC	they observed that  with subjective probability held constant  participants displayed a consistent behavioral pattern  bets in a domain of competence were preferred to bets on random events  which in turn were preferred to bets in a domain of incompetence
MISC	they concluded that people seek out ambiguity in domains of competence but avoid it in areas of incompetence
MISC	fox and tversky  CITATION  presented a companion to the competence hypothesis  the comparative ignorance hypothesis  positing that relative knowledge affects decisions most strongly when the contrast between conditions of greater and lesser competence is brought to the decision maker's attention
MISC	these findings are notably contrary to the early ambiguity findings with random events  when evaluating bets on vaguely probable events with a skill component  participants preferred the ambiguous skilled option at high probabilities but preferred the unambiguous random option at low probabilities
OWNX	however  the evidence specifically in support of the control hypothesis remains limited to heath and tversky's experiment  NUMBER  comparing just two domains under unusual selection techniques  which are discussed at more length below
MISC	more recent studies  CITATION  assessed risk attitude by pitting a bet on knowledge item against no bet at all  rather than a bet on a random event of equivalent probability
MISC	goodie constructed bets on knowledge items to be fair  having zero average marginal value if confidence was well calibrated
MISC	in the first two experiments  bet acceptance sharply increased as confidence increased for knowledge bets  bearing a striking resemblance to the comparable data obtained by heath and tversky  CITATION  when using mixed-domain questions
MISC	in experiment  NUMBER   one group considered bets on their knowledge
MISC	the other groups considered bets on events that appeared random to participants but that goodie constructed to be identical in every statistical way to bets on knowledge
MISC	participants accepted more bets on random events at low probabilities and more bets on their knowledge at high probabilities  revealing the anticipated crossover effect
MISC	an important difference arises between studies that utilize questions drawn from a single domain e g   u s history and those that use questions from mixed domains e g   greek mythology  u s history  and sports
MISC	as heath and tversky  CITATION  noted in discussing the differences between single and mixed domains  low confidence items in mixed-domain populations will systematically include more questions from low-competence domains
MISC	similarly  gigerenzer  CITATION  noted the importance of utilizing single-domain questions in assessing confidence in answers
MISC	in a mixed-domain set of general knowledge questions  the methods used by the decision maker to generate confidence assessments become uninterpretable because the decision maker may be using a different reference set than the experimenter
MISC	asking participants questions in a single domain allows for more reliable representations of confidence across all questions asked
MISC	there is reason to expect that control per se influences decision making
MISC	skinner  CITATION   in a major review of the literature  notes that   w hen people perceive that they have a high degree of control  they exert effort  try hard  initiate action  and persist in the face of failures and setbacks  they evince interest  optimism  sustained attention  problem solving  and an action orientation   CITATION
MISC	where control prevails  a prospect with negative expected value  narrowly conceived  might also be an opportunity to learn new skill that will result in future prospects with positive value  and might therefore be worth accepting
MISC	this is an interesting complement to the normative argument made by frisch and baron  CITATION  that other ambiguous prospects  even with positive expected value  might be worth postponing until further information is available to permit better-valued decisions
MISC	we argue that ambiguous prospects characterized by control  even with negative expected value  might be worth pursuing in order to set up better-valued decisions later
MISC	the possibility of accepting bets in order to increase skill does not apply when competence already exists  only when the possibility of exerting control to increase competence prevails
MISC	the goals of this paper are  a to compare across domains wherein people have different degrees of competence  in order to observe the degree to which variation in competence makes a difference in risk attitude  b to extend the risk-attitude findings of goodie  CITATION  to single-domain formats  a manipulation that made a considerable difference in the ambiguity-attitude findings of heath and tversky  CITATION   and c to begin to compare the roles of competence and control in decisions under uncertainty
MISC	the present experiments test the competence hypothesis against the control hypothesis by eliciting betting decisions within domains of varying difficulty and among participants of varying ability
MISC	the distinction between competence and control is most evident in a skill-based task in which a particular participant has little skill
MISC	the control hypothesis suggests people bet more when skill could be attained  the competence hypothesis only when it has been attained
MISC	we can best differentiate between these two hypotheses when skill could be attained but has not
OWNX	the control hypothesis suggests the skill element does alter decision making under such conditions  whereas the competence hypothesis suggests it does not
OWNX	we report three experiments which use the methods developed by goodie  CITATION
OWNX	the basic task of fair bets on knowledge uses three kinds of questions  administered in two phases
MISC	the first question type was a two-alternative forced choice question
MISC	prior studies  CITATION  adapted questions from a collection  CITATION  that sampled from diverse domains
MISC	the present studies randomly selected questions from five well-defined domains
OWNX	three question populations selected two of the  NUMBER  u s states at random and asked for a binary comparison on one statistic  population  land area  or population density  manipulated between-subjects
MISC	the other two question populations randomly selected two of the  NUMBER  largest u s cities and elicited a comparison of the cities on either population or driving distance to athens  georgia
MISC	the second question type asked for an assessment of confidence in each question  placed in one of the following categories   NUMBERNUMBER  percent    NUMBERNUMBER  percent    NUMBERNUMBER  percent    NUMBERNUMBER  percent    NUMBERNUMBER  percent    NUMBERNUMBER  percent   and  NUMBERNUMBER  percent 
MISC	in a binary task such as this one  the range of  NUMBER  percentNUMBER  percent  reflects the full range of competence  from complete ignorance where accuracy would be  NUMBER  percent  and confidence should not be much higher  to absolute knowledge where accuracy and confidence are both  NUMBER  percent 
OWNX	confidence was taken as the midpoint of the selected confidence category
OWNX	we used these categories to assess risk taking across a well-defined array of probabilities from chance to certainty  combining equal spacing of categories in the mid-range and greater discrimination near the endpoints
MISC	this range confers the advantages of reflecting all binary choices and being simple and easily understood  although it also bears the clear limitations of excluding half the probability spectrum
OWNX	these studies adopted confidence elicitation methods without alteration from those used by goodie  CITATION
MISC	a third question type elicited acceptance or rejection of a bet on the correctness of each answer that was given
MISC	participants played out these bets for point accumulations that were not backed by monetary incentives
MISC	in all conditions  participants faced a two-alternative choice between a certain outcome and a bet
OWNX	the bet was always fair  having average value equal to the certain option if the participant's confidence judgment was well-calibrated
MISC	its average value was less than that of the certain option if the participant was overconfident and greater than the certain option if the participant was underconfident
OWNX	after accepting or rejecting the bet  the participant received feedback  including the correct answer to the question  the number of points gained or lost including if no points were gained or lost  and the cumulative point total
MISC	we used two betting formats  with mixed gains and losses  and gains only
MISC	the mixed format was used in order to reflect the structure of many risks which contain the possibility of either gain or loss
MISC	the gains only format was used to eliminate the complexity of possibly differing value and weighting for gains and losses
OWNX	we designed both betting formats to provide average outcomes that were equal if the bet was accepted or rejected  assuming good calibration
MISC	betting formats were always varied between subjects  or were kept constant within an experiment  so that no participant needed to comprehend  remember  or distinguish between both
MISC	in the mixed format  the certain option was no change in points  and the bet provided for a gain of  NUMBER  points if the answer was correct or a loss of  NUMBER    confidence  NUMBER -confidence points if the answer was incorrect
OWNX	for example  if a participant was  NUMBER  percent  confident in an answer  then she considered a bet wherein she won  NUMBER  points if the answer was correct but a loss of  NUMBER      NUMBER    NUMBER     NUMBER  points if the answer was wrong
MISC	if she rejected the bet  she did not gain or lose any points
MISC	in the gains only structure  the certain option was a gain of  NUMBER  points
OWNX	the bet offered a gain of  NUMBER   confidence points if the answer was correct and no gain if the answer was wrong
OWNX	so  if the participant bet on an answer in which she had  NUMBER  percent  confidence  she won  NUMBER    NUMBER     NUMBER  points if the answer was correct but nothing if the answer was wrong
OWNX	she gained  NUMBER  points if she rejected the bet
MISC	it is easy to show that the average outcome of accepting a bet in either format is equal to the certain option no change in the mixed format or a gain of  NUMBER  points in gains only if pcorrect   confidence  less than the certain option if pcorrect  confidence  and greater than the certain option if pcorrect  confidence
MISC	in experiments  NUMBER  and  NUMBER   we randomly assigned participants to two groups that differed in whether they believed they were betting on their knowledge or on a random event
MISC	the answers group bet on their answers  using either the mixed or gains only format in different experiments
MISC	the random group's bets held all statistical properties constant  differing from the answers group's only in appearing to rely on random events rather than participants' answers
MISC	many dimensions of bets on knowledge are determined by the participants' responses  such as the distribution of subjective probabilities of winning determined by confidence  the frequency of winning determined by accuracy  and any order effects on these dimensions  CITATION
MISC	by basing the apparently random bets on the participant's responses  we can rule out these and any other alternative explanations based on such statistical properties of the responses of participants in the answers condition
MISC	bets that appeared stochastic in fact relied on participants' answers and confidence assessments in the knowledge questions
OWNX	in the betting phase  each answer was converted into a bet on a seemingly random event with the stated probability of winning equal to assessed confidence in a corresponding trivia answer  the correctness of the corresponding answer determined the bet's outcome
OWNX	for example  if a participant expressed  NUMBER  percent  confidence in her answer to the first question  then the first bet she encountered in the betting phase instructed  a number will be chosen at random between  NUMBER  and  NUMBER   and to win the bet  the chosen number must be less than or equal to the magic number
MISC	the magic number this time is   NUMBER 
MISC	if the chosen number is less than or equal to the magic number  you gain  NUMBER  points
MISC	if the chosen number is greater than the magic number  you lose  NUMBER  points
OWNX	if the participant accepted the bet  she won the bet if her answer to the corresponding question was correct and lost the bet if her answer was incorrect
OWNX	the magic number  the magnitude of the gain if the bet was won  and the determination of whether the bet was won or lost changed on each betting trial to reflect the confidence expressed in the corresponding answer from the first phase and whether it was correct
OWNX	in all experiments  we recruited participants from the research pool of the psychology department at the university of georgia and compensated them with partial credit toward lower-division courses
OWNX	we prevented participants from participating in more than one of the present experiments or in any additional related experiments
MISC	participants ran in groups of up to three in a room with individual computer stations separated by five-foot-tall partitions
MISC	we omitted participants' data from analysis if they did not use more than three confidence categories  or if they showed evidence of not attending to the task i e   exclusive betting acceptance or rejection  or radical over- or underconfidence
MISC	thirty participants were excluded for this reason  NUMBER  out of  NUMBER  in experiment  NUMBER    NUMBER  out of  NUMBER  in experiment  NUMBER   and  NUMBER  out of  NUMBER  in experiment  NUMBER 
OWNX	see table  NUMBER  for a layout of the structure of our experimental design
MISC	previous research has identified important determinants of overall evaluations for experiences lived across time
MISC	by means of a novel guessing task  i study what decision-makers themselves consider important
MISC	as informants  some participants live and evaluate an experience
MISC	as guessers  others have to infer its overall evaluation by asking informants questions
OWNX	i rewarded accurate inferences  and analyzed and classified the questions in four experiments involving auditory  gustatory and viewing experiences
MISC	results show that guessers thought of overall evaluations as reflecting average momentary impressions
MISC	moreover and alternatively  they tended to consider the personality and attitudes of the experiencing person  experience-specific holistic judgments and behavioral intentions regarding the experience
MISC	thus  according to lay intuitions  overall evaluations are more than a reflection of the experience's momentary impressions
MISC	people often report experiences by expressing a number on a scale
MISC	someone might say    NUMBER  out of  NUMBER  for this concert   or  in terms of painfulness  i rate this medical procedure as  NUMBER  out of  NUMBER 
MISC	   such overall evaluations of experiences have been shown to be important decision inputs  CITATION   and studied extensively
MISC	kahneman  wakker  and sarin  CITATION  suggested that experiences can be represented as intensity profiles of pleasure or discomfort over bounded intervals of time  i e   time profiles of  experienced utility
MISC	  experiments and field studies have shown that people evaluate more positively experiences with increasing  rather than decreasing time profiles at equivalent levels of total pleasure experienced  CITATION
MISC	there is a preference for steeper rates of improvement  CITATION   as well as variability in experience  CITATION
MISC	finally  the  peak-end rule  finding suggests that overall evaluations are best predicted by only two moments of the experience  the most pleasant unpleasant and final  CITATION
MISC	kahneman  wakker and sarin  CITATION  present a set of assumptions about experiences explaining why integration summation of all moments would be correct from a normative point of view
MISC	life satisfaction researchers and psychologists  on the other hand  explore alternative paradigms and study the role of personality and the beliefs of the evaluating person for overall evaluations  CITATION
MISC	in contrast to previous research  the present work aims to reveal what decision makers themselves draw on as they think about overall evaluations of experiences
MISC	i will compare lay intuitions to what researchers have considered
MISC	this comparison may further enrich theories of overall evaluations  and suggest ways of testing them
OWNX	i employ a novel method  the guessing task  in order to elicit lay intuitions
MISC	the philosophy of the method is that of active information search  a method of naturalistic decision-making that huber  wider  and huber  CITATION  proposed for the study of risky choice
OWNX	the method consists of giving participants a minimal description of a decision problem and allowing them to seek information
MISC	i report experiments in which participants had to guess the overall evaluation of an experience lived by another person
MISC	active information search was allowed prior to making the guess
OWNX	the information participants sought was taken to reveal lay intuitions about the target overall evaluation
MISC	Influenza can be transmitted through respirable, inspirable, direct-droplet-spray, and contact modes.
MISC	How these modes are affected by features of the virus strain, host population, and environment have only recently come under investigation.
AIMX	A discrete-event, continuous-time, stochastic transmission model was constructed to analyze the environmental processes through which a virus passes from one person to another via different transmission modes, and explore which factors increase or decrease different modes of transmission.
MISC	With the exception of the inspiratory route, each route on its own can cause high transmission in isolation of other modes.
MISC	Mode-specific transmission was highly sensitive to parameter values.
MISC	For example, droplet and respirable transmission usually required high host density, while the contact route had no such requirement.
MISC	Depending on the specific context, one or more modes may be sufficient to cause high transmission, while in other contexts no transmission may result.
MISC	Because of this, when making intervention decisions that involve blocking environmental pathways, generic recommendations applied indiscriminately may be ineffective; instead intervention choice should be contextualized, depending on the specific features of people, virus strain, or venue in question.
MISC	On June 11, 2009 the WHO declared the H1N1 influenza virus a pandemic.
MISC	Health organizations worldwide were prompted to escalate their efforts to minimize transmission within their jurisdictions.
MISC	Airports began to monitor incoming passengers while schools increased their already intensive surveillance activities.
MISC	Recommendations were established with regard to masks, hygiene, decontamination, and isolation of suspected cases.
MISC	This interest in intervention and control of person-to-person transmitted illnesses with multiple potential routes of transmission began to intensify during the emergence of SARS and later the H5N1 virus.
MISC	Heightened awareness of the potential for another pandemic influenza led to increased funding to study non-pharmaceutical interventions by the CDC as well as increased efforts in modeling influenza transmission.
MISC	These studies were funded in order to better understand optimal intervention and control strategies.
MISC	Much insight was gained into influenza mitigation strategies such as border closure, social distancing, antiviral prophylaxis, restriction of public transportation, and school closure CITATION CITATION.
MISC	To date, however, little is known about the relative contributions of the different influenza transmission modes and how these might vary due to heterogeneity in viral strain, host, and environment.
MISC	This manuscript explores potential effects of these unknown factors by presenting: a transmission model structure that explicitly describes the environmental processes through which viruses pass from one person to another, thereby distinguishing the different modes of transmission; and an analytical approach that explores which factors increase or decrease different modes of transmission under the given model structure.
MISC	The model analyzed is an environmental infection transmission system model that elaborates the approach to such models by Li et al. CITATION by formulating the model in a discrete event framework and greatly expanding on the details of the various processes involved.
MISC	It does not define contact events with transmission probabilities for each event as most transmission models do CITATION.
MISC	A problem with that approach is defining what constitutes a contact.
MISC	Instead we define events related to virus excretion, environmental survival, uptake, and causation of infection.
MISC	This allows us to address events at a level that is more relevant to possible interventions and the construction of more meaningful causal theory.
MISC	To inform relevant intervention options for influenza, we consider four potential modes of transmission: respirable, inspirable, direct-droplet-spray, and contact mediated transmission CITATION CITATION.
OWNX	In this manuscript we consider each mode as follows.
MISC	Respirable transmission occurs when viruses on small particles are inhaled and deposit in the alveolar region of the lower respiratory tract.
MISC	Inspirable transmission occurs when viruses on medium size particles are inhaled and deposit in the upper respiratory tract.
MISC	Direct-droplet-spray transmission occurs when viruses on large particles from the cough or sneeze of an infected individual deposit directly on a susceptible individual's mucous membranes.
MISC	Contact transmission occurs when an infected person contaminates their own hands or contaminates surfaces via their hands or via droplets with virus laden large particles.
MISC	Transfer of pathogens may then result in contamination of the hands of others who then may touch their eyes, nose or mouth to self-inoculate, potentially infecting the upper respiratory tract.
MISC	We assess how different feasible model parameters influence how much transmission follows these different routes.
MISC	For example, different viruses may have different infectivity, survivability, transferability, or shedding profiles.
MISC	Similarly, among different populations who have different behaviors, susceptibility profiles, or shedding profiles, the same virus may have different effects depending on the type of population present.
MISC	Finally, even with identical viral strains and human populations, environmental venues may have variable host densities, surface area to volume ratios, or host movement patterns that can generate different population level infection outcomes.
MISC	These diverse sources of heterogeneity that we address form the corners of the epidemiologic triad .
MISC	We assess the effects of these sources of heterogeneity on relative magnitude of influenza transmission modes in a scenario where all individuals move randomly in an identical fashion.
MISC	We construct a detailed stochastic individual based model of environmental influenza transmission.
MISC	We use values from empirical literature as well as expert judgment to parameterize this model.
OWNX	We apply upper and lower parameter constraints to 18 parameters, and obtain a Latin hypercube sample of this constrained parameter space.
MISC	We analyze the resulting outcome space with respect to how different transmission modes are more or less important in specific contexts.
MISC	With this work we contribute to the body of literature discussing the dominant mode of influenza transmission CITATION, CITATION CITATION.
CONT	Additionally, this work takes an incremental step forward from previous environmental infection transmission models CITATION, CITATION, CITATION CITATION as: we model all four modes of influenza transmission simultaneously; we do so in an agent based framework rather than with ordinary differential equation based framework; and this model is solely informed parametrically by empirical work no model fitting or optimization procedures were used to parameterize this model.
MISC	We explicitly point out where the holes in the empirical literature exist.
MISC	We show that depending on the scenario, one mode may be more or less important than another.
MISC	Therefore, when intervening, generic recommendations applied indiscriminately may be ineffective; instead intervention choice should be contextualized depending on the specific features of people, virus, or venue in question.
MISC	We consider how features related to pathology, behavior, and microbiology in the host, pathogen, and environment alter the magnitude of transmission via each mode.
MISC	Representing and analyzing complex networks remains a roadblock to creating dynamic network models of biological processes and pathways.
OWNX	The study of cell fate transitions can reveal much about the transcriptional regulatory programs that underlie these phenotypic changes and give rise to the coordinated patterns in expression changes that we observe.
OWNX	The application of gene expression state space trajectories to capture cell fate transitions at the genome-wide level is one approach currently used in the literature.
OWNX	In this paper, we analyze the gene expression dataset of Huang et al. which follows the differentiation of promyelocytes into neutrophil-like cells in the presence of inducers dimethyl sulfoxide and all-trans retinoic acid.
MISC	Huang et al. build on the work of Kauffman who raised the attractor hypothesis, stating that cells exist in an expression landscape and their expression trajectories converge towards attractive sites in this landscape.
OWNX	We propose an alternative interpretation that explains this convergent behavior by recognizing that there are two types of processes participating in these cell fate transitions core processes that include the specific differentiation pathways of promyelocytes to neutrophils, and transient processes that capture those pathways and responses specific to the inducer.
MISC	Using functional enrichment analyses, specific biological examples and an analysis of the trajectories and their core and transient components we provide a validation of our hypothesis using the Huang et al. dataset.
MISC	Our understanding of the molecular basis of a wide range of biological processes, including development, differentiation, and disease, has evolved significantly in recent years.
MISC	Increasingly, we are coming to recognize that it is not single genes, but rather complex networks of genes, gene products, and other cellular elements that drive cellular metabolism and cell fate, and when perturbed, can lead to development of disease phenotypes.
MISC	Representing and analyzing such complex networks, encompassing thousands or tens of thousands of elements, presents significant challenges.
MISC	One approach that has begun to be applied is the representation of transcriptional changes as transitions that occur with the state space defined by the expression states of all genes within the cell CITATION, CITATION.
MISC	This approach has a number of advantages, including providing a framework for predictive modeling and the incorporation of stochastic components in the biological process.
MISC	The underlying assumption in such an analysis is that each cellular phenotype can invariably be traced back to a particular class of genome-wide gene expression signatures representing a specific region of the gene expression state space.
MISC	As described in Huang et al. CITATION, this signature for a particular cellular state at a particular instant in time is represented by a multidimensional gene expression vector in a high dimensional space where each coordinate represents the expression level of a particular gene.
OWNX	By considering all possible configurations that this signature can take, we create a multidimensional landscape that is referred to as the expression state space CITATION.
OWNX	Each observed phenotype can be represented as a single point in the state space.
MISC	When cells transition through successive phenotypes, for example, during the different stages of hematopoietic differentiation, specific sets of genes alter their expression levels as dictated by an underlying transcriptional program and these changes can be represented by a continuous trajectory in expression state space; ultimately these represent the transcriptional program being played out by the cell's collection of gene networks and complex pathways.
OWNX	Kauffman CITATION first proposed the idea that stable cell fates, the cellular phenotypes we observe, correspond to attractors in the expression state space, stable points to which the system would return to if subjected to a small perturbation.
OWNX	He points out that in principle cells could adopt any permutation of gene expression states however this is not what we observe in nature.
MISC	According to Kauffman, since there are about 250 different cell types, there must be approximately that number of attractors in state space, either valleys or peaks in the landscape, that represent the stable cell fates or cell types that cells will ultimately converge to in the presence of an inducer or perturbation.
MISC	While this is an interesting model, direct experimental evidence supporting it and its overall utility in explaining cellular mechanism remain to be seen.
MISC	Huang et al. CITATION reported evidence they claim demonstrated the existence of an attractor.
OWNX	They conducted a gene expression time-course experiment on the differentiation of human HL-60 promyelocytic cells into neutrophils using two different inducers, dimethyl sulfoxide and all-trans retinoic acid.
OWNX	Time-course data was collected using Affymetrix U95Av2 GeneChips and analyzed to provide gene expression level measures necessary to create a state-space model.
MISC	Using principal components analysis, they develop a two-dimensional state space representation in which DMSO and ATRA induce initially divergent trajectories that, over time, converge on a common trajectory leading to a final expression state representing the neutrophils.
OWNX	They argue that instead of observing trajectories that explore the state space, the trajectories display convergence to a single point and that this therefore provides empirical proof that attractive states exist in nature.
OWNX	Here, we propose an alternative interpretation of this convergent behavior that does not appeal to the attractor hypothesis but rather explores this observation in the context of a superposition of components that reflect the pathways activated by the applied perturbations.
OWNX	To this end, we extend the work of Huang et al. CITATION by decomposing the state space trajectories into components comprising two sets of genes, a core group and transient group that capture the stimulus-independent and stimulus-dependent effects, respectively.
MISC	The superposition of these components reflect the observation that both sources of effects independently influence the overall shape of the trajectory taken during the cell fate transition.
OWNX	We show how this division allows us to look at functional behavior of genes and their contribution to the cell fate transitions in a more enlightening way.
MISC	Using regression models, we isolate core genes that are common to both stimuli and represent those critical to the differentiation process.
MISC	The genes outside the core represent the transient component of the trajectory corresponding to the perturbation effects.
OWNX	To illustrate our ideas, we apply our method to the same published dataset generated by Huang et al. CITATION .
MISC	The HL-60 cell line has long been used as a model to understand the molecular mechanisms driving the progression and pathogenesis of acute promyelocytic leukemia CITATION.
MISC	In normal promyelocytes, proliferation and differentiation are tightly coupled processes.
OWNX	However this balance comes unstuck in APL cells and as a result cells proliferate in a disregulated fashion.
MISC	The discovery that inducers like RA and DMSO could reprogram APL cells to overcome this block and resume differentiation, led to the emergence of a class of therapeutics known as differentiation therapy CITATION .
OWNX	DMSO is an organic solvent but also functions as a cryoprotective agent for tissue cell culture CITATION.
MISC	Although it is widely used in veterinary medicine in the treatment of pain and inflammation, it is not generally used in humans because it is known to be hepatotoxic.
MISC	The hormone ATRA is a derivative of vitamin A and belongs to a class of molecules called retinoids CITATION.
MISC	ATRA is currently used in differentiation therapies that treat human patients with APL.
MISC	Current complete remission rates for APL patients on ATRA-based differentiation therapy in combination with chemotherapy have been reported to be as high as 90 95 percent CITATION.
OWNX	At the molecular level, both DMSO and ATRA arrest the cell cycle at the G1-S phase transition point, and induce terminal differentiation of HL-60 cells, resulting in neutrophil-like cells.
MISC	ATRA and DMSO are biochemically distinct molecules that activate slightly different sets of pathways in HL-60 cells.
OWNX	Huang et al. CITATION explain that this is the reason why the trajectories initially diverge and explore different parts of the expression state space.
MISC	They argue that it is the presence of an attractor that then causes the trajectories to converge from different directions to eventually arrive at a common endpoint, and discount the possibility of a specific, unique differentiation pathway that may be triggered by both inducers.
MISC	While this argument may seem conceptually appealing, upon further inspection the attractor hypothesis greatly limits our ability to develop mechanistic interpretations or to build predictive models of cell fate transitions.
MISC	We believe that there exists an alternative, more plausible interpretation that Huang et al. CITATION and Kauffman CITATION have not considered.
MISC	Our interpretation is based on the recognition that there are two types of processes that contribute to cell fate transitions: one, a core biological process inherent to the transition-specific event and two, a transient process related to the direct effects that the particular inducing agent exerts on the cell.
MISC	The early divergence seen in the state space trajectories described by Huang et al. CITATION is reflective of the cells' response to specific perturbation and the compound-specific response that follows.
MISC	We expect these transient processes to dominate only at the initial period of the time-course since most drugs are metabolized quickly by the cell.
MISC	Once this disorder has subsided, the targeted effects of each inducer are expected to have begun triggering the core processes and as this occurs, the directions that both trajectories adopt become more and more convergent because the overlap in activated pathways in DMSO-induced cells and ATRA-induced cells is growing larger as the cells transition towards their common endpoint.
MISC	The source of this convergence therefore is not necessarily due to the existence of an attractor but instead can be explained by the combination of these two types of processes exerting their temporal effects on cells.
MISC	Indeed, if such an attractor existed, then there should be a whole class of perturbations that would cause transitions from the initial to the final state, rather than a small number that activate a single core pathway.
MISC	If one adopts the attractor hypothesis as the basis for cell-fate transitions, then our interpretation is much closer to that of Conrad Waddington, in which he argued for the canalization of state space through the existence of defined paths, or canals, between attractor states CITATION CITATION .
MISC	Transposable elements are mobile, repetitive sequences that make up significant fractions of metazoan genomes.
MISC	Despite their near ubiquity and importance in genome and chromosome biology, most efforts to annotate TEs in genome sequences rely on the results of a single computational program, RepeatMasker.
MISC	In contrast, recent advances in gene annotation indicate that high-quality gene models can be produced from combining multiple independent sources of computational evidence.
MISC	To elevate the quality of TE annotations to a level comparable to that of gene models, we have developed a combined evidence-model TE annotation pipeline, analogous to systems used for gene annotation, by integrating results from multiple homology-based and de novo TE identification methods.
MISC	As proof of principle, we have annotated TE models in Drosophila melanogaster Release 4 genomic sequences using the combined computational evidence derived from RepeatMasker, BLASTER, TBLASTX, all-by-all BLASTN, RECON, TE-HMM and the previous Release 3.1 annotation.
OWNX	Our system is designed for use with the Apollo genome annotation tool, allowing automatic results to be curated manually to produce reliable annotations.
OWNX	The euchromatic TE fraction of D. melanogaster is now estimated at 5.3 percent, and we found a substantially higher number of TEs than previously identified.
OWNX	Most of the new TEs derive from small fragments of a few hundred nucleotides long and highly abundant families not previously annotated.
MISC	We also estimated that 518 TE copies are inserted into at least one other TE, forming a nest of elements.
MISC	The pipeline allows rapid and thorough annotation of even the most complex TE models, including highly deleted and/or nested elements such as those often found in heterochromatic sequences.
MISC	Our pipeline can be easily adapted to other genome sequences, such as those of the D. melanogaster heterochromatin or other species in the genus Drosophila.
MISC	Transposable elements are mobile, repetitive DNA sequences that constitute a structurally dynamic component of genomes.
MISC	The taxonomic distribution of TEs is virtually ubiquitous: they have been found in nearly all eukaryotic organisms studied, with few exceptions.
MISC	TEs represent quantitatively important components of genome sequences, and there is no doubt that modern genomic DNA has evolved in close association with TEs.
MISC	TEs show high species specificity, and the number and types of TE can differ quite dramatically between even closely related organisms.
OWNX	There is abundant circumstantial evidence that TEs may transfer horizontally between species by mechanisms that remain obscure.
MISC	The forces controlling the dynamics of TE spread within a species are also poorly understood, as are the systemic effects of the elements on their host genomes.
MISC	Insertions of individual TEs may lead to genome restructuring, mutations in genes, or changes in gene regulation.
MISC	Some TE insertions may even have become domesticated to play roles in the normal functions of the host.
MISC	Despite their manifold effects, abundance, and ubiquity, we understand very little about most aspects of TE biology.
OWNX	One way of furthering our knowledge of TE biology is through the computational analysis of TEs in the growing number of complete genomic sequences.
MISC	By detailed comparison of the abundance and distribution of TEs in entire genomes, we can infer the fundamental biological properties of TEs that are shared or that differ among species.
OWNX	However, meaningful inferences about TE biology based on computationally derived TE annotations can only be done if we are confident about the results of these analyses.
OWNX	The hallmark of a strong result in computational biology should be its robustness to the particular method used.
MISC	The annotation of TEs, however, typically relies on the results of a single computational program, RepeatMasker, which recent studies indicate may be neither the most efficient nor the most sensitive approach for TE annotation CITATION.
MISC	By contrast, recent advances in the field of gene annotation indicate that high-quality gene models can be produced by combining multiple independent sources of computational evidence CITATION CITATION.
OWNX	With the recent development of several new methods for TE and repeat detection CITATION CITATION, it is now possible to apply a similar combined evidence approach to elevate the quality of TE annotations to a level comparable to that of gene models.
OWNX	To achieve this aim, we have developed a TE annotation pipeline that integrates results from multiple homology-based and de novo TE identification methods.
OWNX	Currently, our pipeline uses the combined computational evidence derived from RepeatMasker, BLASTER CITATION, TBLASTX CITATION, all-by-all BLASTN CITATION, RECON CITATION, TE-HMM CITATION, and previously published TE annotations CITATION.
OWNX	We have designed our system to use an evidence-model framework and the Apollo genome annotation tool CITATION, allowing computational evidence to be manually curated in an efficient manner to produce reliable TE models.
MISC	The pipeline allows rapid and thorough annotation of complex TE models, providing key structural details that allow insights into the origin of highly deleted and/or nested elements.
MISC	In contrast to simply masking repeats, our method provides the means to a complete and accurate annotation of TEs, supported by multiple sources of computational evidence, a goal that has important implications for experimental studies of genome and chromosome biology.
OWNX	As a test case we have chosen to annotate the euchromatic genomic sequence of the fruit fly, Drosophila melanogaster.
MISC	The 116.8-Mb Release 3 genome sequence of D. melanogaster is among the highest quality genome sequences and is a particularly well suited sequence for genome-wide studies of TEs, since repetitive DNA sequences have been finished to high quality and systematically verified by restriction fingerprint analysis CITATION.
MISC	Moreover, the Release 3.1 annotation of D. melanogaster includes a manually curated set of TE annotations CITATION that can be used as a benchmark for developing and refining TE annotation methodologies.
AIMX	Controlled tests performed here on the Release 3 sequence show that a combined-evidence approach has superior performance over individual TE detection methods, and that a substantially larger fraction of the genome is composed of TEs than previously estimated.
MISC	We have applied our pipeline to the new 118.4-Mb Release 4 sequence, which has closed several of the gaps in Release 3 and has extended the sequence of the pericentomeric regions, to produce a systematic re-annotation of TEs in the D. melanogaster genome.
OWNX	The euchromatic TE fraction is now estimated at 5.3 percent, and we found a substantially higher number of TEs than previously identified.
MISC	We also estimated that 518 TE copies are inserted into at least one other TE, forming a nest of elements.
MISC	Our pipeline can be easily adapted to other genome sequences, and could markedly increase the efficiency of annotating genomic regions with complex or abundant TE insertions such as heterochromatic sequences.
OWNX	Calmodulin kinase II mediates critical signaling pathways responsible for divergent functions in the heart including calcium cycling, hypertrophy and apoptosis.
MISC	Dysfunction in the CaMKII signaling pathway occurs in heart disease and is associated with increased susceptibility to life-threatening arrhythmia.
MISC	Furthermore, CaMKII inhibition prevents cardiac arrhythmia and improves heart function following myocardial infarction.
MISC	Recently, a novel mechanism for oxidative CaMKII activation was discovered in the heart.
MISC	Here, we provide the first report of CaMKII oxidation state in a well-validated, large-animal model of heart disease.
OWNX	Specifically, we observe increased levels of oxidized CaMKII in the infarct border zone.
MISC	These unexpected new data identify an alternative activation pathway for CaMKII in common cardiovascular disease.
OWNX	To study the role of oxidation-dependent CaMKII activation in creating a pro-arrhythmia substrate following myocardial infarction, we developed a new mathematical model of CaMKII activity including both oxidative and autophosphorylation activation pathways.
OWNX	Computer simulations using a multicellular mathematical model of the cardiac fiber demonstrate that enhanced CaMKII activity in the infarct BZ, due primarily to increased oxidation, is associated with reduced conduction velocity, increased effective refractory period, and increased susceptibility to formation of conduction block at the BZ margin, a prerequisite for reentry.
MISC	Furthermore, our model predicts that CaMKII inhibition improves conduction and reduces refractoriness in the BZ, thereby reducing vulnerability to conduction block and reentry.
MISC	These results identify a novel oxidation-dependent pathway for CaMKII activation in the infarct BZ that may be an effective therapeutic target for improving conduction and reducing heterogeneity in the infarcted heart.
OWNX	Calmodulin kinase II mediates diverse roles in the heart, including excitation-contraction coupling, sinus node automaticity, apoptosis, hypertrophy, and gene transcription CITATION, CITATION.
MISC	Mounting experimental evidence demonstrates an important role for CaMKII in heart disease and arrhythmias.
MISC	Specifically, CaMKII overexpression occurs in human heart failure CITATION and transgenic mice overexpressing CaMKII develop dilated cardiomyopathy CITATION, CITATION.
MISC	Conversely, transgenic inhibition of CaMKII prevents structural remodeling and improves heart function following myocardial infarction CITATION while knockout mice lacking the predominant cardiac CaMKII isoform are resistant to development of pressure overload-induced hypertrophy and/or heart failure CITATION, CITATION.
MISC	Finally, CaMKII inhibition prevents arrhythmias in several different mouse models of heart disease CITATION, CITATION .
MISC	CaMKII is activated by binding of Ca 2 /calmodulin and may undergo inter-subunit autophosphorylation that allows the kinase to retain activity even upon dissociation of Ca 2 /calmodulin CITATION.
OWNX	Recently, a novel CaMKII activation pathway was identified where oxidation at specific methionine residues in the CaMKII regulatory subunit results in persistent activity independent of autophosphorylation CITATION.
MISC	While oxidative-dependent CaMKII activation has been shown to mediate apoptosis in response to chronic AngII treatment in the mouse CITATION as well as arrhythmogenic afterdepolarizations in isolated cardiomyocytes treated with hydrogen peroxide CITATION, nothing is known about its role in large animal models of heart disease.
OWNX	Considering that levels of reactive oxygen species such as H 2O 2 and superoxide are elevated following myocardial infarction CITATION, we hypothesized that oxidation of CaMKII represents an important pathway for CaMKII activation in the infarct border zone that may provide a mechanistic link between increased ROS production, Na channel remodeling and conduction slowing following MI.
OWNX	In this study, we describe a dramatic increase in levels of oxidized CaMKII in a well-validated large animal model of arrhythmias following MI CITATION CITATION.
OWNX	To investigate a role for oxidized CaMKII in regulating refractoriness and conduction in the infarct BZ, we develop a novel mathematical model of CaMKII activity that includes oxidation and autophosphorylation activation pathways.
OWNX	Our computer simulations show that enhanced CaMKII activity in the BZ, due primarily to increased oxidation, leads to slowed conduction, prolonged refractory periods and increased vulnerability to conduction block at the BZ margin.
OWNX	Our results identify oxidation-dependent CaMKII activation as a potential link between oxidative stress and electrical remodeling after myocardial infarction.
OWNX	Furthermore, our findings support CaMKII inhibition as a potential therapy for reducing susceptibility to ventricular tachycardia by improving conduction and reducing refractory gradients in the infarcted heart.
MISC	Finally, it is important to note the oxidative activation of CaMKII allows for independent regulation of the kinase by a host of unique upstream activators and signaling partners with great potential relevance to human disease.
AIMX	As details emerge regarding regulation of the kinase by this newly identified pathway, they may be incorporated into our model to study electrophysiological consequences of CaMKII activation via this independent signaling pathway.
OWNX	Grammar inference deals with determining (preferable simple) models/grammars consistent with a set of observations
MISC	There is a large body of research on grammar inference within the theory of formal languages
MISC	However, there is surprisingly little known on grammar inference for graph grammars
OWNX	In this paper we take a further step in this direction and work within the framework of node label controlled (NLC) graph grammars
MISC	Specifically, we characterize, given a set of disjoint and isomorphic subgraphs of a graph  SYMBOL , whether or not there is a NLC graph grammar rule which can generate these subgraphs to obtain  SYMBOL
OWNX	This generalizes previous results by assuming that the set of isomorphic subgraphs is disjoint instead of non-touching
MISC	This leads naturally to consider the more involved ``non-confluent'' graph grammar rules
MISC	Grammar inference, also called grammar induction, is a general line of research where one is concerned with determining a ``simple'' grammar that is consistent with a given set of possible and impossible outcomes
MISC	Hence, one ``goes back'' in the derivation: instead of determining the generative power of a grammar, one determines the grammar given the generated output
MISC	This topic is well-studied for formal languages, especially with respect to context-free languages, see eg CITATION , however, relatively little is known for graph grammars
MISC	The topic of inference of graph grammars is considered in  CITATION  and uses their so-called Subdue scheme developed in  CITATION
MISC	In  CITATION  a rigorous approach of grammar inference within the framework of node label controlled (NLC) graph grammars  CITATION , a natural and well-studied class of graph grammars, is initiated
MISC	There it is characterized, given a set  SYMBOL  of non-touching isomorphic graphs of a graph  SYMBOL , whether or not there is a graph grammar consisting of one rule able to generate the graphs of  SYMBOL  to obtain  SYMBOL
OWNX	We continue this research and generalize this result for the case where these graphs are disjoint instead of non-touching
OWNX	Such a generalization requires one to deal with a number of issues
MISC	Most notably, one has to deal with non-confluency issues: the generated graph depends on the order in which touching subgraphs are generated \addconf{Due to space constraints, proofs of the results are omitted, but can be found in an extended version
OWNX	
OWNX	of this paper }
OWNX	Sumoylation, the covalent attachment of SUMO to proteins, differs from other Ubl pathways.
MISC	In sumoylation, E2 ligase Ubc9 can function without E3 enzymes, albeit with lower reaction efficiency.
OWNX	Here, we study the mechanism through which E3 ligase RanBP2 triggers target recognition and catalysis by E2 Ubc9.
OWNX	Two mechanisms were proposed for sumoylation.
OWNX	While in both the first step involves Ubc9 conjugation to SUMO, the subsequent sequence of events differs: in the first E2-SUMO forms a complex with the target and E3, followed by SUMO transfer to the target.
MISC	In the second, Ubc9-SUMO binds to the target and facilitates SUMO transfer without E3.
OWNX	Using dynamic correlations obtained from explicit solvent molecular dynamic simulations we illustrate the key roles played by allostery in both mechanisms.
OWNX	Pre-existence of conformational states explains the experimental observations that sumoylation can occur without E3, even though at a reduced rate.
OWNX	Furthermore, we propose a mechanism for enhancement of sumoylation by E3.
OWNX	Analysis of the conformational ensembles of the complex of E2 conjugated to SUMO illustrates that the E2 enzyme is already largely pre-organized for target binding and catalysis; E3 binding shifts the equilibrium and enhances these pre-existing populations.
OWNX	We further observe that E3 binding regulates allosterically the key residues in E2, Ubc9 Asp100/Lys101 E2, for the target recognition.
OWNX	Protein function is regulated by numerous mechanisms, one of which is post-translational modification.
OWNX	Covalent binding of ubiquitin and ubiquitin-like modifiers to target proteins constitute a key step in cellular processes including differentiation, apoptosis, cell cycle, and stress response CITATION CITATION.
OWNX	Here, we focus on one member of the Ubl super-family, SUMO, with the aim of figuring out the mechanism through which SUMO is conjugated to its target proteins.
MISC	SUMO-1, -2, -3 and -4 exist in mammals CITATION CITATION.
MISC	Sumoylation can change the proteins' intracellular localization, interaction patterns with other proteins and modifications by other post-translational events.
MISC	It is important in development CITATION and is related to cancer drug resistance CITATION, CITATION.
MISC	For simplicity, below, SUMO refers to SUMO-1.
MISC	At least 100 different proteins have been reported as targets for sumoylation CITATION CITATION.
MISC	Analogous to conjugation mechanisms of Ub/Ubls, SUMO is attached to target proteins following sequential activation by E1, E2 and in most cases, E3 enzymes CITATION.
MISC	Following activation of the SUMO precursor CITATION, the E1 enzyme Aos1/Uba2 and SUMO form a thioester bond.
OWNX	The SUMO thioester is next transferred to the active cysteine of Ubc9, the single known E2 enzyme of the sumoylation pathway CITATION, CITATION, CITATION.
MISC	Then SUMO is transferred from E2 to a target protein lysine residue.
MISC	E3 enzymes that ensure target specificity and increase reaction efficiency usually mediate this step.
MISC	Among the sumoylation targets, RanGAP1, p53 and I B are modified without an E3 ligase in vitro, although the reaction rates are slower compared to E3-mediated conjugation CITATION.
OWNX	E2 ligase Ubc9 is essential CITATION, CITATION and conserved CITATION.
MISC	It recognizes a consensus sumoylation motif, -K-x-D/E, where represents a hydrophobic residue, K is the SUMO acceptor lysine, x is any amino acid and D/E is an acidic residue CITATION.
OWNX	The E2 ligase also interacts with E3 enzymes during the transfer of SUMO to targets CITATION.
OWNX	In addition to the consensus sumoylation motif, sumoylation target RanGAP1 has a second contact surface with the E2 ligase Ubc9, which is thought to be responsible for the higher efficiency of modification compared to other substrates CITATION.
MISC	A fragment of the E3 enzyme RanBP2, consisting of the IR1-M-IR2 domains is sufficient for E3 activity in vivo and in vitro CITATION.
MISC	Moreover, IR1-M and M-IR2 constructs are also functional with IR1-M being the catalytic core domain CITATION CITATION.
MISC	The activity of the E3 fragment indicates that E3 exerts its catalytic effect by altering the structural properties of the E2-SUMO complex, increasing the affinity of the complex for specific protein targets, rather than by forming direct target interactions CITATION.
MISC	The crystal structure of the SUMO-RanGAP1-Ubc9-RanBP2 complex supports this idea CITATION.
MISC	Recent work also shows that E3 ligase RanBP2 prevents dissociation of SUMO from its target RanGAP1, leading to an increase in the sumoylated RanGAP1 levels CITATION.
MISC	Due to the strong interactions between RanGAP1 and E2, it has been a debated question whether RanBP2 exerts its E3 activity for RanGAP1 or whether it only maintains the complex at the nuclear pore complex CITATION, CITATION .
MISC	Our aim is to understand the mechanism through which the E3 ligase RanBP2 triggers target recognition and catalysis by E2 in sumoylation.
MISC	We carried out explicit solvent molecular dynamic simulations for the E2 ligase Ubc9, SUMO, and the E2-SUMO complex with and without the E3 enzyme RanBP2.
MISC	We modeled the conjugated E2-SUMO complex, in RanBP2 bound and unbound forms, based on the SUMO-RanGAP1-Ubc9-RanBP2 crystal structure.
MISC	Our results indicate that E3 binding induces a higher population of target binding and catalysis-ready E2, restricting the conformational space of the E2-SUMO complex.
MISC	We observe that RanBP2 binding enhances the correlations between the fluctuations of E2 residues involved in catalytic activity and target recognition, which implies that RanBP2 is indeed an E3 ligase for the sumoylation of the target protein RanGAP1.
OWNX	Our results further lead us to propose that the mechanism through which E3 ligase RanBP2 triggers E2 target recognition and catalysis in sumoylation is allostery: RanBP2 is an allosteric effector of E2 ligase Ubc9.
OWNX	Below, we refer to the specific proteins simulated rather than the protein functional class to which they belong.
OWNX	These were the ones crystallized by Reverter and Lima CITATION .
MISC	Recently, different works proposed a new way to mine patterns in databases with pathological size
OWNX	For example, experiments in genome biology usually provide databases with thousands of attributes (genes) but only tens of objects (experiments)
MISC	In this case, mining the ``transposed'' database runs through a smaller search space, and the Galois connection allows to infer the closed patterns of the original database
OWNX	We focus here on constrained pattern mining for those unusual databases and give a theoretical framework for database and constraint transposition
OWNX	We discuss the properties of constraint transposition and look into classical constraints
MISC	We then address the problem of generating the closed patterns of the original database satisfying the constraint, starting from those mined in the ``transposed'' database
MISC	Finally, we show how to generate all the patterns satisfying the constraint from the closed ones
MISC	Frequent pattern mining is now well mastered, but these patterns, like association rules, reveal to be too numerous for the experts and very expensive to compute
MISC	They have to be filtered or constrained
MISC	However, mining and constraining have to be done jointly (pushing the constraint) in order to avoid combinatorial explosion~ CITATION
MISC	Mining under complex constraint has become today a hot topic and the subject of numerous works (e g ,~ CITATION )
OWNX	Moreover, new domains are interested in our applications, and data schemes vary consequently
MISC	In genome biology, biological experiments are very expensive and time consuming
MISC	Therefore, only a small number of these experiments can be processed
MISC	However, thanks to new devices (such as biochips), experiments can provide the measurements of the activity of thousands of genes
MISC	This leads to databases with lots of columns (the genes) and few rows (the experiments)
MISC	Numerous works present efficient algorithms which mine the patterns satisfying a user defined constraint in large databases
MISC	This constraint can combine minimum and maximum frequency threshold together with other syntactical constraints
OWNX	These algorithms are designed for databases with up to several millions of rows
MISC	However, their complexity is exponential in the number of columns and thus they are not suited for databases with too many columns, like those encountered in genome biology
MISC	Recently, two propositions were done to solve this problem: instead of mining the original database, these algorithms work on the ``transposed'' database, i e , columns of the original database become rows in the ``transposed'' database and rows becomes columns (this is indeed the same database but with a different representation)
MISC	Therefore the ``transposed'' database has significantly less columns than the original one
OWNX	The CARPENTER algorithm  CITATION  is specifically designed for mining the frequent closed patterns, and our proposition  CITATION  uses a classical algorithm for mining closed patterns with a monotonic (or anti-monotonic) constraint
MISC	Both approaches use the transposition principle, however the problem of mining under constraints is not fully studied, specially for complex constraints (i e , conjunction and disjunction of simple constraints)
OWNX	In this paper, we study this problem from a theoretical point of view
OWNX	Our aim is to use classical algorithms (constrained pattern mining algorithms or closed patterns mining algorithms) in the ``transposed'' database and to use their output to regenerate patterns of the original database instead of directly mining in the original database
OWNX	There are several interesting questions which we will therefore try to answer:   What kind of information can be gathered in the ``transposed'' database on the patterns of the original database
MISC	Is it possible to ``transpose'' the constraints  I e , given a database and a constraint, is it possible to find a ``transposed'' constraint such that  mining the ``transposed'' database with the ``transposed'' constraint gives information about the patterns which satisfy the original constraint in the original database
MISC	How can we regenerate the closed patterns in the original database from the patterns extracted in the ``transposed'' database
MISC	How can we generate  all  the itemsets satisfying a constraint using  the extracted closed patterns
OWNX	These questions will be addressed respectively in Sec ~,  , ~and~
OWNX	The organization of the paper is as follows: we start Sec ~ by recalling some usual definitions related to pattern mining and Galois connection
OWNX	Then we show in Sec ~ how to transpose usual and complex constraints
AIMX	Section~ is a complete discussion about mining constrained closed patterns using the ``transposed'' database and in Sec ~ we show how to use this to compute all (i e , not only closed) the patterns satisfying a constraint
MISC	Finally Sec ~ is a short conclusion
MISC	Consider an agent interacting with an environment in cycles
MISC	In every interaction cycle the agent is rewarded for its performance
MISC	We compare the average reward  SYMBOL  from cycle  SYMBOL  to  SYMBOL  (average value) with the future discounted reward  SYMBOL  from cycle  SYMBOL  to  SYMBOL  (discounted value)
MISC	We consider essentially arbitrary (non-geometric) discount sequences and arbitrary reward sequences (non-MDP environments)
OWNX	We show that asymptotically  SYMBOL  for  SYMBOL  and  SYMBOL  for  SYMBOL  are equal, provided both limits exist
MISC	Further, if the effective horizon grows linearly with  SYMBOL  or faster, then the existence of the limit of  SYMBOL  implies that the limit of  SYMBOL  exists
MISC	Conversely, if the effective horizon grows linearly with  SYMBOL  or slower, then existence of the limit of  SYMBOL  implies that the limit of  SYMBOL  exists
MISC	We consider the reinforcement learning setup  CITATION , where an agent interacts with an environment in cycles
MISC	In cycle  SYMBOL , the agent outputs (acts)  SYMBOL , then it makes observation  SYMBOL  and receives reward  SYMBOL , both provided by the environment
OWNX	Then the next cycle  SYMBOL  starts
MISC	For simplicity we assume that agent and environment are deterministic
OWNX	Typically one is interested in action sequences, called plans or policies, for agents that result in high reward
MISC	The simplest reasonable measure of performance is the total reward sum or equivalently the average reward, called average value  SYMBOL , where  SYMBOL  should be the lifespan of the agent
MISC	One problem is that the lifetime is often not known in advance, eg \ often the time one is willing to let a system run depends on its displayed performance
MISC	More serious is that the measure is indifferent to whether an agent receives high rewards early or late if the values are the same
MISC	A natural (non-arbitrary) choice for  SYMBOL  is to consider the limit  SYMBOL
MISC	While the indifference may be acceptable for finite  SYMBOL , it can be catastrophic for  SYMBOL
MISC	Consider an agent that receives no reward until its first action is  SYMBOL , and then once receives reward  SYMBOL
OWNX	For finite  SYMBOL , the optimal  SYMBOL  to switch from action  SYMBOL  to  SYMBOL  is  SYMBOL
MISC	Hence  SYMBOL  for  SYMBOL , so the reward maximizing agent for  SYMBOL  actually always acts with  SYMBOL , and hence has zero reward, although a value arbitrarily close to 1 would be achievable (Immortal agents are lazy  CITATION )
MISC	More serious, in general the limit  SYMBOL  may not even exist
MISC	Another approach is to consider a moving horizon
MISC	In cycle  SYMBOL , the agent tries to maximize  SYMBOL , where  SYMBOL  increases with  SYMBOL , eg \  SYMBOL  with  SYMBOL  being the horizon
MISC	This naive truncation is often used in games like chess (plus a heuristic reward in cycle  SYMBOL ) to get a reasonably small search tree
MISC	While this can work in practice, it can lead to inconsistent optimal strategies, i e \ to agents that change their mind
MISC	Consider the example above with  SYMBOL
MISC	In every cycle  SYMBOL  it is better first to act  SYMBOL  and then  SYMBOL  ( SYMBOL ), rather than immediately  SYMBOL  ( SYMBOL ), or  SYMBOL  ( SYMBOL )
OWNX	But entering the next cycle  SYMBOL , the agent throws its original plan overboard, to now choose  SYMBOL  in favor of  SYMBOL , followed by  SYMBOL
OWNX	This pattern repeats, resulting in no reward at all
MISC	The standard solution to the above problems is to consider geometrically=exponentially discounted reward  CITATION
MISC	One discounts the reward for every cycle of delay by a factor  SYMBOL , i e \ considers  SYMBOL
MISC	The  SYMBOL  maximizing policy is consistent in the sense that its actions  SYMBOL  coincide with the optimal policy based on  SYMBOL
MISC	At first glance, there seems to be no arbitrary lifetime  SYMBOL  or horizon  SYMBOL , but this is an illusion
MISC	SYMBOL  is dominated by contributions from rewards  SYMBOL , so has an effective horizon  SYMBOL
MISC	While such a sliding effective horizon does not cause inconsistent policies, it can nevertheless lead to suboptimal behavior
MISC	For every (effective) horizon, there is a task that needs a larger horizon to be solved
MISC	For instance, while  SYMBOL  is sufficient for tic-tac-toe, it is definitely insufficient for chess
MISC	There are elegant closed form solutions for Bandit problems, which show that for any  SYMBOL , the Bayes-optimal policy can get stuck with a suboptimal arm (is not self-optimizing)  CITATION
OWNX	For  SYMBOL ,  SYMBOL , and the defect decreases
MISC	There are various deep papers considering the limit  SYMBOL   CITATION , and comparing it to the limit  SYMBOL   CITATION
MISC	The analysis is typically restricted to ergodic MDPs for which the limits  SYMBOL  and  SYMBOL  exist
MISC	But like the limit policy for  SYMBOL , the limit policy for  SYMBOL  can display very poor performance, i e \ we need to choose  SYMBOL  fixed in advance (but how ), or consider higher order terms  CITATION
OWNX	We also cannot consistently adapt  SYMBOL  with  SYMBOL
MISC	Finally, the value limits may not exist beyond ergodic MDPs
MISC	There is little work on other than geometric discounts
MISC	In the psychology and economics literature it has been argued that people discount a one day=cycle delay in reward more if it concerns rewards now rather than later, eg \ in a year (plus one day)  CITATION
MISC	So there is some work on ``sliding'' discount sequences  SYMBOL
OWNX	One can show that this also leads to inconsistent policies if  SYMBOL  is non-geometric  CITATION
MISC	Is there any non-geometric discount leading to consistent policies
MISC	In  CITATION  the generally discounted value  SYMBOL  with  SYMBOL  has been introduced
MISC	It is well-defined for arbitrary environments, leads to consistent policies, and eg \ for quadratic discount  SYMBOL  to an increasing effective horizon (proportionally to  SYMBOL ), i e \ the optimal agent becomes increasingly farsighted in a consistent way, leads to self-optimizing policies in ergodic ( SYMBOL th-order) MDPs in general, Bandits in particular, and even beyond MDPs
OWNX	See  CITATION  for these and  CITATION  for more results
MISC	The only other serious analysis of general discounts we are aware of is in  CITATION , but their analysis is limited to Bandits and so-called regular discount
MISC	This discount has bounded effective horizon, so also does not lead to self-optimizing policies
MISC	The  asymptotic  total average performance  SYMBOL  and future discounted performance  SYMBOL  are of key interest
MISC	For instance, often we do not know the exact environment in advance but have to  learn  it from past experience, which is the domain of reinforcement learning  CITATION  and adaptive control theory  CITATION
MISC	Ideally we would like a learning agent that performs  asymptotically  as well as the optimal agent that knows the environment in advance
MISC	The subject of study of this paper is the relation between  SYMBOL  and  SYMBOL  for  general discount   SYMBOL  and  arbitrary environment
MISC	The importance of the performance measures  SYMBOL  and  SYMBOL , and general discount  SYMBOL  has been discussed above
OWNX	There is also a clear need to study general environments beyond ergodic MDPs, since the real world is neither ergodic (e g \ losing an arm is irreversible) nor completely observable
MISC	The only restriction we impose on the discount sequence  SYMBOL  is summability ( SYMBOL ) so that  SYMBOL  exists, and monotonicity ( SYMBOL )
MISC	Our main result is that if both limits  SYMBOL  and  SYMBOL  exist, then they are necessarily equal (Section , Theorem )
MISC	Somewhat surprisingly this holds for  any  discount sequence  SYMBOL  and  any  environment (reward sequence  SYMBOL ), whatsoever
MISC	Note that limit  SYMBOL  may exist or not, independent of whether  SYMBOL  exists or not
OWNX	We present examples of the four possibilities in Section
OWNX	Under certain conditions on  SYMBOL , existence of  SYMBOL  implies existence of  SYMBOL , or vice versa
OWNX	We show that if (a quantity closely related to) the effective horizon grows linearly with  SYMBOL  or faster, then existence of  SYMBOL  implies existence of  SYMBOL  and their equality (Section , Theorem )
MISC	Conversely, if the effective horizon grows linearly with  SYMBOL  or slower, then existence of  SYMBOL  implies existence of  SYMBOL  and their equality (Section , Theorem )
OWNX	Note that apart from discounts with oscillating effective horizons, this implies (and this is actually the path used to prove) the first mentioned main result
OWNX	In Sections  and  we define and provide some basic properties of average and discounted value, respectively
OWNX	This paper introduces a model based upon games on an evolving network, and develops three clustering algorithms according to it
MISC	In the clustering algorithms, data points for clustering are regarded as players who can make decisions in games
MISC	On the network describing relationships among data points, an edge-removing-and-rewiring (ERR) function is employed to explore in a neighborhood of a data point, which removes edges connecting to neighbors with small payoffs, and creates new edges to neighbors with larger payoffs
MISC	As such, the connections among data points vary over time
MISC	During the evolution of network, some strategies are spread in the network
OWNX	As a consequence, clusters are formed automatically, in which data points with the same evolutionarily stable strategy are collected as a cluster, so the number of evolutionarily stable strategies indicates the number of clusters
MISC	Moreover, the experimental results have demonstrated that data points in datasets are clustered reasonably and efficiently, and the comparison with other algorithms also provides an indication of the effectiveness of the proposed algorithms \\ \\  Keywords : Unsupervised learning, data clustering, evolutionary game theory, evolutionarily stable strategy
MISC	Cluster analysis is an important branch of Pattern Recognition, which is widely used in many fields such as pattern analysis, data mining, information retrieval and image segmentation
MISC	For the past thirty years, many excellent clustering algorithms have been presented, say,  K -means  CITATION , C4 5~ CITATION , support vector clustering (SVC)  CITATION , spectral clustering~ CITATION , etc , in which the data points for clustering are fixed, and various functions are designed to find separating hyperplanes
MISC	In recent years, however, a significant change has been made
MISC	Some researchers thought about that why not those data points could move by themselves, just like agents or something, and collect together automatically
MISC	Therefore, following their ideas, they created a few exciting algorithms  CITATION , in which data points move in space according to certain simple local rules preset in advance
MISC	Game theory came into being with the book named "Theory of Games and Economic Behavior" by John von Neumann and Oskar Morgenstern  CITATION  in 1940
MISC	In this period, Cooperative Game was widely studied
MISC	Till 1950's, John Nash published two well-known papers to present the theory of non-cooperative game, in which he proposed the concept of Nash equilibrium, and proved the existence of equilibrium in a finite non-cooperative game  CITATION
MISC	Although non-cooperative game was established on the rigorous mathematics, it required that players in a game must be perfect rational or even hyper-rational
MISC	If this assumption could not hold, the Nash equilibrium might not be reached sometimes
OWNX	On the other hand, evolutionary game theory  CITATION  stems from the researches in biology which are to analyze the conflict and cooperation between animals or plants
MISC	It differs from classical game theory by focusing on the dynamics of strategy change more than the properties of strategy equilibria, and does not require perfect rational players
MISC	Besides, an important concept, evolutionarily stable strategy  CITATION , in evolutionary game theory was defined and introduced by John Maynard Smith and George R
OWNX	Price in 1973, which was often used to explain the evolution of social behavior in animals
MISC	To the best of our knowledge, the problem of data clustering has not been investigated based on evolutionary game theory
MISC	So, if data points in a dataset are considered as players in games, could clusters be formed automatically by playing games among them
OWNX	This is the question that we attempt to answer
OWNX	In our clustering algorithm, each player hopes to maximize his own payoff, so he constantly adjusts his strategies by observing neighbors' payoffs
MISC	In the course of strategies evolving, some strategies are spread in the network of players
OWNX	Finally, some parts will be formed automatically in each of which the same strategy is used
OWNX	According to different strategies played, data points in the dataset can be naturally collected as several different clusters
OWNX	The remainder of this paper is organized as follows: Section 2 introduces some basic concepts and methods about the evolutionary game theory and evolutionary game on graph
MISC	In Section 3, the model based upon games on evolving network is proposed and described specifically
OWNX	Section 4 gives three algorithms based on this model, and the algorithms are elaborated and analyzed in detail
OWNX	Section 5 introduces those datasets used in the experiments briefly, and then demonstrates experimental results of the algorithms
OWNX	Further, the relationship between the number of clusters and the number of nearest neighbors is discussed, and three edge-removing-and-rewiring (ERR) functions employed in the clustering algorithms are compared
OWNX	The conclusion is given in Section 6
OWNX	Ryanodine receptors are ion channels that regulate muscle contraction by releasing calcium ions from intracellular stores into the cytoplasm.
OWNX	Mutations in skeletal muscle RyR give rise to congenital diseases such as central core disease.
MISC	The absence of high-resolution structures of RyR1 has limited our understanding of channel function and disease mechanisms at the molecular level.
MISC	Here, we report a structural model of the pore-forming region of RyR1.
OWNX	Molecular dynamics simulations show high ion binding to putative pore residues D4899, E4900, D4938, and D4945, which are experimentally known to be critical for channel conductance and selectivity.
OWNX	We also observe preferential localization of Ca 2 over K in the selectivity filter of RyR1.
OWNX	Simulations of RyR1-D4899Q mutant show a loss of preference to Ca 2 in the selectivity filter as seen experimentally.
OWNX	Electrophysiological experiments on a central core disease mutant, RyR1-G4898R, show constitutively open channels that conduct K but not Ca 2.
OWNX	Our simulations with G4898R likewise show a decrease in the preference of Ca 2 over K in the selectivity filter.
OWNX	Together, the computational and experimental results shed light on ion conductance and selectivity of RyR1 at an atomistic level.
OWNX	Muscle contraction upon excitation by nerve impulse is initiated by a rapid rise in cytoplasmic Ca 2.
OWNX	In skeletal muscle, the rise in cytoplasmic Ca 2 is brought about by the opening of the ryanodine receptor, which releases Ca 2 from intracellular stores CITATION, CITATION.
OWNX	RyRs are large tetrameric ion channels present in the membranes of endoplasmic/sarcoplasmic reticulum.
MISC	They have high conductance for monovalent and divalent cations, while being selective for divalent cations CITATION.
MISC	RyRs are important mediators of excitation-contraction coupling and congenital mutations of RyRs result in neuromuscular diseases such as malignant hypothermia and central core disease CITATION .
MISC	Although RyRs are physiologically important, the molecular basis of their function is poorly understood.
MISC	RyRs have unique properties such as their modes of selectivity and permeation not seen in other ion channels with known structures.
OWNX	Next to the putative selectivity filter, there are two negatively charged residues in RyR1 that are essential for normal selectivity and conductance CITATION.
MISC	K channels have an analogous selectivity filter, but in contrast to RyR1, have only one adjacent negative residue that is not even conserved while other Ca 2 channels have only one conserved negative residue in the equivalent position CITATION.
OWNX	In the selectivity filter, mutations result in non-functional channels CITATION leading to CCD.
MISC	A structural model of the pore region that would reveal the location and function of these residues will be useful in understanding the role of these residues in channel function.
MISC	An early model of RyR ion permeation postulated potential barriers within the pore corresponding to three putative binding sites CITATION.
MISC	Without any knowledge of the structure of the pore, the model was able to quantitatively reproduce conductance data of various ions.
MISC	A PNP-DFT model CITATION accurately modeled the role of residues D4899 and E4900 in RyR1 in generating the high ion conductances of RyRs established by mutagenesis CITATION, CITATION.
MISC	Selectivity was attributed to charge-space competition, as Ca 2 could accommodate the most charge in least space compared to K. However, since the channel model used in these simulations relied on a fixed structure, it could not predict changes due to mutations that potentially alter the structure of the channel.
MISC	Additionally, there are two homology models of the RyR pore region CITATION, CITATION based on KcsA, a bacterial K channel whose solution structure is known CITATION.
MISC	Shah et al. CITATION used bioinformatics approaches to construct models for RyR and the related inositol triphosphate channel.
MISC	The luminal loop in their RyR model begins at 4890G resulting in the selectivity filter being 4890GVRAGG.
MISC	However, mutagenesis has shown that residues I4897, G4898, D4899 and E4900 are important for channel conductance and selectivity, which suggests that they are part of the conduction pathway of RyR1 resulting in the predicted selectivity filter being 4894GGGIGDE.
MISC	Welch et al. also constructed a homology model for the cardiac ryanodine receptor using the structure of the KcsA channel CITATION and performed simulations to identify residues important for channel function.
MISC	Their simulations failed to identify D4899 as an important residue for ion permeation contrary to what has been shown experimentally CITATION.
MISC	Furthermore, cryo-electron microscopy of RyR1 revealed significant differences between the pore region of KcsA and RyR1 CITATION .
MISC	Experimental structure determinations of the RyRs have been mainly performed by cryo-EM CITATION CITATION.
MISC	These studies revealed conformational changes that accompany channel opening CITATION and the binding sites of various effectors of RyRs CITATION CITATION.
MISC	Cryo-EM has a resolution of 10 25 and thus is able to provide only limited structural information regarding the pore structure.
MISC	Samso et al. CITATION manually docked the KcsA pore structure into the transmembrane region of their cryoEM map of the intact closed RyR1.
OWNX	Furthermore, they predicted the presence of at least 6 transmembrane helices from simple volumetric constraints.
MISC	Ludtke et al. CITATION identified several secondary structure elements in their 10 resolution cryo-EM map of the closed RyR1.
MISC	The pore-forming region as visualized by Ludtke et al. consists of a long inner helix made up of 31 residues and a pore helix made up of 15 residues that are presumably connected by a long luminal loop made up of 24 residues.
OWNX	Since the structure is derived from cryo-EM, the positions of pore residues' side chains and the structure of loops connecting the helices are unknown.
OWNX	We build a molecular model of the pore region of RyR1 based on their cryo-EM study by adding the luminal loop and the missing side chains of residues forming the helices of the pore.
OWNX	Furthermore, in our molecular dynamics simulations we examine the interactions of the pore region with mono- and divalent cations known to permeate the channel .
OWNX	we asked whether people can make their confidence judgments more realistic accurate by adjusting them  with the aim of improving the relationship between the level of confidence and the correctness of the answer
MISC	this adjustment can be considered to include a so-called second-order metacognitive judgment
MISC	the participants first gave confidence judgments about their answers to questions about a video clip they had just watched
MISC	next  they attempted to increase their accuracy by identifying confidence judgments in need of adjustment and then modifying them
MISC	the participants managed to increase their metacognitive realism  thus decreasing their absolute bias and improving their calibration  although the effects were small
OWNX	we also examined the relationship between confidence judgments that were adjusted and the retrieval fluency and the phenomenological memory quality participants experienced when first answering the questions  this quality was one of either remember associated with concrete  vivid details or know associated with a feeling of familiarity
MISC	confidence judgments associated with low retrieval fluency and the memory quality of knowing were modified more often
OWNX	in brief  our results provide evidence that people can improve the realism of their confidence judgments  mainly by decreasing their confidence for incorrect answers
MISC	thus  this study supports the conclusion that people can perform successful second-order metacognitive judgments
MISC	realistic confidence judgments about retrieved memories are important in a number of contexts e g   medical and legal contexts
MISC	for example  an eyewitness to a crime must judge his or her level of confidence about correctly having identified the criminal
MISC	although many witnesses may feel confident about their identification  the relation between identification confidence and the correctness of the identification is weak  CITATION
MISC	in spite of this weakness  research has also shown that jurors often judge eyewitness credibility based on the level of confidence the eyewitness expresses  CITATION
MISC	thus  the level of confidence about a memory report should be as accurate as possible relative to the correctness of the report  CITATION
MISC	in general  the realism of confidence judgments pertains to how well a person's confidence for a memory report matches the correctness of the report  CITATION
OWNX	the concept of confidence realism includes two aspects  calibration  the relationship between the level of the confidence judgments and the probability of the answer being correct  and discrimination  the extent to which the respondent can discriminate between correct and incorrect answers by means of their confidence judgments
OWNX	in this study  we attended only to participants' ability to improve calibration
MISC	numerous studies have reported that people often show overconfidence e g   they are more confident than their memory report is correct
MISC	this is the case both for general knowledge questions  CITATION  and event memory questions  CITATION   although the basis of this so-called overconfidence effect has been widely debated  CITATION
MISC	given that people show a lack of realism in their confidence judgments in many contexts  finding ways to help people improve the realism of their confidence judgments is important
MISC	our first aim was to investigate whether individuals can increase the realism of their confidence judgments of memory reports by adjusting confidence judgments they believe are the most unrealistic
MISC	the task of improving the realism of a confidence judgment  designated here as the adjustment task  involves first identifying which confidence judgments to adjust and then modifying them
MISC	when trying to improve the realism of confidence judgments  people presumably rely on various types of cues
MISC	our second aim was to investigate the potential usefulness of two such cues in identifying confidence judgments that are in need of adjustment and modifying them  retrieval fluency the subjective feeling of ease of recall and the phenomenological quality of the retrieved memories  either remember associated with concrete  vivid detail or know associated with a feeling of familiarity
MISC	The versatility of exponential families, along with their attendant convexity properties, make them a popular and effective statistical model
MISC	A central issue is learning these models in high-dimensions, such as when there is some sparsity pattern of the optimal parameter
OWNX	This work characterizes a certain strong convexity property of  general  exponential families, which allow their generalization ability to be quantified
OWNX	In particular, we show how this property can be used to analyze generic exponential families under  SYMBOL  regularization
MISC	Exponential models are perhaps the most versatile and pragmatic statistical model for a variety of reasons --- modelling flexibility (encompassing discrete variables, continuous variables, covariance matrices, time series, graphical models, etc); convexity properties allowing ease of optimization; and robust generalization ability
MISC	A principal issue for applicability to large scale problems is estimating these models when the ambient dimension of the parameters,  SYMBOL , is much larger than the sample size  SYMBOL  --- the `` SYMBOL '' regime
OWNX	Much recent work has focused on this problem in the special case of linear regression in high dimensions, where it is assumed that the optimal parameter vector is sparse (e g CITATION )
MISC	This body of prior work focused on: sharply characterizing the convergence rates for the prediction loss; consistent model selection; and obtaining sparse models
OWNX	As we tackle more challenging problems, there is a growing need for model selection in more general exponential families
OWNX	Recent work here includes learning Gaussian graphs ( CITATION ) and Ising models ( CITATION )
MISC	Classical results established that consistent estimation in  general  exponential families is possible, in the asymptotic limit where the number of dimensions is held constant (though some work establishes rates under certain conditions as  SYMBOL  is allowed to grow slowly with  SYMBOL   CITATION )
MISC	However, in modern problems, we typically grow  SYMBOL  rapidly with  SYMBOL  (so even asymptotically we are often interested in the regime where  SYMBOL , as in the case of sparse estimation)
MISC	While we have a handle on this question for a variety of special cases, a pressing question here is understanding how fast  SYMBOL  can scale as a function of  SYMBOL  in  general  exponential families --- such an analysis must quantify the relevant aspects of the particular family at hand which govern their convergence rate
OWNX	This is the focus of this work
OWNX	We should emphasize that throughout this paper, while we are interested in  modelling  with an exponential family, we are agnostic about the true underlying distribution (e
CONT	g we do not necessarily assume that the data generating process is from an exponential family) \paragraph{Our Contributions and Related Work}  The key issue in analyzing the convergence rates of exponential families in terms of their prediction loss (which we take to be the log loss) is in characterizing the nature in which they are strictly convex --- roughly speaking, in the asymptotic regime where we have a large sample size  SYMBOL  (with  SYMBOL  kept fixed), we have a central limit theorem effect where the log loss of any exponential family approaches the log loss of a Gaussian, with a covariance matrix corresponding to the Fisher information matrix
OWNX	Our first main contribution is quantifying the rate at which this  effect occurs in general exponential families
MISC	In particular, we show that every exponential family satisfies a certain rather natural growth rate condition on their standardized moments and standardized cumulants (recall that the  SYMBOL -th standardized moment is the  unitless  ratio of the  SYMBOL -th central moment to the  SYMBOL -th power of the standard deviation, which for  SYMBOL  is the skew and kurtosis)
MISC	This condition is rather mild, where these moments can grow as fast as  SYMBOL
MISC	Interestingly, similar conditions have been well studied for obtaining exponential tail bounds for the convergence of a random variable to its mean~ CITATION
MISC	We show that this growth rate characterizes the rate at which the prediction loss of the exponential family behaves as a strongly convex loss function
CONT	In particular, our analysis draws many parallels to that of the analysis of Newton's method, where there is a ``burn in'' phase in which a number of iterations must occur until the function behaves as a locally quadratic function --- in our statistical setting, we now require a (quantified) ``burn in'' sample size, where beyond this threshold sample size, the prediction loss inherits the desired strong convexity properties (i e it is locally quadratic)
OWNX	Our second contribution is an analysis of  SYMBOL  regularization in generic families, in terms of both prediction loss and the sparsity level of the selected model
OWNX	Under a particular sparse eigenvalue condition on the design matrix (the Restricted Eigenvalue (RE) condition in  CITATION ), we show how  SYMBOL  regularization in general exponential families enjoys a convergence rate of  SYMBOL  (where  SYMBOL  is the number of relevant features)
OWNX	This RE condition is one of the least stringent conditions which permit  this optimal convergence rate for linear regression case (see  CITATION ) --- stronger mutual incoherence/irrepresentable conditions considered in  CITATION  also provide this rate
OWNX	We show that an essentially identical convergence rate can be achieved for  general  exponential families --- our results are non-asymptotic and precisely relate  SYMBOL  and  SYMBOL
OWNX	Our final contribution is one of  approximate  sparse model selection, i e where our goal is to obtain a sparse model with low prediction loss
OWNX	A drawback of the RE condition in comparison to the mutual incoherence condition is that the latter permits perfect recovery of the true features (at the price of a more stringent condition)
OWNX	However, for the case of the linear regression,  CITATION  show that, under a sparse eigenvalue or RE condition, the  SYMBOL  solution is actually sparse itself (with a multiplicative increase in the sparsity level, that depends on a certain condition number of the design matrix) -- so while the the  SYMBOL  solution may not precisely recover the true model, it still is sparse (with some multiplicative increase) and does recover those features with large true weights
CONT	For general exponential families, while we do not have a characterization of the sparsity level of the  SYMBOL -regularized solution (an interesting open question), we do however provide a simple two stage procedure (thresholding and refitting) which provides a sparse model, with support on no more than merely  SYMBOL  features and which has nearly as good performance (with a rather mild increase in the risk) --- this result is novel even for the square loss case
OWNX	Hence, even under the rather mild RE condition, we can obtain both a favorable convergence rate and a  sparse model for generic families
OWNX	      nips07submit_e
OWNX	sty                                                                                  0000644 0000000 0000000 00000016414 11272723522 013176  0                                                                                                    ustar   root                            root                                                                                                                                                                                                                   %%%% NIPS Macros (LaTex)    \renewcommand{\topfraction}{0 95}   % let figure take up nearly whole page \renewcommand{\textfraction}{0 05}  % let figure take up nearly whole page   \setlength{\paperheight}{11in} \setlength{\paperwidth}{8 5in} 5in    %   Note = 5in 0 07 true in -0 625in \addtolength{\headsep}{0 25in} 9 0 true in       % Height of text (including footnotes & figures) 5 5 true in        % Width of text line \widowpenalty=10000 \clubpenalty=10000   \def\addcontentsline#1#2#3{}  \def\maketitle{ \def\thefootnote{\fnsymbol{footnote}} \def\@makefnmark{to 0pt{ SYMBOL \hss}} % for perfect author \long\def\@makefntext##1{1em to1 8em{ SYMBOL }##1} \@maketitle \@thanks \setcounter{footnote}{0} \let\maketitle\let\@maketitle\gdef\@thanks{}\gdef\@author{}\gdef\@title{}\let\thanks\relax}   \def\makeanontitle{ \def\thefootnote{\fnsymbol{footnote}} \def\@makefnmark{to 0pt{ SYMBOL \hss}} % for perfect author \long\def\@makefntext##1{1em to1 8em{ SYMBOL }##1} \@makeanontitle \@thanks \setcounter{footnote}{0} \let\makeanontitle\let\@makeanontitle\gdef\@thanks{}\gdef\@title{}\let\thanks\relax}    \def\@maketitle{\vbox{\hsize\linewidth0 1in {\LARGE\@title\par}  % 0 1in %  minus \def\And{\end{tabular}\hfil\linebreak[0]\hfil\linebreak[4]%  0 3in minus 0 1in}}  \def\@makeanontitle{\vbox{\hsize\linewidth0 1in {\LARGE\@title\par}  % 0 1in %  minus %  0 3in minus 0 1in}}  \renewenvironment{abstract}{\vskip 075in\centerline{\largeAbstract}1ex}  \def
OWNX	The intrinsic, or mitochondrial, pathway of caspase activation is essential for apoptosis induction by various stimuli including cytotoxic stress.
MISC	It depends on the cellular context, whether cytochrome c released from mitochondria induces caspase activation gradually or in an all-or-none fashion, and whether caspase activation irreversibly commits cells to apoptosis.
OWNX	By analyzing a quantitative kinetic model, we show that inhibition of caspase-3 and Casp9 by inhibitors of apoptosis results in an implicit positive feedback, since cleaved Casp3 augments its own activation by sequestering IAPs away from Casp9.
OWNX	We demonstrate that this positive feedback brings about bistability, and that it cooperates with Casp3-mediated feedback cleavage of Casp9 to generate irreversibility in caspase activation.
OWNX	Our calculations also unravel how cell-specific protein expression brings about the observed qualitative differences in caspase activation.
OWNX	Finally, known regulators of the pathway are shown to efficiently shift the apoptotic threshold stimulus, suggesting that the bistable caspase cascade computes multiple inputs into an all-or-none caspase output.
OWNX	As cellular inhibitory proteins frequently inhibit consecutive intermediates in cellular signaling cascades, the feedback mechanism described in this paper is likely to be a widespread principle on how cells achieve ultrasensitivity, bistability, and irreversibility.
OWNX	Apoptosis, an evolutionary conserved form of cell suicide, allows multicellular organisms to eliminate damaged or excess cells in order to maintain tissue homeostasis.
MISC	Dysregulation of apoptosis is associated with various pathological conditions, including cancer and neurodegenerative disorders.
OWNX	Aspartate-specific cysteine proteases, also known as caspases, are the central executioners of apoptosis.
MISC	In most cases, apoptotic stimuli activate initiator caspases, whose substrates, the effector caspases, ultimatively cause cellular demise by cleaving various cellular substrates CITATION .
OWNX	Figure 1A schematically depicts the so-called extrinsic and intrinsic apoptotic pathways that elicit apoptosis by cleaving and thereby activating caspase-3, the major cellular effector caspase.
MISC	The extrinsic pathway is initiated by ligand-binding to death receptors, which then oligomerize and recruit various proteins, including pro-Casp8, into the so-called death-inducing signaling complex.
MISC	Formation of the death-inducing signaling complex leads to autoprocessing of pro-Casp8 into active Casp8, which then cleaves Casp3.
OWNX	Cytotoxic stress or death-receptor stimulated Casp8 engage the intrinsic, or mitochondrial, apoptosis pathway by inducing the translocation of proapoptotic Bcl-2 family members such as Bax and Bid to mitochondria.
OWNX	This event, which is negatively regulated by antiapoptotic Bcl-2 family members, results in the release of proapoptotic proteins from mitochondria into the cytosol.
MISC	Cytosolic cyto c then elicits the oligomerization of Apaf-1 into an active high-molecular-weight complex, the apoptosome, which recruits and stimulates Casp9, and thereby allows activation of effector caspases such as Casp3.
AIMX	Smac and inhibitors of apoptosis such as X-linked IAP establish an additional layer of regulation in the intrinsic pathway: XIAP inhibits the catalytic activities of Casp9 and Casp3 through reversible binding, and cytosolic Smac relieves this inhibition by sequestering XIAP away from caspases CITATION .
OWNX	Experimental studies revealed that the qualitative behaviour of caspase activation in the intrinsic pathway depends on the cellular context.
MISC	Cyto c added to cytosolic extracts activates Casp3 in an all-or-none fashion in some cells CITATION CITATION, while gradual activation was observed in other systems CITATION CITATION.
MISC	As cyto-c release from mitochondria can be a reversible event CITATION, which does not affect mitochondrial function CITATION CITATION, it has been suggested that downstream caspase activation irreversibly commits cells to apoptosis CITATION, CITATION.
MISC	Accordingly, cyto c induced Casp3 activation remained elevated even after a strong decline in cytosolic cyto c CITATION or after apo cyto c, an inhibitor of apoptosome formation, was added CITATION.
OWNX	Furthermore, the time course of caspase activation via the intrinsic pathway equals that for irreversible commitment to apoptosis CITATION, CITATION, and caspase-inhibition allows for long-term cellular recovery and/or proliferation after removal of apoptotic stimuli CITATION, CITATION, CITATION CITATION.
MISC	Finally, Fas-treated Jurkat T cells, which enter apoptosis by the intrinsic pathway, escaped commitment to death as judged by maintenance of clonogenic potential if Casp3 was inhibited CITATION.
OWNX	On the contrary, Casp3 activation was found to be a reversible event in glycochenodeoxycholate-treated hepatocytes CITATION .
OWNX	These qualitative differences in caspase activation suggest that the intrinsic pathway is bistable in some cells, but monostable in others.
MISC	While simple monostable systems respond in a gradual and reversible manner, complex bistable systems exhibit true all-or-none responses and in some cases irreversibility.
MISC	Bistability is thought to require a positive circuit, which may be established either by positive feedback or by double-negative feedback.
OWNX	Once a threshold stimulus is exceeded, such positive circuits allow bistable systems to switch from low activation levels to high activation levels in an all-or-none fashion.
MISC	Bistable systems display hysteresis, meaning that different stimulus-response curves are obtained depending upon whether the system began in its off or its on state.
MISC	In some cases, the on state is maintained indefinitely after the stimulus is removed, so that the system shows irreversible activation CITATION.
MISC	Experimental studies confirmed that bistability indeed occurs in natural and artificial biological networks CITATION CITATION .
MISC	Recent mathematical modeling demonstrated that bistability can arise from hidden, or implicit, feedback loops that are usually not explicitly drawn in biochemical reaction schemes CITATION, CITATION.
OWNX	Similarily, we present a model showing that inhibition of Casp3 and Casp9 by IAPs results in an implicit positive feedback and in bistability.
OWNX	As cellular inhibitory proteins frequently inhibit consecutive intermediates in cellular signaling cascades, the mechanism described in this paper is likely to be a widespread principle on how cells achieve ultrasensitivity, bistability, and irreversibility .
MISC	Recent advances in reconstruction and analytical methods for signaling networks have spurred the development of large-scale models that incorporate fully functional and biologically relevant features.
MISC	An extended reconstruction of the human Toll-like receptor signaling network is presented herein.
OWNX	This reconstruction contains an extensive complement of kinases, phosphatases, and other associated proteins that mediate the signaling cascade along with a delineation of their associated chemical reactions.
MISC	A computational framework based on the methods of large-scale convex analysis was developed and applied to this network to characterize input output relationships.
OWNX	The input output relationships enabled significant modularization of the network into ten pathways.
OWNX	The analysis identified potential candidates for inhibitory mediation of TLR signaling with respect to their specificity and potency.
OWNX	Subsequently, we were able to identify eight novel inhibition targets through constraint-based modeling methods.
OWNX	The results of this study are expected to yield meaningful avenues for further research in the task of mediating the Toll-like receptor signaling network and its effects.
MISC	Toll-like receptors are a group of conserved pattern recognition receptors that activate the processes of innate and adaptive immunity CITATION.
MISC	Recent activity has focused on the characterization of the TLR network and its involvement in the apoptotic, inflammatory, and innate immune responses CITATION CITATION.
MISC	TLR signaling is a primary contributor to inflammatory responses and has been implicated in several diseases including cardiovascular disease CITATION, CITATION.
MISC	Indeed, even in cases of desired inflammatory response, excessive activation of signaling pathways can lead to septic shock and other serious conditions CITATION .
MISC	As such, there is much interest in the development of methods to attenuate or modulate TLR signaling in a targeted fashion.
OWNX	For example, one approach involves the inhibition of specific reactions or components within the TLR network that will dampen undesired signaling pathways while not adversely affecting other signaling components CITATION, CITATION.
OWNX	These reactions or components should ideally be highly specific to the TLR network and also to one transcription target.
OWNX	Therefore, the available, comprehensive data sets of the TLR network need to be put into a more structured, systematic format that enables better understanding of the associated signaling cascades, pathways, and connections to other cellular networks.
MISC	Such a systemic approach is necessary to achieve the ultimate goal of mediating the effects of Toll-like receptor signaling upon the inflammatory, immune, and apoptotic responses.
MISC	This need is particularly important given the amount of experimental data about TLR signaling that is already too large to be analyzed by simply viewing the complex web of overlapping interactions.
MISC	So far, relatively few attempts have been made to organize the plethora of experimental data into a single unified representation CITATION.
MISC	Hence, there is clearly a need to investigate the function and capabilities of this network using a computational model, particularly to yield further insights into the mechanistic action of the TLRs and their immunoadjuvant effects.
MISC	Constraint-based reconstruction and analysis methods represent a systems approach for computational modeling of biological networks CITATION.
MISC	Briefly, all known biochemical transformations for a particular system are collected from various data sources listing genomic, biochemical, and physiological data CITATION, CITATION.
MISC	The reconstruction is built on existing knowledge in bottom-up fashion and can be subsequently converted into a condition-specific model CITATION, CITATION allowing the investigation of its functional properties CITATION, CITATION.
OWNX	This conversion involves translating the reaction list into a so-called stoichiometric matrix by extracting the stoichiometric coefficients of substrates and products from each network reaction and placing lower and upper bounds on the network reactions.
OWNX	These constraints can include mass-balancing, thermodynamic considerations, and reaction rates CITATION.
MISC	Additionally, environmental constraints can be applied to represent different availabilities of medium components.
MISC	Many computational analysis tools have been developed CITATION, including Flux balance analysis.
OWNX	FBA is a formalism in which a reconstructed network is framed as a linear programming optimization problem and a specific objective function is maximized or minimized CITATION.
MISC	COBRA methods are well established for metabolic networks and both reconstruction and analysis tools are widely used CITATION.
OWNX	Furthermore, these methods have been successfully applied to other important cellular functions such as transcription and translation CITATION, transcriptional regulation CITATION, and signaling, including JAK-STAT CITATION and angiogenesis CITATION .
OWNX	In this study, we present an extended and reformulated model for the TLR network, reconstructed based on the publicly available TLR map CITATION and the COBRA approach CITATION, CITATION.
MISC	Signaling networks have been analyzed using extreme pathway analysis CITATION and FBA CITATION.
OWNX	However, since ExPa analysis becomes computationally challenging in large-scale, mass-balanced networks CITATION, we could not apply this method to the TLR network.
MISC	In contrast, network modularization has been established as a method for reducing large-scale networks into more manageable units CITATION CITATION.
MISC	Another approach for reducing network complexity is to focus on input output relationships CITATION, CITATION.
OWNX	We used FBA to simplify the mesh of network reactions into ten functionally distinct input output pathways, which show different patterns of signal activation control.
OWNX	Furthermore, we used this modular representation of the complex TLR signaling network to determine control points in the network, which are specific for a DIOS pathway.
MISC	These control points allow for the modulation of TLR signaling in a targeted fashion, which will induce a change in undesired signaling while not having an adverse effect on other signaling components.
OWNX	Taken together, we show in this study how a signaling network reconstruction and FBA can be used to identify potential candidates for drug targeting.
MISC	The tracing of potentially infectious contacts has become an important part of the control strategy for many infectious diseases, from early cases of novel infections to endemic sexually transmitted infections.
OWNX	Here, we make use of mathematical models to consider the case of partner notification for sexually transmitted infection, however these models are sufficiently simple to allow more general conclusions to be drawn.
MISC	We show that, when contact network structure is considered in addition to contact tracing, standard mass action models are generally inadequate.
MISC	To consider the impact of mutual contacts we develop an improvement to existing pairwise network models, which we use to demonstrate that ceteris paribus, clustering improves the efficacy of contact tracing for a large region of parameter space.
OWNX	This result is sometimes reversed, however, for the case of highly effective contact tracing.
MISC	We also develop stochastic simulations for comparison, using simple re-wiring methods that allow the generation of appropriate comparator networks.
MISC	In this way we contribute to the general theory of network-based interventions against infectious disease.
MISC	Modelling has become a central tool in understanding the epidemiology of infectious disease, and designing control strategies.
MISC	One control method, contact tracing, has been considered in a large number of disease contexts.
OWNX	These include the 2003 SARS pandemic CITATION, CITATION, the 2001 UK FMD epidemic CITATION CITATION, contingency planning for deliberate release of smallpox CITATION, CITATION, and control of sexually transmitted infections CITATION CITATION.
MISC	A particular benefit of tracing is that it allows targeting of control, at the cost of effort spent on finding the individuals at risk.
MISC	Since contact tracing takes place as a process over the network of interactions between hosts, it is natural to consider network-based models of this process.
MISC	Theoretical work has so far dealt with contact tracing as a branching process CITATION, through modifications to mean-field equations CITATION, pairwise approximations CITATION and simulation CITATION.
MISC	This work means that the implications of heterogeneous numbers of contacts for the efficacy of contact tracing are reasonably well understood.
MISC	For the case of clustering, due to the analytical challenge posed by the existence of short closed loops in the contact network, it has generally been more difficult to make similar progress.
MISC	Existing theoretical work has therefore either been restricted to the limiting case of clump structured populations, with all clustering due to completely connected cliques CITATION, or else simulation on exemplar networks CITATION, CITATION, CITATION .
AIMX	In this work, we derive an improved triple closure for clustered pairwise models that removes two significant problems with existing closure regimes, and use this to make a systematic investigation of the impact of clustering on the efficacy of contact tracing, keeping other network and epidemiological parameters constant as appropriate.
MISC	We find that, for many parameter choices, there are intuitive explanations, borne out by modelling, for the increased impact of contact tracing as clustering increases.
OWNX	This is not, however, a completely general result, meaning that the full implications of clustering for the efficacy of contact tracing are subtle and should be the subject of case by case investigation.
OWNX	We perform our analysis within the SIS paradigm, meaning that while some of our terminology will be general to all infectious disease epidemiology, other statements will be geared towards the modelling of sexually transmitted infections where recovery/treatment does not confer lasting immunity.
MISC	Human disease is heterogeneous, with similar disease phenotypes resulting from distinct combinations of genetic and environmental factors.
MISC	Small-molecule profiling can address disease heterogeneity by evaluating the underlying biologic state of individuals through non-invasive interrogation of plasma metabolite levels.
MISC	We analyzed metabolite profiles from an oral glucose tolerance test in 50 individuals, 25 with normal and 25 with impaired glucose tolerance.
OWNX	Our focus was to elucidate underlying biologic processes.
OWNX	Although we initially found little overlap between changed metabolites and preconceived definitions of metabolic pathways, the use of unbiased network approaches identified significant concerted changes.
OWNX	Specifically, we derived a metabolic network with edges drawn between reactant and product nodes in individual reactions and between all substrates of individual enzymes and transporters.
OWNX	We searched for active modules regions of the metabolic network enriched for changes in metabolite levels.
OWNX	Active modules identified relationships among changed metabolites and highlighted the importance of specific solute carriers in metabolite profiles.
MISC	Furthermore, hierarchical clustering and principal component analysis demonstrated that changed metabolites in OGTT naturally grouped according to the activities of the System A and L amino acid transporters, the osmolyte carrier SLC6A12, and the mitochondrial aspartate-glutamate transporter SLC25A13.
MISC	Comparison between NGT and IGT groups supported blunted glucose- and/or insulin-stimulated activities in the IGT group.
OWNX	Using unbiased pathway models, we offer evidence supporting the important role of solute carriers in the physiologic response to glucose challenge and conclude that carrier activities are reflected in individual metabolite profiles of perturbation experiments.
MISC	Given the involvement of transporters in human disease, metabolite profiling may contribute to improved disease classification via the interrogation of specific transporter activities.
MISC	Disease heterogeneity has challenged the practice of medicine.
MISC	Individuals with the same apparent disease at our current diagnostic resolution often show remarkable variation in prognosis and treatment responsiveness, presumably because a superficially similar disease state can arise from diverse combinations of genetic and environmental factors CITATION.
MISC	Efforts to resolve the heterogeneity have focused on collecting increasing amounts of quantitative patient information, including genotypic CITATION and mRNA CITATION and protein expression data CITATION with the hope of establishing better clinical classifiers based on aberrant activities of specific, targetable biological pathways.
OWNX	Using tumor biopsy samples, oncologists are now exploring the incorporation of genomewide expression profiling into therapy CITATION, CITATION.
MISC	However, for complex human diseases that span multiple organ systems, metabolomics the analysis of a broad array of metabolite levels from biologic fluid samples such as blood or urine represents a minimally-invasive way to obtain quantitative biologic information from patients to uncover disease pathophysiology and aid diagnostic and prognostic classification CITATION .
MISC	Metabolomics data analysis may be facilitated by techniques applied to other high-throughput omic data types.
MISC	For microarray data, the integration of network information from protein-protein interaction data or predefined biologic pathways has greatly assisted elucidation of underlying processes and led to the development of increasingly robust and accurate gene-based classifiers for disease CITATION, CITATION.
MISC	We hypothesize that the characterization of human disease by metabolomic profiling should similarly benefit from interpreting metabolite changes in the context of known metabolic reactions.
MISC	We use data derived from oral glucose tolerance tests in 25 individuals with normal and 25 with impaired glucose tolerance CITATION.
OWNX	We first sought significant overlaps between observed metabolite changes and preconceived definitions of metabolic pathways.
MISC	Next we applied an unbiased pathway analysis by mapping the metabolite changes to a recent reconstruction of the human metabolic network CITATION and use a recently developed variant CITATION of previous approaches CITATION derived for mRNA expression analysis to find active metabolic modules connected subnetworks of highly changed metabolites.
MISC	While the biased approach yielded little, the resulting unbiased pathway models highlight the interconnectedness between changed metabolites and propose a role for solute carriers in OGTT metabolite profiles.
MISC	Hierarchical clustering and principal component analysis confirmed the importance of specific transporters by demonstrating that metabolites cluster naturally according to activities of the System A and L amino acid and SLC6A12 osmolyte transporters.
MISC	Furthermore, they suggest an important role for the SLC25A13 mitochondrial aspartate-glutamate transporter in interindividual metabolite profile variability.
OWNX	Comparison of NGT and IGT active modules suggest blunted glucose- and/or insulin-stimulated enzyme and transporter activities in the IGT group.
MISC	Given that transporters are implicated in multiple human diseases, the interrogation of transporter activities by perturbation-based metabolic profiling may ultimately contribute to improved disease classification and resolution of disease heterogeneity.
OWNX	Many alternative splicing events are regulated by pentameric and hexameric intronic sequences that serve as binding sites for splicing regulatory factors.
OWNX	We hypothesized that intronic elements that regulate alternative splicing are under selective pressure for evolutionary conservation.
OWNX	Using a Wobble Aware Bulk Aligner genomic alignment of Caenorhabditis elegans and Caenorhabditis briggsae, we identified 147 alternatively spliced cassette exons that exhibit short regions of high nucleotide conservation in the introns flanking the alternative exon.
MISC	In vivo experiments on the alternatively spliced let-2 gene confirm that these conserved regions can be important for alternative splicing regulation.
OWNX	Conserved intronic element sequences were collected into a dataset and the occurrence of each pentamer and hexamer motif was counted.
OWNX	We compared the frequency of pentamers and hexamers in the conserved intronic elements to a dataset of all C. elegans intron sequences in order to identify short intronic motifs that are more likely to be associated with alternative splicing.
OWNX	High-scoring motifs were examined for upstream or downstream preferences in introns surrounding alternative exons.
OWNX	Many of the high- scoring nematode pentamer and hexamer motifs correspond to known mammalian splicing regulatory sequences, such as GCATG, indicating that the mechanism of alternative splicing regulation is well conserved in metazoans.
OWNX	A comparison of the analysis of the conserved intronic elements, and analysis of the entire introns flanking these same exons, reveals that focusing on intronic conservation can increase the sensitivity of detecting putative splicing regulatory motifs.
MISC	This approach also identified novel sequences whose role in splicing is under investigation and has allowed us to take a step forward in defining a catalog of splicing regulatory elements for an organism.
OWNX	In vivo experiments confirm that one novel high-scoring sequence from our analysis, CTATC, is important for alternative splicing regulation of the unc-52 gene.
MISC	One of the interesting lessons learned from the analysis of the human genome is that we may possess fewer than 25,000 genes CITATION.
MISC	One mechanism to dramatically increase the complexity of the human proteome from this lower-than-expected number of genes is to allow some genes to encode multiple proteins.
MISC	This process can be accomplished by alternative precursor messenger RNA splicing.
MISC	Studies that use expressed sequence tag alignments to identify alternatively spliced genes have led researchers to predict that up to 60 percent of human genes are alternatively spliced CITATION CITATION.
OWNX	Alternative splicing events can be regulated in tissue-specific, developmental, and hormone-responsive manners, providing additional mechanisms for the regulation of gene expression CITATION, CITATION.
MISC	Understanding alternative splicing and its regulation is a key component to understanding metazoan genomes.
MISC	The current models for alternative splicing regulation are based on the interactions of intronic or exonic RNA sequences, known as cis elements, with splicing regulatory proteins known as trans-acting splicing factors CITATION.
OWNX	The binding of splicing factors to the pre-mRNA regulates the ability of the spliceosomal machinery to recognize and promote alternative splicing.
MISC	The role of intronic elements in regulating splicing is well established and has been shown to work in a combinatorial fashion based on the trans-acting factors that are present.
OWNX	For example, the inclusion of the 18-nucleotide-long, neural-specific N1 exon of the human c-SRC gene is regulated by the downstream control sequence found in the intron downstream of the N1 exon.
MISC	This sequence serves as a recruitment site for both constitutive and neuronal cell-specific splicing factors such as nPTB, FOX-1, and FOX-2 CITATION CITATION.
MISC	The vertebrate RNA-binding protein FOX-1 can also regulate muscle-specific alternative splicing through interactions with the RNA sequence GCAUG CITATION, and repeats of this sequence have been shown to be important for alternative splicing regulation of the fibronectin exon EIIIB and the rat calcitonin/CGRP exon 4 CITATION, CITATION.
MISC	Many other examples of complex and combinatorial regulation of alternative splicing through intronic cis elements have been demonstrated, and combinatorial interactions between proteins such as Nova-1, polypyrimidine tract binding protein, and ETR-3, with specific cis sequences, are important for alternative splicing regulation CITATION CITATION .
MISC	Intronic sequences are non-coding, and therefore they should have less evolutionary selective pressure to maintain their sequence.
MISC	An exception to this should be intronic sequences that regulate alternative splicing.
OWNX	In an analysis of alternatively spliced human cassette exons, it was found that on average, approximately 100 nucleotides of intron sequence, flanking either side of the exon, tend to be highly conserved between the mouse and human genomes, with 88 percent identity in the upstream sequences and 80 percent identity in the downstream sequences CITATION.
MISC	Some clues to potential splicing regulatory motifs arise from these studies.
OWNX	For example, Sorek and Ast found that the sequence TGCATG was the second most common hexamer in the first 100 nucleotides downstream of alternatively spliced exons, appearing in 18 percent of these intronic regions CITATION.
OWNX	Another study of aligned mouse/human alternative exons found that GCATG is the most overrepresented pentamer in the proximal conserved region of the intron downstream of alternative exons CITATION.
OWNX	A third study found that TGCATG is frequently located in introns flanking brain-enriched alternative exons, and its presence and spacing are highly conserved in these genes from fish to man CITATION .
MISC	Using the nematode Caenorhabditis elegans as a model system, we have been working to take advantage of comparative genomics to identify cis-acting regulators of alternative splicing.
MISC	The C. elegans gene structure, splicing machinery, and gene expression regulation is similar to that of other higher eukaryotes, with the exception that the average intron size is smaller.
MISC	Our lab has previously developed methods for identification of alternatively spliced genes in C. elegans by aligning the genome sequence with ESTs and mRNA sequence CITATION.
OWNX	We developed an algorithm, the Wobble Aware Bulk Aligner, for creating interspecies genome alignments between C. elegans and the related roundworm, Caenorhabditis briggsae CITATION.
OWNX	WABA employs a hidden Markov model to identify aligned regions as coding, high homology, low homology, and no homology.
MISC	It also factors the AT richness of C. elegans introns into its calculations when it defines an intronic region as high homology CITATION.
OWNX	C. briggsae and C. elegans diverged approximately 100 million years ago, yet are indistinguishable by eye CITATION.
OWNX	Alignment of these two genomes revealed that exonic sequences are highly conserved between these species, but intronic and intergenic sequences are rarely conserved CITATION.
OWNX	We found that these rare, high homology sequences in introns are more likely to occur in the introns flanking alternatively spliced exons than in total introns CITATION.
OWNX	We hypothesized that these conserved intronic regions were cis-acting regulatory elements for alternative splicing.
OWNX	This nematode alignment, with relatively limited regions of high homology, provides the possibility for more specific pinpointing of intronic splicing regulatory elements than the much longer 100-nucleotide-long conserved regions flanking alternative exons in mouse/human alignments CITATION .
OWNX	In this paper, we present the analysis of conserved regions of introns flanking alternatively spliced exons in C. elegans and correlate these conserved regions with alternative splicing regulation.
OWNX	We collected these conserved sequence regions into a database and searched for overrepresented pentamers and hexamers relative to a total intron database, similar to the method used by Burge's group to identify exonic splicing enhancers CITATION.
MISC	This allowed us to create a table of potential intronic alternative splicing cis-regulatory motifs.
MISC	Since many RNA recognition motif containing splicing factors recognize specific sequences on the order of 4 6 nucleotides in length CITATION, CITATION, CITATION, CITATION CITATION, the high-scoring motifs in this catalog may represent specific binding sites for particular splicing factors.
MISC	Several of our highest scoring motifs in this analysis correlate with known vertebrate splicing regulatory elements, for example, GCATG CITATION, but several have not been previously identified.
MISC	A number of candidates identified by this method were tested in an in vivo splicing reporter system in C. elegans.
OWNX	We have used this analysis to identify and confirm a new, highly conserved, alternative splicing regulatory element, CTATC.
OWNX	We show that this sequence works in coordination with GCATG to regulate the alternative splicing of the unc-52 gene.
MISC	Identification of pathways involved in the structural transitions of biomolecular systems is often complicated by the transient nature of the conformations visited across energy barriers and the multiplicity of paths accessible in the multidimensional energy landscape.
OWNX	This task becomes even more challenging in exploring molecular systems on the order of megadaltons.
MISC	Coarse-grained models that lend themselves to analytical solutions appear to be the only possible means of approaching such cases.
OWNX	Motivated by the utility of elastic network models for describing the collective dynamics of biomolecular systems and by the growing theoretical and experimental evidence in support of the intrinsic accessibility of functional substates, we introduce a new method, adaptive anisotropic network model, for exploring functional transitions.
CONT	Application to bacterial chaperonin GroEL and comparisons with experimental data, results from action minimization algorithm, and previous simulations support the utility of aANM as a computationally efficient, yet physically plausible, tool for unraveling potential transition pathways sampled by large complexes/assemblies.
OWNX	An important outcome is the assessment of the critical inter-residue interactions formed/broken near the transition state, most of which involve conserved residues.
MISC	Many proteins assume more than one functional conformation, stabilized by ligand binding or changes in environmental conditions.
MISC	A typical example is the bacterial chaperonin GroEL CITATION, a widely studied ATP-regulated molecular machine and member of heat shock protein Hsp60 family.
MISC	GroEL assists in unfolding and refolding misfolded or partially folded proteins CITATION CITATION.
MISC	It is composed of two back-to-back stacked rings, each containing seven subunits of 60 kDa.
OWNX	Each subunit is, in turn, composed of three domains, equatorial, intermediate and apical.
OWNX	GroEL works together with the co-chaperonin, GroES.
MISC	The activity of GroEL-GroES complex entails a series of allosteric transitions in structure, triggered by ATP binding and hydrolysis, described in Figure 1: In the absence of nucleotide binding, both rings assume the closed state, designated as T/T state for the two rings.
MISC	Cooperative binding of seven ATP molecules to the subunits in one of the rings, hereafter referred to as the cis ring, drives the conformational change of these subunits to the open state, thus leading to the R/T form of the cis/trans rings.
MISC	The R/T form exposes a number of hydrophobic residues at the apical domains of the cis ring subunits.
MISC	These groups attract the unfolded or partially folded peptide to be encapsulated in the cylindrical chamber following the attachment of GroES.
MISC	ATP hydrolysis provides the energy needed to process the substrate and leads to the state R /T. This process is terminated upon binding of seven ATP molecules to the adjoining ring, hence the term negative cooperative effect induced by ATP binding.
OWNX	The structure with ADP and ATP molecules bound to the respective cis and trans rings favors the opening of the GroES cap and release of the peptide and ADP molecules to start a new cycle, this time, with the roles of the former cis and trans rings being inverted.
MISC	Of interest is to understand the molecular basis of the negative cooperative effect triggered upon binding of seven ATP molecules to the trans ring.
MISC	ATP binding induces in this case a structural change on the cap-binding region at a distance of 65.
MISC	Understanding the mechanism of this allosteric signaling is of fundamental importance because of the critical role chaperonins play in preventing aggregation and regulating folding vs. degradation events.
MISC	Several studies have been published on the allosteric pathways and dynamics of GroEL CITATION CITATION since the original determination of the ADP-bound complex CITATION.
OWNX	These studies provide valuable insights into the successive states involved in the chaperonin cycle.
MISC	The elucidation of allosteric transition mechanisms has been a challenge, however, both experimentally and computationally, due to the transient nature of the high energy conformers between the states, the multiplicity of pathways, and the large size of this biomolecular system.
MISC	Several computational methods have been developed in the last two decades for exploring the structural transition pathways of biomolecules.
MISC	These include methods based on minimizing path-dependent functionals CITATION, CITATION, stochastic path integration CITATION, MaxFlux method for identifying the path of maximum flux CITATION, CITATION, nudged elastic band method CITATION, and the determination of temperature-independent reaction coordinates by action minimization CITATION CITATION.
OWNX	Other groups resorted to targeted molecular dynamics simulations in the presence of holonomic constraints CITATION, CITATION CITATION, Monte Carlo- and MD-based methods for sampling ensembles of stochastic transition paths.
MISC	Yet, the identification of the transition state and accompanying conformational rearrangements are by and large inaccessible for systems of the order of megadaltons like GroEL.
MISC	Coarse-grained models and methods appear as the only tractable tools in such cases.
OWNX	Perhaps the most comprehensive computational study of GroEL allosteric dynamics is that of Hyeon, Lorimer and Thirumalai, where the T R R transition has been examined by Brownian dynamics simulations using a state-dependent self-organized polymer model CITATION.
OWNX	These simulations, performed for subunit dimers and heptamers, provided valuable insights on the heterogeneity of the transition pathways and the kinetics of salt bridges' formation/rupture at the successive transitions T R and R R .
OWNX	Ensemble learning aims to improve generalization ability by using multiple base learners
MISC	It is well-known that to construct a good ensemble, the base learners should be  accurate  as well as  diverse
OWNX	In this paper, unlabeled data is exploited to facilitate ensemble learning by helping augment the diversity among the base learners
OWNX	Specifically, a semi-supervised ensemble method named {\udeed} is proposed
CONT	Unlike existing semi-supervised ensemble methods where error-prone  pseudo-labels  are estimated for unlabeled data to enlarge the labeled data to improve accuracy, {\udeed} works by maximizing accuracies of base learners on labeled data while maximizing diversity among them on unlabeled data
MISC	Experiments show that {\udeed} can effectively utilize unlabeled data for ensemble learning and is highly competitive to well-established semi-supervised ensemble methods
OWNX	In  ensemble learning   CITATION , a number of base learners are trained and then combined for prediction to achieve strong generalization ability
MISC	Numerous effective ensemble methods have been proposed, such as \textsc{Boosting}  CITATION , \textsc{Bagging}  CITATION , \textsc{Stacking}  CITATION , etc , and most of these methods work under the supervised setting where the labels of training examples are known
MISC	In many real-world tasks, however, unlabeled training examples are readily available while obtaining their labels would be fairly expensive
MISC	Semi-supervised learning   CITATION  is a major paradigm to exploit unlabeled data together with labeled training data to improve learning performance automatically, without human intervention
OWNX	This paper deals with semi-supervised ensembles, that is, ensemble learning with labeled and unlabeled data
MISC	In contrast to the huge volume of literatures on ensemble learning and on semi-supervised learning, only a few work has been devoted to the study of semi-supervised ensembles
OWNX	As indicated by Zhou  CITATION , this was caused by the different philosophies of the ensemble learning community and the semi-supervised learning community
MISC	The ensemble learning community believes that it is able to boost the performance of weak learners to strong learners by using multiple learners, and so there is no need to use unlabeled data; while the semi-supervised learning community believes that it is able to boost the performance of weak learners to strong learners by exploiting unlabeled data, and so there is no need to use multiple learners
OWNX	However, as Zhou indicated  CITATION , there are several important reasons why ensemble learning and semi-supervised learning are actually mutually beneficial, among which an important one is that by considering unlabeled data it is possible to help augment the  diversity  among the base learners, as explained in the following paragraph
OWNX	It is well-known that the generalization error of an ensemble is related to the average generalization error of the base learners and the diversity among the base learners
OWNX	Generally, the lower the average generalization error (or, the higher the average accuracy) of the base learners and the higher the diversity among the base learners, the better the ensemble  CITATION
MISC	Previous ensemble methods work under supervised setting, trying to achieve a high average accuracy and a high diversity by using the labeled training set
OWNX	It is noteworthy, however, pursuing a high accuracy and a high diversity may suffer from a dilemma
MISC	For example, for two classifiers which have perfect performance on the labeled training set, they would not have diversity since there is no difference between their predictions on the training examples
OWNX	Thus, to increase the diversity needs to sacrifice the accuracy of one classifier
OWNX	However, when we have unlabeled data, we might find that these two classifiers actually make different predictions on unlabeled data
MISC	This would be important for ensemble design
MISC	For example, given two pairs of classifiers,  SYMBOL  and  SYMBOL , if we know that all of them are with 100 SYMBOL  accuracy on labeled training data, then there will be no difference taking either the ensemble consisting of  SYMBOL  or the ensemble consisting of  SYMBOL ; however, if we find that  SYMBOL  and  SYMBOL  make the same predictions on unlabeled data, while  SYMBOL  and  SYMBOL  make different predictions on some unlabeled data, then we will know that the ensemble consisting of  SYMBOL  should be better
MISC	So, in contrast to previous ensemble methods which focus on achieving both high accuracy and high diversity using only the labeled data, the use of unlabeled data would open a promising direction for designing new ensemble methods
OWNX	In this paper, we propose the {\udeed} ( Unlabeled Data to Enhance Ensemble Diversity ) approach
MISC	Experiments show that by using unlabeled data for diversity augmentation, {\udeed} achieves much better performance than its counterpart which does not consider the usefulness of unlabeled data
MISC	Moreover, {\udeed} also achieves highly comparable performance to other state-of-the-art semi-supervised ensemble methods
OWNX	The rest of this paper is organized as follows
OWNX	Section  briefly reviews related work on semi-supervised ensembles
OWNX	Section  presents {\udeed}
OWNX	Section  reports our experimental results
OWNX	Finally, Section  concludes
MISC	Lasso, or  SYMBOL  regularized least squares, has been explored extensively for its remarkable sparsity properties
OWNX	It is shown in this paper  that the solution to Lasso, in addition to its sparsity, has robustness properties: it is the solution to a robust optimization problem
OWNX	This has two important consequences
MISC	First, robustness provides a connection of the regularizer to a physical property, namely, protection from noise
MISC	This allows a principled selection of the regularizer, and in particular, generalizations of Lasso that also yield convex optimization problems are obtained by considering different uncertainty sets
MISC	Secondly, robustness can itself be used as an avenue to exploring different properties of the solution
OWNX	In particular, it is shown that robustness of the solution  explains why the solution is sparse
OWNX	The analysis as well as the specific results obtained differ from standard sparsity results, providing different geometric intuition
OWNX	Furthermore, it is shown that the robust optimization formulation is related to kernel density estimation, and based on this approach,  a proof that Lasso is consistent is given using robustness directly
OWNX	Finally, a  theorem saying that sparsity and algorithmic stability contradict each other, and hence Lasso is not stable, is presented
OWNX	In this paper we consider linear regression problems with least-square error
MISC	The problem is to find a vector  SYMBOL  so that the  SYMBOL  norm of the residual  SYMBOL  is minimized, for a given matrix  SYMBOL  and vector  SYMBOL
MISC	From a learning/regression perspective, each row of  SYMBOL  can be regarded as a training sample, and the corresponding element of  SYMBOL  as the target value of this observed sample
MISC	Each column of  SYMBOL  corresponds to a feature, and the objective is to find a set of weights so that the weighted sum of the feature values approximates the target value
OWNX	It is well known that minimizing the least squared error can lead to sensitive solutions  CITATION
MISC	Many regularization methods have been proposed to decrease this sensitivity
OWNX	Among them, Tikhonov regularization  CITATION  and Lasso~ CITATION  are two widely known and cited algorithms
MISC	These methods minimize a weighted sum of the residual norm and a certain regularization term,  SYMBOL  for Tikhonov regularization and  SYMBOL  for Lasso
OWNX	In addition to providing regularity, Lasso is also known for the tendency to select sparse solutions
MISC	Recently this has attracted much attention for its ability to reconstruct sparse solutions when sampling occurs far below the Nyquist rate, and also for its ability to recover the sparsity pattern exactly with probability one, asymptotically as the number of observations increases (there is an extensive literature on this subject, and we refer the reader to  CITATION  and references therein)
OWNX	The first result of this paper is that the solution to Lasso has robustness properties: it is the solution to a robust optimization problem
MISC	In itself, this interpretation of Lasso as the solution to a robust least squares problem is a development in line with the results of  CITATION
OWNX	There, the authors propose an alternative approach of reducing sensitivity of linear regression by considering a robust version of the regression problem, i e , minimizing the worst-case residual for the observations under some unknown but bounded disturbance
OWNX	Most of the research in this area considers either the case where the disturbance is row-wise uncoupled  CITATION , or the case where the Frobenius norm of the disturbance matrix is bounded  CITATION
OWNX	None of these robust optimization approaches produces a solution that has sparsity properties (in particular, the solution to Lasso does not solve any of these previously formulated robust optimization problems)
MISC	In contrast, we investigate the robust regression problem where the uncertainty set is defined by feature-wise constraints
MISC	Such a noise model is of interest when values of features are obtained with some noisy pre-processing steps, and the magnitudes of such noises are known or bounded
MISC	Another situation of interest is where features are meaningfully coupled
OWNX	We define  coupled  and  uncoupled  disturbances and uncertainty sets precisely in Section  below
MISC	Intuitively, a disturbance is feature-wise coupled if the variation or disturbance across features satisfy joint constraints, and uncoupled otherwise
OWNX	Considering the solution to Lasso as the solution  of a robust least squares problem has two important consequences
MISC	First, robustness provides a connection of the regularizer to a physical property, namely, protection from noise
MISC	This allows more principled selection of the regularizer, and in particular, considering different uncertainty sets, we construct generalizations of Lasso that also yield convex optimization problems
MISC	Secondly, and perhaps most significantly, robustness  is a strong property that can itself be used as an avenue to investigating different properties of the solution
OWNX	We show that robustness of the solution can explain why the solution is sparse
OWNX	The analysis as well as the specific results we obtain differ from standard sparsity results, providing different geometric intuition, and extending beyond the least-squares setting
MISC	Sparsity results obtained for Lasso ultimately depend on the fact that introducing additional features incurs larger  SYMBOL -penalty than the least squares error reduction
OWNX	In contrast, we exploit the fact that a robust solution is, by definition, the optimal solution under a worst-case perturbation
OWNX	Our results show that, essentially, a coefficient of the solution is nonzero if the corresponding feature is relevant under all allowable perturbations
OWNX	In addition to sparsity, we also use robustness directly to prove consistency of Lasso
OWNX	We briefly list the main contributions as well as the organization of this paper
OWNX	In Section~, we formulate the robust regression problem with feature-wise independent disturbances, and show that this formulation is equivalent to a least-square problem with a weighted  SYMBOL  norm regularization term
OWNX	Hence, we provide an interpretation of Lasso from a robustness perspective
OWNX	% which can be helpful in choosing the regularization parameter
MISC	We generalize the robust regression formulation to loss functions of arbitrary norm in Section~
MISC	We also consider uncertainty sets that require disturbances of different features to satisfy joint conditions
MISC	This can be used to mitigate the conservativeness of the robust solution  and to obtain solutions with additional properties
OWNX	%We call these features ``coupled''
OWNX	In Section~, we present new sparsity results for the robust regression problem with feature-wise independent disturbances
OWNX	This provides a new robustness-based explanation to the sparsity of Lasso
OWNX	Our approach gives new analysis and also geometric intuition, and furthermore allows one to obtain sparsity results for more general loss functions, beyond the squared loss
OWNX	Next, we relate Lasso to kernel density estimation in Section~
OWNX	This allows us to re-prove consistency in a statistical learning setup, using the new robustness tools and formulation we introduce
OWNX	Along with our results on sparsity, this illustrates the power of robustness in explaining and also exploring different properties of the solution
OWNX	Finally, we prove in Section~ a ``no-free-lunch'' theorem, stating that an algorithm that encourages sparsity cannot be stable {Notation}
OWNX	We use capital letters to represent matrices, and boldface letters to represent column vectors
MISC	Row vectors are represented as the transpose of column vectors
MISC	For a vector  SYMBOL ,  SYMBOL  denotes its  SYMBOL  element
OWNX	Throughout the paper,  SYMBOL  and  SYMBOL  are used to denote the  SYMBOL  column and the  SYMBOL  row of the observation matrix  SYMBOL , respectively
MISC	We use  SYMBOL  to denote the  SYMBOL  element of  SYMBOL , hence it is the  SYMBOL  element of  SYMBOL , and  SYMBOL  element of  SYMBOL
MISC	For a convex function  SYMBOL ,  SYMBOL  represents any of its sub-gradients evaluated at  SYMBOL
MISC	A vector with length  SYMBOL  and each element equals  SYMBOL  is denoted as  SYMBOL
MISC	Despite the conventional wisdom that proactive security is superior to reactive security, we show that reactive security can be competitive with proactive security as long as the reactive defender learns from past attacks instead of myopically overreacting to the last attack
MISC	Our game-theoretic model follows common practice in the security literature by making worst-case assumptions about the attacker: we grant the attacker complete knowledge of the defender's strategy and do not require the attacker to act rationally
MISC	In this model, we bound the competitive ratio between a reactive defense algorithm (which is inspired by online learning theory) and the best fixed proactive defense
OWNX	Additionally, we show that, unlike proactive defenses, this reactive strategy is robust to a lack of information about the attacker's incentives and knowledge
MISC	Many enterprises employ a Chief Information Security Officer~(CISO) to manage the enterprise's information security risks
MISC	Typically, an enterprise has many more security vulnerabilities than it can realistically repair
MISC	Instead of declaring the enterprise ``insecure'' until every last vulnerability is plugged, CISOs typically perform a cost-benefit analysis to identify which risks to address, but what constitutes an effective CISO strategy
OWNX	The conventional wisdom~ CITATION  is that CISOs ought to adopt a ``forward-looking'' proactive approach to mitigating security risk by examining the enterprise for vulnerabilities that might be exploited in the future
MISC	Advocates of proactive security often equate reactive security with myopic bug-chasing and consider it ineffective
MISC	We establish sufficient conditions for when reacting  strategically  to attacks is as effective in discouraging attackers
OWNX	We study the efficacy of reactive strategies in an economic model of the CISO's security cost-benefit trade-offs
MISC	Unlike previously proposed economic models of security (see Section~), we do not assume the attacker acts according to a fixed probability distribution
OWNX	Instead, we consider a game-theoretic model with a strategic attacker who responds to the defender's strategy
OWNX	As is standard in the security literature, we make worst-case assumptions about the attacker
MISC	For example, we grant the attacker complete knowledge of the defender's strategy and do not require the attacker to act rationally
MISC	Further, we make conservative assumptions about the reactive defender's knowledge and do not assume the defender knows all the vulnerabilities in the system or the attacker's incentives
OWNX	However, we do assume that the defender can observe the attacker's past actions, for example via an intrusion detection system or user metrics~ CITATION
OWNX	In our model, we find that two properties are sufficient for a reactive strategy to perform as well as the best proactive strategies
MISC	First, no single attack is catastrophic, meaning the defender can survive a number of attacks
MISC	This is consistent with situations where intrusions (that, say, steal credit card numbers) are regrettable but not business-ending
MISC	Second, the defender's budget is \term{liquid}, meaning the defender can re-allocate resources without penalty
MISC	For example, a CISO can reassign members of the security team from managing firewall rules to improving database access controls at relatively low switching costs
MISC	Because our model abstracts many vulnerabilities into a single graph edge, we view the act of defense as increasing the attacker's \term{cost} for mounting an attack instead of preventing the attack (e g , by patching a single bug)
OWNX	By making this assumption, we choose not to study the tactical patch-by-patch interaction of the attacker and defender
OWNX	Instead, we model enterprise security at a more abstract level appropriate for the CISO
MISC	For example, the CISO might allocate a portion of his or her budget to engage a consultancy, such as WhiteHat or iSEC Partners, to find and fix cross-site scripting in a particular web application or to require that employees use SecurID tokens during authentication
MISC	We make the technical assumption that attacker costs are linearly dependent on defense investments locally
MISC	This assumption does not reflect patch-by-patch interaction, which would be better represented by a step function (with the step placed at the cost to deploy the patch)
MISC	Instead, this assumption reflects the CISO's higher-level viewpoint where the staircase of summed step functions fades into a slope
MISC	We evaluate the defender's strategy by measuring the attacker's cumulative return-on-investment, the \term{return-on-attack}~(ROA), which has been proposed previously~ CITATION
OWNX	By studying this metric, we focus on defenders who seek to ``cut off the attacker's oxygen,'' that is to reduce the attacker's incentives for attacking the enterprise
MISC	We do not distinguish between ``successful'' and ``unsuccessful'' attacks
OWNX	Instead, we compare the payoff the attacker receives from his or her nefarious deeds with the cost of performing said deeds
MISC	We imagine that sufficiently disincentivized attackers will seek alternatives, such as attacking a different organization or starting a legitimate business
OWNX	In our main result, we show sufficient conditions for a learning-based reactive strategy to be competitive with the best fixed proactive defense in the sense that the competitive ratio between the reactive ROA and the proactive ROA is at most  SYMBOL , for all  SYMBOL , provided the game lasts sufficiently many rounds (at least  SYMBOL )
OWNX	To prove our theorems, we draw on techniques from the online learning literature
AIMX	We extend these techniques to the case where the learner does not know all the game matrix rows  a priori , letting us analyze situations where the defender does not know all the vulnerabilities in advance
OWNX	Although our main results are in a graph-based model with a single attacker, our results generalize to a model based on Horn clauses with multiple attackers
OWNX	Our results are also robust to switching from ROA to attacker profit and to allowing the proactive defender to revise the defense allocation a fixed number of times
MISC	Although myopic bug chasing is most likely an ineffective reactive strategy, we find that in some situations a  strategic  reactive strategy is as effective as the optimal fixed proactive defense
MISC	In fact, we find that the natural strategy of gradually reinforcing attacked edges by shifting budget from unattacked edges ``learns'' the attacker's incentives and constructs an effective defense
MISC	Such a strategic reactive strategy is both easier to implement than a proactive strategy---because it does not presume that the defender knows the attacker's intent and capabilities---and is less wasteful than a proactive strategy because the defender does not expend budget on attacks that do not actually occur
OWNX	Based on our results, we encourage CISOs to  question the assumption that proactive risk management is inherently superior to reactive risk management \paragraph{Organization } Section~ formalizes our model
OWNX	Section~ shows that perimeter defense and defense-in-depth arise naturally in our model
OWNX	Section~ presents our main results bounding the competitive ratio of reactive versus proactive defense strategies
OWNX	Section~ outlines scenarios in which reactive security out-performs proactive security
OWNX	Section~ generalizes our results to Horn clauses and multiple attackers
MISC	Section~ relates related work
OWNX	Section~ concludes }
OWNX	this paper investigates the boundaries of the recent result that eliciting more than one estimate from the same person and averaging these can lead to accuracy gains in judgment tasks
MISC	it first examines its generality  analysing whether the kind of question being asked has an effect on the size of potential gains
OWNX	experimental results show that the question type matters
MISC	previous results reporting potential accuracy gains are reproduced for year-estimation questions  and extended to questions about percentage shares
MISC	on the other hand  no gains are found for general numerical questions
OWNX	the second part of the paper tests repeated judgment sampling's practical applicability by asking judges to provide a third and final answer on the basis of their first two estimates
OWNX	in an experiment  the majority of judges do not consistently average their first two answers
OWNX	as a result  they do not realise the potential accuracy gains from averaging
MISC	imagine you have been asked to make a quantitative judgment  say  somebody wants to know when shakespeare's romeo and juliet was first performed  or you might be planning a holiday in the alps and are wondering about the elevation of mont blanc
MISC	an effective strategy to answer such questions is to make an estimate and average it with that of a second judge  a friend  a colleague or just about anybody else  CITATION
MISC	what  though  if your colleague or friend is unavailable and cannot give you that second opinion
OWNX	recent research suggests that you could improve your answer by bringing yourself to make a second estimate and applying the averaging principle to your own two estimates  CITATION
MISC	the effectiveness of this suggestion  however  will depend on both the degree to which you are able to elicit two independent estimates from yourself and your willingness to average them
MISC	previous research has focused on the method used to elicit the second estimate
MISC	the focus here lies on the type of question being asked  and its interaction with how successive estimates are generated
OWNX	i report experimental results for different sets of questions which aim to be more representative of quantitative judgments  CITATION
OWNX	i first reproduce previous results which establish the existence of accuracy gains for year-estimation questions such as  in what year were bacteria discovered
OWNX	   CITATION
MISC	while i find similar gains for questions about percentage shares e g    which percentage of spanish homes have access to the internet
MISC	   i do not find evidence of accuracy gains for general numerical questions such as  what is the distance in kilometers between barcelona and the city of hamburg  in germany
MISC	  or  what is the average depth of the mediterranean sea
OWNX	 
MISC	i then investigate whether this difference can be explained by the degree to which answers to the various question types are implicitly bounded  but this hypothesis is not supported by the data
MISC	a second factor is whether judges actually recognise the potential gains from averaging and behave accordingly
MISC	larrick and soll  CITATION  argue that people often do not understand the properties and benefits of averaging procedures
OWNX	my experimental data provide further evidence  only a small minority of judges consistently average their estimates
MISC	often  judges settle for one of their first two judgments as the final answer instead or even extrapolate  providing a final answer that lies outside of the range spanned by their first two estimates
MISC	When introduced into a novel environment, mammals establish in it a preferred place marked by the highest number of visits and highest cumulative time spent in it.
OWNX	Examination of exploratory behavior in reference to this home base highlights important features of its organization.
MISC	It might therefore be fruitful to search for other types of marked places in mouse exploratory behavior and examine their influence on overall behavior.
MISC	Examination of path curvatures of mice exploring a large empty arena revealed the presence of circumscribed locales marked by the performance of tortuous paths full of twists and turns.
MISC	We term these places knots, and the behavior performed in them knot-scribbling.
MISC	There is typically no more than one knot per session; it has distinct boundaries and it is maintained both within and across sessions.
MISC	Knots are mostly situated in the place of introduction into the arena, here away from walls.
OWNX	Knots are not characterized by the features of a home base, except for a high speed during inbound and a low speed during outbound paths.
OWNX	The establishment of knots is enhanced by injecting the mouse with saline and placing it in an exposed portion of the arena, suggesting that stress and the arousal associated with it consolidate a long-term contingency between a particular locale and knot-scribbling.
MISC	In an environment devoid of proximal cues mice mark a locale associated with arousal by twisting and turning in it.
OWNX	This creates a self-generated, often centrally located landmark.
OWNX	The tortuosity of the path traced during the behavior implies almost concurrent multiple views of the environment.
MISC	Knot-scribbling could therefore function as a way to obtain an overview of the entire environment, allowing re-calibration of the mouse's locale map and compass directions.
MISC	The rich vestibular input generated by scribbling could improve the interpretation of the visual scene.
MISC	When introduced into a novel environment rats establish in it a preferred place characterized by the highest frequency of visits, by the highest cumulative dwell time, by an upper bound on the number of stops per roundtrip performed from it, by low outbound trajectory speed and high inbound trajectory speed, with the speed relationship reversed in later stages of the session CITATION CITATION.
OWNX	The existence of highly organized behavior across the whole arena in reference to this so-called home base CITATION illustrates the influence a preferred place might have on the overall organization of exploratory behavior and prompts the search for other types of preferred places that may have a similar influence on the organization of exploratory behavior.
MISC	In contrast to the situation with rats, there is an ambiguity regarding the establishment of home bases in mice: while some studies mention home bases, their establishment is mostly of a low occurrence in the forced exploration setup.
MISC	Even though mice readily establish home bases near physical objects CITATION CITATION and near nesting material CITATION, they are reported to fail to establish distinct home bases during forced exploration of a relatively featureless environment CITATION CITATION .
MISC	When mice used as a control group in another study were injected with saline and placed in the exposed portion of a large open field arena, they established in it preferred places, typically not more than one per session, which they visited sporadically, tracing in them a tortuous path full of twists, turns, and bends that looked like a knot.
MISC	We termed these places knots, and the behavior performed in them - knot-scribbling.
OWNX	This knot phenomenon, which appeared in its full blown form in the saline-injected mice, was subsequently uncovered, albeit in a less striking form, also in intact mice.
OWNX	In the present study we describe the full-blown knot phenomenon in saline-injected mice and only then verify the existence of knots in intact mice.
OWNX	To uncover knots we utilize a basic feature of the locomotor path its curvature.
MISC	Depending on the size of the window that is used for measuring path curvature this measure discloses various features of path texture, from overall large-scale curvature to fine-grained tortuosity CITATION.
OWNX	In the present study we use a window size that makes the fine-grained tortuosity of the path as conspicuous as possible.
MISC	Curvature has been measured previously only as a cumulative measure of paths without coupling a particular degree of curvature to particular topographical locations CITATION CITATION.
OWNX	To uncover knots we first calculate fine-grained path curvature for each data point on the path traced by the mouse.
OWNX	Then we partition the arena into small 5 5cm unit areas and summate, for each unit area, the curvature of the path included within that unit area.
OWNX	The magnitude of path curvature per unit area is then color coded in a visualization of the paths, thus highlighting the unit areas that are marked by the highest curvature.
OWNX	Having uncovered a high curvature locale we then design and use algorithms that define its boundaries and quantify some of its features.
OWNX	Finally, we ask whether the knots we discover are also endowed with the classical home base features, and consider their function.
OWNX	Extracting network-based functional relationships within genomic datasets is an important challenge in the computational analysis of large-scale data.
MISC	Although many methods, both public and commercial, have been developed, the problem of identifying networks of interactions that are most relevant to the given input data still remains an open issue.
MISC	Here, we have leveraged the method of random walks on graphs as a powerful platform for scoring network components based on simultaneous assessment of the experimental data as well as local network connectivity.
OWNX	Using this method, NetWalk, we can calculate distribution of Edge Flux values associated with each interaction in the network, which reflects the relevance of interactions based on the experimental data.
MISC	We show that network-based analyses of genomic data are simpler and more accurate using NetWalk than with some of the currently employed methods.
OWNX	We also present NetWalk analysis of microarray gene expression data from MCF7 cells exposed to different doses of doxorubicin, which reveals a switch-like pattern in the p53 regulated network in cell cycle arrest and apoptosis.
OWNX	Our analyses demonstrate the use of NetWalk as a valuable tool in generating high-confidence hypotheses from high-content genomic data.
MISC	An important challenge in the analyses of high throughput datasets is integration of the data with prior knowledge interactions of the measured molecules for the retrieval of most relevant biomolecular networks CITATION CITATION.
MISC	This approach facilitates interpretation of the data within the context of known functional interactions between biological molecules and subsequently leads to high-confidence hypothesis generation.
MISC	Typically, this procedure would entail identification of genes with highest or lowest data values, which is then followed by identification of associated networks.
MISC	However, retrieval of most relevant biological networks/pathways associated with the upper or lower end of the data distribution is not a trivial task, mainly because members of a biological pathway do not usually have similar data values, which necessitates the use of various computational algorithms for finding such networks of genes CITATION, CITATION, CITATION, CITATION, CITATION CITATION.
MISC	One class of methods for finding relevant networks utilize optimization procedures for finding highest-scoring subnetworks/pathways of genes based on the data values of genes CITATION, CITATION.
CONT	Although this approach is likely to result in highly relevant networks, it is computationally expensive and inefficient, and is therefore not suitable for routine analyses of functional genomics data in the lab.
MISC	The most popular of the existing methods of extraction of relevant networks from genomic data, however, usually involve a network building strategy using a pre-defined focus gene set, which is typically a set of genes with most significant data values CITATION, CITATION.
MISC	The network is built by filling in other nodes from the network either based on the enrichment of interactions for the focus set CITATION, or based on the analysis of shortest paths between the focus genes CITATION, CITATION.
OWNX	Both methods aim at identifying genes in the network that are most central to connecting the focus genes to each other.
MISC	Problems associated with these methods have been outlined previously CITATION.
MISC	However perhaps most importantly, the central genes identified by these methods may have incoherent data values with the focus genes, as data values of nodes are not accounted for during the network construction process using the seed gene list.
MISC	This may result in uninformative networks that are not representative of the networks most significantly represented in the genomic data.
MISC	In addition, these methods do not account for genes with more subtle data values that collectively may be more important than those with more obvious data values CITATION.
MISC	Although powerful data analysis methods for finding sets of genes with significant, albeit subtle, expression changes have been developed, such an approach has not been incorporated into methods for extracting interaction networks that are most highlighted by the data.
MISC	In order to overcome these problems, we have employed the method of random walks in graphs for scoring the relevance of interactions in the network to the data.
MISC	The method of random walks has been well-established for structural analyses of networks, as it can fully account for local as well as global topological structure within the network CITATION, CITATION and it is very useful for identifying most important/central nodes CITATION CITATION.
OWNX	Here, instead of working with a pre-defined set of focus genes, we overlay the entire data distribution onto the network, and bias the random walk probabilities based on the data values associated with nodes.
OWNX	This method, NetWalk, generates a distribution of Edge Flux values for each interaction in the network, which then can be used for dynamical network building or further statistical analyses.
OWNX	Here, we describe the concept of NetWalk, demonstrate its usefulness in extracting relevant networks compared to Ingenuity Pathway Analysis, and show the use of NetWalk results in comparative analyses of highlighted networks between different conditions.
MISC	We tested NetWalk on experimentally derived genomic data from breast cancer cells treated with different concentrations of doxorubicin, a clinically used chemotherapeutic agent.
OWNX	Using NetWalk, we identify several previously unreported network processes involved in doxorubicin-induced cell death.
OWNX	From these studies we propose that NetWalk is a valuable network based analysis tool that integrates biological high throughput data with prior knowledge networks to define sub-networks of genes that are modulated in a biologically meaningful way.
MISC	Use of NetWalk will greatly facilitate analysis of genomic data.
MISC	Paired-end sequencing is emerging as a key technique for assessing genome rearrangements and structural variation on a genome-wide scale.
MISC	This technique is particularly useful for detecting copy-neutral rearrangements, such as inversions and translocations, which are common in cancer and can produce novel fusion genes.
MISC	We address the question of how much sequencing is required to detect rearrangement breakpoints and to localize them precisely using both theoretical models and simulation.
OWNX	We derive a formula for the probability that a fusion gene exists in a cancer genome given a collection of paired-end sequences from this genome.
OWNX	We use this formula to compute fusion gene probabilities in several breast cancer samples, and we find that we are able to accurately predict fusion genes in these samples with a relatively small number of fragments of large size.
OWNX	We further demonstrate how the ability to detect fusion genes depends on the distribution of gene lengths, and we evaluate how different parameters of a sequencing strategy impact breakpoint detection, breakpoint localization, and fusion gene detection, even in the presence of errors that suggest false rearrangements.
MISC	These results will be useful in calibrating future cancer sequencing efforts, particularly large-scale studies of many cancer genomes that are enabled by next-generation sequencing technologies.
OWNX	Cancer is a disease driven by selection for somatic mutations.
MISC	These mutations range from single nucleotide changes to large-scale chromosomal aberrations such as deletion, duplications, inversions and translocations.
MISC	While many such mutations have been cataloged in cancer cells via cytogenetics, gene resequencing, and array-based techniques there is now great interest in using genome sequencing to provide a comprehensive understanding of mutations in cancer genomes.
MISC	The Cancer Genome Atlas is one such sequencing initiative that focuses sequencing efforts in the pilot phase on point mutations in coding regions.
OWNX	This approach largely ignores copy neutral genome rearrangements including translocations and inversions.
OWNX	Such rearrangements can create novel fusion genes, as observed in leukemias, lymphomas, and sarcomas CITATION CITATION.
MISC	The canonical example of a fusion gene is BCR-ABL, which results from a characteristic translocation in many patients with chronic myelogenous leukemia CITATION.
MISC	The advent of Gleevec, a drug targeted to the BCR-ABL fusion gene, has proven successful in treatment of CML patients CITATION, invigorating the search for other fusion genes that might provide tumor-specific biomarkers or drug targets.
MISC	Until recently, it is was generally believed that recurrent translocations and their resulting fusion genes occurred only in hematological disorders and sarcomas, with few suggesting that such recurrent events were prevalent across all tumor types including solid tumors CITATION, CITATION.
MISC	This view has been challenged by the discovery of a fusion between the TMPRSS2 gene and several members of the ERG protein family in prostate cancer CITATION and the EML4-ALK fusion in lung cancer CITATION .
MISC	These studies raise the question of what other recurrent rearrangements remain to be discovered.
MISC	One strategy for genome-wide high-resolution identification of fusion genes and other large scale rearrangements is paired-end sequencing of clones, or other fragments of genomic DNA, from tumor samples.
MISC	The resulting end-sequence pairs, or paired reads, are mapped back to the reference human genome sequence.
MISC	If the mapped locations of the ends of a clone are invalid then a genomic rearrangement is suggested.
OWNX	This strategy was initially described in the End Sequence Profiling approach CITATION and later used to assess genetic structural variation CITATION, CITATION.
MISC	An innovative approach utilizing SAGE-like sequencing of concatenated short paired-end tags successfully identified fusion transcripts in cDNA libraries CITATION.
MISC	Present and forthcoming next-generation DNA sequencers hold promise for extremely high-throughput sequencing of paired-end reads.
MISC	For example, the Illumina Genome Analyzer will soon be able to produce millions of paired reads of approximately 30 bp from fragments of length 500 1000 bp CITATION, while the SOLiD system from Applied Biosystems promises 25 bp reads from each end of size selected DNA fragments of many sizes CITATION.
MISC	Similar strategies coupling the generation of paired-end tags with 454 sequencing have also been described CITATION, CITATION .
MISC	Whole genome paired-end sequencing approaches allow for a genome-wide survey of all potential fusion genes and other rearrangements in a tumor.
MISC	This approach holds several advantages over transcript or protein profiling in cancer studies.
MISC	First, discovery of fusion genes using mRNA expression CITATION, cDNA sequencing, or mass spectrometry CITATION depends on the fusion genes being transcribed under the specific cellular conditions present in the sample at the time of the assay.
MISC	These conditions might be different than those experienced by the cells during tumor development.
MISC	Second, measurement of fusions at the DNA sequence level focuses on gene fusions due to genomic rearrangements and thus is less impeded by splicing artifacts or trans splicing CITATION.
OWNX	Finally, genome sequencing can identify more subtle regulatory fusions that result when the promoter of one gene is fused to the coding region of another gene, as in the case with with the c-Myc oncogene fusion with the immunoglobin gene promoter in Burkitt's lymphoma CITATION .
AIMX	In this paper, we address a number of theoretical and practical considerations for assessing cancer genome organization using paired-end sequencing approaches.
MISC	We are largely concerned with detecting a rearrangement breakpoint, where a pair of non-adjacent coordinates in the reference genome is adjacent in the cancer genome.
OWNX	In particular, we extend this idea of a breakpoint to examine the ability to detect fusion genes.
OWNX	Specifically, if a clone with end sequences mapping to distant locations identifies a rearrangement in the cancer genome, does this rearrangement lead to formation of a fusion gene?
MISC	Obviously, sequencing the clone will answer this question, but this requires additional effort/cost and may be problematic; e.g. most next-generation sequencing technologies do not archive the genome in a clone library for later analysis.
MISC	We derive a formula for the probability of fusion between a pair of genomic regions given the set of all mapped clones and the empirical distribution of clone lengths.
OWNX	These probabilities are useful for prioritizing follow-up experiments to validate fusion genes.
MISC	In a test experiment on the MCF7 breast cancer cell-line, 3,201 pairs of genes were found near clones with aberrantly mapping end-sequences.
OWNX	However, our analysis revealed only 18 pairs of genes with a high probability of fusion, of which six were tested and five experimentally confirmed .
MISC	The advent of high throughput sequencing strategies raises important experimental design questions in using these technologies to understand cancer genome organization.
OWNX	Obviously, sequencing more clones improves the probability of detecting fusion genes and breakpoints.
MISC	However, even with the latest sequencing technologies, it would be neither practical nor cost effective to shotgun sequence and assemble the genomes of thousands of tumor samples.
MISC	Thus, it is important to maximize the probability of detecting fusion genes with the least amount of sequencing.
MISC	This probability depends on multiple factors including the number and length of end-sequenced clones, the length of genes that are fused, and possible errors in breakpoint localization.
MISC	Here, we derive several formulae that elucidate the trade-offs in experimental design of both current and next-generation sequencing technologies.
OWNX	Our probability calculations and simulations demonstrate that even with current paired-end technology we can obtain an extremely high probability of breakpoint detection with a very low number of reads.
MISC	For example, more than 90 percent of all breakpoints can be detected with paired-end sequencing of less than 100,000 clones.
MISC	Additionally, next-generation sequencers can potentially detect rearrangements with a greater than 99 percent probability and localize the breakpoints of these rearrangements to intervals of less than 300 bp in a single run of the machine .
MISC	Statistical learning theory chiefly studies restricted hypothesis classes,  particularly those with finite Vapnik-Chervonenkis (VC) dimension
OWNX	The fundamental quantity of interest is the sample complexity: the number of samples required to learn to a specified level of accuracy
OWNX	Here we consider learning over the set of all computable labeling functions
OWNX	Since the VC-dimension is infinite and a priori (uniform) bounds on the number of samples are impossible, we let the learning algorithm decide when it has seen sufficient samples to have learned
OWNX	We first show that learning in this setting is indeed possible, and develop a learning algorithm
OWNX	We then show, however, that bounding sample complexity independently of the distribution is impossible
MISC	Notably, this impossibility is entirely due to the requirement that the learning algorithm be computable,  and not due to the statistical nature of the problem
MISC	Suppose we are trying to learn a difficult classification problem: for example determining whether the given image contains a human face,  or whether the MRI image shows a malignant tumor, etc
OWNX	We may first try to train a simple model such as a small neural network
OWNX	If that fails, we may move on to other, potentially more complex, methods of classification such as support vector machines with different kernels,  techniques to apply certain transformations to the data first, etc
OWNX	Conventional statistical learning theory attempts to bound the number of samples needed to learn to a specified level of accuracy for each of the above models (e g \ neural networks, support vector machines)
MISC	Specifically, it is enough to bound the VC-dimension of the learning model to determine the number of samples to use~ CITATION
MISC	However, if we allow ourselves to change the model, then the VC-dimension of the overall learning algorithm is not finite, and much of statistical learning theory does not directly apply
MISC	Accepting that much of the time the complexity of the model cannot be a priori bounded,  Structural Risk Minimization~ CITATION  explicitly considers a hierarchy of increasingly complex models
OWNX	An alternative approach, and one we follow in this paper, is simply to consider a single learning model that includes all possible classification methods
MISC	We consider the unrestricted learning model consisting of all computable classifiers
MISC	Since the VC-dimension is clearly infinite,  there are no uniform bounds (independent of the distribution and the target concept) on the number of samples needed to learn accurately~ CITATION
OWNX	Yet we still want to guarantee a desired level of accuracy
MISC	Rather than deciding on the number of samples a priori,  it is natural to allow the learning algorithm to decide when it has seen sufficiently many labeled samples based on the training samples seen up to now and their labels
OWNX	Since the above learning model includes any practical classification scheme, we term it universal (PAC-) learning
OWNX	We first show that there is a computable learning algorithm in our universal setting
OWNX	Then, in order to obtain bounds on the number of training samples that would be needed, we consider measuring sample complexity of the learning algorithm as a function of the unknown correct labeling function (i e \ target concept)
OWNX	Although the correct labeling is unknown, this sample complexity measure could be used to compare learning algorithms speculatively: ``if the target labeling were such and such, learning algorithm  SYMBOL  requires fewer samples than learning algorithm  SYMBOL "
MISC	By asking what is the largest sample size needed assuming the target labeling function is in a certain class, we could compare the sample complexity of the universal learner to a learner over the restricted class (e g \ with finite VC-dimension)
OWNX	However, we prove that it is impossible to bound the sample complexity of any  computable  universal learning algorithm, even as a function of the target concept
OWNX	Depending on the distribution, any such bound will be exceeded with arbitrarily high probability
MISC	The impossibility of a distribution-independent bound is entirely due to the computability requirement
OWNX	Indeed we show there is an uncomputable learning procedure for which we bound the number of samples queried as a function of the unknown target concept, independently of the distribution
MISC	Our results imply that computable learning algorithms in the universal setting must ``waste samples" in the sense of requiring more samples than is necessary for statistical reasons alone
MISC	we examine two departures of individual perceptions of randomness from probability theory  the hot hand and the gambler's fallacy  and their respective opposites
OWNX	this paper's first contribution is to use data from the field individuals playing roulette in a casino to demonstrate the existence and impact of these biases that have been previously documented in the lab
OWNX	decisions in the field are consistent with biased beliefs  although we observe significant individual heterogeneity in the population
OWNX	a second contribution is to separately identify these biases within a given individual  then to examine their within-person correlation
OWNX	we find a positive and significant correlation across individuals between hot hand and gambler's fallacy biases  suggesting a common root cause of the two related errors
OWNX	we speculate as to the source of this correlation locus of control  and suggest future research which could test this speculation
OWNX	almost every decision we make involves uncertainty in some way
MISC	yet research on decision making under uncertainty demonstrates that our judgments are often not consistent with probability theory
MISC	intuitive ideas of randomness depart systematically from the laws of chance
MISC	this research suggests that we have developed a number of judgment heuristics for analyzing complex  real-world events
MISC	although many decisions based on these heuristics are consistent with probability theory  there are also situations where heuristics lead to statistical illusions and suboptimal actions
OWNX	this paper investigates the existence and impact of two of these statistical illusions  the gambler's fallacy and the hot hand
MISC	both of these illusions characterize individuals' perceptions of non-autocorrelated random sequences
OWNX	thus both involve perceptions of sequences of events rather than one-time events
MISC	the gambler's fallacy is a belief in negative autocorrelation of a non-autocorrelated random sequence of outcomes like coin flips
MISC	for example  imagine jim repeatedly flipping a fair coin and guessing the outcome before it lands
OWNX	if he believes in the gambler's fallacy  then after observing three heads in a row  his subjective probability of seeing another head is less than  NUMBER  percent 
MISC	thus he believes a tail is  due   and is more likely to appear on the next flip than a head
MISC	in contrast  the hot hand is a belief in positive autocorrelation of a non-autocorrelated random sequence of outcomes like winning or losing
MISC	for example  imagine rachel repeatedly flipping a fair coin and guessing the outcome before it lands
OWNX	if she believes in the hot hand  then after observing three correct guesses in a row her subjective probability of guessing correctly on the next flip is higher than  NUMBER  percent 
MISC	thus she believes that she is  hot  and more likely than chance to guess correctly
MISC	notice that these two biases are not simply opposites
MISC	the gambler's fallacy describes beliefs about outcomes of the random process e g   heads or tails  while the hot hand describes beliefs of outcomes of the individual like wins and losses
MISC	in the gambler's fallacy  the coin is due  in the hot hand the person is hot
OWNX	for purposes of our study  we will identify four possible biases that individuals could exhibit
MISC	the gambler's fallacy and its opposite  the hot outcome  are beliefs about the coin's outcomes involving negative versus positive autocorrelation of random outcomes
MISC	the hot hand and its opposite  the stock of luck  are beliefs about the individual's success involving positive versus negative autocorrelation of winning or losing
MISC	thus someone can believe both in the gambler's fallacy that after three coin flips of heads tails is due and the hot hand that after three wins they will be more likely to correctly guess the next outcome of the coin toss
MISC	these biases are believed to stem from the same source  the representativeness heuristic  as discussed below  CITATION
OWNX	in this paper we use empirical data from gamblers in casinos to examine the existence  prevalence and correlation between gambler's fallacy and hot hand beliefs
OWNX	a companion paper  croson and sundali  CITATION  uses the same data to examine the aggregate market impact of these biases
OWNX	in contrast  here we will identify the biases at the individual level  and examine the within-participant correlation between the two
MISC	empirical data  while difficult to obtain and to code  can provide an important complement and robustness check on other methods in investigating biases
MISC	participants in the casinos are making real decisions with their own money on the line
MISC	further  the participants represent a more motivated sample than typical students at a university  gamblers have a very real incentive to learn the game they are playing and to make decisions in accordance with their beliefs
OWNX	the use of casino data does  however  involve some limitations
OWNX	in particular  we were prevented from directly contacting the gamblers in the study  thus we cannot ask particular individuals why they bet how they did or about their beliefs at the time of placing the bet
MISC	also  the gambling population  while motivated  is a selected subsample of the population at large
OWNX	thus we will have to be cautious in our claims of external validity from this study
OWNX	nonetheless  we believe that the demonstration of these biases in the field at the level of the individual is an important contribution in and of itself
MISC	we are also one of the very few papers to identify multiple biases within an individual and to characterize the correlation between them
MISC	the gambler's fallacy is defined as an incorrect belief in negative autocorrelation of a non-autocorrelated random sequence
MISC	for example  individuals who believe in the gambler's fallacy believe that after three red numbers appearing on the roulette wheel  a black number is  due   that is  is more likely to appear than a red number
OWNX	gambler's fallacy-type beliefs were first observed in the laboratory under controlled conditions in the literature on probability matching
OWNX	in these experiments subjects were asked to guess which of two colored lights would next illuminate
MISC	after seeing a string of one outcome  subjects were significantly more likely to guess the other  an effect referred to in that literature as negative recency  CITATION
OWNX	ayton and fischer  CITATION  also demonstrate the existence of gambler's fallacy beliefs in the lab when subjects choose which of two colors will appear next on a simulated roulette wheel
MISC	gal and baron  CITATION  show that gambler's fallacy behavior is not simply caused by boredom  participants in their experiments were asked how they would best maximize their earnings  and they responded with gambler's fallacy type logic
MISC	the gambler's fallacy is thought to be caused by the representativeness heuristic  CITATION
OWNX	here  chance is perceived as  a self-correcting process in which a deviation in one direction induces a deviation in the opposite direction to restore the equilibrium   CITATION
OWNX	thus after a sequence of three red numbers appearing on the roulette wheel  black is more likely to occur than red because a sequence red-red-red-black is more representative of the underlying distribution than a sequence red-red-red-red
OWNX	we test for the gambler's fallacy in our data by looking at the impact of previous outcomes on current bets at roulette
MISC	people who believe in the gambler's fallacy should be less likely to bet on a number that has previously appeared
OWNX	for purposes of this analysis  we will examine two separate definitions of hotness  hot outcome and hot   hand
OWNX	hot outcome will simply be the opposite of the gambler's fallacy  that is  an incorrect belief in positive autocorrelation of a non-autocorrelated random sequence
MISC	for example  individuals who believe in hot outcome believe that after three red numbers appearing on the roulette wheel  another red number is more likely to appear than a black number because red numbers are hot
MISC	notice that here the outcomes are hot e g   red numbers  rather than individuals  as in the hot hand  below
MISC	in the lab  the literature on probability matching also provides evidence favoring hot outcome beliefs
OWNX	edwards  CITATION   lindman and edwards  CITATION  and feldman  CITATION  all found positive recency effects in probability matching tasks
MISC	in particularly long sequences of the probability matching game  participants were significantly more likely to guess the same outcome as had been observed previously
OWNX	we will test for hot outcome beliefs in our data by looking at the impact of previous outcomes on current bets at roulette
MISC	if gamblers believe in hot outcomes  they should be more likely to bet on an outcome that has previously been observed
MISC	thus a positive relationship between previously-observed outcomes and current bets is indicative of a belief in hot outcomes
MISC	hot hand is different from hot outcome
MISC	rather than believing that a particular outcome is hot  individuals who believe in the hot hand believe that a particular person is hot
MISC	for example  if an individual has won in the past  whatever numbers they choose to bet on are likely to win in the future  not just the numbers they've won with previously
MISC	gilovich  vallone and tversky  CITATION  demonstrated that individuals believe in the hot hand in basketball shooting  and that these beliefs are not correct i e   basketball shooters' probability of success is indeed serially uncorrelated
MISC	other evidence from the lab shows that subjects in a simulated blackjack game bet more after a series of wins than they do after a series of losses  both when betting on their own play and on the play of others  CITATION
MISC	further evidence of the hot hand in a laboratory experiment comes from ayton and fischer  CITATION
MISC	participants exhibit more confident in their guesses of what color will next appear after a string of correct guesses than after a string of incorrect guesses
MISC	explanations for the hot hand are numerous
MISC	it is clearly related to the illusion of control  CITATION   where individuals believe they can control outcomes that are  in fact  random
MISC	gilovich et al    CITATION  suggest that the hot hand also arises out of the representativeness heuristic  just as the gambler's fallacy
MISC	they write        this second explanation is supported by data in which participants are asked to generate strings of random numbers
MISC	the strings generated produced significantly fewer runs of the same outcome than a truly random sequence would  CITATION
OWNX	we will test for hot hand beliefs in our data by looking at how betting behavior changes in response to wins and losses
MISC	in particular  hot hand beliefs predict that after winning  individuals will increase the number of bets they place and after losing  decrease them
MISC	just as the gambler's fallacy and the hot outcome are opposing biases  the hot hand has an opposing bias  referred to here as  stock of luck  beliefs
MISC	individuals believe they have a stock or fixed amount of luck and  once it's spent  their probability of winning decreases
MISC	thus after a string of wins  individuals are less likely to win rather than more likely as predicted by the hot hand because they have exhausted their stock of luck
MISC	the effect has been demonstrated in the lab by leopard  CITATION  who examines choice behavior in a series of gambles and demonstrates that subjects take more risk after losing than after winning  suggesting that their bad luck is about to change or their good luck about to run out
MISC	stock of luck beliefs predict that after winning  individuals will decrease the number of bets they place and  after a loss  increase them
OWNX	thus a negative relationship observed between current betting behavior and previous wins losses will provide evidence for this bias
MISC	a large literature identifies individual differences in risk attitudes  CITATION
MISC	in addition  previous work has identified individual heterogeneity in biased beliefs about sequences of gambles
MISC	friedland  CITATION  uses a personality inventory to categorize individuals into luck-oriented and chance-oriented
MISC	in a questionnaire design  he finds gamblers' fallacy behavior in luck-oriented individuals but no such behavior  and in particular  no dependence of current bets on past outcomes  in chance-oriented individuals
MISC	in the field  previous work has also found individual heterogeneity in biased beliefs
MISC	keren and wagenaar  CITATION  examine blackjack play of  NUMBER  individuals who played at least  NUMBER  hands and changed their bets over time
MISC	of these   NUMBER  had relationships between previous outcomes and bet changes thus  exhibiting a bias of some sort
MISC	fourteen of them increased their bets after they won and decreased them after they lost consistent with the hot hand  while  NUMBER  decreased their bets after winning and increased them after losing consistent with stock of luck
OWNX	as in these studies  we will use our data to analyze individual differences in betting behavior
OWNX	only two previous papers examine field behavior at roulette
MISC	the first is an observational sociological field study by oldman  CITATION  which informally reports both the gambler's fallacy and the hot outcome
MISC	he writes that   t he bet on a particular spin tends to be placed on outcomes that are  due' either because they have not occurred for some time or because that is the way  things are running
MISC	 ' p  NUMBER 
OWNX	the second source  wagenaar  CITATION   discusses data from  NUMBER  roulette players in a casino who stayed between  NUMBER  and  NUMBER  spins each
MISC	of the  NUMBER  players who varied their bets most  he finds after a win  NUMBER  percent  of bets involve increased risk hot hand and  NUMBER  percent  involve decreased risk stock of luck
OWNX	after a loss   NUMBER  percent  of bets involve decreased risk hot hand and  NUMBER  percent  of bets do not stock of luck
MISC	however  wagenaar does not present an analysis of how individuals differ on this dimension
OWNX	while previous papers have investigated the gambler's fallacy and hot hand biases  our work makes two important and original contributions
MISC	first  it provides a field setting in which it is possible to investigate both biases at once
MISC	these biases have been analyzed together only in the lab  CITATION
OWNX	second  our empirical data will allow us to identify individual differences in these biases
OWNX	we will be able to examine the correlation between these biases within the individual
OWNX	in this study we use observational data from the field  individuals betting at roulette in a casino
MISC	roulette is a useful game for a number of reasons
MISC	first  it is serially uncorrelated  unlike other casino games like blackjack or baccarat where cards are dealt without replacement
MISC	second  each player has his or her own colored chips  thus tracking an individual's betting behavior is feasible
MISC	finally  roulette is an extremely popular and accessible game which requires relatively little skill to play unlike craps  for example  which is perceived as a game for experts
OWNX	thus roulette is likely to suffer from less selection bias than craps  although we are already selecting participants from the casino gambling population  mentioned above as an unavoidable selection bias
OWNX	roulette involves a dealer sometimes two  a wheel and a layout
OWNX	the wheel is divided into  NUMBER  even sectors  numbered  NUMBERNUMBER   plus  NUMBER  and  NUMBER 
OWNX	each space is red or black  with the  NUMBER  and  NUMBER  colored green
MISC	the wheel is arranged as shown in figure  NUMBER   such that red and black numbers alternate
MISC	players arrive at the roulette table and offer the dealer money either cash or casino chips
MISC	in exchange  they are given special roulette chips for betting at this wheel
MISC	these chips are not valid anywhere else in the casino  and each player at the table has a unique color of chips
MISC	players bet by placing chips on a numbered layout  the wheel is spun and a small white ball rolled around its edge
OWNX	the ball lands on a particular number in the wheel  which is the winning number for that round  and is announced publicly by the dealer
MISC	next  the dealer clears away all losing bets  players who had bet on the winning number in some configuration are paid in their own-colored chips and a new round of betting begins
MISC	figure  NUMBER  shows a typical layout  along with the types of bets that can be made
MISC	unlike the wheel  the layout is arranged in numerical order
MISC	players can place their bets on varying places on the layout
MISC	bets of the type on the number  NUMBER  are called  straight up  bets
MISC	these are bets on a single number
MISC	if the number comes up on the wheel  this bet would pay the player  NUMBER  for  NUMBER   NUMBER  to  NUMBER 
MISC	that is  when  NUMBER  chip is bet  the dealer pays the player  NUMBER  chips directly  and the chip that was bet is not removed from the table
MISC	bets of the type between the  NUMBER  and  NUMBER    line bets  are bets on two numbers
MISC	if either of the numbers comes up  this bet pays the player  NUMBER  for  NUMBER 
MISC	players can also bet on combinations of  NUMBER  numbers by the  NUMBER  which pay  NUMBER  for  NUMBER   combinations of  NUMBER  numbers on the corner of  NUMBERNUMBERNUMBERNUMBER  which pay  NUMBER  for  NUMBER   or combinations of  NUMBER  numbers by the  NUMBERNUMBER  which pay  NUMBER  for  NUMBER 
MISC	players can  of course  bet on  outside  bets like red black  even odd and low high
OWNX	these bets will not be included in our analysis  as they are not bet often enough to allow identification at the individual level  but are discussed in our companion paper on aggregate behavior  croson and sundali  CITATION
OWNX	notice that all these bets have the same expected value NUMBER   NUMBER  percent  on a double-zero wheel
MISC	since the house advantage on almost all bets at the wheel is the same  there is no economic reason to bet one way or another or for that matter  at all
AIMX	in this paper  we will compare actual betting behavior we observe against a benchmark of random betting and search for systematic and significant deviations from that benchmark
MISC	three experiments tested if individuals show violations of transitivity in choices between risky gambles in linked designs
MISC	the binary gambles varied in the probability to win the higher better prize  the value of the higher prize  and the value of the lower prize
MISC	each design varied two factors  with the third fixed
MISC	designs are linked by using the same values in different designs
MISC	linked designs allow one to determine if a lexicographic semiorder model can describe violations of transitivity in more than one design using the same parameters
MISC	in addition  two experiments tested interactive independence  a critical property implied by all lexicographic semiorder models
MISC	very few people showed systematic violations of transitivity  only one person out of  NUMBER  showed violations of transitivity in two designs that could be linked by a lexicographic semiorder
MISC	however  that person violated interactive independence  as did the majority of other participants
MISC	most individuals showed systematic violations of the assumptions of stochastic independence and stationarity of choice responses
MISC	that means that investigators should evaluate models with respect to response patterns response combinations rather than focusing entirely on choice proportions
MISC	descriptive theories of risky decision making can be divided into two groups  those that satisfy transitivity of preference and those that do not
MISC	transitivity of preference is the assumption that  if a person prefers a to b and prefers b to c  then that person should prefer a to c  apart from random error
MISC	we use the symbol    x NUMBER b   to denote preference  so the property can be denoted as follows  a   x NUMBER b  b and b   x NUMBER b  c   x NUMBER d NUMBER   a   x NUMBER b  c
MISC	theories that represent each gamble by a single number automatically imply transitivity
MISC	these theories assume that a   x NUMBER b  b   x NUMBER d NUMBER   ua  greater than  ub  where ua and ub are the numerical values or utilities of the two gambles
MISC	expected utility theory eu  cumulative prospect theory cpt  and the transfer of attention exchange model tax  as well as many other theories  fall in this class of theories that satisfy transitivity  CITATION
MISC	theories that represent choice in terms of contrasts between the components of the alternatives  however  need not satisfy transitivity of preference
MISC	theories that violate transitivity include the family of lexicographic semiorder ls models  the priority heuristic  regret theory rt  the stochastic difference model sdm and others  CITATION
OWNX	We describe an adaptation and application of a search-based structured prediction algorithm ``\searn'' to unsupervised learning problems
OWNX	We show that it is possible to reduce unsupervised learning to supervised learning and demonstrate a high-quality unsupervised shift-reduce parsing model
MISC	We additionally show a close connection between unsupervised \searn\ and expectation maximization
OWNX	Finally, we demonstrate the efficacy of a semi-supervised extension
OWNX	The key idea that enables this is an application of the  predict-self  idea for unsupervised learning
MISC	A prevalent and useful version of unsupervised learning arises when both the observed data and the latent variables are structured
MISC	Examples range from hidden alignment variables in speech recognition  CITATION  and machine translation  CITATION , to latent trees in unsupervised parsing  CITATION , and to pose estimation in computer vision  CITATION
OWNX	These techniques are all based on probabilistic models
OWNX	Their applicability hinges on the tractability of (approximately) computing latent variable expectations, thus enabling the use of EM  CITATION
OWNX	In this paper we show that a recently-developed  search-based  algorithm, \searn\  CITATION  (see Section~), can be utilized for unsupervised structured prediction (Section~)
AIMX	We show: (1) that under an appropriate construction, \searn\ can imitate the expectation maximization (Section~); (2) that unsupervised \searn\ can be used to obtain competitive performance on an unsupervised dependency parsing task (Section~); and (3) that unsupervised \searn\ naturally extends to a semi-supervised setting (Section~)
OWNX	The key insight that enables this work is that we can consider the prediction of the (observed) input to be, itself, a structured prediction problem
MISC	according to the time-saving bias  drivers underestimate the time saved when increasing from a low speed and overestimate the time saved when increasing from a relatively high speed
MISC	previous research used a specific type of task - drivers were asked to estimate time saved when increasing speed and to give a numeric response - to show this
OWNX	the present research conducted two studies with multiple questions to show that the time-saving bias occurs in other tasks
MISC	study  NUMBER  found that drivers committed the time-saving bias when asked to estimate a the time saved when increasing speed or b the distance that can be completed at a given time when increasing speed or c the speed required to complete a given distance in decreasing times
MISC	study  NUMBER  showed no major differences in estimations of time saved compared to estimations of the remaining journey time and also between responses given on a numeric scale versus a visual analog scale
MISC	study  NUMBER  tested two possible explanations for the time-saving bias  a proportion heuristic and a differences heuristic
OWNX	some evidence was found for use of the latter
MISC	if you need to complete a  NUMBER  km journey  how much time would it take at a mean speed of  NUMBER  kph
MISC	most people would find it easy to answer such a question -  NUMBER  km at  NUMBER  kph takes half an hour or  NUMBER  minutes
MISC	but what if you wanted to increase speed in order to reduce journey time
MISC	how much time would you save if you increase your speed to  NUMBER  kph or to  NUMBER  or  NUMBER  kph
MISC	many people consistently give the wrong answers to these questions
MISC	several studies have shown that people underestimate the time saved when increasing from a relatively low speed and overestimate the time saved when increasing from a relatively high speed  CITATION
OWNX	% After building a classifier with modern tools of machine learning we typically have a black box at hand that is able to predict well for unseen data
OWNX	Thus, we get an answer to the question  what  is the most likely label of a given unseen data point
MISC	However, most methods will provide no answer  why  the model predicted the particular label for a single instance and what features were most influential for that particular instance
MISC	The only method that is currently able to provide such explanations are decision trees
OWNX	This paper proposes a procedure which (based on a set of assumptions) allows to explain the decisions of  any  classification method
OWNX	Automatic nonlinear classification is a common and powerful tool in data analysis
MISC	Machine learning research has created methods that are practically useful and that can classify unseen data after being trained on a limited training set of labeled examples
MISC	Nevertheless, most of the algorithms do not  explain  their decision
OWNX	However in practical data analysis it is essential to obtain an instance based explanation, i e we would like to gain an understanding what input features made the nonlinear machine give its answer for each individual data point
MISC	Typically, explanations are provided jointly for all instances of the training set, for example feature selection methods  (including Automatic Relevance Determination) find out which inputs are salient for a good generalization  CITATION
OWNX	While this can give a coarse impression about the global usefulness of each input dimension, it is still an ensemble view and does not provide an answer on an instance basis
MISC	In the neural network literature also solely an ensemble view was taken in algorithms like input pruning  CITATION
MISC	The only classification which does provide individual explanations are decision trees  CITATION
OWNX	This paper proposes a simple framework that provides local explanation vectors applicable to  any  classification method in order to help understanding prediction results for single data instances
MISC	The local explanation yields the features being relevant for the prediction at the very points of interest in the data space and is able to spot local peculiarities which are neglected in the global view eg due to cancellation effects
OWNX	The paper is organized as follows: We define local explanation vectors as class probability gradients in Section  and give an illustration for Gaussian Process Classification (GPC)
MISC	Some methods output a prediction without a direct probability interpretation
OWNX	For these we propose in Section  a way to estimate local explanations
MISC	In Section  we will apply our methodology to learn distinguishing properties of Iris flowers by estimating explanation vectors for a k-NN classifier applied to the classic Iris data set
OWNX	Section  will discuss how our approach applied to a SVM classifier allows us to explain how digits "two" are distinguished from digit "8" in the USPS data set
AIMX	In Section  we discuss a more real-world application scenario where the proposed explanation capabilities prove useful in drug discovery: Human experts regularly decide how to modify existing lead compounds in order to obtain new compounds with improved properties
MISC	Models capable of explaining predictions can help in the process of choosing promising modifications
MISC	Our automatically generated explanations match with chemical domain knowledge about toxifying functional groups of the compounds in question
OWNX	Section  contrasts our approach with related work and Section  discusses characteristic properties and limitations of our approach, before we conclude the paper in Section
OWNX	                                                                                                                                                                                                                                                                                                                                                                                                                                                                                iris_knn
MISC	Biophysically detailed models of single cells are difficult to fit to real data.
MISC	Recent advances in imaging techniques allow simultaneous access to various intracellular variables, and these data can be used to significantly facilitate the modelling task.
OWNX	These data, however, are noisy, and current approaches to building biophysically detailed models are not designed to deal with this.
MISC	We extend previous techniques to take the noisy nature of the measurements into account.
MISC	Sequential Monte Carlo methods, in combination with a detailed biophysical description of a cell, are used for principled, model-based smoothing of noisy recording data.
MISC	We also provide an alternative formulation of smoothing where the neural nonlinearities are estimated in a non-parametric manner.
MISC	Biophysically important parameters of detailed models are inferred automatically from noisy data via expectation-maximisation.
OWNX	Overall, we find that model-based smoothing is a powerful, robust technique for smoothing of noisy biophysical data and for inference of biophysical parameters in the face of recording noise.
MISC	Recent advances in imaging techniques allow measurements of time-varying biophysical quantities of interest at high spatial and temporal resolution.
MISC	For example, voltage-sensitive dye imaging allows the observation of the backpropagation of individual action potentials up the dendritic tree CITATION CITATION.
MISC	Calcium imaging techniques similarly allow imaging of synaptic events in individual synapses.
MISC	Such data are very well-suited to constrain biophysically detailed models of single cells.
MISC	Both the dimensionality of the parameter space and the noisy and undersampled nature of the observed data renders the use of statistical techniques desirable.
MISC	Here, we here use sequential Monte Carlo methods CITATION, CITATION a standard machine-learning approach to hidden dynamical systems estimation to automatically smooth the noisy data.
OWNX	In a first step, we will do this while inferring biophysically detailed models; in a second step, by inferring non-parametric models of the cellular nonlinearities.
MISC	Given the laborious nature of building biophysically detailed cellular models by hand CITATION CITATION, there has long been a strong emphasis on robust automatic methods CITATION CITATION.
MISC	Large-scale efforts have added to the need for such methods and yielded exciting advances.
MISC	The Neurofitter CITATION package, for example, provides tight integration with a number of standard simulation tools; implements a large number of search methods; and uses a combination of a wide variety of cost functions to measure the quality of a model's fit to the data.
OWNX	These are, however, highly complex approaches that, while extremely flexible, arguably make optimal use neither of the richness of the structure present in the statistical problem nor of the richness of new data emerging from imaging techniques.
MISC	In the past, it has been shown by us and others CITATION, CITATION CITATION that knowledge of the true transmembrane voltage decouples a number of fundamental parameters, allowing simultaneous estimation of the spatial distribution of multiple kinetically differing conductances; of intercompartmental conductances; and of time-varying synaptic input.
MISC	Importantly, this inference problem has the form of a constrained linear regression with a single, global optimum for all these parameters given the data.
MISC	None of these approaches, however, at present take the various noise sources in recording situations explicitly into account.
AIMX	Here, we extend the findings from CITATION, applying standard inference procedures to well-founded statistical descriptions of the recording situations in the hope that this more specifically tailored approach will provide computationally cheaper, more flexible, robust solutions, and that a probabilistic approach will allow noise to be addressed in a principled manner.
OWNX	Specifically, we approach the issue of noisy observations and interpolation of undersampled data first in a model-based, and then in a model-free setting.
MISC	We start by exploring how an accurate description of a cell can be used for optimal de-noising and to infer unobserved variables, such as Ca 2 concentration from voltage.
MISC	We then proceed to show how an accurate model of a cell can be inferred from the noisy signals in the first place; this relies on using model-based smoothing as the first step of a standard, two-step, iterative machine learning algorithm known as Expectation-Maximisation CITATION, CITATION.
MISC	The Maximisation step here turns out to be a weighted version of our previous regression-based inference method, which assumed exact knowledge of the biophysical signals.
OWNX	The aim of this paper is to fit biophysically detailed models to noisy electrophysiological or imaging data.
AIMX	We first give an overview of the kinds of models we consider; which parameters in those models we seek to infer; how this inference is affected by the noise inherent in the measurements; and how standard machine learning techniques can be applied to this inference problem.
OWNX	The overview will be couched in terms of voltage measurements, but we later also consider measurements of calcium concentrations.
MISC	Compartmental models are spatially discrete approximations to the cable equation CITATION, CITATION, CITATION and allow the temporal evolution of a compartment's voltage to be written asFORMULAwhere FORMULA is the voltage in compartment FORMULA, FORMULA is the specific membrane capacitance, and FORMULA is current evolution noise.
MISC	Note the important factor FORMULA which ensures that the noise variance grows linearly with time FORMULA.
OWNX	The currents FORMULA we will consider here are of three types:
MISC	Axial currents along dendritesFORMULA
MISC	Transmembrane currents from active, passive, or other membrane conductancesFORMULA
MISC	Experimentally injected currentsFORMULAwhere FORMULA indicates one particular current type, FORMULA its reversal potential and FORMULA its maximal conductance in compartment FORMULA, FORMULA is the membrane resistivity and FORMULA is the current experimentally injected into that compartment.
MISC	The variable FORMULA represents the time-varying open fraction of the conductance, and is typically given by complex, highly nonlinear functions of time and voltage.
OWNX	For example, for the Hodgkin and Huxley K -channel, the kinetics are given by FORMULA, withFORMULAand FORMULA themselves nonlinear functions of the voltage CITATION and we again have an additive noise term.
OWNX	In practice, the gate noise is either drawn from a truncated Gaussian, or one can work with the transformed variable FORMULA.
MISC	Similar equations can be formulated for other variables such as the intracellular free Ca 2 concentration CITATION .
MISC	the assumption that people possess a repertoire of strategies to solve the inference problems they face has been made repeatedly
MISC	the experimental findings of two previous studies on strategy selection are reexamined from a learning perspective  which argues that people learn to select strategies for making probabilistic inferences
MISC	this learning process is modeled with the strategy selection learning ssl theory  which assumes that people develop subjective expectancies for the strategies they have
MISC	they select strategies proportional to their expectancies  which are updated on the basis of experience
MISC	for the study by newell  weston  and shanks  CITATION  it can be shown that people did not anticipate the success of a strategy from the beginning of the experiment
OWNX	instead  the behavior observed at the end of the experiment was the result of a learning process that can be described by the ssl theory
MISC	for the second study  by broder and schiffer  CITATION   the ssl theory is able to provide an explanation for why participants only slowly adapted to new environments in a dynamic inference situation
OWNX	the reanalysis of the previous studies illustrates the importance of learning for probabilistic inferences
OWNX	how do people make probabilistic inferences  such as inferring the selling price of a car  the severity of an illness  or the likely winner of a tennis match
MISC	different strategies can be applied to make these inferences  such as integrating all available information to predict the criterion
MISC	in fact  many researchers have argued that people are equipped with a repertoire of different cognitive strategies for making judgments and decisions  CITATION
OWNX	do people apply different strategies for solving probabilistic inferences
MISC	and if so  how do they select from their strategy repertoire
MISC	the cost-benefit approach to strategy selection argues that people trade off the strategies' anticipated costs and benefits
MISC	in contrast  i will argue that selection is achieved via learning-that is  people learn the success and failure of strategies through experience and select a strategy based on past success
OWNX	i will describe a computational theory that specifies this learning process  CITATION  and will use it to explain people's probabilistic  inferences in two previous studies
MISC	Metabolic rate, heart rate, lifespan, and many other physiological properties vary with body mass in systematic and interrelated ways.
MISC	Present empirical data suggest that these scaling relationships take the form of power laws with exponents that are simple multiples of one quarter.
MISC	A compelling explanation of this observation was put forward a decade ago by West, Brown, and Enquist.
MISC	Their framework elucidates the link between metabolic rate and body mass by focusing on the dynamics and structure of resource distribution networks the cardiovascular system in the case of mammals.
MISC	Within this framework the WBE model is based on eight assumptions from which it derives the well-known observed scaling exponent of 3/4.
AIMX	In this paper we clarify that this result only holds in the limit of infinite network size and that the actual exponent predicted by the model depends on the sizes of the organisms being studied.
MISC	Failure to clarify and to explore the nature of this approximation has led to debates about the WBE model that were at cross purposes.
MISC	We compute analytical expressions for the finite-size corrections to the 3/4 exponent, resulting in a spectrum of scaling exponents as a function of absolute network size.
MISC	When accounting for these corrections over a size range spanning the eight orders of magnitude observed in mammals, the WBE model predicts a scaling exponent of 0.81, seemingly at odds with data.
MISC	We then proceed to study the sensitivity of the scaling exponent with respect to variations in several assumptions that underlie the WBE model, always in the context of finite-size corrections.
OWNX	Here too, the trends we derive from the model seem at odds with trends detectable in empirical data.
CONT	Our work illustrates the utility of the WBE framework in reasoning about allometric scaling, while at the same time suggesting that the current canonical model may need amendments to bring its predictions fully in line with available datasets.
MISC	Whole-organism metabolic rate, B, scales with body mass, M, across species as CITATION FORMULAwhere B 0 is a normalization constant and is the allometric scaling exponent, typically measured to be very close to 3/4 CITATION.
MISC	The empirical regularity expressed in Equation 1 with 3/4 is known as Kleiber's Law CITATION, CITATION .
MISC	Many other biological rates and times scale with simple multiples of 1/4.
MISC	For example, cellular or mass-specific metabolic rates, heart and respiratory rates, and ontogenetic growth rates scale as M 1/4, whereas blood circulation time, development time, and lifespan scale close to M 1/4 CITATION CITATION.
MISC	Quarter-power scaling is also observed in ecology and evolution CITATION, CITATION, CITATION.
MISC	The occurrence of quarter-power scaling at such diverse levels of biological organization suggests that all these rates are closely linked.
MISC	Metabolic rate seems to be the most fundamental because it is the rate at which energy and materials are taken up from the environment, transformed in biochemical reactions, and allocated to maintenance, growth, and reproduction.
MISC	In a series of papers starting in 1997, West, Brown, and Enquist published a model to account for the 3/4-power scaling of metabolic rate with body mass across species CITATION, CITATION CITATION.
MISC	The broad theory of biological allometry developed by WBE and collaborators attributes such quarter-power scaling to near-optimal fractal-like designs of resource distribution networks and exchange surfaces.
MISC	There is some evidence that such designs are realized at molecular, organelle, cellular, and organismal levels for a wide variety of plants and animals CITATION, CITATION .
MISC	Intensifying controversy has surrounded the WBE model since its original publication, even extending to a debate about the quality and analysis of the data CITATION CITATION.
MISC	One of the most frequently raised objections is that the WBE model cannot predict scaling exponents for metabolic rate that deviate from 3/4 CITATION, CITATION, even though the potential for such deviations was appreciated by WBE themselves CITATION.
MISC	If this criticism were true, WBE could not in principle explain data for taxa whose scaling exponents have been reported to be above or below 3/4 CITATION CITATION, or deviations from 3/4 that have been observed for small mammals CITATION.
MISC	Likewise, the WBE model would be unable to account for the scaling of maximal metabolic rate with body mass, which appears to have an exponent of 0.88 CITATION.
MISC	It is important to note that the actual nature of maximal metabolic rate scaling is, however, not without its own controversy; see CITATION for an argument that maximal metabolic rate scales closer to 3/4 when body temperature is taken into consideration.
MISC	Much of the work aimed at answering these criticisms has relied on alteration of the WBE model itself.
MISC	Enquist and collaborators account for different scaling exponents among taxonomic groups by emphasizing differences in the normalization constant B 0 of Equation 1 and deviations from the WBE assumptions regarding network geometry CITATION, CITATION CITATION.
MISC	While these results are suggestive, it remains unclear whether or not WBE can predict exponents significantly different from 3/4 and measurable deviations from a pure power law even in the absence of any variation in B 0 and with networks following exactly the geometry required by the theory.
MISC	Although WBE has been frequently tested and applied CITATION CITATION, it is remarkable that no theoretical work has been published that provides more detailed predictions from the original theory.
MISC	Also, work aimed at extending WBE by relaxing or modifying some of its assumptions has hardly been complete; many variations in network structure might have important and far-reaching consequences once properly analyzed.
OWNX	This is what we set out to do in the present contribution.
MISC	We show that a misunderstanding of the original model has led to the claim that WBE can only predict a 3/4 exponent.
MISC	This is because many of the predictions and tests of the original model are derived from leading-order approximations.
OWNX	In this paper we derive more precise predictions and tests.
OWNX	For the purpose of stating our conclusions succinctly, we refer to the WBE framework as an approach to explaining allometric scaling phenomena in terms of resource distribution networks and to the WBE model as an instance of the WBE framework that employs particular parameters specifying geometry and dynamics of these networks CITATION, CITATION.
OWNX	Our main findings are: 1.
MISC	The 3/4 exponent only holds exactly in the limit of organisms of infinite size.
OWNX	2.
OWNX	For finite-sized organisms we show that the WBE model does not predict a pure power-law but rather a curvilinear relationship between the logarithm of metabolic rate and the logarithm of body mass. 3.
MISC	Although WBE recognized that finite size effects would produce deviations from pure 3/4 power scaling for small mammals and that the infinite size limit constitutes an idealization CITATION, the magnitude and importance of finite-size effects were unclear.
MISC	We show that, when emulating current practice by calculating the scaling exponent of a straight line regressed on this curvilinear relationship over the entire range of body masses, the exponent predicted by the WBE model can differ significantly from 3/4 without any modifications to its assumptions or framework.
OWNX	4.
MISC	When realistic parameter values are employed to construct the network, we find that the exponent resulting from finite-size corrections comes in at 0.81, significantly higher than the 3/4 figure based on current data analysis.
OWNX	5.
OWNX	Our data analysis indeed detects a curvilinearity in the relationship between the logarithm of metabolic rate and the logarithm of body mass. However, that curvilinearity is opposite to what we observe in the WBE model.
OWNX	This implies that the WBE model needs amendment and/or the data analysis needs reassessment.
OWNX	Beyond finite-size corrections we examine the original assumptions of WBE in two ways.
OWNX	First, we vary the predicted switch-over point above which the vascular network architecture preserves the total cross-sectional area of vessels at branchings and below which it increases the total cross-sectional area at branchings.
MISC	These two regimes translate into different ratios of daughter to parent radii at vessel branch points.
MISC	Second, we allow network branching ratios to differ for large and small vessels.
MISC	We analyze the sensitivity of the scaling exponent with respect to each of these changes in the context of networks of finite size.
MISC	This approach is similar in spirit to Price et al. CITATION, who relaxed network geometry and other assumptions of WBE in the context of plants.
MISC	In the supplementary online material Text S1, we also argue that data analysis should account for the log-normal distribution of body mass abundance, thus correcting for the fact that there are more small mammals than large ones.
MISC	Despite differences in the structure and hydrodynamics of the vascular systems of plants and animals CITATION, CITATION, detailed models of each yield a scaling exponent of 3/4 to leading-order.
OWNX	In the present paper, we focus on the WBE model of the cardiovascular system of mammals.
MISC	All of our assumptions, derivations, and calculations should be interpreted within that context.
MISC	Finite-size corrections and departures from the basic WBE assumptions are important in the context of plants as well, as shown in recent studies by Enquist and collaborators CITATION, CITATION CITATION .
OWNX	In final analysis, we are led to the seemingly incongruent conclusions that many of the critiques of the WBE framework are misguided and the exact predictions of the WBE model are not fully supported by empirical data.
MISC	The former means that the WBE framework remains, once properly understood, a powerful perspective for elucidating allometric scaling principles.
MISC	The latter means that the WBE model must become more respectful of biological detail whereupon it may yield predictions that more closely match empirical data.
MISC	Our work explores how such details can be added to the model and what effects they can have.
OWNX	The paper is organized as follows.
OWNX	For the sake of a self-contained presentation, we start with a systematic overview of the assumptions, both explicit and implicit, underlying the WBE theory.
OWNX	In Text S1, we provide a detailed exposition of the hydrodynamic derivations that the model rests upon.
MISC	These calculations are not original, but they have not appeared to a full extent before in the literature.
MISC	While nothing in section Assumptions of the WBE model is novel, there seems to be no single go to place in the WBE literature that lays out all components of the WBE theory.
MISC	Our paper then proceeds with a brief derivation of the exact, rather than approximate, relationship between metabolic rate and body mass. We then calculate the exact predictions for scaling exponents for networks of finite size and revisit certain assumptions of the theory.
OWNX	In section Comparison to empirical data we compare our results to trends detectable in empirical data.
OWNX	We put forward our conclusions in the Discussion section.
MISC	% This paper describes a methodology for detecting anomalies from sequentially observed and potentially noisy data
AIMX	The proposed approach consists of two main elements: (1)  filtering , or assigning a belief or likelihood to each successive measurement based upon our ability to predict it from previous noisy observations, and (2)  hedging , or flagging potential anomalies by comparing the current belief against a time-varying and data-adaptive threshold
OWNX	The threshold is adjusted based on the available feedback from an end user
MISC	Our algorithms, which combine universal prediction with recent work on online convex programming, do not require computing posterior distributions given all current observations and involve simple primal-dual parameter updates
MISC	At the heart of the proposed approach lie exponential-family models which can be used in a wide variety of contexts and applications, and which yield methods that achieve sublinear per-round regret against both static and slowly varying product distributions with marginals drawn from the same exponential family
MISC	Moreover, the regret against static distributions coincides with the minimax value of the corresponding online strongly convex game
MISC	We also prove bounds on the number of mistakes made during the hedging step relative to the best offline choice of the threshold with access to all estimated beliefs and feedback signals
OWNX	We validate the theory on synthetic data drawn from a time-varying distribution over binary vectors of high dimensionality, as well as on the Enron email dataset \\   {Keywords:} anomaly detection, exponential families, filtering, individual sequences, label-efficient prediction, minimax regret, online convex programming, prediction with limited feedback, sequential probability assignment, universal prediction
OWNX	\PARstart{I}{n this} paper, we explore the performance of online anomaly detection methods built on sequential probability assignment and dynamic thresholding based on limited feedback
MISC	We assume we sequentially monitor the state of some system of interest
MISC	At each time step, we observe a possibly  noise-corrupted  version  SYMBOL  of the current state  SYMBOL , and need to infer whether  SYMBOL  is  anomalous  relative to the actual sequence  SYMBOL  of the past states
MISC	This inference is encapsulated in a binary decision  SYMBOL , which can be either  SYMBOL  (non-anomalous or nominal behavior) or  SYMBOL  (anomalous behavior)
OWNX	After announcing our decision, we may occasionally receive  feedback  on the ``true'' state of affairs and use it to adjust the future behavior of the decision-making mechanism
MISC	Our inference engine should make good use of this feedback, whenever it is available, to improve its future performance
MISC	One reasonable way to do it is as follows
OWNX	Having observed  SYMBOL  (but not  SYMBOL ), we can use this observation to assign ``beliefs" or ``likelihoods" to the clean state  SYMBOL
MISC	Let us denote this likelihood assignment as  SYMBOL
OWNX	Then, if we actually had access to the clean observation  SYMBOL , we could evaluate  SYMBOL  and declare an anomaly ( SYMBOL ) if  SYMBOL , where  SYMBOL  is some positive threshold; otherwise we would set  SYMBOL  (no anomaly at time  SYMBOL )
MISC	This approach is based on the intuitive idea that a new observation  SYMBOL  should be declared anomalous if it is very unlikely based on our past knowledge (namely,  SYMBOL )
CONT	In other words, observations are considered anomalous if they are in a portion of the observation domain which has very low likelihood according to the best probability model that can be assigned to them on the basis of previously seen observations (In fact, anomaly detection algorithms based on density level sets revolve around precisely this kind of reasoning ) The complication here, however, is that we do not actually observe  SYMBOL , but rather its noise-corrupted version  SYMBOL
OWNX	Thus, we settle instead for an  estimate   SYMBOL  of  SYMBOL  based on  SYMBOL  and compare this estimate against  SYMBOL
OWNX	If we receive feedback  SYMBOL  at time  SYMBOL  and it differs from our label  SYMBOL , then we adjust the threshold appropriately
MISC	We discuss multi-task online learning when a decision maker has to deal simultaneously with  SYMBOL  tasks
MISC	The tasks are related, which is modeled by imposing that the  SYMBOL --tuple of actions taken by the decision maker needs to satisfy certain constraints
AIMX	We give natural examples of such restrictions and then discuss a general class of tractable constraints, for which we introduce computationally efficient ways of selecting actions, essentially by reducing to an on-line shortest path problem
OWNX	We briefly discuss ``tracking'' and ``bandit'' versions of the problem and extend the model in various ways, including non-additive global losses and uncountably infinite sets of tasks
MISC	Multi-task learning has recently received considerable attention, see  CITATION
MISC	In multi-task learning problems, one simultaneously learns several tasks that are related in some sense
MISC	The relationship of the tasks has been modeled in different ways in the literature
MISC	In our setting, a decision maker chooses an action simultaneously for each of  SYMBOL  given tasks, in a repeated manner (To each of these tasks corresponds a game, and we will use interchangeably the concepts of game and task ) The relatedness is accounted for by putting some hard constraints on these simultaneous actions
MISC	As a motivating example, consider a distance-selling company that designs several commercial offers for its numerous customers, and the customers are ordered (say) by age
MISC	The company has to choose whom to send which offer
OWNX	A loss of earnings is suffered whenever a customer does not receive the commercial offer that would have been best for him
MISC	Basic marketing considerations suggest that offers given to customers with similar age should not be very different, so the company selects a batch of offers that satisfy such a constraint
MISC	Additional budget constraint may limit further the set of batches from which the company may select
OWNX	After the offers are sent out, the customers' responses are observed (at least partially) and new offers are selected and sent
MISC	We model such situations by playing many repeated games simultaneously with the restriction that the vector of actions that can be selected at a time needs to belong to a previously given set
MISC	This set in determined beforehand by the budget and marketing constraints discussed above
MISC	The goal of the decision maker is to minimize the total accumulated regret (across the many games and through time), that is, perform, on the long run, almost as well as the best constant vector of actions satisfying the constraint
MISC	The problem of playing repeatedly several games simultaneously has been considered by  CITATION  who studies convergence to Nash equilibria but does not address the issue of computational feasibility when a large number of games is played
OWNX	On-line multi-task learning problems were also studied by  CITATION  and  CITATION
OWNX	As the latter reference, we consider minimizing regret simultaneously in parallel, by enforcing however some hard constraints
MISC	As  CITATION , we measure the total loss as the sum of the losses suffered in each game but assume that all tasks have to be performed at each round (This assumption is, however relaxed in Section , where we consider global losses more general than the sums of losses ) The main additional difficulty we face is the requirement that the decision maker chooses from a restricted subset of vectors of actions
MISC	In previous models restrictions were only considered on the comparison class, but not on the way the decision maker plays
OWNX	We formulate the problem in the framework of on-line regret minimization, see  CITATION  for a survey
MISC	The main challenge is to construct a strategy for playing the many games simultaneously with small regret such that the strategy has a manageable computational complexity
AIMX	We show that in various natural examples the computational problem may be reduced to an online shortest path problem in an associated graph for which well-known efficient algorithms exist (We however propose a specific scheme for implementation that is slightly more effective )  The results can be extended easily to the ``tracking'' case in which the goal of the decision maker is to perform as well as the best strategy that can change the vector of actions (taken from the restricted set) at a limited number of times
MISC	We also consider the ``bandit'' version of the problem when the decision maker, instead of observing the losses of all actions in all games, only learns the sum of the losses of the chosen actions
MISC	Finally, we also consider cases when there are infinitely many tasks, indexed by real numbers
MISC	In such cases the decision maker chooses a function from a certain restricted class of functions
MISC	We show examples that are natural extensions of the cases we consider for finitely many tasks and discuss the computational issues that are closely related to the theory of exact simulation of continuous-time Markov chains
MISC	We concentrate on exponentially weighted average forecasters because, when compared to its most likely competitors, that is, follow-the-leader-type algorithms, they have better performance guarantees, especially in the case of bandit feedback
MISC	Besides, the two families of forecasters, as pointed out by  CITATION , usually have implementation complexities of the same order
MISC	In this paper, spectrum access in cognitive radio networks is modeled as a repeated auction game subject to monitoring and entry costs
OWNX	For secondary users, sensing costs are incurred as the result of primary users' activity
MISC	Furthermore, each secondary user pays the cost of transmissions upon successful bidding for a channel
OWNX	Knowledge regarding other secondary users' activity is limited due to the distributed nature of the network
MISC	The resulting formulation is thus a dynamic game with incomplete information
OWNX	In this paper, an efficient bidding learning algorithm is proposed based on the outcome of past transactions
OWNX	As demonstrated through extensive simulations, the proposed distributed scheme outperforms a myopic one-stage algorithm, and can achieve a good balance between efficiency and fairness
MISC	Recent studies have shown that despite claims of spectral scarcity, the actual licensed spectrum remains unoccupied for long periods of time~ CITATION
MISC	Thus, cognitive radio (CR) systems have been proposed~ CITATION  in order to efficiently exploit these spectral holes
MISC	CRs or secondary users (SUs) are wireless devices that can intelligently monitor and adapt to their environment, hence, they are able to share the spectrum with the licensed primary users (PUs), operating whenever the PUs are idle
MISC	Three key design challenges are active topics of research in cognitive radio networks, namely, distributed implementation, spectral efficiency, and the tradeoff between sensing and spectrum access
MISC	Previous studies have tackled various aspects of spectrum sensing and spectrum access
MISC	In  CITATION , the performance of spectrum sensing, in terms of throughput, is investigated when the SUs share their instantaneous knowledge of the channel
MISC	The work in  CITATION  studies the performance of different detectors for spectrum sensing, while in  CITATION  spatial diversity methods are proposed for improving the probability of detecting the PU by the SUs
MISC	Other aspects of spectrum sensing are discussed in  CITATION  and  CITATION
MISC	Furthermore, spectrum access has also received increased attention, eg ,  CITATION
MISC	In  CITATION , a dynamic programming approach is proposed to allow the SUs to maximize their channel access time while taking into account a penalty factor from any collision with the PU
MISC	The work in  CITATION  (and the references therein) establish that, in practice, the sensing time of CR networks is large and affects the access performance of the SUs
MISC	In  CITATION , the authors model the spectrum access problem as a non-cooperative game, and propose learning algorithms to find the correlated equilibria of the game
MISC	Non-cooperative solutions for dynamic spectrum access are also proposed in  CITATION  while taking into account changes in the SUs' environment such as the arrival of new PUs, among others
MISC	%In  CITATION ,  When multiple SUs compete for spectral opportunities, the issues of fairness and efficiency arise
MISC	On one hand, it is desirable for an SU to access a channel with high availability
MISC	On the other hand, the effective achievable rate of an SU decreases when contending with many SUs over the most available channel
MISC	Consequently, efficiency of spectrum utilization in the system reduces
MISC	Therefore, an SU should explore transmission opportunities in other channels if available and refrain from transmission in the same channel all the time
MISC	Intuitively, diversifying spectrum access in both frequency (exploring more channels) and time (refraining from continuous transmission attempts) would be beneficial to achieving fairness among multiple SUs, in that SUs experiencing poorer channel conditions are not starved in the long run
AIMX	The objective of this paper is to design a mechanism that enables fair and efficient sharing of spectral resources among SUs
MISC	We model spectrum access in cognitive radio networks as a repeated auction game with entry and monitoring costs
MISC	Auctioning the spectral opportunities is carried out repeatedly
MISC	At the beginning of each period, each SU that wishes to participate in the spectrum access submits a bid to a coordinator based on its view of the channel and past auction history
OWNX	Knowledge regarding other secondary users' activities is limited due to the distributed nature of the network
MISC	The resulting formulation is thus a dynamic game with incomplete information
MISC	The bidder with the highest bid gains spectrum access
OWNX	Entry fees are charged for all bidders who participate in the auction irrespective of the outcome of the auction
MISC	An SU can also choose to stay out (SO) of the current round, in which case no entry fee is incurred
OWNX	At the end of each auction period, information regarding bidding and allocation are made available to all SUs, and in turn a monitoring fee is incurred
OWNX	To achieve efficient bidding, a learning algorithm is proposed based on the outcome of past transactions
MISC	Each SU decides on local actions with the objective of increasing its long-term cost effectiveness
MISC	As demonstrated through extensive simulations, the proposed distributed scheme outperforms a myopic one-stage algorithm where an SU always participates in the spectrum access game in both single channel and multi-channel networks
MISC	A comment is in order on the feasibility of such an auction-based approach to spectrum access in practice
OWNX	Due to commercial and industrial exploitation and different stake holders' interests, the functional architectures and cognitive signaling schemes are currently under discussion within standardization forums, including IEEE SCC 41 and ETSI TC RRS (Reconfigurable Radio Systems)
MISC	Cognitive pilot channel (CPC) has gained attention as a potential enabler of data-aided mitigation techniques between secondary and primary communication systems as well as a  mechanism to support optimized radio resource and data management across heterogeneous networks
MISC	In CPC, a common control channel is used to provide the information corresponding to the operators, Radio Access Technology and frequencies allocated in a given area
MISC	We can thus leverage the intelligence of the CPC coordinator and the control channel to solicit bidding and broadcast the outcome of auctions
MISC	The main contributions of this paper are:   We have formulated the spectrum access problem in cognitive radio networks as a repeated auction game
OWNX	A distributed learning algorithm is proposed for single-channel networks, and a non-regret learning algorithm is investigated for multi-channel networks
OWNX	The rest of the paper is organized as follows
OWNX	In Section~, the system model and terminology are introduced
MISC	Mechanism design of the repeated auction with learning is presented in Section~
OWNX	Simulation results are given in Section~ followed by conclusions and a discussion of future work in Section~
OWNX	%   <- trailing '%' for backward compatibility of
MISC	sty file The Sample Compression Conjecture of Littlestone \& Warmuth has remained unsolved for over two decades
MISC	While maximum classes (concept classes meeting Sauer's Lemma with equality) can be compressed, the compression of general concept classes reduces to compressing maximal classes (classes that cannot be expanded without increasing VC-dimension)
MISC	Two promising ways forward are: embedding maximal classes into maximum classes with at most a polynomial increase to VC dimension, and compression via operating on geometric representations
OWNX	This paper presents positive results on the latter approach and a first negative result on the former, through a systematic investigation of finite maximum classes
MISC	Simple arrangements of hyperplanes in Hyperbolic space are shown to represent maximum classes, generalizing the corresponding Euclidean result
MISC	We show that  sweeping a generic hyperplane across such arrangements forms an unlabeled compression scheme of size VC dimension and corresponds to a special case of peeling the one-inclusion graph, resolving a recent conjecture of Kuzmin \& Warmuth
MISC	A bijection between finite maximum classes and certain arrangements of Piecewise-Linear (PL) hyperplanes in either a ball or Euclidean space is established
MISC	Finally we show that  SYMBOL -maximum  classes corresponding to PL hyperplane arrangements in  SYMBOL  have cubical complexes homeomorphic to a  SYMBOL -ball, or equivalently complexes that are manifolds with boundary
MISC	A main result is that PL arrangements can be swept by a moving hyperplane to unlabeled  SYMBOL -compress  any  finite maximum class, forming a peeling scheme as conjectured by Kuzmin \& Warmuth
MISC	A corollary is that some  SYMBOL -maximal classes cannot be embedded into any maximum class of VC dimension  SYMBOL , for any constant  SYMBOL
OWNX	The construction of the PL sweeping involves  Pachner moves  on the one-inclusion graph, corresponding to moves of a hyperplane across the intersection of  SYMBOL  other hyperplanes
MISC	This extends the well known Pachner moves for triangulations to cubical complexes
OWNX	\term{Maximum} concept classes have the largest cardinality possible for their given VC dimension
OWNX	Such classes are of particular interest as their special recursive structure underlies all general sample compression schemes known to-date~ CITATION
OWNX	It is this structure that admits many elegant geometric and algebraic topological representations upon which this paper focuses
MISC	CITATION  introduced the study of \term{sample compression schemes}, defined as a pair of mappings for given concept class  SYMBOL : a \term{compression function} mapping a  SYMBOL -labeled  SYMBOL -sample to a subsequence of labeled examples and a \term{reconstruction} \term{function} mapping the subsequence to a concept consistent with the entire  SYMBOL -sample
MISC	A compression scheme of bounded size---the maximum cardinality of the subsequence image---was shown to imply learnability
MISC	The converse---that classes of VC dimension  SYMBOL  admit compression schemes of size  SYMBOL ---has become one of the oldest unsolved problems actively pursued within learning theory~ CITATION
MISC	Interest in the  conjecture has been motivated by its interpretation as the converse to the existence of compression bounds for PAC learnable classes~ CITATION , the basis of practical machine learning methods on compression schemes~ CITATION , and the conjecture's connection to a deeper understanding of the combinatorial properties of concept classes~ CITATION
MISC	Recently~ CITATION  achieved compression of maximum classes without the use of labels
MISC	They also conjectured that their elegant Min-Peeling Algorithm constitutes such an unlabeled  SYMBOL -compression scheme for  SYMBOL -maximum classes
MISC	As discussed in our previous work~ CITATION , maximum classes can be  fruitfully viewed as \term{cubical complexes}
MISC	These are also topological spaces, with each cube equipped with a natural topology of open sets from its standard embedding into Euclidean space
MISC	We proved that  SYMBOL -maximum classes correspond to \term{ SYMBOL -contractible complexes}---topological spaces with an identity map homotopic to a constant map---extending the result that  SYMBOL -maximum classes have trees for one-inclusion graphs
MISC	Peeling can be viewed as a special form of contractibility for maximum classes
MISC	However, there are many  non-maximum contractible cubical complexes that cannot be peeled, which demonstrates that peelability reflects more detailed structure of maximum classes than given by contractibility alone
OWNX	In this paper we approach peeling from the direction of simple hyperplane arrangement representations of maximum classes
MISC	CITATION  predicted that  SYMBOL -maximum classes corresponding to simple linear hyperplane arrangements could be unlabeled  SYMBOL -compressed by sweeping a generic hyperplane across the arrangement, and that concepts are min-peeled as their corresponding cell is swept away
OWNX	We positively resolve the first part of the conjecture and show that sweeping such arrangements corresponds to a new form of \term{corner-peeling}, which we prove is distinct from min-peeling
MISC	While \term{min-peeling} removes minimum degree concepts from a one-inclusion graph, corner-peeling peels vertices that are contained in unique cubes of maximum dimension
OWNX	We explore simple hyperplane arrangements in Hyperbolic geometry, which we show correspond to a set of maximum classes, properly containing those represented by simple linear Euclidean arrangements
OWNX	These classes can again be corner-peeled by sweeping
OWNX	Citing the proof of existence of maximum unlabeled compression schemes due to~ CITATION ,  CITATION  ask whether unlabeled compression schemes for infinite classes such as positive half spaces can be constructed explicitly
MISC	We present constructions for illustrative but simpler classes, suggesting that there are many interesting infinite maximum classes admitting explicit compression schemes, and under appropriate conditions, sweeping infinite Euclidean, Hyperbolic or PL arrangements corresponds to compression by  corner-peeling
OWNX	Next we prove that all maximum classes in  SYMBOL  are represented as simple arrangements of Piecewise-Linear (PL) hyperplanes in the  SYMBOL -ball
MISC	This extends previous work by~ CITATION  on viewing simple PL hyperplane arrangements as maximum classes
MISC	The close relationship between such arrangements and their Hyperbolic versions suggests that they could be equivalent
OWNX	Resolving the main problem left open in the preliminary version of this paper,~ CITATION , we show that sweeping of  SYMBOL -contractible PL arrangements does compress all finite  maximum classes by corner-peeling, completing~ CITATION
MISC	We show that a one-inclusion graph  SYMBOL  can be represented by a  SYMBOL -contractible PL hyperplane arrangement if and only if  SYMBOL  is a strongly contractible cubical complex
MISC	This motivates the nomenclature of  SYMBOL -contractible for the class of arrangements of PL hyperplanes
MISC	Note then that these one-inclusion graphs admit a corner-peeling scheme of the same  size  SYMBOL  as the largest dimension of a cube in  SYMBOL
MISC	Moreover if such a graph  SYMBOL  admits a corner-peeling scheme, then it is a contractible cubical complex
MISC	We give a simple example to show that there are one-inclusion graphs which admit corner-peeling schemes but are not strongly contractible and so are not represented by a  SYMBOL -contractible PL hyperplane arrangement
OWNX	Compressing \term{maximal classes}---classes which cannot be grown without an increase to their VC dimension---is sufficient for compressing all classes, as embedded classes trivially inherit compression schemes of their super-classes
MISC	This reasoning motivates the attempt to embed  SYMBOL -maximal classes into  SYMBOL -maximum classes~ CITATION
OWNX	We present non-embeddability results following from our earlier counter-examples to Kuzmin \& Warmuth's minimum  degree conjecture~ CITATION , and our new results on corner-peeling
MISC	We explore with examples, maximal classes that can be compressed but not peeled, and classes that are not strongly contractible but can be compressed
OWNX	Finally, we investigate algebraic topological properties of maximum classes
OWNX	Most notably we characterize  SYMBOL -maximum classes, corresponding to simple linear Euclidean arrangements, as cubical complexes homeomorphic to the  SYMBOL -ball
OWNX	The result that such classes' boundaries are homeomorphic to the  SYMBOL -sphere begins the study of the boundaries of maximum classes, which are closely related to peeling
OWNX	We conclude with several open problems
MISC	Comparison of elastic network model predictions with experimental data has provided important insights on the dominant role of the network of inter-residue contacts in defining the global dynamics of proteins.
MISC	Most of these studies have focused on interpreting the mean-square fluctuations of residues, or deriving the most collective, or softest, modes of motions that are known to be insensitive to structural and energetic details.
MISC	However, with increasing structural data, we are in a position to perform a more critical assessment of the structure-dynamics relations in proteins, and gain a deeper understanding of the major determinants of not only the mean-square fluctuations and lowest frequency modes, but the covariance or the cross-correlations between residue fluctuations and the shapes of higher modes.
MISC	A systematic study of a large set of NMR-determined proteins is analyzed using a novel method based on entropy maximization to demonstrate that the next level of refinement in the elastic network model description of proteins ought to take into consideration properties such as contact order and the secondary structure types of the interacting residues, whereas the types of amino acids do not play a critical role.
OWNX	Most importantly, an optimal description of observed cross-correlations requires the inclusion of destabilizing, as opposed to exclusively stabilizing, interactions, stipulating the functional significance of local frustration in imparting native-like dynamics.
OWNX	This study provides us with a deeper understanding of the structural basis of experimentally observed behavior, and opens the way to the development of more accurate models for exploring protein dynamics.
MISC	Associated with each protein fold is a set of intrinsically accessible global motions that arise solely from the 3-dimensional geometry of the fold and involve the entire architecture.
MISC	For a number of systems it has been shown that these intrinsic motions play an important role in protein function CITATION, facilitating events such as recognition and binding CITATION, CITATION, catalysis CITATION CITATION and allosteric regulation CITATION, CITATION, CITATION.
MISC	The time scales of these cooperative motions are usually beyond the reach of conventional MD simulations.
MISC	They are modeled instead with coarse-grained techniques that omit the finer details of atomic interactions.
MISC	The elastic network model is an example of a coarse-grained model that has enjoyed considerable success in predicting global dynamics of proteins and other macromolecules.
MISC	The central idea behind the ENM is that, in the vicinity of a minimum, the potential energy landscape of a biomolecular system can be approximated by the sum of pairwise harmonic potentials that stabilize the native contacts.
MISC	In the simplest ENM, the Gaussian network model CITATION, each node of the network is identified by an amino acid, and each edge is a spring that provides a linear restoring force to deviations from the minimum-energy structure.
MISC	The system's dynamics is therefore expressed in terms of the normal modes of vibration of the many-bodied system about its equilibrium state; and dynamical information about the protein, such as the expectation values of residue fluctuations or cross-correlations, is uniquely defined by the network topology.
MISC	A few prevalent methods are used for constructing ENMs, but most have at their hearts two underlying assumptions: The springs are all at their rest lengths in the equilibrium conformation, and the force constants decrease with the distance between nodes, among other variables.
MISC	In the earliest models CITATION, CITATION and the anisotropic network model CITATION CITATION, force constants were taken to be uniform for all nodes separated by a distance less than a specified cutoff distance and zero for greater distances.
MISC	In parallel, models were proposed in which the force constants decay exponentially CITATION, CITATION or as an inverse power of distance CITATION, CITATION, or where stronger interactions are assigned to sequentially adjacent residues CITATION, CITATION, CITATION.
MISC	Although such modifications can lead to modest improvements in the agreement between ENM predictions and certain experimental data, there is still no clear best method for assigning force constants in an ENM.
MISC	A common approach for assessing the performance of ENMs or estimating their force constants has been to compare the ENM-derived autocorrelations of residue motions to the corresponding X-ray crystallographic B-factors or the mean-square fluctuations in residue coordinates observed between NMR models.
MISC	Because the slow modes have the largest amplitudes, often the focus of study has been a narrow band of the slowest modes.
MISC	The ENM slow modes have indeed been shown to agree well with those predicted by detailed atomic-level force fields and with experimentally determined dynamics CITATION, CITATION.
MISC	However, the majority of the dynamical information conveyed by the ENM is contained in the residue cross-correlations, and this information has been largely overlooked during comparisons of ENM results to experimental data.
MISC	Further, the subtle and complex dynamics of the structures that lie beneath the gross global motions are ignored when only the slowest modes are considered.
MISC	Mid- and high-frequency modes are predicted with relatively lower confidence by ENMs, but these modes may be important for coordinating the finer motions of the molecule while the slower modes orchestrate its global rearrangements CITATION.
MISC	Finally, while the ENM-based studies have shown that the network topology is the dominant factor that defines the collective modes, especially those in the low frequency regime, there may be other structural properties that are not accounted for by ENMs but which may provide a more realistic description of equilibrium dynamics, if accurately modeled.
OWNX	Here we examine the ensembles of structural models determined by NMR for 68 proteins and evaluate for each ensemble the covariance in the deviations of residue-positions from their mean values.
OWNX	We present a technique for optimizing ENM force constants within a pre-defined network topology so as to provide the most accurate representation of the experimentally observed covariance data.
MISC	Our method is based on the concept of entropy maximization: Briefly, when inferring the form of an unknown probability distribution, the one that is least reliant on the form of missing data is that which maximizes the system's entropy subject to constraints imposed by the available data CITATION, CITATION.
MISC	This method has been applied to a variety of biological problems, including neural networks CITATION, gene interaction networks CITATION, and protein folding CITATION .
OWNX	The resulting auto- and cross-correlations in residue fluctuations are used to build an ENM-based model with optimal force constants.
MISC	It can be shown that when the constraints of the maximization are pair correlations, the probability distribution takes a Gaussian form.
MISC	Further, the only terms that contribute to the probability distribution are those that correspond to pairs with correlations that are explicitly considered as constraints on the entropy maximization.
MISC	In terms of the ENM, this means that for a given network topology, there exists a unique set of force constants that exactly reproduces the experimentally observed cross- correlations between all pairs of interacting residues, along with their autocorrelations .
OWNX	Notably, our technique captures the physical significance of factors such as sequence separation and spatial distance which have been empirically found to influence force constant strengths.
MISC	Sequence separation is expressed in terms of contact order, i.e., the number of residues along the sequence between two residues that are connected by a spring in the ENM.
OWNX	Further, our analysis benchmarked against a test set of 41 NMR ensembles of proteins suggests additional factors, including hydrogen bond formation and secondary structure type, which should also be incorporated in the ENMs for a more accurate description of experimental data.
MISC	It also identifies factors that are of little consequence insofar as the collective dynamics near equilibrium conditions are concerned.
MISC	Amino acid specificity turns out to be one of them; diffuse, overlapping distributions of OFCs are obtained for different types of amino acids, precluding the assignment of residue-specific OFCs.
MISC	A modified version of the GNM, mGNM, that accounts for these factors is proposed and is verified to perform better than existing models especially in reproducing cross-correlations.
OWNX	Finally, the study highlights the importance of higher modes and the role of frustration in protein dynamics, the implications of which are discussed with regard to model development and protein design.
OWNX	Detecting outliers which are grossly different from or inconsistent with the remaining dataset is a major challenge in real-world KDD applications
OWNX	Existing outlier detection methods are ineffective on scattered real-world datasets due to implicit data patterns and parameter setting issues
OWNX	We define a novel  Local Distance-based Outlier Factor  (LDOF) to measure the {outlier-ness} of objects in scattered datasets which addresses these issues
OWNX	LDOF uses the relative location of an object to its neighbours to determine the degree to which the object deviates from its neighbourhood
MISC	Properties of LDOF are theoretically analysed including LDOF's lower bound and its false-detection probability, as well as parameter settings
OWNX	In order to facilitate parameter settings in real-world applications, we employ a top- SYMBOL  technique in our outlier detection approach, where only the objects with the highest LDOF values are regarded as outliers
OWNX	Compared to conventional approaches (such as top- SYMBOL  KNN and top- SYMBOL  LOF), our method top- SYMBOL  LDOF is more effective at detecting outliers in scattered data
MISC	It is also easier to set parameters, since its performance is relatively stable over a large range of parameter values, as illustrated by experimental results on both real-world and synthetic datasets
MISC	Of all the data mining techniques that are in vogue, outlier detection comes closest to the metaphor of mining for nuggets of information in real-world data
MISC	It is concerned with discovering the exceptional behavior of certain objects~ CITATION
MISC	Outlier detection techniques have widely been applied in medicine (e g adverse reactions analysis), finance (e g financial fraud detection), security (e g counter-terrorism), information security (e g intrusions detection) and so on
MISC	In the recent decades, many outlier detection approaches have been proposed, which can be broadly classified into several categories: distribution-based~ CITATION , depth-based~ CITATION , distance-based (e g KNN)~ CITATION , cluster-based (e g DBSCAN)~ CITATION  and density-based (e g LOF)~ CITATION  methods
MISC	However, these methods are often unsuitable in real-world applications due to a number of reasons
MISC	Firstly, real-world data usually have a scattered distribution, where objects are loosely distributed in the domain feature space
MISC	That is, from a `local' point of view, these objects cannot represent explicit patterns (e g clusters) to indicate normal data `behavior'
OWNX	However, from a `global' point of view, scattered objects constitute several {mini-clusters}, which represent the pattern of a subset of objects
OWNX	Only the objects which do not belong to any other object groups are genuine outliers
MISC	Unfortunately, existing outlier definitions depend on the assumption that most objects are crowded in a few main clusters
OWNX	They are incapable of dealing with scattered datasets, because {mini-clusters} in the dataset evoke a high false-detection rate (or low precision)
OWNX	Secondly, it is difficult in current outlier detection approaches to set accurate parameters for real-world datasets
MISC	Most outlier algorithms must be tuned through {trial-and-error}~ CITATION
MISC	This is impractical, because real-world data usually do not contain labels for anomalous objects
MISC	In addition, it is hard to evaluate detection performance without the confirmation of domain experts
OWNX	Therefore, the detection result will be uncontrollable if parameters are not properly chosen
MISC	To alleviate the parameter setting problem, researchers proposed top- SYMBOL  style outlier detection methods
OWNX	Instead of a binary outlier indicator, top- SYMBOL  outlier methods provide a ranked list of objects to represent the degree of {`outlier-ness'} for each object
MISC	The users (domain experts) can {re-examine} the selected top- SYMBOL  (where  SYMBOL  is typically far smaller than the cardinality of dataset) anomalous objects to locate real outliers
MISC	Since this detection procedure can provide a good interaction between data mining experts and users, top- SYMBOL  outlier detection methods become popular in real-world applications
OWNX	Distance-based, top- SYMBOL  { SYMBOL -Nearest} Neighbour distance~ CITATION  is a typical top- SYMBOL  style outlier detection approach
OWNX	In order to distinguish from the original {distance-based} outlier detection method in~ CITATION , we denote { SYMBOL -Nearest} Neighbour distance outlier as {top- SYMBOL  KNN} in this paper
MISC	In {top- SYMBOL  KNN} outlier, the distance from an object to its  SYMBOL  nearest neighbour (denoted as { SYMBOL -distance} for short) indicates {outlier-ness} of the object
MISC	Intuitively, the larger the { SYMBOL -distance} is, the higher {outlier-ness} the object has {Top- SYMBOL  KNN} outlier regards the  SYMBOL  objects with the highest values of { SYMBOL -distance} as outliers~ CITATION
OWNX	A {density-based} outlier, Local Outlier Factor (LOF)~ CITATION , was proposed in the same year as top- SYMBOL  KNN
MISC	In LOF, an outlier factor is assigned for each object w r t its surrounding neighbourhood
OWNX	The outlier factor depends on how the data object is closely packed in its locally reachable neighbourhood~ CITATION
OWNX	Since LOF uses a threshold to differentiate outliers from normal objects~ CITATION , the same problem of parameter setting arises
OWNX	A lower {outlier-ness} threshold will produce high false-detection rate, while a high threshold value will result in missing genuine outliers
MISC	In recent real-world applications, researchers have found it more reliable to use LOF in a top- SYMBOL  manner~ CITATION , i e \ only objects with the highest LOF values will be considered outliers
OWNX	Hereafter, we call it top- SYMBOL  LOF
MISC	Besides top- SYMBOL  KNN and top- SYMBOL  LOF, researchers have proposed other methods to deal with real-world data, such as the {connectivity-based} (COF)~ CITATION , and Resolution {cluster-based} ({RB-outlier})~ CITATION
OWNX	Although the existing top- SYMBOL  style outlier detection techniques alleviate the difficulty of parameter setting, the detection precision of these methods (in this paper, we take {top- SYMBOL  KNN} and top- SYMBOL  LOF as typical examples) is low on scattered data
OWNX	In Section~, we will discuss further problems of top- SYMBOL  KNN and top- SYMBOL  LOF
OWNX	In this paper we propose a new outlier detection definition, named Local Distance-based Outlier Factor (LDOF), which is sensitive to outliers in scattered datasets
OWNX	LDOF uses the relative distance from an object to its neighbours to measure how much objects deviate from their scattered neighbourhood
MISC	The higher the violation degree an object has, the more likely the object is an outlier
OWNX	In addition, we theoretically analyse the properties of LDOF, including its lower bound and false-detection probability, and provide guidelines for choosing a suitable neighbourhood size
OWNX	In order to simplify parameter setting in real-world applications, the top- SYMBOL  technique is employed in our approach
OWNX	To validate LDOF, we perform various experiments on both synthetic and real-world datasets, and compare our outlier detection performance with top- SYMBOL  KNN and top- SYMBOL  LOF
OWNX	The experimental results illustrate that our proposed top- SYMBOL  LDOF represents a significant improvement on outlier detection capability for scattered datasets
OWNX	The paper is organised as follows: In Section~, we illustrate and discuss the problems of top- SYMBOL  KNN and top- SYMBOL  LOF on a real-world data
OWNX	In Section~, we formally introduce the outlier definition of our approach, and mathematically analyse properties of our {outlier-ness} factor in Section~
OWNX	In Section~, the top- SYMBOL  LDOF outlier detection algorithm is described, together with an analysis of its complexity
OWNX	Experiments are reported in Section~, which show the superiority of our method to previous approaches, at least on the considered datasets
OWNX	Finally, conclusions are presented in Section~
OWNX	% %AG_18/04/08 Update to abstract We propose a framework for analyzing and comparing distributions, allowing us to design statistical tests to determine if two samples are drawn from different distributions
OWNX	Our test statistic is the largest difference in expectations over functions in the unit ball of a reproducing kernel Hilbert space (RKHS)
MISC	We present two tests based on large deviation bounds for the test statistic, while a third is based on the asymptotic distribution of this statistic
OWNX	The test statistic can be computed in quadratic time, although efficient linear time approximations are available
MISC	Several classical metrics on distributions are recovered when the function space used to compute the difference in expectations is allowed to be more general (eg ~a Banach space)
MISC	We apply our two-sample tests  to a variety of problems, including attribute matching for databases using the Hungarian marriage method, where they perform strongly
OWNX	Excellent performance is also obtained when comparing distributions over graphs, for which these are the first such tests
MISC	We address the problem of comparing samples from two probability distributions, by proposing  statistical tests of the hypothesis that these distributions are different (this is  called  the two-sample or homogeneity problem)
MISC	Such tests have application in a variety of areas
OWNX	In bioinformatics, it is of interest to compare microarray data from identical tissue types as measured by different laboratories, to detect whether the data may be analysed jointly, or whether differences in experimental procedure have caused systematic differences in the data distributions
OWNX	Equally of interest are comparisons between microarray data from different tissue types, either to determine whether two subtypes of cancer may be treated as statistically indistinguishable from a diagnosis perspective, or to detect differences in healthy and cancerous tissue
MISC	In database attribute matching, it is desirable to merge databases containing multiple fields, where it is not known in advance which fields correspond: the fields are matched by maximising the similarity in the distributions of their entries
MISC	We test whether distributions  SYMBOL  and  SYMBOL  are different on the basis of samples drawn from each of them, by finding a well behaved (e g \ smooth) function which is large on the points drawn from  SYMBOL , and small (as negative as possible) on the points from  SYMBOL
OWNX	We use as our test statistic the difference between the mean function values on the two samples; when this is large, the samples are likely from different distributions
OWNX	We call this statistic the Maximum Mean Discrepancy (MMD)
OWNX	Clearly the quality of the MMD as a statistic  depends on the class  SYMBOL  of smooth functions that define it
MISC	On one hand,  SYMBOL  must be ``rich enough'' so that the population MMD vanishes if and only if  SYMBOL
MISC	On the other hand, for the test to be consistent,  SYMBOL  needs to be ``restrictive'' enough for the empirical estimate of MMD to converge quickly to its expectation as the sample size increases
OWNX	We shall use the unit balls in universal reproducing kernel Hilbert spaces  CITATION  as our function classes, since these will be shown to satisfy both of the foregoing properties (we also review classical metrics on distributions, namely the Kolmogorov-Smirnov and Earth-Mover's distances, which are based on different function classes)
MISC	On a more practical note, the MMD has a reasonable computational cost, when compared with other two-sample tests: given  SYMBOL  points sampled from  SYMBOL  and  SYMBOL  from  SYMBOL , the cost is  SYMBOL  time
MISC	We also propose a less statistically efficient algorithm  with a computational cost of  SYMBOL , which can yield superior performance at a given computational cost by looking at a larger volume of data
OWNX	We define three non-parametric statistical tests based on the MMD
OWNX	The first two, which use distribution-independent uniform convergence bounds, provide finite sample guarantees of test performance, at the expense of being conservative in detecting differences between  SYMBOL  and  SYMBOL
MISC	The third test is based on the asymptotic distribution of the MMD, and is in practice more sensitive to differences in distribution at small sample sizes
OWNX	The present work synthesizes and expands on  results of  CITATION ,  CITATION , and  CITATION  who in turn build on the earlier work of  CITATION
MISC	Note that the latter addresses only the third kind of test, and that the  approach of  CITATION  employs a more accurate approximation to the asymptotic distribution of the test statistic
OWNX	We begin our presentation in Section  with a formal definition of the MMD, and a  proof that the population MMD is zero if and only if  SYMBOL  when  SYMBOL  is the unit ball of a universal RKHS
OWNX	We also review alternative function classes for which the MMD defines a metric on probability distributions
OWNX	In Section , we give an overview of hypothesis testing as it applies to the two-sample problem, and review other approaches to this problem
OWNX	We present our first two hypothesis tests in Section ,  based on two different bounds on the deviation between the population and empirical  SYMBOL
OWNX	We take a different approach in Section , where we use the asymptotic distribution of the empirical  SYMBOL  estimate as the basis for a third test
OWNX	When large volumes of data are available, the cost of computing the MMD (quadratic in the sample size) may  be excessive: we therefore propose in Section  a modified version of the MMD statistic that has a linear cost in the number of samples, and an associated asymptotic test
OWNX	In Section , we provide an overview of methods related to the MMD in the statistics and machine learning literature
OWNX	Finally, in Section , we demonstrate the performance of MMD-based two-sample tests on problems from neuroscience, bioinformatics, and attribute matching using the Hungarian marriage method
OWNX	Our approach performs well on high dimensional data with low sample size; in addition, we are able to successfully distinguish distributions on graph data,  for which ours is the first proposed test
MISC	For a variety of regularized optimization problems in machine learning,  algorithms computing the entire solution path have been developed recently
MISC	Most of these methods are quadratic programs that are parameterized by a single parameter, as for example the Support Vector Machine (SVM)
MISC	Solution path algorithms do not only compute the solution for one particular value of the regularization parameter but the entire path of solutions, making the selection of an optimal parameter much easier
MISC	It has been assumed that these piecewise linear solution paths have only linear complexity, ie \ linearly many bends
OWNX	We prove that for the support vector machine this complexity can be exponential in the number of training points in the worst case
OWNX	More strongly, we construct  a single instance of  SYMBOL  input points in  SYMBOL  dimensions for an SVM such that at least  SYMBOL  many distinct subsets of  support vectors % occur as the regularization parameter changes
OWNX	Regularization methods such as support vector machines (SVM) and  related kernel methods % have become very successful standard tools in many optimization, classification and regression tasks in a variety of areas, for example signal processing, statistics, biology, computer vision and computer graphics as well as data mining
MISC	These regularization methods have in common that they are convex, usually quadratic, optimization problems containing a special parameter in their objective function, called the regularization parameter, representing the tradeoff between two optimization objectives
MISC	In machine learning the two terms are usually the model complexity (regularization term) and the accuracy on the training data (loss term), or in other words the tradeoff between a good generalization performance and over-fitting
MISC	Such parameterized quadratic programming problems have been studied extensively in both optimization and machine learning, resulting in many algorithms that are able to not only compute solutions at a single value of  the parameter, but along the whole solution path as the parameter varies
MISC	For many variants, it is known that the solution paths are piecewise linear functions in the parameter, however, the complexity of these paths remained unknown
OWNX	Here we prove that the complexity of the solution path for SVMs, which  are simple instances of parameterized quadratic programs, is indeed  exponential in the worst case
OWNX	Furthermore, our example shows that  exponentially many distinct subsets of support vectors of the optimal  solution occur as the regularization parameter changes
MISC	Here  the ``exponentially many'' is valid both in terms of the number of input  points and also in the dimension of the space containing the points
MISC	We uncovered the underlying energy landscape for a cellular network.
MISC	We discovered that the energy landscape of the yeast cell-cycle network is funneled towards the global minimum from the experimentally measured or inferred inherent chemical reaction rates.
MISC	The funneled landscape is quite robust against random perturbations.
OWNX	This naturally explains robustness from a physical point of view.
OWNX	The ratio of slope versus roughness of the landscape becomes a quantitative measure of robustness of the network.
MISC	The funneled landscape can be seen as a possible realization of the Darwinian principle of natural selection at the cellular network level.
OWNX	It provides an optimal criterion for network connections and design.
MISC	Our approach is general and can be applied to other cellular networks.
MISC	In the post-genome era, it is crucial to uncover the underlying mechanism of cellular networks to understand their biological function CITATION CITATION.
MISC	The underlying nature of cellular networks has been explored by genetic techniques CITATION.
MISC	Cellular networks have been found to be generally quite robust and to perform their biological functions against environmental perturbations.
MISC	There are increasing numbers of studies on the global topological structures of networks recently CITATION in which the scale-free properties and hierarchical architectures for networks have been found CITATION CITATION.
MISC	The hubs, highly connected nodes in the network essential for keeping the network together, might play an important role for the robustness of the network.
MISC	However, there are so far very few studies of why the network should be robust and perform the biological function from the physical point of view CITATION CITATION .
MISC	Theoretical models of cellular networks have often been formulated with a set of chemical rate equations.
OWNX	These dynamical descriptions are inherently local.
MISC	To probe the global properties, one often has to change the parameters.
MISC	The parameter space is huge.
MISC	The global robustness therefore is hard to see from this approach.
OWNX	Here we will explore the nature of networks from another angle and formulate the problem in terms of a potential function or potential energy landscape.
MISC	If the potential energy landscape of the cellular network is known, the global properties can be explored CITATION, CITATION.
MISC	This is in analogy with the fact that the global thermodynamic properties can be explored when knowing the inherent interaction potentials in the system.
MISC	For the set of the normal chemical rate equations describing the cellular networks, F with x being the concentrations of proteins and F being the chemical reaction rate flux, one cannot in general write the right-hand side of these equations as the gradient of a potential energy function.
OWNX	However, typical chemical reaction network equations are only approximations on the average concentration level.
OWNX	In the cell, statistical fluctuations coming from the finite number of molecules provide the source of intrinsic internal noise, and the fluctuations from highly dynamical and inhomogeneous environments of the interior of the cell provide the source of the external noise for the networks CITATION CITATION.
MISC	Both the internal and external noise play important roles in determining the properties of the network.
MISC	In general, one should study the chemical reaction network equations in noisy conditions to model cellular environments more realistically.
MISC	One can also study steady-state properties of these chemical reaction equation networks under noisy environments.
MISC	The generalized potential for the steady state of the network exists in general CITATION, CITATION CITATION, CITATION.
MISC	Once the network problem is formulated in terms of the generalized potential energy function or potential energy landscape, the issue of the global stability or robustness is much easier to address.
OWNX	In fact, it is the purpose of this paper to study the global robustness problem directly from the properties of the potential landscape of the network.
OWNX	To explore the nature of the underlying potential landscape of the cellular networks, we will study the yeast cell-cycle network.
MISC	One of the most important functions of the cell is the reproduction and growth.
MISC	It is therefore crucial to understand the cell cycle and its underlying process.
MISC	The cell cycles during development are usually divided into several phases: the G0/G1, S, G2, and M phases.
MISC	In most eukaryotic cells, the elaborate control mechanisms over DNA synthesis and mitosis make sure that the crucial events in the cell cycle are carried out properly and precisely.
MISC	Physiologically, there are usually three checkpoints for controlling and coordination: G0/G1 before the new round of division, G2 before the mitotic process begins, and M before segregation.
MISC	Recently, many of the underlying controlling mechanisms are revealed by genetic techniques such as mutations and gene knockouts.
MISC	It has been found that control has been centered around cyclin-dependent protein kinases, which trigger the major events of the eukaryotic cell cycle.
MISC	For example, the activation of the cyclin/CDK dimer drives the cells at both the G1 and G2 checkpoints for further progress.
MISC	During other phases and checkpoints CDK/cyclin are activated.
OWNX	Although molecular interactions regulating the CDK activities are known, the mechanisms of the checkpoint controls are still uncertain CITATION CITATION .
OWNX	In Figure 1, a coarse-grained relationship between cyclin and cdc2 in the cell cycle is illustrated.
MISC	In step 1, cyclin is synthesized de novo.
MISC	Newly synthesized cyclin may be unstable.
OWNX	Cyclin combines with cdc2-P to form pre-MPF.
OWNX	At some point after heterodimer formation, the cyclin subunit is phosphorylated.
MISC	The cdc2 subunit is then dephosphorylated to form active MPF.
MISC	In principle, the activation of MPF may be opposed by a protein kinase.
MISC	Nuclear division is triggered when a sufficient quantity of MPF has been activated, but concurrently active MPF is destroyed in step 6.
MISC	Breakdown of the MPF complex releases phosphorylated cyclin, which is subject to rapid proteolysis.
MISC	Finally, the cdc2 subunit is phosphorylated, and the cycle repeats itself.
MISC	Mathematical models of the cell cycle controls have been formulated with a set of ordinary first-order differential equations mimicking the underlying biochemical processes CITATION CITATION, CITATION.
MISC	The models have been applied to the budding yeast cycle and have explained many qualitative physiological behaviors.
MISC	The checkpoints can be viewed as fixed points.
MISC	Since the intracellular and intercellular signal transduction induces the changes in the regulatory networks, the cell cycle can be described by or mimicked by the dynamics in and out of the fixed points.
MISC	Although detailed simulations give some insights towards the issues, due to the limitation of the parameter space search it is difficult to perceive the global or universal properties of the cycle networks.
MISC	It is the purpose of the current study to address this issue.
MISC	We will develop a global energy landscape theory for the cell cycle network.
MISC	This statistical-based approach is good for two reasons.
MISC	It is a coarse-grained approach that captures only the most important factors, so that the analysis can be carried out relatively easily, revealing some global properties.
MISC	On the other hand, the statistical approach can be very useful and informative when the data are rapidly accumulating.
MISC	In this picture, there are many possible states of the network corresponding to different patterns of activation and inhibition of the protein states.
OWNX	Each checkpoint can be viewed as a basin of attractions of globally low energy states.
OWNX	The G0/G1 phase states should have the lowest global energy since it is the end of the cycle.
MISC	To initiate the new cycle, the network has to receive the signal to activate or pump to the next phase to proceed.
MISC	The dynamics of the cell cycle are described as the dynamical motions on the landscape state space from one basin to another.
MISC	This kinetic search is not entirely random but directed, since the random search takes cosmological time.
OWNX	The direction or gradient of the landscape is provided from the tilting towards the G0/G1 phase.
OWNX	The landscape therefore becomes funneled towards the G0/G1 state, with the bottom of the funnel what we call the native state.
OWNX	At the end of G0/G1 phase, the network is pumped to high energy excited states at the top of the funnel.
OWNX	The cell cycle then follows as it cascades through the configurational state space in a directed way, passing several checkpoints, and finally reaching the bottom of the funnel G0/G1 phase again before being pumped again for another cycle.
OWNX	We will study the global stability by exploring the underlying potential landscape for the yeast cell-cycle network.
OWNX	The aim of this paper is to provide a framework and a tool to study at the cell network globally.
OWNX	At the conclusion of this paper we show that the potential landscape of the budding yeast cell cycle is funneled and robust against the perturbation from the kinetic rates and the environmental disturbances through noise.
MISC	Building rules on top of ontologies is the ultimate goal of the logical layer of the Semantic Web
OWNX	To this aim an ad-hoc mark-up language for this layer is currently under discussion
MISC	It is intended to follow the tradition of hybrid knowledge representation and reasoning systems such as  SYMBOL -log that integrates the description logic  SYMBOL  and the function-free Horn clausal language \textsc{Datalog}
OWNX	In this paper we consider the problem of automating the acquisition of these rules for the Semantic Web
OWNX	We propose a general framework for rule induction that adopts the methodological apparatus of Inductive Logic Programming and relies on the expressive and deductive power of  SYMBOL -log
OWNX	The framework is valid whatever the scope of induction (description vs prediction) is
OWNX	Yet, for illustrative purposes, we also discuss an instantiation of the framework which aims at description and turns out to be useful in Ontology Refinement
MISC	During the last decade increasing attention has been paid on  ontologies  and their role in Knowledge Engineering  CITATION
MISC	In the philosophical sense, we may refer to an ontology as a particular system of categories accounting for a certain vision of the world
MISC	As such, this system does not depend on a particular language: Aristotle's ontology is always the same, independently of the language used to describe it
MISC	On the other hand, in its most prevalent use in Artificial Intelligence, an ontology refers to an engineering artifact (more precisely, produced according to the principles of  Ontological Engineering   CITATION ), constituted by a specific vocabulary used to describe a certain reality, plus a set of explicit assumptions regarding the intended meaning of the vocabulary words
MISC	This set of assumptions has usually the form of a first-order logical theory, where vocabulary words appear as unary or binary predicate names, respectively called concepts and relations
MISC	In the simplest case, an ontology describes a hierarchy of concepts related by subsumption relationships; in more sophisticated cases, suitable axioms are added in order to express other relationships between concepts and to constrain their intended interpretation
MISC	The two readings of ontology described above are indeed related each other, but in order to solve the terminological impasse the word conceptualization is used to refer to the philosophical reading as appear in the following definition, based on  CITATION :  An ontology is a formal explicit specification of a shared conceptualization for a domain of interest
MISC	Among the other things, this definition emphasizes the fact that an ontology has to be specified in a language that comes with a formal semantics
MISC	Only by using such a formal approach ontologies provide the machine interpretable meaning of concepts and relations that is expected when using an ontology-based approach
OWNX	Among the formalisms proposed by Ontological Engineering, the most currently used are  Description Logics  (DLs)  CITATION
MISC	Note that DLs are decidable fragments of First Order Logic (FOL) that are incomparable with Horn Clausal Logic (HCL) as regards the expressive power  CITATION  and the semantics  CITATION  } Ontology Engineering, notably its DL-based approach, is playing a relevant role in the definition of the  Semantic Web
MISC	The Semantic Web is the vision of the World Wide Web enriched by machine-processable information which supports the user in his tasks  CITATION
MISC	The architecture of the Semantic Web is shown in Figure
MISC	It consists of several layers, each of which is equipped with an ad-hoc mark-up language
MISC	In particular, the design of the mark-up language for the  ontological layer , OWL}, has been based on the very expressive DL  SYMBOL   CITATION
MISC	Whereas OWL is already undergoing the standardization process at W3C, the debate around a unified language for  rules  is still ongoing
MISC	Proposals like SWRL} extend OWL with constructs inspired to Horn clauses in order to meet the primary requirement of the  logical layer : 'to build rules on top of ontologies'
MISC	SWRL is intended to bridge the notorious gaps between DLs and HCL in a way that is similar in the spirit to hybridization in Knowledge Representation and Reasoning (KR\&R) systems such as  SYMBOL -log  CITATION
OWNX	Generally speaking,  hybrid systems  are KR\&R systems which are constituted by two or more subsystems dealing with distinct portions of a single knowledge base by performing specific reasoning procedures  CITATION
MISC	The motivation for investigating and developing such systems is to improve on two basic features of KR\&R formalisms, namely  representational adequacy  and  deductive power , by preserving the other crucial feature, i e decidability
MISC	In particular, combining DLs with HCL can easily yield to undecidability if the interface between them is not reduced  CITATION
MISC	The hybrid system  SYMBOL -log integrates  SYMBOL   CITATION  and \textsc{Datalog}  CITATION  by using  SYMBOL  concept assertions essentially as type constraints on variables
MISC	It has been very recently mentioned as the blueprint for  well-founded  Semantic Web rule mark-up languages because its underlying form of integration (called  safe ) assures semantic and computational advantages that SWRL - though more expressive than  SYMBOL -log - currently can not assure  CITATION
MISC	Defining rules (including the ones for the Semantic Web) has been usually considered as a demanding task from the viewpoint of Knowledge Engineering
MISC	It is often supported by Machine Learning algorithms that can vary in the approaches
MISC	The approach known under the name of Inductive Logic Programming (ILP) seems to be promising for the case at hand due to the common roots with Logic Programming  CITATION
MISC	ILP has been historically concerned with rule induction from examples and background knowledge within the representation framework of HCL and with the aim of prediction  CITATION
MISC	More recently ILP has moved towards either different FOL fragments (e g , DLs) or new learning goals (e g , description)
OWNX	In this paper we resort to the methodological apparatus of ILP to define a  general  framework for learning rules on top of ontologies for the Semantic Web within the KR\&R framework of  SYMBOL -log
OWNX	The framework proposed is general in the sense that it is valid whatever the scope of induction (description vs prediction) is
OWNX	For the sake of illustration we concentrate on an instantiation of the framework for the case of description
OWNX	The paper is organized as follows
OWNX	Section  introduces the basic notions of  SYMBOL -log
OWNX	Section  defines the framework for learning rules in  SYMBOL -log
OWNX	Section  illustrates an instantiation of the framework
OWNX	Section  concludes the paper with final remarks
OWNX	clarifies the links between OWL and DLs
OWNX	We present molecular dynamics simulations of unliganded human hemoglobin A under physiological conditions, starting from the R, R2, and T state.
MISC	The simulations were carried out with protonated and deprotonated HC3 histidines His146, and they sum up to a total length of 5.6 s. We observe spontaneous and reproducible T R quaternary transitions of the Hb tetramer and tertiary transitions of the and subunits, as detected from principal component projections, from an RMSD measure, and from rigid body rotation analysis.
MISC	The simulations reveal a marked asymmetry between the and subunits.
OWNX	Using the mutual information as correlation measure, we find that the subunits are substantially more strongly linked to the quaternary transition than the subunits.
OWNX	In addition, the tertiary populations of the and subunits differ substantially, with the subunits showing a tendency towards R, and the subunits showing a tendency towards T. Based on the simulation results, we present a transition pathway for coupled quaternary and tertiary transitions between the R and T conformations of Hb.
MISC	Conformational transitions of allosteric proteins are fundamental to a variety of biological functions.
MISC	For instance, quaternary transitions in hemoglobin give rise to the cooperativity of ligand binding and have therefore drawn extensive and ongoing scientific interest over many decades CITATION, CITATION.
OWNX	The end points of the quaternary transition of Hb are referred to as deoxy T state and oxy R state of Hb, which are characterized by low and high oxygen affinity, respectively CITATION, and the cooperativity of ligand binding originates from the dependence of quaternary population on the number of liganded subunits CITATION.
MISC	The oxygen affinity of Hb decreases with lower pH, a phenomenon that is referred to as alkaline Bohr effect.
MISC	Approximately 40 percent of the Bohr effect has been attributed to the protonation of the terminal His146 residues of the subunits, which are also denoted as HC3 histidines CITATION .
OWNX	The stereochemical explanation of Hb cooperativity and the characterization of the transition pathway were originally based on the HbCO and deoxyHb crystal structures, corresponding to the R and T state, respectively.
MISC	According to these structures, the transition can mainly be described by a 12 15 rotation of the 1 1 dimer with respect to the 1 2 dimer CITATION, CITATION.
MISC	Later, a second quaternary structure of liganded Hb, termed R2, was found CITATION, with a 1.1 larger distance between the centers of mass of two subunits as compared to the R structure.
OWNX	Differences between R and R2 at the 1 2 interface triggered a still unresolved discussion whether R2 is a stable intermediate on a R-R2-T pathway CITATION CITATION.
OWNX	NMR experiments indicate that liganded Hb in solution is in equilibrium between the R and R2 structures CITATION.
MISC	More recently, two additional liganded Hb structures RR2 and R3 were found using the high-salt crystallization conditions of Perutz CITATION, emphasizing that a consensus view on the liganded Hb state in solution is far from being reached.
OWNX	RR2 represents an intermediate structure between R and R2, whereas the distance between the COMs of the two subunits is reduced by 3.1 in R3 as compared to the R structure.
OWNX	Extensive efforts aimed to identify the transition pathway of Hb in response to ligand dissociation CITATION.
OWNX	The kinetics of the R T transition after photodissociation of the CO adduct, HbCO, have been studied using time-resolved spectroscopic techniques including absorption CITATION, Raman CITATION, CITATION, and circular dichroism spectroscopy CITATION, CITATION.
MISC	The picture derived from these experiments suggests a multistep R T pathway via several metastable intermediates, with relaxation rates ranging from tens of nanoseconds to tens of microseconds, and with a time constant of 21 s for the overall R T quaternary transition CITATION.
OWNX	The experiments provide extremely valuable insights into the kinetics of Hb, but they also bear limitations.
MISC	They do not directly detect the global quaternary transitions, but mainly measure the formation of hydrogen bonds of aromatic residues, such as the Trp37-Asp94 and the Tyr42-Asp99 H-bonds, which must be interpreted in terms of conformational transitions.
OWNX	A full-atomistic picture of the R T transition could so far exclusively be derived for a mollusk dimeric hemoglobin using time-resolved X-ray crystallography CITATION.
OWNX	Such experiments provide an ensemble-averaged picture, whereas Hb may follow heterogeneous transition pathways that may not be fully reflected by the spectra.
MISC	Furthermore, in contrast to the well-studied R T transition, little is known about the kinetics of the T R transition because that transition cannot be triggered by photolysis.
MISC	Molecular dynamics simulations can provide a full-atomistic picture of Hb and are therefore well suited to complement experimental efforts.
MISC	Early MD efforts focused on the photodissociation of CO CITATION, or were restricted to the dynamic treatment of a subset of Hb residues CITATION.
MISC	Ramadas and Rifkind considered the response of Hb to the perturbation of the heme on a several 100ps time scale CITATION, and Mouawad and coworkers enforced quaternary transitions within 200ps using a technique called path exploration method CITATION.
MISC	In addition, a set of MD simulation of up to 6ns were carried out with a focus on the mechanism of effectors CITATION.
MISC	Recently, a single 45-ns simulation of Hb was published without observing any conformational transitions CITATION.
OWNX	Complementary to the MD studies, a normal mode analysis considered the collective motions intrinsic to the Hb tetramer CITATION, and an elastic network study suggested a T-R2 transition as the preferential quaternary transition pathway CITATION .
MISC	So far, no spontaneous quaternary or tertiary transitions of Hb were observed during MD simulations, presumably since previous simulations were restricted to too short time scales.
OWNX	Here, we apply extensive MD simulations to investigate the deoxy R, R2, and T state of human.
MISC	We observe for the first time spontaneous and reproducible quaternary transitions of Hb, as well as tertiary transitions of the and subunits.
OWNX	Hence, these simulations allow one to study the transition mechanism in atomistic detail.
OWNX	We find the T-R pathway as the primary quaternary transition pathway.
MISC	By analyzing repeated T-R transitions, we find a marked asymmetry between the and subunits.
OWNX	Based on the simulation results, we present a schematic mechanism underlying the preferential transition pathway between the R and T states of hemoglobin.
OWNX	Ensemble methods, such as stacking, are designed to boost predictive accuracy by blending the predictions of multiple machine learning models
MISC	Recent work has shown that the use of meta-features, additional inputs describing each example in a dataset, can boost the performance of ensemble methods, but the greatest reported gains have come from nonlinear procedures requiring significant tuning and training time
OWNX	Here, we present a linear technique, Feature-Weighted Linear Stacking (FWLS), that incorporates meta-features for improved accuracy while retaining the well-known virtues of linear regression regarding speed, stability, and interpretability
OWNX	FWLS combines model predictions linearly using coefficients that are themselves linear functions of meta-features
OWNX	This technique was a key facet of the solution of the second place team in the recently concluded Netflix Prize competition
OWNX	Significant increases in accuracy over standard linear stacking are demonstrated on the Netflix Prize collaborative filtering dataset
OWNX	``Stacking'' is a technique in which the predictions of a collection of models are given as inputs to a second-level learning algorithm
OWNX	This second-level algorithm is trained to combine the model predictions optimally to form a final set of predictions
OWNX	Many machine learning practitioners have had success using stacking and related techniques to boost prediction accuracy beyond the level obtained by any of the individual models
MISC	In some contexts, stacking is also referred to as blending, and we will use the terms interchangeably here
OWNX	Since its introduction  CITATION , modellers have employed stacking successfuly on a wide variety of problems, including chemometrics  CITATION , spam filtering  CITATION , and large collections of datasets drawn from the UCI Machine learning repository  CITATION
OWNX	One prominent recent example of the power of model blending was the Netflix Prize collaborative filtering competition
MISC	The team  BellKor's Pragmatic Chaos  won the \$1 million prize using a blend of hundreds of different models  CITATION
OWNX	Indeed, the winning solution was a blend at multiple levels, i e , a blend of blends
MISC	Intuition suggests that the reliability of a model may vary as a function of the conditions in which it is used
OWNX	For instance, in a collaborative filtering context where we wish to predict the preferences of customers for various products, the amount of data collected may vary significantly depending on which customer or which product is under consideration
MISC	Model A may be more reliable than model B for users who have rated many products, but model B may outperform model A for users who have only rated a few products
OWNX	In an attempt to capitalize on this intuition, many researchers have developed approaches that attempt to improve the accuracy of stacked regression by adapting the blending on the basis of side information
OWNX	Such an additional source of information, like the number of products rated by a user or the number of days since a product was released, is often referred to as a ``meta-feature,'' and we will use that terminology here
OWNX	Unsurprisingly, linear regression is the most common learning algorithm used in stacked regression
MISC	The many virtues of linear models are well known to modellers
MISC	The computational cost involved in fitting such models (via the solution of a linear system) is usually modest and always predictable
MISC	They typically require a minimum of tuning
MISC	The transparency of the functional form lends itself naturally to interpretation
MISC	At a minimum, linear models are often an obvious initial attempt against which the performance of more complex models is benchmarked
MISC	Unfortunately, linear models do not (at first glance) appear to be well suited to capitalize on meta-features
MISC	If we simply merge a list of meta-features with a list of models to form one overall list of independent variables to be linearly combined by a blending algorithm, then the resulting functional form does not appear to capture the intuition that the relative emphasis given the predictions of various models should depend on the meta-features, since the coefficient associated with each model is constant and unaffected by the values of the meta-features
MISC	Previous work has indeed suggested that nonlinear, iteratively trained models are needed to make good use of meta-features for blending
MISC	The winning Netflix Prize submission of  BellKor's Pragmatic Chaos  is a complex blend of many sub-blends, and many of the sub-blends use blending techniques which incorporate meta-features
MISC	The number of user and movie ratings, the number of items the user rated on a particular day, the date to be predicted, and various internal parameters extracted from some of the recommendation models were all used within the overall blend
OWNX	In almost all cases, the algorithms used for the sub-blends incorporating meta-features were nonlinear and iterative, i e , either a neural network or a gradient-boosted decision tree
MISC	In  CITATION , a system called STREAM (Stacking Recommendation Engines with Additional Meta-Features) which blends recommendation models is presented
MISC	Eight meta-features are tested, but the results showed that most of the benefit came from using the number of user ratings and the number of item ratings, which were also two of the most commonly used meta-features by  BellKor's Pragmatic Chaos
OWNX	Linear regression, model trees, and bagged model trees are used as blending algorithms with bagged model trees yielding the best results
OWNX	Linear regression was the least successful of the approaches
MISC	Collaborative filtering is not the only application area where the use of meta-features or other dynamic approaches to model blending has been attempted
OWNX	In a classification problem context  CITATION , Dzeroski and Zenko attempt to augment a linear regression stacking algorithm by meta-features such as the entropy of the predicted class probabilities, although they found that it yielded limited benefit on a suite of tasks from the UC Irvine machine learning repository
OWNX	An approach which does not use meta-features per se but which does employ an adaptive approach to blending is described by Puuronen, Terziyan, and Tsymbal  CITATION
MISC	They present a blending algorithm based on weighted nearest neighbors which changes the weightings assigned to the models depending on estimates of the accuracies of the models within particular subareas of the input space
MISC	Thus, a survey of the pre-existing literature suggests that nonparametric or iterative nonlinear approaches are usually required in order to make good use of meta-features when blending
OWNX	The method presented in this paper, however, can capitalize on meta-features while being fit via linear regression techniques
MISC	The method does not simply add meta-features as additional inputs to be regressed against
OWNX	It parametrizes the coefficients associated with the models as linear functions of the meta-features
OWNX	Thus, the technique has all the familiar speed, stability, and interpretability advantages associated with linear regression while still yielding a significant accuracy boost
MISC	The blending approach was an important part of the solution submitted by  The Ensemble , the team which finished in second place in the Netflix Prize competition
OWNX	We present a streaming model for large-scale classification (in the context of  SYMBOL -SVM)  by leveraging connections between learning and computational geometry
MISC	The streaming model imposes the constraint that only a single pass over the data is allowed
MISC	The  SYMBOL -SVM is known to have an equivalent formulation in terms of the minimum enclosing ball (MEB) problem, and an efficient algorithm based on the idea of  core sets  exists (CVM)  CITATION
OWNX	CVM learns a  SYMBOL -approximate MEB for a set of points and yields an approximate solution to corresponding SVM instance
MISC	However CVM works in batch mode requiring multiple passes over the data
OWNX	This paper presents a single-pass SVM which is based on the minimum enclosing ball of streaming data
MISC	We show that the MEB updates for the streaming case can be easily adapted to learn the SVM weight vector in a way similar to using online stochastic gradient updates
MISC	Our algorithm performs polylogarithmic computation at each example, and requires very small and constant storage
MISC	Experimental results show that, even in such restrictive settings, we can learn efficiently in just one pass and get accuracies comparable to other state-of-the-art SVM solvers (batch and online)
OWNX	We also give an analysis of the algorithm, and discuss some open issues and possible extensions
MISC	Learning in a streaming model poses the restriction that we are constrained both in terms of time, as well as storage
MISC	Such scenarios are quite common, for example, in cases such as analyzing network traffic data, when the data arrives in a streamed fashion at a very high rate
MISC	Streaming model also applies to cases such as disk-resident large datasets which cannot be stored in memory
MISC	Unfortunately, standard learning algorithms do not scale well for such cases
OWNX	To address such scenarios, we propose applying the  stream model  of computation  CITATION  to supervised learning problems
MISC	In the stream model, we are allowed only one pass (or a small number of passes) over an ordered data set, and polylogarithmic storage and polylogarithmic computation per element
MISC	In spite of the severe limitations imposed by the streaming framework, streaming algorithms have been successfully employed in many different domains  CITATION
MISC	Many of the problems in geometry can be adapted to the streaming setting and since many learning problems have equivalent geometric formulations, streaming algorithms naturally motivate the development of efficient techniques for solving (or approximating) large-scale batch learning problems
OWNX	In this paper, we study the application of the stream model to the problem of maximum-margin classification, in the context of  SYMBOL -SVMs  CITATION
OWNX	Since the support vector machine is a widely used classification framework, we believe success here will encourage further research into other frameworks
MISC	SVMs are known to have a natural formulation in terms of the minimum enclosing ball problem in a high dimensional space  CITATION
MISC	This latter problem has been extensively studied in the computational geometry literature and admits natural streaming algorithms  CITATION
OWNX	We adapt these algorithms to the classification setting, provide some extensions, and outline some open issues
OWNX	Our experiments show that we can learn efficiently in just one pass and get competetive classification accuracies on synthetic and real datasets
MISC	The emergence of low-cost sensor architectures for diverse modalities has made it possible to deploy sensor arrays that capture a single event from a large number of vantage points and using multiple modalities
MISC	In many scenarios, these sensors acquire very high-dimensional data such as audio signals, images, and video
MISC	To cope with such high-dimensional data, we typically rely on low-dimensional models
MISC	Manifold models provide a particularly powerful model that captures the structure of high-dimensional data when it is governed by a low-dimensional set of parameters
MISC	However, these models do not typically take into account dependencies among multiple sensors
OWNX	We thus propose a new  joint manifold  framework for data ensembles that exploits such dependencies
OWNX	We show that simple algorithms can exploit the joint manifold structure to improve their performance on standard signal processing applications
OWNX	Additionally, recent results concerning dimensionality reduction for manifolds enable us to formulate a network-scalable data compression scheme that uses random projections of the sensed data
OWNX	This scheme efficiently fuses the data from all sensors through the addition of such projections, regardless of the data modalities and dimensions
MISC	The geometric notion of a low-dimensional manifold is a common, yet powerful, tool for modeling high-dimensional data
MISC	Manifold models arise in cases where ( i ) a  SYMBOL -dimensional parameter  SYMBOL  can be identified that carries the relevant information about a signal and ( ii ) the signal  SYMBOL  changes as a continuous (typically nonlinear) function of these parameters
OWNX	Some typical examples include a one-dimensional (1-D) signal shifted by an unknown time delay (parameterized by the translation variable), a recording of a speech signal (parameterized by the underlying phonemes spoken by the speaker), and an image of a 3-D object at an unknown location captured from an unknown viewing angle (parameterized by the 3-D coordinates of the object and its roll, pitch, and yaw)
MISC	In these and many other cases, the geometry of the signal class forms a nonlinear  SYMBOL -dimensional manifold in  SYMBOL ,  SYMBOL } where  SYMBOL  is the  SYMBOL -dimensional parameter space~ CITATION
OWNX	Low-dimensional manifolds have also been proposed as approximate models for nonparametric signal classes such as images of human faces or handwritten digits~ CITATION
MISC	In many scenarios, multiple observations of the same event may be performed simultaneously, resulting in the acquisition of multiple manifolds that share the same parameter space
MISC	For example, sensor networks --- such as camera networks or microphone arrays --- typically observe a single event from a variety of vantage points, while the underlying phenomenon can often be described by a set of common global parameters (such as the location and orientation of the objects of interest)
MISC	Similarly, when sensing a single phenomenon using multiple modalities, such as video and audio, the underlying phenomenon may again be described by a single parameterization that spans all modalities
MISC	In such cases, we will show that it is advantageous to model this joint structure contained in the ensemble of manifolds as opposed to simply treating each manifold independently
OWNX	Thus we introduce the concept of the  joint manifold : a model for the concatenation of the data vectors observed by the group of sensors
OWNX	Joint manifolds enable the development of improved manifold-based learning and estimation algorithms that exploit this structure
MISC	Furthermore, they can be applied to data of any modality and dimensionality
OWNX	In this work we conduct a careful examination of the theoretical properties of joint manifolds
MISC	In particular, we compare joint manifolds to their component manifolds to see how quantities like geodesic distances, curvature, branch separation, and condition number are affected
OWNX	We then observe that these properties lead to improved performance and noise-tolerance for a variety of signal processing algorithms when they exploit the joint manifold structure, as opposed to processing data from each manifold separately
AIMX	We also illustrate how this joint manifold structure can be exploited through a simple and efficient data fusion algorithm that uses random projections, which can also be applied to multimodal data
MISC	Related prior work has studied  manifold alignment , where the goal is to discover maps between several datasets that are governed by the same underlying low-dimensional structure
MISC	Lafon et al \ proposed an algorithm to obtain a one-to-one matching between data points from several manifold-modeled classes~ CITATION
OWNX	The algorithm first applies dimensionality reduction using diffusion maps to obtain data representations that encode the intrinsic geometry of the class
OWNX	Then, an affine function that matches a set of landmark points is computed and applied to the remainder of the datasets
OWNX	This concept was extended by Wang and Mahadevan, who apply Procrustes analysis on the dimensionality-reduced datasets to obtain an alignment function between a pair of manifolds~ CITATION
OWNX	Since an alignment function is provided instead of a data point matching, the mapping obtained is applicable for the entire manifold rather than for the set of sampled points
OWNX	In our setting, we assume that either ( i ) the manifold alignment is provided intrinsically via synchronization between the different sensors or ( ii ) the manifolds have been aligned using one of the approaches described above
OWNX	Our main focus is a theoretical analysis of the benefits provided by analyzing the joint manifold versus solving our task of interest separately on each of the manifolds observed by individual sensors
OWNX	This paper is organized as follows
MISC	Section~ introduces and establishes some basic properties of joint manifolds
OWNX	Section~ considers the application of joint manifolds to the tasks of classification and manifold learning
OWNX	Section~ then describes an efficient method for processing and aggregating data when it lies on a joint manifold, and Section~ concludes with discussion
OWNX	                                                                                                                                                                                                                                                                                                                                                                                                                                                                 jam-paper
OWNX	bbl                                                                                       0000644 0000000 0000000 00000012053 11307647155 012123  0                                                                                                    ustar   root                            root                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         jam-paper
OWNX	tex                                                                                       0000644 0000000 0000000 00000014040 11307647375 012166  0                                                                                                    ustar   root                            root                                                                                                                                                                                                                   \documentclass[12pt]{article} \input{preamble}  \title{A Theoretical Analysis of Joint Manifolds}  Mark A
OWNX	Davenport, Chinmay Hegde, Marco F
MISC	Duarte, \\ and Richard G
OWNX	Baraniuk \protect\\\protect\\ Rice University \protect\\ Department of Electrical and Computer Engineering\protect\\ Technical Report TREE0901}     \end{document}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 jam
MISC	Progress in understanding the brain mechanisms underlying vision requires the construction of computational models that not only emulate the brain's anatomy and physiology, but ultimately match its performance on visual tasks.
MISC	In recent years, natural images have become popular in the study of vision and have been used to show apparently impressive progress in building such models.
OWNX	Here, we challenge the use of uncontrolled natural images in guiding that progress.
OWNX	In particular, we show that a simple V1-like model a neuroscientist's null model, which should perform poorly at real-world visual object recognition tasks outperforms state-of-the-art object recognition systems on a standard, ostensibly natural image recognition test.
OWNX	As a counterpoint, we designed a simpler recognition test to better span the real-world variation in object pose, position, and scale, and we show that this test correctly exposes the inadequacy of the V1-like model.
OWNX	Taken together, these results demonstrate that tests based on uncontrolled natural images can be seriously misleading, potentially guiding progress in the wrong direction.
MISC	Instead, we reexamine what it means for images to be natural and argue for a renewed focus on the core problem of object recognition real-world image variation.
MISC	Visual object recognition is an extremely difficult computational problem.
OWNX	The core problem is that each object in the world can cast an infinite number of different 2-D images onto the retina as the object's position, pose, lighting, and background vary relative to the viewer.
MISC	Yet the brain solves this problem effortlessly.
MISC	Progress in understanding the brain's solution to object recognition requires the construction of artificial recognition systems that ultimately aim to emulate our own visual abilities, often with biological inspiration.
MISC	Such computational approaches are critically important because they can provide experimentally testable hypotheses, and because instantiation of a working recognition system represents a particularly effective measure of success in understanding object recognition.
MISC	However, a major challenge is assessing the recognition performance of such models.
MISC	Ideally, artificial systems should be able to do what our own visual systems can, but it is unclear how to evaluate progress toward this goal.
MISC	In practice, this amounts to choosing an image set against which to test performance.
MISC	Although controversial, a popular recent approach in the study of vision is the use of natural images CITATION, CITATION CITATION, in part because they ostensibly capture the essence of problems encountered in the real world.
MISC	For example, in computational vision, the Caltech101 image set has emerged as a gold standard for testing natural object recognition performance CITATION.
OWNX	The set consists of a large number of images divided into 101 object categories plus an additional background category.
MISC	While a number of specific concerns have been raised with this set, its images are still currently widely used by neuroscientists, both in theoretical and experimental contexts.
MISC	The logic of Caltech101 is that the sheer number of categories and the diversity of those images place a high bar for object recognition systems and require them to solve the computational crux of object recognition.
MISC	Because there are 102 object categories, chance performance is less than 1 percent correct.
MISC	In recent years, several object recognition models have shown what appears to be impressively high performance on this test better than 60 percent correct CITATION, CITATION CITATION, suggesting that these approaches, while still well below human performance, are at least heading in the right direction.
MISC	However, we argue here for caution, as it is not clear to what extent such natural image tests actually engage the core problem of object recognition.
MISC	Specifically, while the Caltech101 set certainly contains a large number of images, variations in object view, position, size, etc., between and within object category are poorly defined and are not varied systematically.
MISC	Furthermore, image backgrounds strongly covary with object category.
MISC	The majority of images are also composed photographs, in that a human decided how the shot should be framed, and thus the placement of objects within the image is not random and the set may not properly reflect the variation found in the real world.
OWNX	Furthermore, if the Caltech101 object recognition task is hard, it is not easy to know what makes it hard different kinds of variation are all inextricably mixed together.
MISC	Such problems are not unique to the Caltech101 set, but also apply to other uncontrolled natural image sets .
MISC	Transcriptional regulators recognize specific DNA sequences.
OWNX	Because these sequences are embedded in the background of genomic DNA, it is hard to identify the key cis-regulatory elements that determine disparate patterns of gene expression.
OWNX	The detection of the intra- and inter-species differences among these sequences is crucial for understanding the molecular basis of both differential gene expression and evolution.
MISC	Here, we address this problem by investigating the target promoters controlled by the DNA-binding PhoP protein, which governs virulence and Mg 2 homeostasis in several bacterial species.
MISC	PhoP is particularly interesting; it is highly conserved in different gamma/enterobacteria, regulating not only ancestral genes but also governing the expression of dozens of horizontally acquired genes that differ from species to species.
OWNX	Our approach consists of decomposing the DNA binding site sequences for a given regulator into families of motifs using a machine learning method inspired by the Divide Conquer strategy.
OWNX	By partitioning a motif into sub-patterns, computational advantages for classification were produced, resulting in the discovery of new members of a regulon, and alleviating the problem of distinguishing functional sites in chromatin immunoprecipitation and DNA microarray genome-wide analysis.
MISC	Moreover, we found that certain partitions were useful in revealing biological properties of binding site sequences, including modular gains and losses of PhoP binding sites through evolutionary turnover events, as well as conservation in distant species.
MISC	The high conservation of PhoP submotifs within gamma/enterobacteria, as well as the regulatory protein that recognizes them, suggests that the major cause of divergence between related species is not due to the binding sites, as was previously suggested for other regulators.
OWNX	Instead, the divergence may be attributed to the fast evolution of orthologous target genes and/or the promoter architectures resulting from the interaction of those binding sites with the RNA polymerase.
OWNX	Whole genome sequences, as well as microarray and chromatin inmunoprecipitation with array hybridization data provide the raw material for the characterization and understanding of the underlying regulatory systems.
MISC	It is still challenging, however, to discern the sequence elements relevant to differential gene expression, such as those corresponding to the binding sites of transcriptional factors and RNA polymerase, when they are embedded in the background of genomic DNA sequences that do not play a role in gene expression CITATION.
MISC	This raises the question: how does a single regulator distinguish promoter sequences when affinity is a major determinant of differential expression?
MISC	Also, how does a regulator evolve given that there appears to be a non-monotonic co-evolution of regulators and targets CITATION CITATION ?
OWNX	Methods that look for matching to a consensus pattern have been successfully used to identify BSs in promoters controlled by particular TFs CITATION CITATION.
OWNX	Tools for motif discovery are designed to find unknown, relatively short sequence patterns located primarily in the promoter regions of genomes CITATION.
MISC	Because these searches are performed in a context of short signals embedded in high statistical noise, current tools tend to discard a relevant number of samples that only weakly resemble a consensus CITATION.
MISC	Moreover, the strict cutoffs used by these methods, while increasing specificity, display lower sensitivity CITATION, CITATION to weak but still functional BSs.
OWNX	Because the consensus motif reflects a single pattern derived by averaging DNA sequences, it often conceals sub-patterns that might define distinct regulatory mechanisms CITATION.
MISC	Overall, the use of consensuses tends to homogenize sequence motifs among promoters and even across species CITATION, CITATION, which hampers the discovery of key features that distinguish co-regulated promoters within and across species.
OWNX	To circumvent the limitations of consensus methods CITATION, we decomposed BS motifs into sub-patterns CITATION, CITATION by applying the classical Divide Conquer strategy CITATION, CITATION.
OWNX	We then compared different forms of decomposed BS motifs of a TF into families of motifs from a computational clustering perspective.
MISC	In so doing, we extracted the maximal amount of useful genomic information through the effective handling of the biological and experimental variability inherent in the data, and then combined them into an accurate multi-classifier predictor CITATION, CITATION.
CONT	Although there is a computational usefulness of the submotifs CITATION, CITATION, it was not clear if these families of motifs were just a computational artifact or if they could provide insights into the regulatory process carried out by a regulator and its targets.
OWNX	To address this problem, we evaluated the ability of the submotifs to characterize gene expression both within and across genomes.
OWNX	First, we used submotifs to distinguish between functional and non-functional BSs in genome-wide searches using a combination of ChIP-chip and custom expression microarray experiments.
MISC	Then, we determined the evolutionary significance of the submotifs by calculating their rate of evolution CITATION, CITATION and mapping the gain and loss events along the phylogenetic tree of gamma/enterobacteria.
MISC	The interspecies variation of orthologous genes, the conservation of the regulatory protein, as well as the cis-features conforming the promoter architecture allowed us to evaluate the major causes of divergences between species CITATION, CITATION .
OWNX	We applied our approach to analyze the genes regulated by the PhoP/PhoQ two-component system, which mediates the adaptation to low Mg 2 environments and/or virulence in several bacteria species including Escherichia coli species, Salmonella species, Shigella species, Erwinia species, Photorhabdus and Yersinia species.
OWNX	Two-component systems represent the primary signal transduction paradigm in prokaryotic organisms.
MISC	Although proteins encoded by these systems are often well conserved throughout different bacterial species CITATION, CITATION, regulators like PhoP differentially control the expression of many horizontally-acquired genes, which constitute one of the major sources of genomic variation CITATION .
MISC	The calcium/calmodulin-dependent protein kinase II plays a key role in the induction of long-term postsynaptic modifications following calcium entry.
MISC	Experiments suggest that these long-term synaptic changes are all-or-none switch-like events between discrete states.
MISC	The biochemical network involving CaMKII and its regulating protein signaling cascade has been hypothesized to durably maintain the evoked synaptic state in the form of a bistable switch.
MISC	However, it is still unclear whether experimental LTP/LTD protocols lead to corresponding transitions between the two states in realistic models of such a network.
MISC	We present a detailed biochemical model of the CaMKII autophosphorylation and the protein signaling cascade governing the CaMKII dephosphorylation.
OWNX	As previously shown, two stable states of the CaMKII phosphorylation level exist at resting intracellular calcium concentration, and high calcium transients can switch the system from the weakly phosphorylated to the highly phosphorylated state of the CaMKII.
OWNX	We show here that increased CaMKII dephosphorylation activity at intermediate Ca 2 concentrations can lead to switching from the UP to the DOWN state.
OWNX	This can be achieved if protein phosphatase activity promoting CaMKII dephosphorylation activates at lower Ca 2 levels than kinase activity.
MISC	Finally, it is shown that the CaMKII system can qualitatively reproduce results of plasticity outcomes in response to spike-timing dependent plasticity and presynaptic stimulation protocols.
MISC	This shows that the CaMKII protein network can account for both induction, through LTP/LTD-like transitions, and storage, due to its bistability, of synaptic changes.
MISC	Synaptic plasticity is thought to underlie learning and memory, but the mechanisms by which changes in synaptic efficacy are induced and maintained over time are still unclear.
MISC	Numerous experiments have shown how synaptic efficacy can be increased or decreased by spike timing of presynaptic and postsynaptic neurons CITATION, CITATION, presynaptic firing rate CITATION, CITATION, or presynaptic firing paired with postsynaptic holding potential CITATION.
MISC	These experiments have led to phenomenological models that capture one or several of these aspects CITATION CITATION.
MISC	However, these models tell us nothing about the biochemical mechanisms of induction and maintenance of synaptic changes.
MISC	The question of the mechanisms at the biochemical level has been addressed by another line of research work originating from early work by Lisman CITATION.
OWNX	Models at the biochemical level describe enzymatic reactions of proteins in the postsynaptic density CITATION CITATION.
OWNX	These proteins form a network with positive feedback loops that can potentially provide a synapse with several stable states two, in the simplest case providing a means to maintain the evoked changes.
OWNX	Hence, synapses in such models are similar to binary switches, exhibiting two stable states, an UP state with high efficacy, and a DOWN state with low efficacy.
MISC	The idea of binary synapses is supported by recent experiments on CA3-CA1 synapses CITATION CITATION .
OWNX	One of the proposed positive feedback loops involves the calcium/calmodulin-dependent protein kinase II kinase-phosphatase system CITATION CITATION.
MISC	CaMKII activation is governed by Ca 2 /calmodulin binding and is prolonged beyond fast-decaying calcium transients by its autophosphorylation CITATION.
MISC	Autophosphorylation of CaMKII at the residue theronine-286 in the autoregulatory domain occurs after calcium/calmodulin binding and enables the enzyme to remain autonomously active after dissociation of calcium/calmodulin CITATION.
OWNX	In turn, as long as CaMKII stays activated it is reversibly translocated to a postsynaptic density -bound state where it interacts with multiple LTP-related partners structurally organizing protein anchoring assemblies and therefore potentially delivering -amino-3-hydroxyl-5-methyl-4-isoxazole-propionate acid receptors to the cell surface CITATION, CITATION CITATION.
OWNX	The direct phosphorylation of the AMPA receptor GluR1 subunit by active CaMKII enhances AMPA channel function CITATION, CITATION.
MISC	The network involving CaMKII is particularly appealing in terms of learning and memory maintenance since N-methyl-D-aspartate receptor -dependent LTP requires calcium/calmodulin activation of CaMKII, potentially expressed by the phosphorylation level or the number of AMPA receptors, or both CITATION, CITATION, CITATION, CITATION CITATION.
MISC	However, the role of CaMKII beyond LTP induction remains controversial CITATION CITATION.
MISC	Finally, there is experimental evidence for the involvement of proteins associated with CaMKII activity, and calcineurin in LTP and LTD CITATION CITATION.
OWNX	We emphasize that multiple mechanisms supporting LTP/LTD induction and expression are likely to be present in synapses of different regions we focus here on synapses for which the above statements have been shown to apply, e.g., the CA3-CA1 Schaffer collateral synapse .
MISC	Modeling studies have shown that a system including CaMKII and associated pathways could be bistable in a range of calcium concentrations including the resting level a necessary requirement for the maintenance of long-term changes CITATION, CITATION, CITATION, CITATION.
OWNX	In such models, the two states correspond to two stable phosphorylation levels of the CaMKII protein for a given calcium concentration, i.e., a weakly and a highly phosphorylated state.
MISC	A transition from the DOWN to the UP state which could underlie long-term potentiation can be induced by a sufficiently large and prolonged increase in calcium concentration.
OWNX	However, the opposite transition which could underlie depotentiation or LTD only occurs under unrealistic conditions, for example decrease of calcium concentration below resting level.
MISC	Furthermore, it has not been considered how these biochemical network models behave in response to calcium transients evoked by experimental protocols that are known to induce synaptic plasticity such as STDP, which has been shown to rely on kinase and phosphatase activation CITATION.
MISC	Rubin et al. reproduce experimental results on STDP using a model detector system which qualitatively resembles the protein network influencing CaMKII, but this model does not exhibit bistability CITATION.
MISC	Other studies on biochemical signal transduction pathways including CaMKII showed that the AMPA receptor activity can reproduce bidirectional synaptic plasticity as a function of calcium CITATION, CITATION.
OWNX	However, realistic stimulation protocols were not investigated in these models, and again they do not show bistability.
OWNX	In this paper, we consider a realistic model of protein interactions associated with CaMKII autophosphorylation through calcium/calmodulin and dephosphorylation by protein phosphatase 1 in the PSD.
OWNX	We first study the steady-state phosphorylation properties of CaMKII with respect to calcium and changing levels of PP1 activity.
MISC	Conditions are elaborated for which the system allows for LTP and LTD transitions in reasonable ranges of calcium concentrations.
MISC	We then demonstrate the ability of the CaMKII system to perform LTP- or LTD-like transitions in response to STDP stimulation protocols.
MISC	We expose the CaMKII system to calcium transients evoked by pairs of presynaptic and postsynaptic spikes with a given time lag and show that short positive time lags evoke transitions from the DOWN to the UP state and short negative time lags lead to transitions from the UP to the DOWN state.
OWNX	We demonstrate furthermore that the CaMKII model qualitatively reproduces experimental plasticity outcomes for presynaptic stimulation protocols.
OWNX	Finally, we consider the transition behavior in response to purely presynaptic or postsynaptic spike-pair stimulation protocols.
OWNX	This work describes a method of approximating matrix permanents efficiently using belief propagation
OWNX	We formulate a probability distribution whose partition function is exactly the permanent, then use Bethe free energy to approximate this partition function
OWNX	After deriving some speedups to standard belief propagation, the resulting algorithm requires  SYMBOL  time per iteration
OWNX	Finally, we demonstrate the advantages of using this approximation
MISC	The permanent is a scalar quantity computed from a matrix and has been an active topic of research for well over a century
MISC	It plays a role in cryptography and statistical physics where it is fundamental to Ising and dimer models
OWNX	While the determinant of an  SYMBOL  matrix can be evaluated exactly in sub-cubic time, efficient methods for computing the permanent have remained elusive
MISC	Since the permanent is  SYMBOL P-complete, efficient exact evaluations cannot be found in general
MISC	The best exact methods improve over brute force ( SYMBOL ) and include Ryser's algorithm  CITATION  which requires as many as  SYMBOL  arithmetic operations
OWNX	Recently, promising fully-polynomial randomized approximate schemes (FPRAS) have emerged which provide arbitrarily close approximations
OWNX	Many of these methods build on initial results by Broder  CITATION  who applied Markov chain Monte Carlo (a popular tool in machine learning and statistics) for sampling perfect matchings to approximate the permanent
MISC	Recently, significant progress has produced an FPRAS that can handle arbitrary  SYMBOL  matrices with non-negative entries  CITATION
OWNX	The method uses Markov chain Monte Carlo and only requires a polynomial order of samples
CONT	However, while these methods have tight theoretical guarantees, they carry expensive constant factors, not to mention relatively high polynomial running times that discourage their usage in practical applications
OWNX	In particular, we have experienced that the prominent algorithm in  CITATION  is slower than Ryser's exact algorithm for any feasible matrix size, and project that it only becomes faster around  SYMBOL
MISC	It remains to be seen if other approximate inference methods can be brought to bear on the permanent
MISC	For instance, loopy belief propagation has also recently gained prominence in the machine learning community
MISC	The method is exact for singly-connected networks such as trees
MISC	In certain special loopy graph cases, including graphs with a single loop, bipartite matching graphs  CITATION  and bipartite multi-matching graphs  CITATION , the convergence of BP has been proven
MISC	In more general loopy graphs, loopy BP still maintains some surprising empirical success
MISC	Theoretical understanding of the convergence of loopy BP has recently been improved by noting certain general conditions for its fixed points and relating them to minima of Bethe free energy
OWNX	This article proposes belief propagation for computing the permanent and investigates some theoretical and experimental properties
OWNX	In Section , we describe a probability distribution parameterized by a matrix similar to those described in  CITATION  for which the partition function is exactly the permanent
OWNX	In Section , we discuss Bethe free energy and introduce belief propagation as a method of finding a suitable set of pseudo-marginals for the Bethe approximation
OWNX	In Section , we report results from experiments
OWNX	We then conclude with a brief discussion
MISC	Kinetically stable proteins, those whose stability is derived from their slow unfolding kinetics and not thermodynamics, are examples of evolution's best attempts at suppressing unfolding.
MISC	Especially in highly proteolytic environments, both partially and fully unfolded proteins face potential inactivation through degradation and/or aggregation, hence, slowing unfolding can greatly extend a protein's functional lifetime.
MISC	The prokaryotic serine protease -lytic protease has done just that, as its unfolding is both very slow and so cooperative that partial unfolding is negligible, providing a functional advantage over its thermodynamically stable homologs, such as trypsin.
MISC	Previous studies have identified regions of the domain interface as critical to LP unfolding, though a complete description of the unfolding pathway is missing.
OWNX	In order to identify the LP unfolding pathway and the mechanism for its extreme cooperativity, we performed high temperature molecular dynamics unfolding simulations of both LP and trypsin.
OWNX	The simulated LP unfolding pathway produces a robust transition state ensemble consistent with prior biochemical experiments and clearly shows that unfolding proceeds through a preferential disruption of the domain interface.
OWNX	Through a novel method of calculating unfolding cooperativity, we show that LP unfolds extremely cooperatively while trypsin unfolds gradually.
OWNX	Finally, by examining the behavior of both domain interfaces, we propose a model for the differential unfolding cooperativity of LP and trypsin involving three key regions that differ between the kinetically stable and thermodynamically stable classes of serine proteases.
OWNX	-lytic protease, a prokaryotic serine protease of the chymotrypsin family, has evolved an unusual energetic landscape, providing it a functional advantage over its metazoan homologs.
MISC	Unlike most proteins, LP's active state is not stabilized by thermodynamics, but by a large kinetic barrier to unfolding, with an unfolding t 1/2 of 1 year.
MISC	CITATION While thermodynamically stable homologs like trypsin have similar unfolding rates, they are degraded at rates up to 100x faster than LP under highly proteolytic conditions.
OWNX	CITATION, CITATION In addition, the rates of LP unfolding and degradation are nearly identical, indicating that partial unfolding leading to proteolysis is negligible.
MISC	Therefore, LP's functional advantage is derived from not only its very slow unfolding, which it shares with trypsin, but also its suppression of local unfolding events that would render it protease-accessible.
MISC	Thus, it appears that the evolution of LP has generated such extreme cooperativity in unfolding in order to maximize its functional lifetime under harsh conditions.
MISC	The cost of maximizing resistance to unfolding comes in the form of extremely slow folding and the consequent loss of thermodynamic stability of the active state relative to the unfolded state.
MISC	CITATION, CITATION However, LP also evolved a large Pro-region folding catalyst, which speeds folding by nine orders of magnitude and is then degraded by the mature protease, decoupling the folding and unfolding landscapes so that unfolding resistance can be maximized.
OWNX	CITATION, CITATION, CITATION
MISC	Given LP's unusual energetic landscape and its reliance on kinetic stability, much effort has focused on elucidating its unfolding mechanism in detail.
MISC	Native-state hydrogen-deuterium exchange showed over half of its 194 backbone amides are well-protected from exchange, and 31 have protection factors greater than 10 9.
MISC	CITATION This extreme rigidity is spread throughout both domains and is indicative of LP's high unfolding cooperativity.
MISC	Thermodynamic decomposition of the unfolding energetics into entropic and enthalpic contributions suggested a prominent role for the extensive domain interface in unfolding, with the critical step involving solvation of the domain interface while the individual domains remain relatively intact.
MISC	CITATION Mutational studies on LP inspired by the acid-resistant homolog NAPase were consistent with this hypothesis.
MISC	The distribution of salt-bridges in NAPase and LP differ markedly; replacement of a salt-bridge at LP's domain interface with an intra-domain salt-bridge resulted in significant increases in LP's resistance to low pH unfolding.
MISC	CITATION A major component of the domain interface, the Domain Bridge, is the only covalent linkage between the two domains.
MISC	This structure exists only in prokaryotic proteases and varies considerably among LP and its homologs.
MISC	The area buried by the domain bridge is inversely correlated with the high-temperature unfolding rate for four kinetically stable proteases, indicating both its relevance and that it is weakened early in unfolding.
MISC	CITATION Another domain interface component is a -hairpin in the C-terminal domain, unique to kinetically stable proteases, that forms part of the active site.
MISC	Substitution of a more stable -turn was consistent with an unfolding pathway where C H loses its domain interface contacts early in unfolding.
MISC	CITATION Despite much progress, we still lack a global picture of LP unfolding, especially at high resolution.
MISC	For higher-resolution views of protein folding/unfolding, researchers have often turned to -value analysis.
OWNX	CITATION CITATION These studies involve large-scale protein engineering experiments which investigate the molecule's folding and unfolding kinetics after making perturbing mutations, normally hydrophobic deletions.
OWNX	By analyzing sufficiently large numbers of perturbations, structure in the transition state ensemble can be inferred and a folding/unfolding mechanism can be proposed.
MISC	Unfortunately, the extremely slow folding and unfolding rates for LP make large-scale -value analysis on LP impractical.
OWNX	As an alternative, we decided to investigate the LP unfolding pathway computationally in order to explain previous experiments and guide new ones.
MISC	High-temperature molecular dynamics unfolding simulations offer the highest structural and temporal resolution for studying protein unfolding, but their results must be validated experimentally.
MISC	Since unfolding rates for proteins are typically very slow under physiological conditions, very high temperatures are required to accelerate the unfolding into the ns range required for computational analysis.
OWNX	As a consequence, initially there was significant concern as to the relevance of the high temperature TSEs to real proteins under physiological conditions.
MISC	Daggett and co-workers have been pioneers in this field, using Chymotrypsin Inhibitor 2 as a model system and have shown that the simulated unfolding calculations agree remarkably well with experimental -values and were even able to predict faster folding mutants.
MISC	CITATION CITATION Further work on other proteins by multiple groups has established MD unfolding simulations as a useful tool in examining protein unfolding at atomic resolution while correlating well with experiments.
OWNX	CITATION CITATION
MISC	A critical step in analyzing unfolding simulations is accurately pinpointing the TSE from the multitude of conformations generated.
MISC	Because the TSE is experimentally accessible through a molecule's folding and unfolding kinetics, its identification computationally can be used for both explanatory and predictive purposes.
MISC	Various methods for identifying the TSE have been used in the past, breaking down into conformational clustering and landscape methods.
MISC	CITATION, CITATION, CITATION, CITATION, CITATION CITATION Conformational clustering relies on all-versus-all comparisons of conformations, often by C RMSD, while landscapes separating native from unfolded structures can be generated using properties of the conformations, such as the fraction of native contacts or secondary structure.
MISC	Here, we report the results of multiple MD simulations carried out at high temperature in order to probe the mechanism of LP's extremely cooperative unfolding.
MISC	Due to the robustness and cooperativity of LP unfolding, the same TSE is obtained using either conformational clustering or landscape methods.
AIMX	The simulated unfolding pathway for LP matches well with previously described experiments and provides atomic resolution to previous models for LP unfolding which highlight the role of the domain interface.
OWNX	In addition, we have performed similar simulations on trypsin with the goal of understanding the observed experimental differences in unfolding cooperativity.
OWNX	Through a novel method for calculating cooperativity in MD simulations, we show LP unfolds significantly more cooperatively than trypsin, mirroring the experimental results.
AIMX	Finally, by analyzing the domain interfaces of both proteins during unfolding, we propose a mechanism for how this differential cooperativity is achieved.
MISC	Protein folding dynamics is often described as diffusion on a free energy surface considered as a function of one or few reaction coordinates.
OWNX	However, a growing number of experiments and models show that, when projected onto a reaction coordinate, protein dynamics is sub-diffusive.
MISC	This raises the question as to whether the conventionally used diffusive description of the dynamics is adequate.
OWNX	Here, we numerically construct the optimum reaction coordinate for a long equilibrium folding trajectory of a Go model of a FORMULA-repressor protein.
MISC	The trajectory projected onto this coordinate exhibits diffusive dynamics, while the dynamics of the same trajectory projected onto a sub-optimal reaction coordinate is sub-diffusive.
OWNX	We show that the higher the free energy profile for the putative reaction coordinate, the more diffusive the dynamics become when projected on this coordinate.
MISC	The results suggest that whether the projected dynamics is diffusive or sub-diffusive depends on the chosen reaction coordinate.
OWNX	Protein folding can be described as diffusion on the free energy surface as function of the optimum reaction coordinate.
MISC	And conversely, the conventional reaction coordinates, even though they might be based on physical intuition, are often sub-optimal and, hence, show sub-diffusive dynamics.
MISC	A free energy surface projected onto one or a small number of coordinates is often used to describe the equilibrium and kinetic properties of complex systems with a very large number of degrees of freedom.
MISC	Studies of protein folding are an important case where this type of projected surface has been introduced and coordinates such as the number of native contacts and radius of gyration have been used CITATION CITATION.
OWNX	Protein folding then is described as diffusion on the projected free energy surface.
MISC	Diffusive dynamics is characterized by means square displacement linearly growing with time, FORMULA, where D is the diffusion coefficient.
MISC	For a single reaction coordinate diffusive dynamics is completely specified by the free energy profile, i.e. the free energy as a function of the coordinate and coordinate-dependent diffusion coefficient, which conveniently can be computed from conventional and cut based free energy profiles CITATION.
MISC	Construction of a good reaction coordinate is challenging.
MISC	In many cases, the standard progress variables are not good reaction coordinates, because they do not preserve the barriers on the FES and thus may mask the inherent complexity of the latter CITATION.
MISC	A number of methods to construct good reaction coordinates have been suggested CITATION, CITATION CITATION .
AIMX	Employing the Mori-Zwanzig formalism CITATION, CITATION one can derive generalized Langevin equations, which describe system dynamics projected on the reaction coordinates.
OWNX	The generalized Langevin equation contains a memory kernel, which leads to non-Markovian dynamics and subdiffusion.
MISC	Subdiffusion is characterized by the mean square displacement growing slower than that for diffusion, FORMULA with exponent FORMULA.
OWNX	To completely specify dynamics in this case one has to compute the memory kernel, which is not trivial, since it requires the solution of a multidimensional partial differential equation CITATION.
MISC	Long-term memory in correlation functions and anomalous diffusion in proteins was observed experimentally and theoretically CITATION CITATION.
MISC	This raises the question whether the folding dynamics of proteins can be described as simple diffusion on the projected free energy surface, as is often done, or if one has to use more sophisticated descriptions, e.g. generalized Langevin equations CITATION, CITATION, fractional Fokker-Plank equations CITATION or multiscale state space networks CITATION.
OWNX	Here we show that if the reaction coordinate is properly optimized, then the dynamics projected onto this coordinate is diffusive, while the same dynamics projected onto a sub-optimal coordinate is sub-diffusive.
MISC	donation requests often convey numerical information about the people in need
OWNX	in two studies we investigated the effects of numeracy and presentation format on the underlying affective and cognitive mechanisms of donation decisions
MISC	in study  NUMBER   participants were presented with information about a victim in need  either in a frequency format or in a percentage format
OWNX	in study  NUMBER   we manipulated the identifiability and number of target victims
OWNX	our results demonstrate that donations of individuals lower in numeracy were more susceptible to changes in numeric presentation format than those higher in numeracy
MISC	importantly  the underlying mechanisms for donations differed by numeracy
MISC	whereas the mental image of the victim influenced donation decisions of less numerate people only  the estimated impact of a donation was positively correlated with donation amounts for both more and less numerate individuals
MISC	in reports of the effects of natural and man-made catastrophes e g   famines  floods  tsunamis  and wars  it is common to encounter statistics about the number of human lives affected
MISC	for example  the earthquake in haiti on january  NUMBER    NUMBER  affected  NUMBER  million people  of which approximately  NUMBER   NUMBER  lost their lives  CITATION  and an estimated  NUMBER   NUMBER  families were left homeless  CITATION
MISC	although it may be difficult to truly comprehend the scope of such tragedies  CITATION   numerical figures are typically used to convey the enormity of suffering
OWNX	humanitarian aid organizations likewise use numerical information to communicate the needs of the victims and to entice benefactors to make financial contributions
MISC	the total number of lives affected  the estimated number of individuals that would benefit from a donation  and the ratio between them can all be important aspects in the decision to help
OWNX	potential donors are expected to understand and use such numerical information when deciding whether to support a humanitarian aid project
MISC	however  comprehension and use of this information may differ depending on how it is presented and who the potential donor is
MISC	Given a random binary sequence  SYMBOL  of random variables,  SYMBOL   SYMBOL , for instance, one that is generated by a Markov source of order  SYMBOL  (each state represented by  SYMBOL  bits)
MISC	Let  SYMBOL  be the probability of  SYMBOL  and assume it is constant with respect to  SYMBOL  (due to stationarity)
OWNX	Consider a learner based on a parametric model, for instance a Markov model of order  SYMBOL , who trains on a sample sequence  SYMBOL  which is randomly drawn by the source
MISC	Test the learner's performance by giving it a sequence  SYMBOL  (generated by the source) and check its predictions on every bit of  SYMBOL  An error occurs at time  SYMBOL  if the  prediction  SYMBOL  differs from the true bit value  SYMBOL
MISC	Denote by  SYMBOL  the sequence of errors where the error bit  SYMBOL  at time  SYMBOL  equals  SYMBOL  or  SYMBOL  according to whether the event of an error occurs or not, respectively
OWNX	Consider the subsequence  SYMBOL  of  SYMBOL  which corresponds to the errors of predicting a  SYMBOL , ie ,  SYMBOL  consists of the bits of  SYMBOL  only at times  SYMBOL  such that  SYMBOL  In this paper we compute an upper bound on the deviation of the frequency of  SYMBOL s of  SYMBOL  from  SYMBOL  showing dependence on  SYMBOL ,  SYMBOL ,  SYMBOL
MISC	From basic theory on finite Markov chains, since the matrix  SYMBOL  is stochastic (i e , the sum of the elements in any row equals  SYMBOL ) then  SYMBOL  has a stationary joint probability distribution  SYMBOL *} which is not necessarily unique
OWNX	To keep the notation simple we use  SYMBOL  to denote also any marginal distribution derived from the stationary joint distribution
MISC	For instance,  SYMBOL
MISC	Henceforth, all random binary sequences are assumed to be drawn according to this probability distribution  SYMBOL
MISC	Thus for any  SYMBOL  and  SYMBOL  satisfying  SYMBOL  the probability of a string  SYMBOL  can be expressed as  SYMBOL } Let us denote by  SYMBOL } the stationary probability of the event  SYMBOL  at time  SYMBOL
MISC	Data generation : We henceforth assume that the source reached stationarity and produces the data sequence  SYMBOL  with respect to  SYMBOL
MISC	Consider the learner's model  SYMBOL
MISC	Its set of parameters are the true (unknown) probability values of transitions between states in  SYMBOL  where the probability values are assigned according to the source distribution  SYMBOL
MISC	We denote them by  SYMBOL  For instance, suppose  SYMBOL  and  SYMBOL  and consider two states  SYMBOL  and  SYMBOL
MISC	The corresponding transition probability is  SYMBOL  Based on  SYMBOL  the learner estimates  SYMBOL  by  SYMBOL  where for a state  SYMBOL ,  SYMBOL  denotes the number of times that  SYMBOL  appears in  SYMBOL  and  SYMBOL  denotes the number of times there is a transition from state  SYMBOL  to  SYMBOL  in  SYMBOL
MISC	For instance, if  SYMBOL ,  SYMBOL  and  SYMBOL  then  SYMBOL
MISC	Thus  SYMBOL  are the frequency of state-transitions in  SYMBOL
MISC	Note that  SYMBOL ,  SYMBOL , are dependent random variables since the Markov chain may visit each state a random number of times and they must satisfy  SYMBOL
MISC	After training, the learner is tested on the remaining  SYMBOL  bits of the data  SYMBOL
MISC	It makes a binary prediction  SYMBOL  for  SYMBOL ,  SYMBOL  based on the maximum  a posteriori  probability which is defined as follows: suppose that the current state is  SYMBOL  then the prediction is   SYMBOL } where  SYMBOL  is defined as  SYMBOL  for the state  SYMBOL  obtained from  SYMBOL  by a type-1 transition, i e , if  SYMBOL  then  SYMBOL
MISC	The corresponding true probability value is denoted by  SYMBOL
MISC	Note that () may be expressed alternatively as SYMBOL }   We claim that  SYMBOL ,  SYMBOL , are independent random variables when conditioned on the vector  SYMBOL
OWNX	We now prove the claim which will be used in Section
MISC	Let us denote by  SYMBOL ,  SYMBOL ,  SYMBOL , the particular sequence of states corresponding to the sequence  SYMBOL
OWNX	To show the dependence of  SYMBOL  on  SYMBOL  we will sometimes write  SYMBOL
MISC	Then by () we have SYMBOL *} Since at every bit there are only two types of transitions then not every sequence  SYMBOL  is possible
MISC	For instance, if  SYMBOL  then the state sequence  SYMBOL  is valid but  SYMBOL  is not valid
OWNX	Denote by  SYMBOL  the set of  valid  state sequences  SYMBOL
MISC	We now show that if  SYMBOL  is in  SYMBOL  then, conditioned on  SYMBOL , any other state sequence that visits the same states as  SYMBOL  the same number of times (perhaps in a different order) must have the same probability
MISC	For any state  SYMBOL  denote by  SYMBOL  the random variable whose value is the number of type-1 transitions from state  SYMBOL  in a sequence of random states  SYMBOL
MISC	Define by  SYMBOL  the number of type-1 transitions from state  SYMBOL  in the sequence  SYMBOL
MISC	Since all state transitions are either type-0 or type-1  then we have SYMBOL } where  SYMBOL  was defined above
MISC	Let  SYMBOL  be a non-negative integer parameter and define the random variable  SYMBOL
MISC	Associate a conditional probability function with parameter  SYMBOL  for the random variable  SYMBOL  as  SYMBOL  Then the right side of () equals SYMBOL } For a fixed value of  SYMBOL  the event {}`` SYMBOL '' is equivalent to the event {}`` SYMBOL ''
MISC	Hence alternatively, the right side of () can be expressed as  SYMBOL } The right side of () is a product of probability functions of the random variables  SYMBOL
MISC	So conditioned on  SYMBOL  and on the event that  SYMBOL  corresponds to a valid state sequence  SYMBOL , the event that  SYMBOL  is generated by the source Markov chain  SYMBOL  is equivalent to the event that its corresponding state sequence  SYMBOL  has transition frequencies  SYMBOL  that independently take the particular values  SYMBOL  as prescribed in  SYMBOL
OWNX	The claim is proved
MISC	It also follows that  SYMBOL  is the average of independent Bernoulli trials (success taken as a type-1 transition from state  SYMBOL )
MISC	It is distributed according to the Binomial distribution with parameters  SYMBOL  and  SYMBOL
OWNX	We now summarize the problem setting under which the main result of the paper holds
OWNX	Problem setting : Let  SYMBOL  and  SYMBOL  be positive integers
OWNX	Let  SYMBOL  be the stationary probability distribution based on a finite, ergodic and reversible Markov chain with probability-transition matrix  SYMBOL  that has a second largest eigenvalue  SYMBOL
MISC	All probability values are measured according to  SYMBOL
MISC	Denote by  SYMBOL
OWNX	After reaching stationarity the source generates a binary sequence  SYMBOL  by repeatedly drawing  SYMBOL  according to  SYMBOL
MISC	Denote by  SYMBOL
MISC	Let  SYMBOL  be a data-sequence obtained by randomly drawing according to  SYMBOL
MISC	Let the learner's model  SYMBOL  be Markov of order  SYMBOL , and denote by  SYMBOL  the probability of making a type-1 transition from state  SYMBOL  of  SYMBOL
OWNX	The learner uses the first  SYMBOL  bits,  SYMBOL , to estimate  SYMBOL ) by  SYMBOL
MISC	Let  SYMBOL  denote the number of times that state  SYMBOL  appears in  SYMBOL ,  SYMBOL
MISC	After training, the learner's decision at state  SYMBOL  is to output  SYMBOL  if  SYMBOL  else output  SYMBOL
MISC	Denote by  SYMBOL  the probability that a Binomial random variable with parameters  SYMBOL ,  SYMBOL , is larger (or smaller) than  SYMBOL  given that  SYMBOL  is smaller (or larger) than  SYMBOL , respectively
OWNX	Let  SYMBOL
OWNX	Let  SYMBOL
MISC	Using  SYMBOL  the learner is tested incrementally on the remaining  SYMBOL  bits  SYMBOL  of the data and predicts an output bit  SYMBOL  for bit  SYMBOL  in  SYMBOL  to be  SYMBOL  if  SYMBOL , else  SYMBOL
MISC	Denote by  SYMBOL  the sequence of mistakes where  SYMBOL  if  SYMBOL , and  SYMBOL  otherwise,  SYMBOL
MISC	Denote by  SYMBOL ,  SYMBOL , the subsequence of  SYMBOL  with time instants  SYMBOL  corresponding to  SYMBOL -predictions,  SYMBOL ,  SYMBOL
OWNX	Note that  SYMBOL  is also a subsequence of the input sequence  SYMBOL  hence effectively the learner acts as a selection rule which picks certain bits  SYMBOL  from  SYMBOL
OWNX	Let    SYMBOL *}   and assume that the learner's model order  SYMBOL  satisfies,    SYMBOL  We now state the main result of the paper
OWNX	Before presenting the proof we make the following remarks,   The effect of the training sequence length  SYMBOL  on  SYMBOL  is as  SYMBOL  which is  SYMBOL
MISC	As  SYMBOL  increases the class of possible learnt models (hypothesis class) decreases in size thereby decreasing the bound  SYMBOL  on the deviation of the error sequence
OWNX	The effect of the learner's model order  SYMBOL  is opposite of that of  SYMBOL
MISC	We see that  SYMBOL  and as  SYMBOL  increases, the hypothesis class increases in size
MISC	The effect of the length  SYMBOL  of the error sequence on  SYMBOL  is as  SYMBOL
OWNX	Clearly, the longer the subsequence the less chance that its frequency of 1s deviate from the mean  SYMBOL
OWNX	The effect of the inter-dependence between the states of the source model  SYMBOL  on  SYMBOL  is as  SYMBOL
MISC	As the dependence increases,  SYMBOL  decreases which increases the possible deviation size  SYMBOL
MISC	As  SYMBOL  decreases, the bits of the sequence  SYMBOL  become less dependent and  SYMBOL  decreases
MISC	Angiogenesis plays a crucial role in a variety of physiological and pathological conditions including cancer, cardiovascular disease, and wound healing.
MISC	Vascular endothelial growth factor is a critical regulator of angiogenesis.
OWNX	Multiple VEGF receptors are expressed on endothelial cells, including signaling receptor tyrosine kinases and the nonsignaling co-receptor Neuropilin-1.
MISC	Neuropilin-1 binds only the isoform of VEGF responsible for pathological angiogenesis, and is thus a potential target for inhibiting VEGF signaling.
OWNX	Using the first molecularly detailed computational model of VEGF and its receptors, we have shown previously that the VEGFR Neuropilin interactions explain the observed differential effects of VEGF isoforms on VEGF signaling in vitro, and demonstrated potent VEGF inhibition by an antibody to Neuropilin-1 that does not block ligand binding but blocks subsequent receptor coupling.
AIMX	In the present study, we extend that computational model to simulation of in vivo VEGF transport and binding, and predict the in vivo efficacy of several Neuropilin-targeted therapies in inhibiting VEGF signaling: blocking Neuropilin-1 expression; blocking VEGF binding to Neuropilin-1; blocking Neuropilin VEGFR coupling.
MISC	The model predicts that blockade of Neuropilin VEGFR coupling is significantly more effective than other approaches in decreasing VEGF VEGFR2 signaling.
OWNX	In addition, tumor types with different receptor expression levels respond differently to each of these treatments.
MISC	In designing human therapeutics, the mechanism of attacking the target plays a significant role in the outcome: of the strategies tested here, drugs with similar properties to the Neuropilin-1 antibody are predicted to be most effective.
OWNX	The tumor type and the microenvironment of the target tissue are also significant in determining therapeutic efficacy of each of the treatments studied.
MISC	Angiogenesis, the growth of new blood microvessels from preexisting microvasculature, is a critical physiological process for the growth of developing organs and during wound healing, ovulation, and pregnancy.
MISC	Coronary or peripheral ischemia may be relieved by inducing angiogenesis CITATION, CITATION, while diseases of hypervascularization, such as cancer or diabetic retinopathy, are targets of anti-angiogenic drugs CITATION, CITATION.
MISC	Neuronal expression of angiogenic receptors CITATION, CITATION suggests that this work may also be relevant to the development nervous system.
MISC	Our goal is to propose effective targeted therapies using anatomically accurate and molecularly detailed computational models of the growth factors and receptors involved in angiogenesis.
OWNX	In this study, we predict that three methods of targeting the same molecule result in distinct therapeutic outcomes, and that one of these methods is more effective than the others.
OWNX	Thus, identification of a therapeutic target must be followed by rational design of the targeting molecule to obtain characteristics that maximize the therapeutic potential.
MISC	In addition, the microenvironment in which the drug is to act for example, the expression level of receptors in the tissue is a critical factor in the impact of the therapy.
MISC	Vascular endothelial growth factor is a family of secreted glycoproteins and critical regulators of angiogenesis CITATION, CITATION.
MISC	In vitro, VEGF increases endothelial cell survival, proliferation, and migration.
MISC	In vivo, it increases vascular permeability, activates endothelial cells, and acts as a chemoattractant for nascent vessel sprouts.
OWNX	Multiple splice isoforms of VEGF exist; the two most abundant in the human are VEGF 121 and VEGF 165.
MISC	Both isoforms bind to the VEGF receptor tyrosine kinases to induce signals.
OWNX	VEGF 165 also interacts with nonsignaling Neuropilin co-receptors and with proteoglycans of the extracellular matrix CITATION, CITATION.
MISC	The binding sites on VEGF 165 for VEGFR2 and Neuropilin-1 are nonoverlapping, so VEGF 165 may bind both simultaneously CITATION.
OWNX	There are thus two parallel pathways for VEGF 165 to bind its signaling receptor: binding directly to VEGFR2; and binding to Neuropilin-1, which presents VEGF to VEGFR2.
MISC	VEGF 121 can only form VEGFR2 complexes directly CITATION.
MISC	The VEGF 165 Neuropilin interaction is thus of particular value as a therapeutic target because VEGF 165 is the isoform of VEGF that has been identified as inducing pathological angiogenesis CITATION, CITATION : aberrant angiogenic signaling may be targeted while allowing the normal levels of physiological VEGF signaling to continue.
MISC	In previous work CITATION, CITATION, we developed computational models of VEGF interactions with endothelial cell receptors in vitro, and incorporated previously published experimental data to estimate the kinetic rate of VEGFR2-Neuropilin coupling by VEGF 165.
OWNX	We showed that VEGFR2 Neuropilin coupling is sufficient to account for the observed differential effects of VEGF isoforms on multiple cell types and that our model reproduces the distinct VEGF binding and signaling effects on each of these cell types CITATION, CITATION CITATION.
MISC	In addition, we used the model to distinguish between alternate hypotheses of molecular mechanisms of action and demonstrated that the Neuropilin-1 antibody under investigation acts by blocking VEGFR Neuropilin coupling, not by blocking VEGF Neuropilin binding.
MISC	Here, we extend that validated model of the molecular interactions of the VEGF family and its receptors to predict the in vivo behavior of the system by including the ECM and basement membranes, as well as multiple cell types and geometrical parameters characteristic of the tissue.
OWNX	Three methods for targeting the VEGF 165 Neuropilin interaction are modeled here.
MISC	First, a blockade of Neuropilin-1 expression may be induced by use of siRNA or other methods to prevent the synthesis of the protein in the cells.
MISC	Second, a protein that occupies the VEGF binding site on Neuropilin-1 can compete with VEGF 165 for binding to that receptor.
OWNX	An example is a fragment of the placental growth factor isoform PlGF 2.
MISC	Full-length PlGF 2 binds Neuropilin-1 and VEGFR1 CITATION.
OWNX	The fragment, denoted PlGF 2 here, contains only the Neuropilin-1 binding site and does not bind to VEGFR1.
MISC	This protein has been used to block VEGF binding to Neuropilin in vitro CITATION, CITATION.
OWNX	An alternative would be a Neuropilin-binding fragment of VEGF 165 itself CITATION, CITATION.
OWNX	Third, we may block the interaction between Neuropilins and the VEGFRs, preventing the presentation of VEGF 165 to the signaling receptor, but permitting Neuropilin to sequester that isoform.
OWNX	This may be done using a Neuropilin-1 antibody CITATION CITATION that we have previously characterized as permitting VEGF binding to Neuropilin-1, but blocking the subsequent VEGFR coupling CITATION.
MISC	Each of these three strategies has been demonstrated to inhibit VEGF signaling in in vitro assays CITATION, CITATION, CITATION, CITATION ; here we predict their in vivo efficacy.
MISC	This is the first computational model to our knowledge to include the interactions of the VEGF family and their receptors explicitly and in biophysical detail.
MISC	The model includes the kinetics of all ligand receptor interactions, which allows us to examine both short-term and long-term behavior of the system.
MISC	All the parameters for the model have been obtained from previously published experimental data.
MISC	Analysis of characteristic parameters shows that the kinetics of VEGF interactions are slower than the diffusion process, so diffusion is assumed to be fast, and we construct a compartmental model with parenchymal cells secreting VEGF into the interstitial space and VEGF binding to receptors on the endothelial cell surface .
OWNX	The geometrical parameters of the tissue under investigation here are also incorporated into the model: interstitial space, tumor cell volume and surface area, microvessel volume and surface area.
OWNX	Changes to these parameters would result in changes to the kinetic parameters and concentrations in the model.
MISC	The results presented here are therefore tissue-specific, but the model may be applied to other tissues.
OWNX	VEGFR2 is the primary signaling receptor for VEGF, and we first analyze the results of the model for a tissue in which the endothelial cells express VEGFR2 and Neuropilin-1, but not VEGFR1; the effect of VEGFR1 is considered later.
MISC	Initially, the system is in a steady state, as VEGF is secreted by the parenchymal cells and internalized by the endothelial cells, resulting in a flux through the interstitial space and the ECM.
OWNX	One of three treatments is initiated at time zero and the time course of VEGF binding followed for 48 hours.
MISC	VEGF VEGFR2 and VEGF VEGFR1 binding are taken as a surrogate for VEGF signaling.
MISC	We consider the least-square regression problem with regularization by a block  SYMBOL -norm, ie , a sum of  Euclidean norms over spaces of dimensions larger than one
MISC	This problem, referred to as the group Lasso, extends the usual regularization by the  SYMBOL -norm where all spaces have dimension one, where it is commonly referred to as the Lasso
OWNX	In this paper, we study the asymptotic model consistency of the group Lasso
OWNX	We derive necessary and sufficient conditions for the consistency of group Lasso under practical assumptions, such as model misspecification
MISC	When the linear predictors and  Euclidean norms are replaced by functions and reproducing kernel Hilbert norms, the problem is usually referred to as multiple kernel learning and is commonly used for learning from heterogeneous data sources and for non linear variable selection
OWNX	Using tools from functional analysis, and in particular covariance operators,  we extend the consistency results to this infinite dimensional case and also propose an adaptive scheme to obtain a consistent model estimate, even when the necessary  condition required for the non adaptive scheme is not satisfied
MISC	Regularization has emerged as a dominant theme in machine  learning and  statistics
OWNX	It provides an intuitive and principled tool for learning from high-dimensional data
CONT	Regularization by squared Euclidean norms or squared Hilbertian norms has been thoroughly studied in various settings, from approximation theory to statistics, leading to efficient practical algorithms based on linear algebra and very general theoretical consistency results~ CITATION
MISC	In recent years, regularization by non Hilbertian norms  has generated considerable interest in linear supervised learning, where the goal is to predict a response as a linear function of  covariates;  in particular, regularization by the  SYMBOL -norm (equal to the sum of absolute values), a method commonly referred to as the  Lasso ~ CITATION , allows to perform variable selection
MISC	However,  regularization by non Hilbertian norms cannot be solved empirically by simple linear algebra and instead leads to general convex optimization problems and much of the early effort has been dedicated to algorithms to solve the optimization problem efficiently
OWNX	In particular, the  Lars  algorithm of~ CITATION  allows to find the entire regularization path (i e , the set of solutions for all values of the regularization parameters) at the cost of a single matrix inversion
OWNX	As the consequence of the optimality conditions,  regularization by the  SYMBOL -norm  leads to  sparse  solutions, i e , loading vectors with many zeros
OWNX	Recent works  CITATION  have looked precisely at the model consistency of the Lasso, i e , if we know that the data were generated from a sparse loading vector, does the Lasso actually recover it when the number of observed data points grows
OWNX	In the case of a fixed number of covariates, the Lasso does recover the sparsity pattern if and only if a certain simple condition on the generating covariance matrices is verified~ CITATION
MISC	In particular, in low correlation settings, the Lasso is indeed consistent
MISC	However, in presence of strong correlations, the Lasso cannot be consistent, shedding light on potential problems of such procedures for variable selection
MISC	Adaptive versions where data-dependent weights are added to the  SYMBOL -norm  then allow to keep the consistency in all situations~ CITATION
MISC	A related Lasso-type procedure is the  group Lasso , where the covariates are assumed to be clustered in groups, and instead of summing the absolute values of each individual loading, the sum of Euclidean norms of the loadings in each group is used
MISC	Intuitively, this should drive all the weights in one group to zero  together , and thus lead to group selection~ CITATION
OWNX	In \mysec{grouplasso}, we extend the consistency results of the Lasso to the group Lasso, showing that similar correlation conditions are necessary and sufficient conditions for consistency
OWNX	The passage from groups of size one to groups of larger sizes leads however to a slightly weaker result as we can not get a single necessary and sufficient condition (in \mysec{refined}, we show that the stronger result similar to the Lasso is not true as soon as one group has dimension larger than one)
OWNX	Also, in our proofs, we relax the  assumptions usually made for such consistency results, i e , that the model is completely well-specified (conditional expectation of the response which is linear in the covariates and constant conditional variance)
AIMX	In the context of  misspecification , which is a common situation when applying methods such as the ones presented in this paper, we simply prove convergence to the best linear predictor (which is assumed to be sparse), both in terms of loading vectors and sparsity patterns
MISC	The group Lasso essentially replaces groups of size one by groups of size larger than one
MISC	It is natural in this context to allow the size of each group to grow unbounded, i e , to replace the sum of Euclidean norms by a sum  of appropriate Hilbertian norms
CONT	When the Hilbert spaces are reproducing kernel Hilbert spaces (RKHS), this procedure turns out to be equivalent to learn the best convex combination  of a set of basis kernels, where each kernel corresponds to one  Hilbertian norm used for regularization~ CITATION
MISC	This framework, referred to as  multiple kernel learning ~ CITATION , has applications in kernel selection, data fusion from heterogeneous data sources and non linear variable selection~ CITATION
OWNX	In this latter case,  multiple kernel learning can exactly be seen as variable selection in a  generalized additive model ~ CITATION
OWNX	We extend  the consistency results of the group Lasso to this non parametric  case, by using covariance operators and appropriate notions of functional analysis
MISC	These notions allow to carry out the analysis entirely in  ``primal/input''  space, while the algorithm has to work in  ``dual/feature''   space to avoid infinite dimensional optimization
OWNX	Throughout the paper, we will always go back and forth between primal and dual formulations, primal formulation for analysis and dual formulation for algorithms
OWNX	The paper is organized as follows: in \mysec{grouplasso}, we present the consistency results for the group Lasso, while in \mysec{mklsec}, we extend these to Hilbert spaces
OWNX	Finally, we present the adaptive schemes in \mysec{adaptive} and illustrate our set of results with simulations on synthetic examples in \mysec{simulations}
MISC	Cells of the embryonic vertebrate limb in high-density culture undergo chondrogenic pattern formation, which results in the production of regularly spaced islands of cartilage similar to the cartilage primordia of the developing limb skeleton.
MISC	The first step in this process, in vitro and in vivo, is the generation of cell condensations, in which the precartilage cells become more tightly packed at the sites at which cartilage will form.
AIMX	In this paper we describe a discrete, stochastic model for the behavior of limb bud precartilage mesenchymal cells in vitro.
MISC	The model uses a biologically motivated reaction diffusion process and cell-matrix adhesion as the bases of chondrogenic pattern formation, whereby the biochemically distinct condensing cells, as well as the size, number, and arrangement of the multicellular condensations, are generated in a self-organizing fashion.
MISC	Improving on an earlier lattice-gas representation of the same process, it is multiscale, and the cells are represented as spatially extended objects that can change their shape.
MISC	The authors calibrate the model using experimental data and study sensitivity to changes in key parameters.
OWNX	The simulations have disclosed two distinct dynamic regimes for pattern self-organization involving transient or stationary inductive patterns of morphogens.
OWNX	The authors discuss these modes of pattern formation in relation to available experimental evidence for the in vitro system, as well as their implications for understanding limb skeletal patterning during embryonic development.
MISC	Skeletal pattern formation in the developing vertebrate limb depends on interactions of precartilage mesenchymal cells with factors that control the spatiotemporal differentiation of cartilage.
MISC	The most fundamental skeletogenic processes involve the spatial separation of precartilage mesenchyme into chondrogenic and nonchondrogenic domains CITATION, and can be studied in vitro as well as in vivo.
MISC	In high-density micromass cultures of chondrogenic embryonic limb mesenchymal cells CITATION, CITATION, as well as in the developing limb itself CITATION, morphogens of the TGF- family induce the local aggregation or condensation of these cells by a process that involves the upregulation of the adhesive extracellular glycoprotein fibronectin CITATION, CITATION.
MISC	Cells first accumulate in regions of increased cell fibronectin adhesive interactions CITATION CITATION and then acquire epithelioid properties by upregulation of cell cell adhesion molecules CITATION, CITATION.
MISC	Cartilage differentiation follows at the sites of condensation both in vitro and in vivo .
MISC	In certain developmental processes, such as angiogenesis and invasion by cancer cells of surrounding tissues, pre-existing multicellular structures become more elaborate.
MISC	Precartilage condensation, by contrast, is an example of a developmental process in which cells that start out as independent entities interact to form multicellular structures.
MISC	Others in this second category include vasculogenesis, the formation of feather germs, and the aggregation of social amoebae into streams and fruiting bodies.
MISC	Both continuous CITATION CITATION and discrete CITATION CITATION models have been used previously to analyze a wide range of pattern formation behaviors in both categories using concepts such as chemotaxis, haptotaxis, and reaction diffusion instability.
MISC	Discrete models describe the behaviors and interactions of individual biological entities such as organisms, cells, proteins, etc. They are often applied to microscale events where a small number of elements can have a large impact on a system.
MISC	In a previous study CITATION we presented a discrete biological lattice gas model for high-density cultures of precartilage mesenchymal cells derived from the embryonic vertebrate limb.
MISC	This model, which was based on the physical notion of a lattice gas, in which individual particles are free to move from point to point on a lattice at discrete time-steps, accurately simulated the formation of patterns of mesenchymal condensations observed in high-density micromass cultures of such cells.
MISC	In these simulations, the distribution and relative size of the condensations corresponded to in vitro values when appropriate quantities for cell behavioral parameters were chosen, and the simulated patterns were robust against small variations of these values.
MISC	Moreover, the simulated patterns were altered similarly to the cultures when cell density and exposure to or expression of molecular factors represented in the model were altered in a fashion analogous to their counterparts in the living system.
MISC	In the earlier model, each of the limb precartilage mesenchymal cells, and each molecule from a core subset of the molecules they secrete, was represented as a single particle on a common grid.
MISC	Default motion of the cell particles was random, but cell movement was also biased by the presence of fibronectin particles produced and deposited by the cells according to a set of rules involving TGF- and inhibitor particles.
OWNX	The latter in turn were produced in a cell-dependent fashion according to a reaction diffusion scheme, the network structure of which was suggested by in vitro experiments CITATION, CITATION, CITATION .
MISC	The ability of the model of Kiskowski et al. CITATION to simulate both qualitative and quantitative aspects of precartilage condensation formation and distribution suggested that the core genetic network cell behavioral mechanism that underlies this biological lattice gas might be sufficient to account for pattern formation in the limb cell micromass system and corresponding features of in vivo limb development.
MISC	However, the model deviated from biological reality in several important ways.
MISC	Mesenchymal cells in vitro are initially surrounded by a small layer of ECM that separates them by less than a cell diameter.
MISC	Those that undergo condensation round up, reducing their surface area, but do not move away from adjacent noncondensing cells.
MISC	Therefore, unlike the situation in the model of Kiskowski et al. CITATION, mesenchymal condensation in micromass culture does not involve accumulation of cells at particular sites with concomitant depletion of cells in surrounding zones.
MISC	The representation of cells, morphogens, and ECM on a common grid is physically unrealistic.
MISC	This is not simply a matter of pixel scale: molecular substances can indeed form deposits and gradients on the same linear scale as cells, and a molecular pixel could be considered to correspond to thousands of molecules.
MISC	Nonetheless, the dynamics of morphogen transport is continuous and is represented in an inauthentically saltatory fashion by pixel displacement on a grid of the same mesh size as that supporting cell translocation.
MISC	Whereas the model of Kiskowski et al. made the assumption that cells halt their motion when they encounter suprathreshold levels of extracellular fibronectin CITATION, this does not agree with measurements CITATION, CITATION indicating that cells actually slightly increase their speed of motion as they enter condensation centers and have a finite probability of escaping from these foci.
MISC	Despite the successes of the model of Kiskowski et al. CITATION, it was unknown whether removing its artifactual aspects and replacing them with more realistic assumptions would lead to similarly authentic results.
OWNX	We have therefore designed a more sophisticated model that overcomes each of the listed deficiencies of the earlier one.
MISC	The cells in the new model are extended, multipixel objects that can change shape in the plane and round up by moving pixels into a virtual third dimension.
MISC	The model cells are separated by less than a cell diameter, condense without denuding the regions surrounding condensation centers, and are not irreversibly trapped upon entering a center.
MISC	Finally, two grids of different mesh size are used for cell and molecular dynamics.
MISC	We have found that not only does this improved model reproduce the experimental data accounted for by the model of Kiskowski et al., but that additional morphogenetic features of the micromass culture system are simulated as well.
CONT	Moreover, potential dynamic properties of the developmental process not seen in the earlier simulations, and not capable of being distinguished on the basis of existing experimental data, were disclosed in simulations using the new model, which has therefore provided motivation for further empirical tests.
MISC	scholars in economics and psychology have created a large literature studying reward  punishment and reciprocity
MISC	labor markets constitute a popular application of this body of work  with particular emphasis on how reciprocity helps regulate workplace relationships where managers are unable to perfectly monitor workers
OWNX	we study how idiosyncratic features of the labor market compared to most scenarios in which reciprocity applies affect the nature of worker reciprocity
OWNX	in particular  we show how having an excess supply of workers simulating unemployment and managers who can observe the reciprocal behavior of workers and hire fire them on that basis simulating the reputational concerns inherent in labor market transactions profoundly alters worker reciprocity
MISC	in the absence of reputational concerns  workers tend to reward kind behavior and punish unkind behavior by managers in approximately equal measure
MISC	in the presence of reputational concerns  workers exhibit a marked increase decrease in the propensity to reward kind punish unkind behavior by managers
OWNX	we demonstrate how this is a consequence of workers and managers responding to changes in the strategic incentives to reward and punish
OWNX	the principle of retaliation is as old as mankind
MISC	as far back as the hammarabian code some  NUMBER  years ago  retaliation of some form has served to organize behavior in both market and non-market situations
MISC	perhaps illustrating the importance of revenge most succinctly is the biblical injunction of exodus  NUMBER   NUMBER - NUMBER    life for life  eye for eye  tooth for tooth bruise for bruise 
MISC	for their part  scholars have explored the importance of negative actions alongside their seemingly more benign cousins  positive actions
MISC	one of the key insights that can be taken from the decades of research within the social sciences is that reciprocity in general is important  and that negative actions toward an individual induce a greater behavioral response than comparable positive actions
MISC	this stylized fact is perhaps best illustrated in the words of baumeister et al CITATION   who provide a broad survey of several areas of study examining positive and negative reciprocity  and conclude that p  NUMBER - NUMBER   italics added   the breadth and convergence of evidence  however  across different areas were striking  which forms the most important evidence
OWNX	in no area were we able to find a consistent reversal  such that one could draw a firm conclusion that good is stronger than bad
OWNX	this failure to find any substantial contrary patterns occurred despite our own wishes and efforts
OWNX	hence  we must conclude that bad is stronger than good at a pervasive  general level
MISC	 within economics  such results have served as the classic example of loss aversion - that people are more sensitive to negative realizations than to positive realizations of uncertainty  CITATION  - have played an important role in policymaking  CITATION   and have informed mechanism design
MISC	in terms of the latter  the principal is confronted with an interesting decision problem if framing of the incentive scheme matters to agent behavior or the number of instruments available to the principal is constrained
MISC	in this manner  choosing between carrots and sticks  for example  plays an important role in the outcome  CITATION
MISC	more generally  scholars have frequently remarked that loss aversion represents one of the most robust general behavioral patterns in the social sciences  CITATION
OWNX	in this study  we explore a general  labor-market setting wherein economic theory provides predictions that positive reciprocity should be stronger than negative reciprocity
OWNX	the two key features are that the agent is on the short end of a market that includes reputational considerations and that being out of the market provides less utility than being a participant
OWNX	under this design  a worker that respects her initial affective reaction and punishes the employer will find herself unemployed
MISC	alternatively  a worker who is nice to the employer will be more likely to be employed in the next period
MISC	since being employed dominates unemployment  we predict that the worker will restrain herself and will not follow the initial affective reaction
MISC	on the other hand  if the employer is nice  the worker will reciprocate strongly since in this situation not only is she employed  but also by a nice employer
OWNX	thus  in this situation  positive reciprocity will be stronger than negative reciprocity
OWNX	to test our theory  we design a simple controlled laboratory experiment  which yields several insights
OWNX	first  consonant with the literature  agents reciprocate
OWNX	and  when the interactions are anonymous  negative reciprocity is slightly more important than positive reciprocity  but not significantly so
MISC	also consonant with the literature is the fact that agents become emotionally charged when treated poorly
MISC	yet  this emotional charge does not readily transfer to actions when realistic institutional features of labor markets are in place
MISC	for example  when agents can form reputations  they respond much more acutely to positive than to negative stimuli
OWNX	second  the data suggest that the source of the behavioral differences observed is strategic  rather than a change in the social norm of reciprocation in a gift exchange setting
OWNX	the remainder of our study proceeds as follows
OWNX	section  NUMBER  contains the experimental design
OWNX	section  NUMBER  summarizes the experimental results
MISC	Knowledge of the Free Energy Landscape topology is the essential key to understanding many biochemical processes.
MISC	The determination of the conformers of a protein and their basins of attraction takes a central role for studying molecular isomerization reactions.
OWNX	In this work, we present a novel framework to unveil the features of a Free Energy Landscape answering questions such as how many meta-stable conformers there are, what the hierarchical relationship among them is, or what the structure and kinetics of the transition paths are.
MISC	Exploring the landscape by molecular dynamics simulations, the microscopic data of the trajectory are encoded into a Conformational Markov Network.
MISC	The structure of this graph reveals the regions of the conformational space corresponding to the basins of attraction.
MISC	In addition, handling the Conformational Markov Network, relevant kinetic magnitudes as dwell times and rate constants, or hierarchical relationships among basins, completes the global picture of the landscape.
MISC	We show the power of the analysis studying a toy model of a funnel-like potential and computing efficiently the conformers of a short peptide, dialanine, paving the way to a systematic study of the Free Energy Landscape in large peptides.
MISC	Polymers and, more specifically, proteins, show complex behavior at the cellular system level, e.g. in protein-protein interaction networks CITATION, and also at the individual level, where proteins show a large degree of multistability: a single protein can fold in different conformational states CITATION CITATION.
MISC	As a complex system CITATION, CITATION, the dynamics of a protein cannot be understood by studying its parts in isolation, instead, the system must be analyzed as a whole.
MISC	Tools able to represent and handle the information of the entire picture of a complex system are thus necessary.
MISC	Complex network theory CITATION, CITATION has proved to be a powerful tool used in seemingly different biologically-related fields such as the study of metabolic reactions, ecological and food webs, genetic regulatory systems and the study of protein dynamics CITATION.
MISC	In this latter context, diverse studies have analyzed the conformational space of polymers and proteins making use of network representations CITATION CITATION, where nodes account of polymer conformations.
MISC	Additionally, some studies have tried to determine the common and general properties of these conformational networks CITATION, CITATION looking at magnitudes such as clustering coefficient, cyclomatic number, connectivity, etc. Recently, trying to decompose the network in modules corresponding to the free energy basins, the use of community algorithms over these conformational networks have been proposed CITATION.
MISC	Although this approach has opened a promising path for the analysis of Free Energy Landscapes, the community based description of the network leads to multiple characterizations of the FEL and thus it is difficult to establish a clear map from the communities found to the basins of the FEL.
MISC	A similar approach, commonly used to analyze the complex dynamics, is the construction of Markovian models.
OWNX	Markovian state models let us treat the information of one or several trajectories of molecular dynamics as a set of conformations with certain transition probabilities among them CITATION, CITATION, CITATION.
OWNX	Therefore, the time-continuous trajectory turns into a transition matrix, offering global observables as relaxation times and modes.
OWNX	In CITATION CITATION the use of Markovian models is proposed with the aim of detecting FEL meta-stable states.
OWNX	However, the above approaches to analyze FELs of peptides involves extremely large computational cost: either general community algorithms or large transition matrices.
MISC	Finally, other strategies to characterize the FEL that have successfully helped to understand the physics of biopolymers, are based on the study of the Potential Energy Surface CITATION, CITATION, CITATION CITATION.
OWNX	The classical transition-state theory CITATION allows us to project the behavior of the system at certain temperature from the knowledge of the minima and transition states of the PES.
MISC	This approach entails some feasible approximations, such as harmonic approximation to the PES, limit of high damping, assumption of high barriers, etc. These approximations could be avoided working directly from the MD data.
AIMX	In this article we make a novel study of the FEL capturing its mesoscopic structure and hence characterizing conformational states and the transitions between them.
OWNX	Inspired by the approaches presented in CITATION, CITATION and CITATION, CITATION, we translate a dynamical trajectory obtained by MD simulations into a Conformational Markov Network.
OWNX	We show how to efficiently handle the graph to obtain, through its topology, the main features of the landscape: conformers and their basins of attraction, dwell times, rate constants between the conformational states detected and a coarse-grained picture of the FEL.
OWNX	The framework is shown and validated analyzing a synthetic funnel-like potential.
MISC	After this, the terminally blocked alanine peptide is studied unveiling the main characteristics of its FEL.
MISC	Knowledge of social contact patterns still represents the most critical step for understanding the spread of directly transmitted infections.
MISC	Data on social contact patterns are, however, expensive to obtain.
MISC	A major issue is then whether the simulation of synthetic societies might be helpful to reliably reconstruct such data.
OWNX	In this paper, we compute a variety of synthetic age-specific contact matrices through simulation of a simple individual-based model.
MISC	The model is informed by Italian Time Use data and routine socio-demographic data.
MISC	The model is named Little Italy because each artificial agent is a clone of a real person.
MISC	In other words, each agent's daily diary is the one observed in a corresponding real individual sampled in the Italian Time Use Survey.
MISC	We also generated contact matrices from the socio-demographic model underlying the Italian IBM for pandemic prediction.
MISC	These synthetic matrices are then validated against recently collected Italian serological data for Varicella and ParvoVirus.
OWNX	Their performance in fitting sero-profiles are compared with other matrices available for Italy, such as the Polymod matrix.
MISC	Synthetic matrices show the same qualitative features of the ones estimated from sample surveys: for example, strong assortativeness and the presence of super- and sub-diagonal stripes related to contacts between parents and children.
OWNX	Once validated against serological data, Little Italy matrices fit worse than the Polymod one for VZV, but better than concurrent matrices for B19.
MISC	This is the first occasion where synthetic contact matrices are systematically compared with real ones, and validated against epidemiological data.
OWNX	The results suggest that simple, carefully designed, synthetic matrices can provide a fruitful complementary approach to questionnaire-based matrices.
MISC	The paper also supports the idea that, depending on the transmissibility level of the infection, either the number of different contacts, or repeated exposure, may be the key factor for transmission.
MISC	A century after the first contributions giving birth to mathematical epidemiology, and after 20 years of fast growth since the first public health oriented contributions CITATION CITATION, infectious diseases modeling has recently received a further dramatic impulse from pandemics threats.
MISC	The Bio-terrorism and SARS first, the fear of a potentially devastating pandemic of avian flu then, and finally the recent pandemic of A/H1N1 influenza, have all fostered the development of more and more detailed predictive tools.
MISC	These range from traditional models to network analysis, to highly detailed, large scale, individual-based models CITATION CITATION.
MISC	IBM are highly flexible tools for policy makers as they allow to define intervention measures at the finest possible levels.
MISC	For the first time, a pandemic model on a continental scale has been proposed CITATION .
MISC	A critical aspect common to all such models, is the parameterization of social contact patterns, i.e. how people socially mix with each other CITATION.
MISC	Social contact patterns are the key factors underlying the transmission dynamics of directly transmitted close-contacts infectious diseases CITATION.
OWNX	Different models, independently of their level of complexity or geographical scale, are sensitive to the parameterization of social contact patterns.
MISC	In a relatively simple case, where individuals are stratified by age only, contact patterns are represented in the form of contact matrices whose entries represent the average number of contacts that individuals in age group i have with individuals in age group j, per unit of time.
MISC	Until recently, contact patterns were estimated indirectly by calibrating suitably restricted contact matrices using observed epidemiological data, such as serological or case notifications data.
OWNX	The two major examples of this indirect approach are the Who-Acquires-Infection-From-Whom matrix CITATION, and the proportionate/preferred mixing approach CITATION.
OWNX	Such approaches have important restrictions: in a population divided in n age groups, a contact matrix contains nxn n 2 unknown entries.
MISC	Therefore, in order to estimate the n 2 parameters from the n data points some simplifying assumptions about the structure of the matrix are needed.
MISC	In addition, indirect approaches can only estimate adequate contacts or transmission rates, i.e. composite parameters given by the product between a contact rate and the corresponding risk of infection per contact.
MISC	Recently, important progress has been made in this area through direct collection of contact data by means of sample surveys CITATION CITATION.
OWNX	The direct approach is based on appropriate definitions of an at risk event.
MISC	Survey respondents are then asked to record in a diary relevant characteristics of all the individuals they had contact with during a randomly assigned day, or other factors such as the location where the contact occurred.
MISC	Standardized international survey data on social contact patterns in 8 European countries are currently available CITATION.
MISC	In addition, contact matrices, and time in contact matrices, have been estimated from secondary data sources such as transportation surveys CITATION or time use data CITATION, which are increasingly available.
MISC	In the case of time use data, the underlying hypothesis is that the amount of time people spend doing the same activity in the same place is relevant for the transmission of the disease.
MISC	A drawback of time use data is that they usually do not give direct information about the number of social contacts of respondents, or the time they spent in contacts.
MISC	They only give marginal information on the time individuals allocated to the various daily activities CITATION.
MISC	Therefore, these data need to be augmented with other data and/or assumptions to produce reliable estimates of contact matrices CITATION.
MISC	A way to supplement time use data relies on socio-demographic sources which provide information on the size and distribution of the arenas where contacts take place.
MISC	For example, for school contacts we often know the average class size and the average pupils-teacher ratio for all compulsory grades.
MISC	As for contacts within the household, we have information on household size and composition.
MISC	For most other activities, however, there is little information.
MISC	Assumptions, e.g. independency, are therefore necessary to give some coarse ideas of contact patterns CITATION.
MISC	However, this approach ignores the structure of the social networks where contacts are formed.
MISC	A promising approach is then to reconstruct such networks by the simulation of appropriate artificial social networks.
MISC	A first example is the social network generated by the Portland synthetic population CITATION.
MISC	In that case, contact and time in contact matrices by age are by-products of the social dynamics of the Portland model.
OWNX	These matrices have the standard expected features: population contacts cluster around children and adult, children interact most frequently with other children close to their own age, etc. However, such matrices were neither compared with other contact matrices, nor validated against empirical epidemiological data.
MISC	Thus, no actual evaluation of their goodness in explaining transmission of infections is available.
OWNX	In this paper, we follow the same line and aim to reconstruct contact and time-in-contacts matrices by simulating a suitable minimalistic socio-demographic individual-based model for Italy.
MISC	The model is parameterized by integrating time use data from the Italian time use survey CITATION and other official socio-demographic data CITATION CITATION.
MISC	In the model, each artificial agent is a clone of a real individual, i.e. there is a one-to-one correspondence between the diary of each artificial agent and the one of a corresponding real survey participant.
OWNX	Since the sample is representative of the Italian population, but the size of the model population is comparable to that of a small Italian city, we named the model Little Italy.
OWNX	From this point of view, our model resembles the Portland model CITATION, and the Eemnes model CITATION.
MISC	In the Little Italy world, agents physically displace during the day in order to attend their various daily activities in the corresponding location.
MISC	In these locations, agents contact other agents.
MISC	We defined a contact as having shared the same physical environment during a given time slot.
OWNX	With our approach we generate three different types of contact matrices, possibly informative of distinct aspects of the biology of transmission: a matrix describing the time spent in contact CITATION, a matrix counting the number of repetition of contact episodes, and a matrix counting contacts as the average number of different persons contacted, i.e. the number of different social partnerships, as in CITATION .
OWNX	In addition, we extracted an adequate CITATION contact matrix from the socio-demographic model underlying the Italian IBM for pandemic prediction and mitigation CITATION, that we named Big-Italy.
MISC	The synthetic contact matrices computed by simulation of Little and Big-Italy are tested against recently collected Italian serological data on Varicella and ParvoVirus.
MISC	Their performances are compared with other contact matrices available for Italy, i.e. the Polymod and time use matrices.
OWNX	We consider a problem of significant practical importance,  namely, the reconstruction of a low-rank data matrix from a small subset of its entries
MISC	This problem appears in many areas such as  collaborative filtering, computer vision and wireless sensor networks
OWNX	In this paper, we focus on the matrix completion problem  in the case when the observed samples are corrupted by noise
OWNX	We compare the performance of  three state-of-the-art matrix completion algorithms  (OptSpace, ADMiRA and FPCA) on a single simulation platform  and present numerical results
MISC	We show that in practice  these efficient algorithms can be used to reconstruct real data matrices, as well as randomly generated matrices, accurately
OWNX	We consider the problem of reconstructing an  SYMBOL   low rank matrix  SYMBOL  from a small set of observed entries possibly corrupted by noise
MISC	This problem is of considerable practical interest and has many applications
OWNX	One example is collaborative filtering, where users submit rankings  for small subsets of, say, movies, and the goal is  to infer the preference of unrated movies for a recommendation system  CITATION
MISC	It is believed that the movie-rating matrix is approximately low-rank,  since only a few factors contribute to a user's preferences
OWNX	Other examples of matrix completion include the problem of inferring  3-dimensional structure from motion  CITATION  and triangulation from incomplete  data of distances between wireless sensors  CITATION
MISC	a wise decider d uses the contents of his mind fully  accurately and efficiently
OWNX	d's ideal decisions  i e   those that best serve his interests  would be embedded in a comprehensive set of totally coherent judgments lodged in his mind
MISC	they would conform to the norms of statistical decision theory  which extracts quantitative judgments of fact and value from d's mind contents and checks them for coherence
MISC	however  the most practical way for d to approximate his ideal may not be with models that embody those norms  i e   with applied decision theory adt
MISC	in practice  adt can represent only some of d's judgments and those imperfectly
MISC	quite different decision aid  including intuition  pattern recognition and cognitive vigilance especially combined  typically outperform feasible adt models-with some notable exceptions
MISC	however  decision theory training benefits d's informal decisions
MISC	adt  both formal and informal  should become increasingly useful and widespread  as technical  cultural and institutional impediments are overcome
MISC	we would surely all agree that most people especially other people
OWNX	make poor decisions and suffer the consequences
MISC	we marry abusive spouses and elect incompetent presidents  where we should have known better
MISC	we do not seem to have learned much over the ages
MISC	in the  NUMBER s  a new analytic technology  applied decision theory adt-also known as  decision analysis -promised to revolutionize decision practice  CITATION
MISC	i have spent a long career trying to realize that promise
MISC	Accumulating infections of highly pathogenic H5N1 avian influenza in humans underlines the need to track the ability of these viruses to spread among humans.
MISC	A human-transmissible avian influenza virus is expected to cause clusters of infections in humans living in close contact.
MISC	Therefore, epidemiological analysis of infection clusters in human households is of key importance.
MISC	Infection clusters may arise from transmission events from the animal reservoir, humans who were infected by animals, or humans who were infected by humans.
OWNX	Here we propose a method of analysing household infection data to detect changes in the transmissibility of avian influenza viruses in humans at an early stage.
MISC	The method is applied to an outbreak of H7N7 avian influenza virus in The Netherlands that was the cause of more than 30 human-to-human transmission events.
MISC	The analyses indicate that secondary human-to-human transmission is plausible for the Dutch household infection data.
OWNX	Based on the estimates of the within-household transmission parameters, we evaluate the effectiveness of antiviral prophylaxis, and conclude that it is unlikely that all household infections can be prevented with current antiviral drugs.
OWNX	We discuss the applicability of our method for the detection of emerging human-to-human transmission of avian influenza viruses in particular, and for the analysis of within-household infection data in general.
MISC	Outbreaks of highly pathogenic H5N1 avian influenza in Southeast Asia, Europe, and Africa have devastating consequences for poultry CITATION, CITATION, and have resulted in numerous infections in humans CITATION CITATION.
MISC	Although these infections from the animal reservoir continue to accumulate, the virus does not seem to spread extensively among humans.
MISC	Nevertheless, a fear is that these human infections may ultimately spark an influenza pandemic CITATION CITATION.
MISC	Indeed, recent clusters of infections in human households hint at the possibility of virus transmission from humans who were infected by poultry to their household contacts CITATION, CITATION.
MISC	These suggestions are strengthened by the observation of mutations in recent H5N1 viruses that seem to predispose the virus for more efficient transmission in mammals, including humans CITATION CITATION .
MISC	It is likely that a virus with pandemic potential will present itself initially through an increase in the number of infections in humans who have been in close contact with the case infected by animals.
OWNX	Therefore, rapid detection and control of clusters of infections is of key importance CITATION, CITATION.
MISC	Such clusters may result from multiple introductions from the animal reservoir, multiple transmission events from humans who were infected by animals, or multiple transmission events from humans who were themselves infected by humans.
MISC	Obviously, evidence for is the most worrisome as it indicates that the virus has acquired the ability to spread efficiently in humans.
MISC	It is often thought that pathogens from the animal reservoir that have made the jump to a new host species are usually not well-adapted for sustained transmission in the new host, and that transmissibility in a new species will gradually increase over time by the process of adaptation by means of natural selection CITATION CITATION.
MISC	Interestingly, however, in the case of H5N1 avian influenza in humans, the evidence so far does not seem to fit this prediction CITATION CITATION.
MISC	Mechanisms that could be responsible for the lack of efficient secondary human-to-human transmission could be due to a dose effect whereby humans infected by animals receive a higher infection dose than humans infected by humans, or to behavioural changes after infection that limit spread of the virus after it has been detected.
OWNX	In this paper we develop a method to detect and quantify different routes of virus transmission in a household setting.
MISC	Our main aim is to investigate whether within-household pathogen transmission has been restricted to transmission from the primary infected individual or whether there is evidence that the transmission chain has extended beyond the first generation of human-to-human infections.
MISC	Our analyses are based on theoretical developments on the distribution of the final size of an epidemic in finite populations, which allow construction of flexible methods to analyse within-household transmission chains.
OWNX	We apply the method to a recent study of within-household transmission of highly pathogenic avian influenza of the H7N7 subtype that caused a large epidemic in poultry in The Netherlands in 2003.
MISC	Shortly after the detection of virus circulation, the Dutch authorities undertook an aggressive control strategy that consisted of an animal movement ban in the affected regions, tracing and screening suspected flocks, and culling of infected and contiguous flocks.
MISC	In all, a total of 255 flocks became infected during a period of nine weeks, and more than 30 million birds were culled CITATION, CITATION.
MISC	Subsequent studies of poultry workers revealed that at least 86 infections from the animal reservoir to humans had taken place CITATION CITATION.
MISC	In addition, more than 30 household contacts of the infected poultry workers who had not been in direct contact with poultry were reported positive.
MISC	These reports indicate that human-to-human transmission did occur from individuals infected from the animal reservoir.
MISC	Here we analyse data of the transmission chains in 24 households that led to 33 human-to-human transmission events, measuring the extent of onward transmission from humans who were infected by humans.
MISC	We complement the statistical analyses by systematic power analyses to obtain insight into the study size needed to be able to find significant secondary human-to-human transmission, given that it is present.
OWNX	Although we have applied the method to a specific dataset, we believe that our method is of general interest as it enables rapid estimation of within-household transmission rates based on data that are easily gathered for most infectious diseases.
MISC	For instance, our method of analysis is not restricted to the analysis of emerging pandemic influenza, but it can just as well be used to estimate different routes of within-household transmission rates of human influenza A viruses CITATION CITATION and, importantly, to assess the potential effectiveness of control measures.
OWNX	Understanding of the intracellular molecular machinery that is responsible for the complex collective behavior of multicellular populations is an exigent problem of modern biology.
MISC	Quorum sensing, which allows bacteria to activate genetic programs cooperatively, provides an instructive and tractable example illuminating the causal relationships between the molecular organization of gene networks and the complex phenotypes they control.
OWNX	In this work we to our knowledge for the first time present a detailed model of the population-wide transition to quorum sensing using the example of Agrobacterium tumefaciens.
OWNX	We construct a model describing the Ti plasmid quorum-sensing gene network and demonstrate that it behaves as an on off gene expression switch that is robust to molecular noise and that activates the plasmid conjugation program in response to the increase in autoinducer concentration.
MISC	This intracellular model is then incorporated into an agent-based stochastic population model that also describes bacterial motion, cell division, and chemical communication.
OWNX	Simulating the transition to quorum sensing in a liquid medium and biofilm, we explain the experimentally observed gradual manifestation of the quorum-sensing phenotype by showing that the transition of individual model cells into the on state is spread stochastically over a broad range of autoinducer concentrations.
MISC	At the same time, the population-averaged values of critical autoinducer concentration and the threshold population density are shown to be robust to variability between individual cells, predictable and specific to particular growth conditions.
OWNX	Our modeling approach connects intracellular and population scales of the quorum-sensing phenomenon and provides plausible answers to the long-standing questions regarding the ecological and evolutionary significance of the phenomenon.
OWNX	Thus, we demonstrate that the transition to quorum sensing requires a much higher threshold cell density in liquid medium than in biofilm, and on this basis we hypothesize that in Agrobacterium quorum sensing serves as the detector of biofilm formation.
MISC	Molecular networks, which integrate signal transduction and gene expression into the unified decision circuitry, are ultimately responsible for the realization of all life activities of biological cells including internal developmental programs and responses to environmental factors.
MISC	One of the main challenges of systems biology is to uncover and understand the relationships between the properties of these molecular circuits and the macroscopic cellular phenotypes that are controlled by them CITATION.
MISC	Particularly important are the phenotypes involving interaction and cooperative action of multiple cells.
MISC	The mapping of networks onto phenotypes is still difficult to accomplish in multicellular eukaryotic organisms owing to their staggering complexity.
MISC	Less complex and more experimentally accessible prokaryotic organisms became the systems of choice for dissecting social behavior at the genetic level CITATION.
MISC	The phenomenon of bacterial quorum sensing gives us a particularly unique opportunity to follow the causal relationships from molecular circuitry to cooperative population dynamics.
MISC	QS refers to the ability of bacterial populations to collectively activate certain gene expression programs, e.g., toxin release or antibiotic production, once some critical population density has been reached.
MISC	QS is found in a vast variety of bacterial species and has been extensively studied experimentally CITATION CITATION.
MISC	In Gram-negative bacteria, the QS phenomenon is usually controlled by a small gene expression network that functions as an environmentally activated on off gene expression switch CITATION, CITATION whose operation is analogous to that of radar.
OWNX	At the low cell density that normally corresponds to the off switch state, a key transcription factor required for the expression of proteins responsible for the phenotype is suppressed.
MISC	At the same time, the cell steadily produces a small amount of the QS signaling molecule, termed the autoinducer, that can freely diffuse in and out of the cell.
OWNX	While the population density is low, most of the autoinducer molecules are washed out and dispersed in the environment by diffusion.
MISC	As the cell density grows, more molecules of autoinducer enter the bacterium from outside.
OWNX	Once certain cell quorum is reached, the inbound autoinducer signal triggers the transition of the QS network to the on state, resulting in the production of the transcription factor and the expression of the target genes.
OWNX	This transition on both intracellular and population-wide scales is the focus of our study.
MISC	We investigate the phenomenon of QS in the soil-dwelling plant pathogen Agrobacterium tumefaciens, the causative agent of crown gall disease CITATION.
MISC	Bacteria of this species often harbor Ti plasmids that endow their hosts with the unique ability to genetically modify susceptible plants through a cross-kingdom DNA transfer.
MISC	Like many other soil bacteria, Agrobacterium is chemotactic to exudates released by plant wounds and is capable of catabolizing various nutrients that leave injured plant roots.
OWNX	Once bacteria form physical contact with the surface of the wound, Ti plasmids offer their hosts an extraordinary advantage over their plasmidless competitors.
MISC	A fragment of the plasmid, termed the vir region, is injected into the plant cell in the form of a virion-like complex and is stably incorporated into the plant genome CITATION.
MISC	One of the imported genes is responsible for the synthesis of opines, a class of low-molecular-weight nitrogen-rich metabolites, that can be utilized as a nutrient only by the bacteria that harbor the Ti plasmid.
MISC	Other transferred genes cause a vigorous proliferation of infected plant cells that eventually results in the formation of a characteristic gall tumor.
MISC	Once productive infection is established, Ti plasmids attempt to propagate themselves into the plasmidless bacteria of the same or related species by means of genetic conjugation.
MISC	It has been shown that the conjugal transfer of Ti plasmids requires the QS phenomenon CITATION .
OWNX	Functional significance of QS for the control of Ti plasmid conjugation remains an ecological and evolutionary puzzle.
MISC	It is widely believed CITATION, CITATION that QS controls processes, such as production of toxins and antibiotics, that are either inefficient or devoid of adaptive value if not performed on a population scale.
OWNX	Thus, the fact that the establishment of QS is upstream of the initiation of conjugation seems to imply that plasmids await the critical density of donors to collectively begin transfer to recipients.
OWNX	Since multiple donors cannot cooperate in DNA transfer, the necessity for collective action does not seem to be relevant in our case.
OWNX	Instead, to increase the probability of successful conjugation it would appear beneficial to exceed a certain number of recipients per donor.
MISC	However the density of plasmidless recipients cannot be estimated using QS since they do not produce the autoinducer.
MISC	This seemingly paradoxical situation may imply that our understanding of the biological function of QS is not yet complete.
MISC	Indeed, an alternative function for QS as a sensor of the volume enclosing the bacteria has also been proposed CITATION.
MISC	To answer what bacteria really measure using QS in each particular situation, it is necessary to consider the ecologically relevant conditions of bacterial growth CITATION .
MISC	An experimental approach to this problem is often complicated by the technical difficulty of work in real ecosystems.
MISC	On the other hand, mathematical modeling can significantly aid and complement experimental methods in answering biological questions that involve spatial and temporal scales of the QS phenomenon.
MISC	Some aspects of either intracellular CITATION CITATION or population CITATION CITATION dynamics have been mathematically modeled to gain insight into the QS phenomenon in Pseudomonas aeruginosa and Vibrio fischeri.
MISC	However, because of the lack of detailed molecular information, experimentally testable conclusions on the connections between intracellular and population dynamics have rarely been made.
OWNX	Here we develop a multi-level modeling approach that describes both the intracellular and the population-wide dynamics and allows us to follow the connections between them explicitly.
MISC	Although much has been learned about the molecular details of the Agrobacterium QS network, it is not always clear what functions they perform.
OWNX	Here we construct a detailed model of the QS network in Agrobacterium and analyze it both quantitatively and qualitatively.
OWNX	We demonstrate that the network possesses properties of the on off gene expression switch robust to molecular noise.
MISC	We further develop a population-scale model that incorporates bacterial motion, cell division, and chemical communication while explicitly considering the individual intracellular dynamics of each cell.
OWNX	This allows us to describe the transition to QS on both cellular and population scales and quantitatively predict the values of critical autoinducer concentration and threshold cell density as functions of various intracellular and environmental parameters.
OWNX	Finally, comparing feasibility of the transition to QS in homogeneous medium and biofilm, we present a hypothesis explaining the ecological and evolutionary roles of QS in regulation of Ti plasmid conjugal transfer.
OWNX	All genes that are thought to constitute the QS network are located on the Ti plasmid itself CITATION.
MISC	The entire QS network is controlled upstream by the availability of the plant-produced opines to ensure that energetically expensive conjugation machinery is activated only after the establishment of a successful plant wound infection.
MISC	Based on the chemical nature of the encoded opines, Ti plasmids are divided into two major types CITATION, of which we consider only the octopine type.
MISC	We reconstructed the layout of the QS network for the octopine-type Ti plasmids from the published experimental data.
OWNX	In this plasmid class, octopine molecules that are imported through the cell wall eventually cause activation of transcription from the operon occ CITATION.
OWNX	In the model, we assume that octopine is constitutively available at the saturating concentration that results in the maximal rate of occ transcription.
OWNX	The last open reading frame of this operon codes for the QS transcription activator TraR.
MISC	Binding of TraR to its cognate autoinducer is thought to occur only within a narrow window of time during traR mRNA translation when the newly formed protein chain tightly winds around a single molecule of Agrobacterium autoinducer CITATION CITATION.
OWNX	This total engulfment of AAI molecule makes formation of the TraR AAI complex practically irreversible.
MISC	Furthermore, TraR protein translated in the absence of AAI is misfolded, insoluble, and unable to bind AAI CITATION, CITATION.
MISC	This has an important consequence in that the rate of production of TraR depends on the concentrations of traR mRNA and AAI and does not depend on the accumulation of misfolded TraR protein, as explicitly shown in Figure 1.
MISC	Once formed, TraR quickly dimerizes to form a stable transcriptionally active TraR dimer with a relatively short half-life of 35 min CITATION.
MISC	TraRd is capable of activating a number of operons that encode proteins necessary for conjugation.
OWNX	The first open reading frame of the trb operon codes for the acyl-homoserine lactone synthetase TraI, which utilizes two metabolites abundant in the bacterial cell to create AAI CITATION.
OWNX	Since our model considers transition to QS in the mostly nutrient-rich, stress-free conditions of an optimized growth medium, we assume that the substrates of TraI are present in excess and their concentrations do not limit the rate of AAI production.
MISC	Both traR and traI were shown to be expressed at some low constitutive rate even in the absence of octopine CITATION.
OWNX	The TraR TraI couple constitutes the classic QS positive feedback loop found in many Gram-negative bacteria.
MISC	Additional feedback loops that also involve other components of the QS network are specific for Agrobacterium.
OWNX	Thus, negative control of QS is provided by the antiactivator traM, whose transcription is directly activated by TraRd CITATION.
MISC	TraM effectively sequesters TraRd through the formation of a very stable complex in which TraRd is unable to bind DNA CITATION, CITATION.
MISC	Recently, a number of authors reported that, like TraR, TraM also forms a dimer CITATION CITATION.
MISC	The stoichiometry of the reaction between TraR and TraM, however, remains controversial CITATION CITATION.
MISC	In our model we follow the original hypothesis of Swiderska et al. CITATION, which assumes that the complex consists of one TraRd and one monomer of TraM.
MISC	This hypothesis is partially supported by Chen et al. CITATION, who showed that the TraM dimer must dissociate to form a complex with TraR.
OWNX	Under these assumptions we disregard dimerization of TraM as not affecting the network behavior.
OWNX	An additional positive feedback loop arises because TraRd activates transcription of the msh operon, which is a suboperon of occ that contains traR itself.
MISC	Several lines of evidence suggest that active transporters facilitate traffic of the QS signaling molecules through the cell wall in a number of bacterial species including Agrobacterium CITATION CITATION.
OWNX	In our model, we explore the hypothesis that AAI is imported from the environment by an active pump that is also under the transcriptional control of TraRd.
OWNX	Indeed, the msh operon contains five open reading frames that encode a putative ABC-type importer whose function is not completely understood but that has been hypothesized to be an active transporter of AAI into the cell CITATION.
OWNX	Taking into consideration this uncertainty, the putative AAI importer in the model is denoted simply as Imp.
OWNX	The AraC family transcription factor MarA activates 40 genes of the Escherichia coli chromosome resulting in different levels of resistance to a wide array of antibiotics and to superoxides.
MISC	Activation of marA/soxS/rob regulon promoters occurs in a well-defined order with respect to the level of MarA; however, the order of activation does not parallel the strength of MarA binding to promoter sequences.
OWNX	To understand this lack of correspondence, we developed a computational model of transcriptional activation in which a transcription factor either increases or decreases RNA polymerase binding, and either accelerates or retards post-binding events associated with transcription initiation.
OWNX	We used the model to analyze data characterizing MarA regulation of promoter activity.
MISC	The model clearly explains the lack of correspondence between the order of activation and the MarA-DNA affinity and indicates that the order of activation can only be predicted using information about the strength of the full MarA-polymerase-DNA interaction.
MISC	The analysis further suggests that MarA can activate without increasing polymerase binding and that activation can even involve a decrease in polymerase binding, which is opposite to the textbook model of activation by recruitment.
MISC	These findings are consistent with published chromatin immunoprecipitation assays of interactions between polymerase and the E. coli chromosome.
MISC	We find that activation involving decreased polymerase binding yields lower latency in gene regulation and therefore might confer a competitive advantage to cells.
OWNX	Our model yields insights into requirements for predicting the order of activation of a regulon and enables us to suggest that activation might involve a decrease in polymerase binding which we expect to be an important theme of gene regulation in E. coli and beyond.
MISC	Transcription factors control cellular protein production by binding to DNA and changing the frequency with which mRNA transcripts are produced.
OWNX	There are hundreds of transcription factors in Escherichia coli and while most of these target only a small number of genes, there are several that regulate expression of ten or more genes.
OWNX	Taken together, such global transcription factors directly regulate more-than half of the 4,300 genes in E. coli and their regulatory interactions yield important insights into the organization of the genetic regulatory network CITATION, CITATION, CITATION.
CONT	Because they regulate so many genes, global transcription factors also play a large role in controlling cellular behavior; however, insights into behavior are currently limited by a lack of quantitative information about how transcription factors differentially regulate target genes.
OWNX	One important global transcription factor is MarA, an AraC family protein that activates 40 genes of the Escherichia coli chromosome resulting in different levels of resistance to a wide array of antibiotics and superoxides.
OWNX	The effect of MarA at different promoters can vary due to changes in the detailed sequence of the DNA-binding site and its distance from and orientation with respect to the promoter CITATION, CITATION.
MISC	These variations can influence the order in which the promoters respond to increasing concentrations of MarA and presumably have important functional consequences for E. coli.
OWNX	To characterize quantitative variations in MarA regulation at different promoters, we recently placed the expression of MarA under the control of the LacI repressor, determined the relationship between isopropyl -D-1-thiogalactopyranoside concentration and the intracellular concentration of MarA, and examined the expression of 10 promoters of the regulon as a function of activator concentration CITATION.
MISC	We found that activation of marA/soxS/rob regulon promoters occurs in a well-defined order with respect to the level of MarA, enabling cells to mount a response that is commensurate to the level of threat detected in the environment.
OWNX	We also found that only the marRAB, sodA, and micF promoters were saturated at the highest level of MarA.
MISC	In contrast with a commonly held assumption, we found that the order of activation does not parallel the strength of MarA binding to promoter sequences.
OWNX	This finding suggested that interactions between MarA and the RNA polymerase transcriptional machinery play an important role in determining the order of activation, but the data did not immediately reveal what the nature of these interactions might be at the various promoters.
AIMX	Here, we have developed a computational model of promoter activity to understand how interactions between MarA and polymerase activate transcription at the marRAB, sodA, and micF promoters of the 10 we examined previously, these three promoters are the only ones that exhibited saturation, which provides an important constraint for the modeling.
MISC	The model was specifically designed to compare a strict recruitment model in which MarA increases polymerase binding but does not increase the rate of post-binding events CITATION, CITATION, with a more general model in which activator can either increase or decrease polymerase binding, and can either increase or decrease the rate of post-binding events.
OWNX	For each promoter, we evaluated the agreement of both the strict recruitment model and the general model with the data at many points within a physically reasonable region of parameter space.
OWNX	The model successfully explains why the order of promoter activation does not parallel the strength of MarA-DNA binding.
OWNX	For all promoters, the best fit of the general model was better than that of the strict recruitment model.
MISC	Comparison to the strict recruitment model and full analysis of the goodness-of-fit landscape suggest that MarA does not increase polymerase binding but does increase the rate of post-binding events at these promoters.
OWNX	Moreover, the analysis for the micF promoter suggests that MarA activation can involve a decrease in polymerase binding that is associated with low latency in gene regulation.
OWNX	We discuss the broader significance of these findings.
MISC	One of the major goals of structural genomics projects is to determine the three-dimensional structure of representative members of as many different fold families as possible.
OWNX	Comparative modeling is expected to fill the remaining gaps by providing structural models of homologs of the experimentally determined proteins.
MISC	However, for such an approach to be successful it is essential that the quality of the experimentally determined structures is adequate.
AIMX	In an attempt to build a homology model for the protein dynein light chain 2A we found two potential templates, both experimentally determined nuclear magnetic resonance structures originating from structural genomics efforts.
MISC	Despite their high sequence identity, the folds of the two structures are markedly different.
OWNX	This urged us to perform in-depth analyses of both structure ensembles and the deposited experimental data, the results of which clearly identify one of the two models as largely incorrect.
OWNX	Next, we analyzed the quality of a large set of recent NMR-derived structure ensembles originating from both structural genomics projects and individual structure determination groups.
MISC	Unfortunately, a visual inspection of structures exhibiting lower quality scores than DLC2A reveals that the seriously flawed DLC2A structure is not an isolated incident.
CONT	Overall, our results illustrate that the quality of NMR structures cannot be reliably evaluated using only traditional experimental input data and overall quality indicators as a reference and clearly demonstrate the urgent need for a tight integration of more sophisticated structure validation tools in NMR structure determination projects.
MISC	In contrast to common methodologies where structures are typically evaluated as a whole, such tools should preferentially operate on a per-residue basis.
OWNX	Experimentally determined three-dimensional structures of biomolecules form the foundation of structural bioinformatics, and any structural analysis would be impossible without them.
OWNX	Two main techniques are available for biomolecular structure determination: x-ray crystallography and nuclear magnetic resonance spectroscopy.
MISC	It is important to realize that all resulting structure models are derived from their underlying experimental data.
MISC	Unfortunately, any experiment and thus any structure model will have errors associated with it.
MISC	Random errors depend on the precision of the experimental measurements and are propagated to the precision of the final models.
OWNX	Systematic errors and mistakes often result from errors in the interpretation of the experimental data and relate directly to the accuracy of the final structure models.
MISC	For example, in NMR spectroscopy errors can be introduced by misassignment of the spectral signals; in x-ray crystallography errors are most likely made when the protein structure is positioned in the electron density CITATION, CITATION .
MISC	Several studies have shown that not all experimentally determined biomolecular structure models are of equally high quality CITATION CITATION.
MISC	Many different types of errors can be identified in protein structures, ranging from too tightly restrained bond lengths and angles, to molecules exhibiting a completely incorrect fold.
MISC	Where the former type of errors often does not have large consequences for the analysis of the structure and typically can be easily remedied by refinement in a proper force field CITATION, CITATION, the latter renders a structure model completely useless for all practical purposes.
MISC	Throughout the years several such errors have been uncovered in the Protein Data Bank CITATION, which often resulted in the replacement of the incorrect models with improved ones.
MISC	A typical example of an incorrectly folded structure model is the first crystal structure of photoactive yellow protein.
OWNX	The structure was solved initially in 1989 CITATION and deposited under the now obsolete PDB entry 1PHY.
MISC	An updated model released 6 y later showed that in the original model the electron density had been misinterpreted CITATION.
MISC	Similar chain tracing problems led to an incorrect model for a DD-peptidase CITATION, which was corrected 10 y later when the structure was solved again but now at higher resolution CITATION .
MISC	Also, for structures determined using NMR spectroscopy, cases are known where reevaluation of the experimental data, often prompted by publication of a corresponding structure, has resulted in the replacement of structures in the PDB.
MISC	A well-known example is the original NMR structure of the oligomerization domain of p53 CITATION.
OWNX	In this dimer of dimers, a difference in the orientation of the two dimers was observed between the NMR and crystal structure, the latter published shortly after the NMR structure CITATION.
MISC	Reexamination of the nuclear Overhauser enhancement data led to the identification of three misinterpreted peaks in the original p53 NOE assignments and the inclusion of several new NOEs, resulting in a revision of the original PDB entry CITATION.
MISC	A similar low number of misinterpreted NOE signals resulted in a largely incorrect fold for the anti factor AsiA CITATION.
MISC	In this case, it was not until a second solution structure of AsiA was published CITATION that the experimental data of the original AsiA structure were reexamined and the assignment errors were discovered CITATION .
AIMX	In this paper, we describe a detailed analysis of two recently released NMR structures of the protein dynein light chain 2A, one from human and one from mouse.
MISC	Both structures originate from large structural genomics initiatives: the structure of human DLC2A was determined by the Northeast Structural Genomics Consortium, and the mouse variant was determined by the Center for Eukaryotic Structural Genomics.
OWNX	Despite 96 percent sequence identity, large structural differences are observed between the two ensembles; an unexpected and extremely unlikely result.
OWNX	Using the deposited experimental data we show that only the 1Y4O structure ensemble is correct.
OWNX	Subsequently, we analyze both ensembles using various structure and data validation methods to show that the erroneous structure ensemble could have been identified prior to deposition.
MISC	Finally, we validate a large set of protein NMR structures that were released from the PDB in the period 2003 to 2005 and show that the DLC2A example does not stand on its own, but that more errors of this magnitude can be found.
MISC	We conclude with some suggestions on how, in the future, such large errors can be identified during the structure determination process using readily available validation software.
MISC	Hidden Markov Models (HMMs) are one of the most fundamental and widely used statistical tools for modeling discrete time series
MISC	In general, learning HMMs from data is computationally hard (under cryptographic assumptions), and practitioners typically resort to search heuristics which suffer from the usual local optima issues
OWNX	We prove that under a natural separation condition (bounds on the smallest singular value of the HMM parameters), there is an efficient and provably correct algorithm for learning HMMs
MISC	The sample complexity of the algorithm does not explicitly depend on the number of distinct (discrete) observations---it implicitly depends on this quantity through spectral properties of the underlying HMM
MISC	This makes the algorithm particularly applicable to settings with a large number of observations, such as those in natural language processing where the space of observation is sometimes the words in a language
MISC	The algorithm is also simple, employing only a singular value decomposition and matrix multiplications
MISC	Hidden Markov Models (HMMs)  CITATION  are the workhorse statistical model for discrete time series, with widely diverse applications including automatic speech recognition, natural language processing (NLP), and genomic sequence modeling
MISC	In this model, a discrete hidden state evolves according to some Markovian dynamics, and observations at a particular time depend only on the hidden state at that time
MISC	The learning problem is to estimate the model only with observation samples from the underlying distribution
MISC	Thus far, the predominant learning algorithms have been local search heuristics, such as the Baum-Welch / EM algorithm  CITATION
MISC	It is not surprising that practical algorithms have resorted to heuristics, as the general learning problem has been shown to be hard under cryptographic assumptions  CITATION
OWNX	Fortunately, the hardness results are for HMMs that seem divorced from those that we are likely to encounter in practical applications
MISC	The situation is in many ways analogous to learning mixture distributions with samples from the underlying distribution
MISC	There, the general problem is also believed to be hard
MISC	However, much recent progress has been made when certain separation assumptions are made with respect to the component mixture distributions ( eg ~ CITATION )
MISC	Roughly speaking, these separation assumptions imply that with high probability, given a point sampled from the distribution, one can determine the mixture component that generated the point
MISC	In fact, there is a prevalent sentiment that we are often only interested in clustering when such a separation condition holds
OWNX	Much of the theoretical work here has focused on how small this separation can be and still permit an efficient algorithm to recover the model
OWNX	We present a simple and efficient algorithm for learning HMMs under a certain natural separation condition
OWNX	We provide two results for learning
OWNX	The first is that we can approximate the joint distribution over observation sequences of length  SYMBOL  (here, the quality of approximation is measured by total variation distance)
MISC	As  SYMBOL  increases, the approximation quality degrades polynomially
OWNX	Our second result is on approximating the  conditional  distribution over a future observation, conditioned on some history of observations
MISC	We show that this error is asymptotically bounded--- i e ~for any  SYMBOL , conditioned on the observations prior to time  SYMBOL , the error in predicting the  SYMBOL -th outcome is controlled
OWNX	Our algorithm can be thought of as `improperly' learning an HMM in that we do not explicitly recover the transition and observation models
OWNX	However, our model does maintain a hidden state representation which is closely (in fact, linearly) related to the HMM's, and can be used for interpreting the hidden state
OWNX	The separation condition we require is a spectral condition on both the observation matrix and the transition matrix
OWNX	Roughly speaking, we require that the observation distributions arising from distinct hidden states be distinct (which we formalize by singular value conditions on the observation matrix)
MISC	This requirement can be thought of as being weaker than the separation condition for clustering in that the observation distributions can overlap quite a bit---given one observation, we do not necessarily have the information to determine which hidden state it was generated from (unlike in the clustering literature)
MISC	We also have a spectral condition on the correlation between adjacent observations
MISC	We believe both of these conditions to be quite reasonable in many practical applications
MISC	Furthermore, given our analysis, extensions to our algorithm which relax these assumptions should be possible
OWNX	The algorithm we present has both polynomial sample and computational complexity
OWNX	Computationally, the algorithm is quite simple---at its core is a singular value decomposition (SVD) of a correlation matrix between past and future observations
MISC	This SVD can be viewed as a Canonical Correlation Analysis (CCA)~ CITATION  between past and future observations
OWNX	The sample complexity results we present do not explicitly depend on the number of distinct observations; rather, they implicitly depend on this number through spectral properties of the HMM
MISC	This makes the algorithm particularly applicable to settings with a large number of observations, such as those in NLP where the space of observations is sometimes the words in a language
AIMX	in the current paper we investigate how feedback over decision outcomes may affect future decisions
OWNX	in an experimental study we demonstrate that if people receive feedback over the outcomes they obtained  factual outcomes  and the outcomes they would have obtained had they decided differently  counterfactual outcomes   they become regret-averse in subsequent decisions
MISC	this effect is not only observed when this feedback evoked regret with counterfactual outcomes being higher than factual outcomes  but even when the feedback evoked no regret with factual outcomes being equal to counterfactual outcomes
MISC	the findings suggest that this effect on subsequent decisions is at least partly due to the transfer of a comparison mind-set triggered in the prior choice
MISC	regret is a negative experience that most of us would want to avoid
MISC	it stems from comparing an obtained decision outcome to outcomes that might have been had one chosen differently  CITATION
MISC	research on regret has consistently shown that the anticipation of regret and the motivation to avoid regret drives many of our decisions
MISC	although the literature on regret distinguishes between experienced regret and anticipated regret  it does acknowledge a connection between the two in the sense that the experience of current regret may affect the anticipation of future regret  CITATION
MISC	in agreement with this notion  creyer and ross  CITATION  found that experienced regret on a bidding subsequently led to more risk averse biddings
MISC	more specifically  it led people to subsequently prefer high probability  low payoff options over low probability  high payoff options
MISC	also  in the context of consumer decision making  cooke et al CITATION  showed that experienced regret over a first decision influenced subsequent purchase decisions
MISC	in a similar vein  zeelenberg and pieters  CITATION  showed that experienced regret led consumers to switch to a different product
MISC	in these studies  the effect of experienced regret on subsequent decisions was domain-specific  in the sense that for example regret on purchasing a specific product was found to affect subsequent purchases of the same or similar product
MISC	more recently  however  raeva  mittone  and schwarzbach  CITATION  found that the effects of experienced regret might be broader in scope and even extend to decisions in other domains
MISC	in their study  regret over a risky decision affected subsequent decisions in an intertemporal choice setting
MISC	after playing a gamble  participants who learned that they could have obtained higher outcomes had they decided differently i e   had they played another gamble showed a stronger time preference  CITATION
MISC	time preference does not refer to a comparison between factual and counterfactual outcomes  and it is not related to the traditional gamble paradigm  and thus pertains to a different domain than the one in which participants experienced regret
OWNX	so how should we explain these findings
MISC	for the domain-specific effects of experienced regret on subsequent choice  the most straightforward explanation would be that after the experience of regret  decision-makers merely learn that they should not repeat their mistake  and thus change their behavior i e    once bitten  twice shy 
OWNX	this would be consistent with most models of emotion regulation  CITATION  and more specifically regret regulation  CITATION
MISC	for the broader effects of experienced regret  however  such an explanation in terms of learning may not suffice
MISC	after all  after experiencing regret in a risky setting  it does not directly follow that one can avoid making the same  mistake  by showing a strong time preference
MISC	note  however  that even for the non-domain specific effects of regret one could envisage a carry-over process by assuming that it is not the specific decision-related regret that carries over to subsequent decisions  but rather that it is a more unspecified nature of regret that carries over
MISC	that is  the experience of regret may sensitize decision makers to future experiences of regret  and increase their motivation to avoid anticipated regret
MISC	rather than concluding that they do not want to make the same mistake twice  decision makers may reason that they do not want to experience the same negative emotion twice
MISC	it is this explanation that was favored by raeva et al CITATION
MISC	we do not want to dispute the regret-specific explanations that have been put forward in previous research
OWNX	however  we do want to draw attention to an additional  as yet unexplored and more general process that may result from the experience of regret  the experience of regret may lead to a carry-over of a comparative mind-set  CITATION
MISC	one of the defining characteristics of regret is that it is an emotion that it results from comparing  what is  to  what could have been 
MISC	when the obtained outcomes what is after making a choice compare unfavorable to the outcomes one could have obtained  decision-makers will experience regret
MISC	the comparing of decision outcomes is therefore essential to the experience of regret  if you don't compare  you don't regret  CITATION
OWNX	in the current paper we draw attention to the consequences of making such a comparison
MISC	in particular we suggest the mere fact of making comparative judgments about decision outcomes may already elicit a comparative mind-set  and this mind-set may carry-over to subsequent decisions
MISC	xu and wyer  CITATION  recently demonstrated such a carry-over effect in a series of studies on purchase decisions
MISC	for example  in one of their experiments  they presented participants with an opportunity to buy one out of four types of products chocolate bars  potato chips  chewing gum  and pens
OWNX	to choose and buy one of these products  one needs to compare the products
MISC	consistent with their comparative mind-set idea  participants' willingness to purchase one of these products increased if previously they had completed a task requiring them to compare animals to each other e g   comparing elephants to hippos
MISC	in other words  the evoked comparative mind-set in the animals task carried over to the product purchase task
MISC	in more general terms  xu and wyer p  NUMBER  described a carry-over of a  comparative mind-set that  once activated  persist to influence behaviors and decisions in other situations in which comparison processes might come into play
MISC	 in agreement with these insights we here suggest that the experience of regret  which is critically dependent on the comparison of  what is  to  what could have been   may evoke a comparative mind-set  and that this comparative mind-set persists to influence subsequent decision-making
OWNX	to investigate this possibility  we designed an experiment in which participants made two successive decisions
MISC	first  we presented participants with a decision task in which they would or would not experience regret
OWNX	subsequently  we presented them with a different task a matching task in which they had to match two options in terms of attractiveness
MISC	to induce regret on the first task  participants were presented with a situation in which they obtained low outcomes and learned that they would have obtained higher outcomes had they chosen differently
AIMX	to investigate the idea that-at least part of-the effects of this induction of regret may be attributed to the invoked comparative mind-set  we also included several alternative inductions
OWNX	in some  we presented our participants with the same low outcomes  but we did not inform them of the outcomes they could have obtained had they chosen differently
MISC	in these conditions  participants thus obtained low outcomes but could not compare their outcomes to what could have been
MISC	in the absence of a comparison of decision outcomes  people could therefore not regret their decision
MISC	this is consistent with bell  CITATION   who argued that  key to the identification of regret as a factor in decision making under uncertainty is the hypothesis that it may matter whether a foregone lottery is resolved or not
OWNX	this is the predicted phenomenon on which experimentation should be concentrated
MISC	  indeed  studies followed up on this advice and found that decision makers are most likely to anticipate regret when expecting feedback  CITATION
MISC	in another condition  however  we did inform the participants about the outcome they would have obtained had they chosen differently  but told them that this outcome would have yielded exactly the same outcome
MISC	note that this condition is crucial  because in this condition too  participants would experience no regret  but this no-regret would now be the result of a similar comparison process  in this case  the conclusion that there is nothing to regret also results from a comparison of  what is  with  what could have been
MISC	 this experimental setup allowed us to investigate the plausibility of our general comparative mind-set explanation versus more specific explanations such as the learning and regret sensitivity explanations put forward in prior research
MISC	if the effects of experienced regret on the subsequent decisions would primarily be the result of a carry-over of the specific experience of regret  we should find that the effects would be observed only in the condition in which we induced regret
MISC	Images can be segmented by first using a classifier to predict an affinity graph that reflects the degree to which image pixels must be grouped together and then partitioning the graph to yield a segmentation
MISC	Machine learning has been applied to the affinity classifier to produce affinity graphs that are good in the sense of minimizing edge misclassification rates
MISC	However, this error measure is only indirectly related to the quality of segmentations produced by ultimately partitioning the affinity graph
MISC	We present the first machine learning algorithm for training a classifier to produce affinity graphs that are good in the sense of producing segmentations that directly minimize the Rand index, a well known segmentation performance measure
MISC	The Rand index measures segmentation performance by quantifying the classification of the connectivity of image pixel pairs after segmentation
MISC	By using the simple graph partitioning algorithm of finding the connected components of the thresholded affinity graph, we are able to train an affinity classifier to directly minimize the Rand index of segmentations resulting from the graph partitioning
MISC	Our learning algorithm corresponds to the learning of maximin affinities between image pixel pairs, which are predictive of the pixel-pair connectivity
MISC	Supervised learning has emerged as a serious contender in the field of image segmentation, ever since the creation of training sets of images with {}``ground truth'' segmentations provided by humans, such as the Berkeley Segmentation Dataset  CITATION
OWNX	Supervised learning requires 1) a parametrized algorithm that map images to segmentations, 2) an objective function that quantifies the performance of a segmentation algorithm relative to ground truth, and 3) a means of searching the parameter space of the segmentation algorithm for an optimum of the objective function
MISC	In the supervised learning method presented here, the segmentation algorithm consists of a parametrized  classifier  that predicts the weights of a nearest neighbor affinity graph over image pixels, followed by a graph  partitioner  that thresholds the affinity graph and finds its connected components
MISC	Our objective function is the Rand index  CITATION , which has recently been proposed as a quantitative measure of segmentation performance  CITATION
MISC	We {}``soften'' the thresholding of the classifier output and adjust the parameters of the classifier by gradient learning based on the Rand index
OWNX	Because maximin edges of the affinity graph play a key role in our learning method, we call it  maximin affinity learning of image segmentation , or MALIS
MISC	The minimax path and edge are standard concepts in graph theory, and maximin is the opposite-sign sibling of minimax
OWNX	Hence our work can be viewed as a machine learning application of these graph theoretic concepts
MISC	MALIS focuses on improving classifier output at maximin edges, because classifying these edges incorrectly leads to genuine segmentation errors, the splitting or merging of segments
OWNX	To the best of our knowledge, MALIS is the first supervised learning method that is based on optimizing a genuine measure of segmentation performance
MISC	The idea of training a classifier to predict the weights of an affinity graph is not novel
OWNX	Affinity classifiers were previously trained to minimize the number of misclassified affinity edges  CITATION
MISC	This is not the same as optimizing segmentations produced by partitioning the affinity graph
MISC	There have been attempts to train affinity classifiers to produce good segmentations when partitioned by normalized cuts  CITATION
MISC	But these approaches do not optimize a genuine measure of segmentation performance such as the Rand index
OWNX	The work of Bach and Jordan  CITATION  is the closest to our work
MISC	However, they only minimize an upper bound to a renormalized version of the Rand index
OWNX	Both approaches require many approximations to make the learning tractable
MISC	In other related work, classifiers have been trained to optimize performance at detecting image pixels that belong to object boundaries  CITATION
MISC	Our classifier can also be viewed as a boundary detector, since a nearest neighbor affinity graph is essentially the same as a boundary map, up to a sign inversion
OWNX	However, we combine our classifier with a graph partitioner to produce segmentations
OWNX	The classifier parameters are not trained to optimize performance at boundary detection, but to optimize performance at segmentation as measured by the Rand index
MISC	There are also methods for supervised learning of image labeling using Markov or conditional random fields  CITATION
MISC	But image labeling is more similar to multi-class pixel classification rather than image segmentation, as the latter task may require distinguishing between multiple objects in a single image that all have the same label
MISC	In the cases where probabilistic random field models have been used for image parsing and segmentation, the models have either been simplistic for tractability reasons  CITATION  or have been trained piecemeal
MISC	For instance, Tu et al CITATION  separately train low-level discriminative modules based on a boosting classifier, and train high-level modules of their algorithm to model the joint distribution of the image and the labeling
MISC	These models have never been trained to minimize the Rand index
MISC	We describe comparative patch analysis for modeling the structures of multidomain proteins and protein complexes, and apply it to the PSD-95 protein.
OWNX	Comparative patch analysis is a hybrid of comparative modeling based on a template complex and protein docking, with a greater applicability than comparative modeling and a higher accuracy than docking.
MISC	It relies on structurally defined interactions of each of the complex components, or their homologs, with any other protein, irrespective of its fold.
MISC	For each component, its known binding modes with other proteins of any fold are collected and expanded by the known binding modes of its homologs.
MISC	These modes are then used to restrain conventional molecular docking, resulting in a set of binary domain complexes that are subsequently ranked by geometric complementarity and a statistical potential.
MISC	The method is evaluated by predicting 20 binary complexes of known structure.
MISC	It is able to correctly identify the binding mode in 70 percent of the benchmark complexes compared with 30 percent for protein docking.
MISC	We applied comparative patch analysis to model the complex of the third PSD-95, DLG, and ZO-1 domain and the SH3-GK domains in the PSD-95 protein, whose structure is unknown.
OWNX	In the first predicted configuration of the domains, PDZ interacts with SH3, leaving both the GMP-binding site of guanylate kinase and the C-terminus binding cleft of PDZ accessible, while in the second configuration PDZ interacts with GK, burying both binding sites.
MISC	We suggest that the two alternate configurations correspond to the different functional forms of PSD-95 and provide a possible structural description for the experimentally observed cooperative folding transitions in PSD-95 and its homologs.
OWNX	More generally, we expect that comparative patch analysis will provide useful spatial restraints for the structural characterization of an increasing number of binary and higher-order protein complexes.
MISC	Protein protein interactions play a key role in many cellular processes CITATION, CITATION.
MISC	An important step towards a mechanistic description of these processes is a structural characterization of the proteins and their complexes CITATION CITATION.
MISC	Currently, there are two computational approaches to predict the structure of a protein complex given the structures of its components, comparative modeling CITATION CITATION and protein protein docking CITATION CITATION .
MISC	In the first approach to modelling a target complex, standard comparative modelling or threading methods build a model using the known structure of a homologous complex as a template CITATION, CITATION.
OWNX	The applicability of this approach is limited by the currently sparse structural coverage of binary interactions CITATION.
MISC	In the second approach, an atomic model is predicted by protein protein docking, starting from the structures of the individual subunits without any consideration of homologous interactions CITATION CITATION.
MISC	This docking is usually achieved by maximizing the shape and physicochemical complementarity of two protein structures, through generating and scoring a large set of possible configurations CITATION, CITATION.
MISC	Experimental information, such as that obtained from NMR chemical shift mapping, residual dipolar couplings, and cross-linking, can also be used to guide protein docking CITATION CITATION.
OWNX	While docking is applicable to any two subunits whose structures are known or modeled, both the sampling of relevant configurations and the discrimination of native-like configurations from the large number of non-native alternatives remain challenging CITATION .
OWNX	Here, we propose a third approach to modeling complexes between two structures.
MISC	The approach, called comparative patch analysis, is a hybrid of protein docking and comparative modeling based on a template complex, with a greater applicability than comparative modeling and a higher accuracy than docking.
MISC	Comparative patch analysis relies on our prior analysis of the location of binding sites within families of homologous domains CITATION.
MISC	This analysis indicated that the locations of the binding sites are often conserved irrespective of the folds of their binding partners.
MISC	The structure of the target complex can thus be modeled by restricting protein docking to only those binding sites that are employed by homologous domains.
OWNX	As a result, comparative patch analysis benefits from knowledge of all interactions involving either one of the two partners.
OWNX	We find that comparative patch analysis increases the prediction accuracy relative to protein docking.
MISC	It is able to correctly identify the binding mode in 70 percent of 20 benchmark complexes, predicting the overall structure with an average improvement in all-atom RMS error of 13.4, compared with protein docking.
OWNX	In contrast, protein docking correctly identifies the binding mode in 30 percent of the complexes.
MISC	We have developed a multi-scale biophysical electromechanics model of the rat left ventricle at room temperature.
MISC	This model has been applied to investigate the relative roles of cellular scale length dependent regulators of tension generation on the transduction of work from the cell to whole organ pump function.
MISC	Specifically, the role of the length dependent Ca 2 sensitivity of tension, filament overlap tension dependence, velocity dependence of tension, and tension dependent binding of Ca 2 to Troponin C on metrics of efficient transduction of work and stress and strain homogeneity were predicted by performing simulations in the absence of each of these feedback mechanisms.
MISC	The length dependent Ca 50 and the filament overlap, which make up the Frank-Starling Law, were found to be the two dominant regulators of the efficient transduction of work.
MISC	Analyzing the fiber velocity field in the absence of the Frank-Starling mechanisms showed that the decreased efficiency in the transduction of work in the absence of filament overlap effects was caused by increased post systolic shortening, whereas the decreased efficiency in the absence of length dependent Ca 50 was caused by an inversion in the regional distribution of strain.
OWNX	Contraction of the heart is a fundamental whole organ phenomenon driven by cellular mechanisms.
MISC	With each beat the myocytes in the heart generate tension and relax.
MISC	This local cellular scale tension is transduced into a coordinated global whole heart deformation resulting in an effective, organized and efficient system level pump function.
OWNX	Fundamental to achieving this efficient transudation of work is the integration of organ, tissue and cellular scale mechanisms.
MISC	However, while efficiency is important in the heart, the role and relative importance of the underlying mechanisms responsible for achieving the efficient transduction of work from the cell to the organ remains unclear.
OWNX	In the healthy heart, structural heterogeneities in the morphology, electrophysiology, metabolic and neural mechanisms provide a stable physiological framework that facilitates a coordinated contraction CITATION resulting in the ETW.
OWNX	However, over shorter time scales, sub cellular mechanisms are the most likely candidates for regulating the ETW in the face of dynamic variation in cardiac demand.
MISC	Specifically, the sarcomeres themselves contain tension and deformation feedback mechanisms that regulate the development of active tension based on the local tension, strain and strain rate.
MISC	These provide a regulatory process to modulate deformation and tension signals experienced by the cell into a coordinated global response CITATION CITATION .
MISC	The four major TDF mechanisms are length dependent changes in Ca 2 sensitivity CITATION, filament overlap CITATION, tension dependent binding of Ca 2 to troponin C CITATION and velocity dependent cross bridge kinetics CITATION.
OWNX	TDF mechanisms 1 and 2 are characterised by the length dependent changes in the steady state force Ca 2 relationship, which is routinely described by a Hill curve CITATION, CITATION.
MISC	Length dependent changes in Ca 50 are measured by the decreased concentration of Ca 2 required to produce half maximal activation as the muscle increases in length.
OWNX	Length dependent changes in the filament overlap result in active tension increasing as the muscle increases in length.
MISC	Ca 2 binding to TnC acts as a switch activating tension generation.
MISC	As crossbridges bind to generate tension they increase the affinity of Ca 2 to TnC causing more Ca 2 to bind, which results in the generation of more tension.
OWNX	The velocity dependence of tension can be described by a transient and stable component.
MISC	The transient component is characterised by the multiphase tension response to step changes in length and the stable component is characterised by the tension during contraction at a constant velocity.
OWNX	In general as the velocity of contraction increases the active tension decreases.
MISC	These four mechanisms provide both positive and negative feedback for tension development and are fundamental to the functioning of the heart, yet their relative roles, if any, in the ETW have not been investigated.
MISC	This is in part due to the experimental challenges in studying subcellular function in whole heart preparations CITATION and the modelling challenges in performing biophysical whole organ coupled electromechanics simulations CITATION, CITATION.
MISC	Recent advances in computer power and coupling methods CITATION now allow the simulation of strongly coupled multi-scale electromechanical models of the left ventricle.
MISC	These models contain explicit biophysical representations of cellular electrophysiology, Ca 2 dynamics, tension generation, deformation and the multiple feedback loops that operate between each of these systems.
OWNX	In this study we analyse the transduction of local cellular scale work into whole organ pressure-volume work in the heart using computational modelling.
OWNX	Using the definitions of Hill CITATION for positive and negative work, we propose a new metric to quantify the ETW during each phase of the contraction cycle as the ratio of positive work to total work.
MISC	To isolate and quantify the role of TDF in the transduction of cellular work into whole organ pump function over a heart beat we have developed a model of the rat left ventricle, at room temperature, that incorporates the TDF mechanisms.
MISC	The model contains a biophysical electromechanical rat myocyte model CITATION, transversely isotropic constitutive law CITATION and heterogeneous fiber orientation CITATION.
OWNX	By comparing the ETW over each phase of the heart beat in the absence of each of the TDF mechanisms we aim to quantify the effect of each of the TDF mechanisms.
MISC	the deliberation without attention dwa effect refers to apparent improvements in decision-making following a period of distraction
MISC	it has been presented as evidence for beneficial unconscious cognitive processes
OWNX	we identify two major concerns with this claim  first  as these demonstrations typically involve subjective preferences  the effects of distraction cannot be objectively assessed as beneficial  second  there is no direct evidence that the dwa manipulation promotes unconscious decision processes
MISC	we describe two tasks based on the dwa paradigm in which we found no evidence that the distraction manipulation led to decision processes that are subjectively unconscious  nor that it reduced the influence of presentation order upon performance
MISC	crucially  we found that a lack of awareness of decision process was associated with poorer performance  both in terms of subjective preference measures used in traditional dwa paradigm and in an equivalent task where performance can be objectively assessed
MISC	therefore  we argue that reliance on conscious memory itself can explain the data
OWNX	thus the dwa paradigm is not an adequate method of assessing beneficial unconscious thought
MISC	decision theorists have long distinguished between analytical and intuitive decision making  CITATION   often attributing them with different processing modes  CITATION
MISC	despite the flourishing theoretical literature supporting this dichotomous view  the number of empirical attempts to contrast the effects of intuition and deliberation is limited
MISC	one reason for this lack of research is the difficulty of assessing the goodness of any particular decision  CITATION
MISC	another reason could originate from the traditional assumption that reasoning and analysis always lead to better outcomes  CITATION
MISC	nevertheless  some of the theories subscribing to this dichotomous view assume that under certain circumstances intuitive decisions can bring more optimal results than rational thinking
OWNX	a number of empirical studies have given support to this notion  suggesting that for some tasks we are really better off without conscious thinking  CITATION
MISC	these results were often explained by the hypothesis that reasoning can lead people to use non-optimal criteria and consequently to make worse decisions  CITATION   or that intuitive decisions can benefit from the use of  smart heuristics   CITATION
OWNX	dijksterhuis and his colleagues  however  propose an alternative explanation for superior performance when analytic strategies are not used
MISC	according to unconscious thought theory  CITATION  intuitive decisions may benefit from unconscious thought  a high capacity process which can weight numerous pieces of information and integrate them into decisions automatically and via distributed  bottom-up processing
MISC	they argue that this  smart  unconscious process is more capable in complex  information-dense decision situations than conscious thought  which is limited by working memory capacity
MISC	empirical support for utt comes primarily from the deliberation-without-attention dwa paradigm  CITATION  in which participants are presented with a list of positive and negative attributes describing a variety of possible choices within a particular category e g   apartments
MISC	the opportunity for thinking before choosing is manipulated across three conditions  participants in the immediate decision condition make their decision at once  those in the conscious thought condition have four minutes to think  those in the unconscious thought condition make a choice after four minutes performance on an irrelevant task
MISC	according to utt  the best choices will be made by participants in the unconscious thought condition  because the irrelevant task interval provides an opportunity for unconscious processing of information
OWNX	by contrast  the conscious thought condition is assumed to promote choices based on limited-capacity  conscious processing
MISC	as has been noted previously  CITATION   it is also possible that a forced delay between evaluation which may be completed early in the four minute interval and response in the conscious thought condition may somehow e g   by self-generated interference reduce performance  the immediate decision condition acts as a baseline  providing control for this counterintuitive effect of forced delay
MISC	initial studies using this paradigm provided many illustrations of this  dwa effect   supporting for utt  CITATION
MISC	however  several recent papers have challenged this interpretation and questioned the degree of support the original paradigm offers for utt
MISC	a series of studies has reported a failure to replicate the original results  CITATION
MISC	others have found that the effect may only occur under specific circumstances  CITATION
MISC	acker  CITATION  used a meta-analysis to determine that the benefit for choices following unconscious thought in the first  NUMBER  studies published was modest mean effect size g     NUMBER 
MISC	a more recent meta-analysis of  NUMBER  studies strick et al   n d reported a similar effect size g    NUMBER   which the authors propose as evidence for important moderators of the effect in the different designs of the task
MISC	are people willing to gamble more for themselves than what they deem reasonable for others
OWNX	we addressed this question in a simplified computer gambling task in which subjects chose from a set of  NUMBER  cards
MISC	subjects selected one card at a time after being instructed that  NUMBER  cards were good win a dollar per card and one was really bad lose all the money and end the game
MISC	subjects could stop playing at any time to collect their winnings
MISC	some subjects played the game  others observed a confederate
MISC	both groups took risks beyond what was rational i e    NUMBER  cards but  textit actors  were riskier than  textit observers 
MISC	the actor observer asymmetry occurred even after controlling for monetary outcome i e   having observers win prizes and after controlling for how the question was framed i e   asking observers what they themselves  textit would  do as opposed to what the confederate  textit should  do
OWNX	we discuss these results in relation to theories of decision making that emphasize separate contributions of rational and experiential systems
MISC	you are at the casino watching a game of black jack  when a player who has a hand of sixteen asks for another card
MISC	you quip to yourself  what an idiot
MISC	he should have held at  NUMBER 
MISC	  but who's to say you wouldn't have done the same
MISC	after all  decision making for the self is likely to depend on cues and processes that are not available when judging the choices of others
MISC	the reward of having drawn a good card  the prospect of winning  the potential regret of overreaching  all are blunted to a detached observer
MISC	then again  you may reach the same decision whether you are an actor or observer  as much of the information needed  including success probability  prize size  and potential loss are all available for a  rational  choice
MISC	as this example illustrates  decision making is influenced both by rational and experiential factors  CITATION
MISC	the rational processes are effortful and logical  using a cost benefit analysis to determine the best choice  CITATION
MISC	in contrast  the experiential processes are intuitive and emotionally-based  using heuristics and the history of reward and punishment to determine the next behavior  CITATION
MISC	presumably  experiential processes weigh more heavily in actors' decisions than in observers' judgments  CITATION
MISC	one reason for this is that actors may have privileged access to their own affective reactions  CITATION
MISC	furthermore  actors' affective system is tapped by rewards and punishments  CITATION
MISC	in contrast  observers usually are not affected by these and  when they are  the influence of rewards and punishments is diminished by their being decoupled from the action
MISC	in simple terms  it can be argued that rewarded actions will show a tendency to be repeated
MISC	thus  the occurrence of reward should motivate actors to repeat the rewarded action with disregard for the potential costs and beyond what observers would deem reasonable
OWNX	in the current study  we explored this specific instance of the actor observer asymmetry and its relation to the rational experiential dichotomy
OWNX	for this  we used a modified version of a task first developed for studying risk taking in children  CITATION
MISC	in this paradigm  ten cards were displayed on the computer screen and subjects were told that nine cards were good and would pay a dollar each  while one card was disastrous and would make them lose all the money they had collected thus ending the game
MISC	subjects turned one card at a time and decided when to stop to collect their prize
MISC	the task could be solved by deciding in advance how many cards to turn  or sequentially by deciding whether to turn the next card
MISC	either way  the expected value in this task is highest for turning five cards  CITATION
MISC	thus  a rational decision maker should stop after turning  NUMBER  cards
MISC	in two experiments  we explored possible departures from rational decision making  and whether such departures were moderated by active task participation
OWNX	A prevailing theory proposes that the brain's two visual pathways, the ventral and dorsal, lead to differing visual processing and world representations for conscious perception than those for action.
OWNX	Others have claimed that perception and action share much of their visual processing.
OWNX	But which of these two neural architectures is favored by evolution?
OWNX	Successful visual search is life-critical and here we investigate the evolution and optimality of neural mechanisms mediating perception and eye movement actions for visual search in natural images.
MISC	We implement an approximation to the ideal Bayesian searcher with two separate processing streams, one controlling the eye movements and the other stream determining the perceptual search decisions.
OWNX	We virtually evolved the neural mechanisms of the searchers' two separate pathways built from linear combinations of primary visual cortex receptive fields by making the simulated individuals' probability of survival depend on the perceptual accuracy finding targets in cluttered backgrounds.
OWNX	We find that for a variety of targets, backgrounds, and dependence of target detectability on retinal eccentricity, the mechanisms of the searchers' two processing streams converge to similar representations showing that mismatches in the mechanisms for perception and eye movements lead to suboptimal search.
MISC	Three exceptions which resulted in partial or no convergence were a case of an organism for which the targets are equally detectable across the retina, an organism with sufficient time to foveate all possible target locations, and a strict two-pathway model with no interconnections and differential pre-filtering based on parvocellular and magnocellular lateral geniculate cell properties.
MISC	Thus, similar neural mechanisms for perception and eye movement actions during search are optimal and should be expected from the effects of natural selection on an organism with limited time to search for food that is not equi-detectable across its retina and interconnected perception and action neural pathways.
OWNX	Neurophysiology studies of the macaque monkey CITATION CITATION support the existence of two functionally distinct neural pathways in the brain mediating the processing of visual information.
MISC	The behavior of patients with brain damage has led to the proposal that perception is mediated by the ventral stream projecting from the primary visual cortex to the inferior temporal cortex, and that action is mediated by the dorsal stream projecting from the primary visual cortex to the posterior parietal cortex CITATION CITATION.
MISC	Although there has been debate about whether this separation into ventral/dorsal streams implies that the brain contains two distinct neural representations of the visual world CITATION CITATION, there has been no formal theoretical analysis about the functional consequences of the two different neural architectures on an animal's survival.
MISC	Visual search requires animals to move their eyes to point the high-resolution region of the eye, the fovea, to potentially interesting regions of the scene to sub-serve perceptual decisions such as localizing food or a predator.
MISC	What is the impact of having similar versus different neural mechanisms guiding eye movements and mediating perceptual decisions on visual search performance for an organism with a foveated visual system?
MISC	We consider two leading computational models of multiple-fixation human visual search, the Bayesian ideal searcher CITATION CITATION and the ideal saccadic targeting model for a search task of a target in one of eight locations equidistant from initial fixation.
OWNX	The ideal searcher uses knowledge of how the detectability of a target varies with retinal eccentricity and statistics of the scenes to move the fovea to spatial locations which maximize the accuracy of the perceptual decision at the end of search CITATION.
MISC	The saccadic targeting model makes eye movements to the most probable target location CITATION, CITATION which is optimal if the goal was to saccade to the target rather than collect information to optimize a subsequent perceptual decision CITATION.
MISC	Depending on the spatial layout of the possible target locations and the visibility map, the IS and MAP strategies lead to similar or diverging eye-fixations.
MISC	For example for a steeply varying visibility map both models make eye movements to the possible target locations while for a broader visibility map the ideal searcher tends to make eye movements in between the possible target locations attempting to obtain simultaneous close-to-fovea processing for more than one location.
MISC	Covert attention allows both models to select possible target locations and ignore locations that are unlikely to contain the target when deciding on saccade endpoints and making perceptual search decisions CITATION, CITATION.
MISC	Perceptual target localization decisions for both models are based on visual information collected in parallel over the whole retina, temporally integrated across saccades, and based on the location with highest sensory evidence for the presence of the target.
OWNX	Critically, we implemented the models to have two processing pathways, one determining where to move the fovea and the other stream processing visual information to reach a final perceptual decision about the target location.
OWNX	Rather than having a single linear mechanism or perceptual template, each pathway in the model had its own neural mechanism which is compared to the incoming visual data at each possible target location.
OWNX	Likelihood ratios CITATION of the observed responses for each of the mechanisms under the hypothesis that the target is present or absent at that location are used to make decisions about where to move the eyes and perceptual decisions .
MISC	We used a genetic algorithm as a method to find near-optimal solutions for perception and action mechanisms but also to simulate the effects of the evolutionary process of natural selection on the neural mechanisms driving saccadic eye movements and perceptual decisions during search.
MISC	The computational complexity of the ideal Bayesian searcher makes it difficult to virtually evolve the model and thus we used a recently proposed approximation to the ideal searcher that is computationally faster.
MISC	The ELM model chooses the fixation location that minimizes the uncertainty of posterior probabilities over the potential target locations.
MISC	The decision rule can be simplified to choose the fixation location with the maximum sum of likelihood ratios across potential target locations, each weighted by its squared detectability given the fixation location CITATION.
OWNX	The ELM model can be shown to approximate the fixation patterns of the ideal searcher CITATION and capture the main characteristics of the fixation patterns of the IS for our task and visibility maps.
OWNX	The process of virtual evolution started with the creation of one thousand simulated individuals with separate linear mechanisms for perception and eye movement programming.
OWNX	Each pathway's template for each individual was created from independent random combinations of the receptive fields of twenty four V1 simple cells.
OWNX	Each simulated individual was allowed two eye movements before making a final perceptual search decision about the location of the target.
MISC	Performance finding the target in one of eight locations for five thousand test-images was evaluated and the probability of survival of an individual was proportional to its performance accuracy.
OWNX	A new generation was then created from the surviving individuals through the process of reproduction, mutation and cross-over.
OWNX	The process was repeated for up to 500 generations.
MISC	Many proteins, especially in eukaryotes, contain tandem repeats of several domains from the same family.
MISC	These repeats have a variety of binding properties and are involved in protein protein interactions as well as binding to other ligands such as DNA and RNA.
MISC	The rapid expansion of protein domain repeats is assumed to have evolved through internal tandem duplications.
OWNX	However, the exact mechanisms behind these tandem duplications are not well-understood.
OWNX	Here, we have studied the evolution, function, protein structure, gene structure, and phylogenetic distribution of domain repeats.
OWNX	For this purpose we have assigned Pfam-A domain families to 24 proteomes with more sensitive domain assignments in the repeat regions.
OWNX	These assignments confirmed previous findings that eukaryotes, and in particular vertebrates, contain a much higher fraction of proteins with repeats compared with prokaryotes.
MISC	The internal sequence similarity in each protein revealed that the domain repeats are often expanded through duplications of several domains at a time, while the duplication of one domain is less common.
MISC	Many of the repeats appear to have been duplicated in the middle of the repeat region.
MISC	This is in strong contrast to the evolution of other proteins that mainly works through additions of single domains at either terminus.
OWNX	Further, we found that some domain families show distinct duplication patterns, e.g., nebulin domains have mainly been expanded with a unit of seven domains at a time, while duplications of other domain families involve varying numbers of domains.
MISC	Finally, no common mechanism for the expansion of all repeats could be detected.
MISC	We found that the duplication patterns show no dependence on the size of the domains.
OWNX	Further, repeat expansion in some families can possibly be explained by shuffling of exons.
OWNX	However, exon shuffling could not have created all repeats.
MISC	Proteins are composed of domains, recurrent protein fragments with distinct structure, function, and evolutionary history.
MISC	Protein domains may occur alone, but are more frequently found in combination with other domains in multidomain proteins.
MISC	While the creation of new multidomain architectures through shuffling of protein domains has been studied extensively during the last few years CITATION CITATION, one type of domain recombination has often been ignored: the creation of domain repeats.
MISC	Domain repeats contain two or more domains from the same domain family in tandem.
MISC	Large repeats with more then ten domains in tandem are common in eukaryotes.
MISC	Repeating domains are often short, such as the leucine rich repeat family with a repeating unit of 30 residues.
MISC	Some repeated domain families are mainly found in repeats, e.g., LRR and C2H2 zinc fingers, while other families are also frequently found as a single unit.
MISC	The repeats may form regular structures, such as antiparallel -sheets or solenoids, while others form filaments or are only structured upon binding to their ligands CITATION.
MISC	Some examples of repeats in protein structures can be found in the Propeat database.
MISC	Single amino acids or short peptide motifs may be repeated in proteins, too.
MISC	However, in this study we have focused on larger repeating units, domains.
MISC	Therefore, when repeats are mentioned in this text, it refers to repeats of protein domains.
MISC	Domain repeats are often involved in interactions with proteins or other ligands such as DNA or RNA.
MISC	Even if the repeated domains have a well-defined and conserved structure, the sequence conservation is often low, with only a few conserved residues required for the correct fold.
MISC	Their variable sequences and the variation in number of domains provide flexible binding to multiple binding partners.
OWNX	Hence, repeats are found in proteins with highly diverse functions such as the tetratrico peptide repeats that are involved in cell-cycle regulation, transcriptional regulation, protein transport, and assisting protein folding CITATION.
MISC	In addition, the flexible binding properties and sequence variability of repeats have been exploited to create high affinity binders as an alternative to antibodies CITATION .
MISC	The domain repeats are found in all kingdoms of life, and long repeats, containing several domains in tandem, have been observed to be particularly common in multicellular species CITATION, CITATION.
OWNX	Repeats have been proposed to provide the eukaryotes with an extra source of variability to compensate for low generation rates CITATION.
MISC	One such example is the LRRs in plant defense systems that enable plants to adapt to new pathogens CITATION .
MISC	Domain repeats are thought to arise via tandem duplications within a gene CITATION, where a segment is duplicated and the copy is inserted next to its origin.
MISC	However, the exact mechanism behind this phenomenon is not fully understood.
MISC	Nonhomologous recombination in intron regions, i.e., exon shuffling, may be responsible for internal duplications in repeats, and this issue has been addressed in this study.
MISC	Another possible explanation is DNA slippage, due to the formation of DNA hairpins, which is common in the creation of nucleotide repeats and short protein repeats CITATION.
MISC	However, Marcotte and coworkers have shown that protein repeats are more likely created from recombination than by DNA slippage since the repeat expansion shows weak dependence on repeat length CITATION .
OWNX	In addition to internal duplications, frequent duplications of repeat-containing genes have occurred in the mammalian genomes CITATION.
MISC	This can, in part, explain their abundance in higher eukaryotes.
MISC	In addition, variation in number of repeats between orthologous genes indicates that the loss/gain of domains in repeats is frequent in evolution CITATION.
MISC	Interestingly, the rapid expansion of repeats in eukaryotes could partly be explained by tandem duplication of units containing several repeated domains CITATION CITATION.
OWNX	In this study, we aim to investigate how frequent duplications of multiple domains are.
MISC	Further, the number of domains that is duplicated is compared among the different domain families.
MISC	Domains as defined by the Pfam-A database CITATION were detected using HMM-alignments.
OWNX	The coverage was increased with relaxed detection criteria for domains in repeated regions of the proteins.
MISC	In addition to investigation of duplication sizes, the domain assignments have been used to study the distribution of repeats and repeated domain families in the three kingdoms of life, the position of repeat expansion, and the location of exon boundaries in repeats.
OWNX	De novo computational design of synthetic gene circuits that achieve well-defined target functions is a hard task.
MISC	Existing, brute-force approaches run optimization algorithms on the structure and on the kinetic parameter values of the network.
MISC	However, more direct rational methods for automatic circuit design are lacking.
OWNX	Focusing on digital synthetic gene circuits, we developed a methodology and a corresponding tool for in silico automatic design.
OWNX	For a given truth table that specifies a circuit's input output relations, our algorithm generates and ranks several possible circuit schemes without the need for any optimization.
MISC	Logic behavior is reproduced by the action of regulatory factors and chemicals on the promoters and on the ribosome binding sites of biological Boolean gates.
OWNX	Simulations of circuits with up to four inputs show a faithful and unequivocal truth table representation, even under parametric perturbations and stochastic noise.
OWNX	A comparison with already implemented circuits, in addition, reveals the potential for simpler designs with the same function.
OWNX	Therefore, we expect the method to help both in devising new circuits and in simplifying existing solutions.
MISC	A central concept of Synthetic Biology CITATION is the rational design of synthetic gene circuits by means of modularized, standard parts, which are DNA traits with well-defined functions.
MISC	The field aims at adapting methods and ideas such as part composability and abstraction hierarchy from engineering to biology.
MISC	Several computational tools embracing these concepts have been developed.
MISC	Moreover, some tools permit to realize circuits in a drag and drop way as it is typical in electronics CITATION CITATION.
MISC	Nevertheless, de novo design of circuits able to reproduce a target function is not an easy task and its automation represents a major challenge in Synthetic Biology.
MISC	Previously, Fran ois and Hakim CITATION showed that small networks characterized by a desired behavior can be obtained by evolutionary optimization of a set of independent circuits.
MISC	Similar optimization-based tools like Genetdes CITATION and OptCircuit CITATION use simulated annealing and mixed integer dynamic optimization, respectively.
MISC	These approaches yielded interesting circuit designs, but they have several inherent limitations.
MISC	Computational complexity requires very simplified models that do not represent basic parts but lump functionalities of entire genes.
MISC	Similarly, brute-force optimization can only cope with rather small networks, and it requires dual optimization of circuit structure and of kinetic parameter values.
MISC	Hence, more direct, rational design methods are desired.
OWNX	Here, instead of looking for a general solution to the automatic design challenge, we focus on digital circuits.
OWNX	These circuits employ Boolean logic where input and output signals can take only two values: 0 and 1.
OWNX	In the simplest case, a Boolean gate uses two input signals to compute a single logical output.
MISC	More complex digital circuits convert FORMULA inputs into a single output.
MISC	In both cases, the input-output relation is represented by a truth table where each entry specifies one of the possible FORMULA combinations of input signal values and the corresponding binary output.
OWNX	In biology, digital circuits are important for several reasons.
MISC	First, logical gates such as those determined by the action of two different activators on a promoter are abundant in natural systems.
MISC	They are often found in association with feed-forward loop motifs and provide more complicated functionalities such as sign sensitive delays CITATION, CITATION and pulse generation CITATION.
MISC	More complex networks of several FFLs interacting with basic Boolean gates control sporulation in B. subtilis CITATION as well as the neuronal system of C. elegans CITATION.
MISC	An analysis of possible implementations of logical gates could, thus, help further our understanding of natural biological networks.
OWNX	In synthetic biology, secondly, complex digital circuits are required for the construction of biosensors and molecular computers.
MISC	Biosensors should respond to well-defined external cues that may be specified with a truth table.
MISC	The more inputs can be sensed, the better is the ability of the biosensor to discriminate between similar environmental conditions.
OWNX	Such biosensors could be integrated, for instance, into bioreactors for the production of biofuels CITATION.
MISC	Furthermore, they could play an important role in disease treatment Anderson et al. CITATION implemented a biosensor that mimics a logical gate to control bacterial invasion of tumor cells in response to signals from the tumor environment.
OWNX	Even more complex biosensors could work as molecular computers that perform a diagnosis on the basis of the sensed substances and release drugs if necessary CITATION .
MISC	Motivated by these two aspects, several synthetic gene circuits that implement Boolean logic have been realized experimentally in the past years.
OWNX	Most of these circuits rely on transcriptional control schemes.
MISC	In fact, it is well known that bacterial promoters can display logic behavior when controlled by two transcription factors CITATION CITATION.
MISC	More complex Boolean promoters have been engineered, for instance, in mammalian cells CITATION.
OWNX	However, the number of repressors and activators generally used in synthetic biology is low and the rational engineering of transcription factors can be a complex process CITATION .
MISC	Alternatively, Boolean gates are achieved in nature by mechanisms of translation control like base-pairing between antisense small-RNAs and the mRNA, or structural mRNA modifications due to the binding of chemical effectors to riboswitches and ribozymes CITATION, CITATION.
MISC	These are complex RNA structures made of two modules: an aptamer, where a chemical binds, and an actuator that either undergoes structural modifications in a riboswitch or gets spliced in a ribozyme as a consequence of the chemical binding.
MISC	Both riboswitches and ribozymes can either repress or activate translation CITATION.
MISC	Furthermore, a tandem riboswitch, where a single actuator is under the control of two aptamers, has been observed in B. clausii CITATION.
OWNX	With two distinct inputs, it represents a natural Boolean gate located on the mRNA.
MISC	Taking these structures as models, similar synthetic RNA constructs have been engineered recently CITATION.
MISC	In particular, Win and Smolke CITATION have built complex ribozymes that establish the most common two-input Boolean gates.
OWNX	Importantly, the design of small RNAs is easy compared to the design of transcription factors.
OWNX	Despite these individual successes, synthetic biology fundamentally lacks tools and concepts for automatic computational design.
MISC	Logical circuits are suitable starting points for automatic design because the target function can be defined easily by a truth table.
OWNX	Here, we combine approaches from electrical circuit design with our previous model for circuit design with composable parts CITATION, CITATION to develop a method for the automatic design of digital synthetic gene circuits.
OWNX	It is implemented as an add-on for the process modeling tool ProMoT CITATION, CITATION.
MISC	The circuits use a set of standard biological parts and Boolean gates whose kinetic parameters take appropriate default values without invoking any optimization algorithms.
OWNX	In addition to previously developed building blocks such as two-operator-containing promoters, we consider externally controllable ribosome binding sites.
OWNX	The method requires only a truth table to directly produce several possible circuit designs that process up to four different inputs to yield a unique, pre-defined output signal.
MISC	Design alternatives are ranked according to a complexity score that reflects the efforts for practical implementation.
OWNX	Simulations on single gates and on networks of different complexity confirm the validity of our approach by highlighting accurate representation of the truth table and robustness of the designed circuits.
MISC	This paper addresses the general problem of domain adaptation which arises in a variety of applications where the distribution of the labeled sample available somewhat differs from that of the test data
OWNX	Building on previous work by \emcite{bendavid}, we introduce a novel distance between distributions,  discrepancy distance , that is tailored to adaptation problems with arbitrary loss functions
OWNX	We give Rademacher complexity bounds for estimating the discrepancy distance from finite samples for different loss functions
OWNX	Using this distance, we derive novel generalization bounds for domain adaptation for a wide family of loss functions
OWNX	We also present a series of novel adaptation bounds for large classes of regularization-based algorithms, including support vector machines and kernel ridge regression based on the empirical discrepancy
OWNX	This motivates our analysis of the problem of minimizing the empirical discrepancy for various loss functions for which we also give novel algorithms
OWNX	We report the results of preliminary experiments that demonstrate the benefits of our discrepancy minimization algorithms for domain adaptation
MISC	In the standard PAC model  CITATION  and other theoretical models of learning, training and test instances are assumed to be drawn from the same distribution
MISC	This is a natural assumption since, when the training and test distributions substantially differ, there can be no hope for generalization
MISC	However, in practice, there are several crucial scenarios where the two distributions are more similar and learning can be more effective
OWNX	One such scenario is that of  domain adaptation , the main topic of our analysis
MISC	The problem of domain adaptation arises in a variety of applications in natural language processing  CITATION , speech processing  CITATION , computer vision  CITATION , and many other areas
MISC	Quite often, little or no labeled data is available from the  target domain , but labeled data from a  source domain  somewhat similar to the target as well as large amounts of unlabeled data from the target domain are at one's disposal
MISC	The domain adaptation problem then consists of leveraging the source labeled and target unlabeled data to derive a hypothesis performing well on the target domain
MISC	A number of different adaptation techniques have been introduced in the past by the publications just mentioned and other similar work in the context of specific applications
CONT	For example, a standard technique used in statistical language modeling and other generative models for part-of-speech tagging or parsing is based on the maximum a posteriori adaptation which uses the source data as prior knowledge to estimate the model parameters  CITATION
MISC	Similar techniques and other more refined ones have been used for training maximum entropy models for language modeling or conditional models  CITATION
OWNX	The first theoretical analysis of the domain adaptation problem was presented by \emcite{bendavid}, who gave VC-dimension-based generalization bounds for adaptation in classification tasks
MISC	Perhaps, the most significant contribution of this work was the definition and application of a distance between distributions, the  SYMBOL  distance, that is particularly relevant to the problem of domain adaptation and that can be estimated from finite samples for a finite VC dimension, as previously shown by \emcite{kifer}
OWNX	This work was later extended by \emcite{blitzer} who also gave a bound on the error rate of a hypothesis derived from a weighted combination of the source data sets for the specific case of empirical risk minimization
MISC	A theoretical study of domain adaptation was presented by \emcite{nips09}, where the analysis deals with the related but distinct case of adaptation with multiple sources, and where the target is a mixture of the source distributions
OWNX	This paper presents a novel theoretical and algorithmic analysis of the problem of domain adaptation
MISC	It builds on the work of \emcite{bendavid} and extends it in several ways
OWNX	We introduce a novel distance, the  discrepancy distance , that is tailored to comparing distributions in adaptation
OWNX	This distance coincides with the  SYMBOL  distance for 0-1 classification, but it can be used to compare distributions for more general tasks, including regression, and with other loss functions
MISC	As already pointed out, a crucial advantage of the  SYMBOL  distance is that it can be estimated from finite samples when the set of regions used has finite VC-dimension
OWNX	We prove that the same holds for the discrepancy distance and in fact give data-dependent versions of that statement with sharper bounds based on the Rademacher complexity
MISC	We give new generalization bounds for domain adaptation and point out some of their benefits by comparing them with previous bounds
OWNX	We further combine these with the properties of the discrepancy distance to derive data-dependent Rademacher complexity learning bounds
OWNX	We also present a series of novel results for large classes of regularization-based algorithms, including support vector machines (SVMs)  CITATION  and kernel ridge regression (KRR)  CITATION
OWNX	We compare the pointwise loss of the hypothesis returned by these algorithms when trained on a sample drawn from the target domain distribution, versus that of a hypothesis selected by these algorithms when training on a sample drawn from the source distribution
OWNX	We show that the difference of these pointwise losses can be bounded by a term that depends directly on the empirical discrepancy distance of the source and target distributions
CONT	These learning bounds motivate the idea of replacing the empirical source distribution with another distribution with the same support but with the smallest discrepancy with respect to the target empirical distribution, which can be viewed as reweighting the loss on each labeled point
OWNX	We analyze the problem of determining the distribution minimizing the discrepancy in both 0-1 classification and square loss regression
OWNX	We show how the problem can be cast as a linear program (LP) for the 0-1 loss and derive a specific efficient combinatorial algorithm to solve it in dimension one
MISC	We also give a polynomial-time algorithm for solving this problem in the case of the square loss by proving that it can be cast as a semi-definite program (SDP)
OWNX	Finally, we report the results of preliminary experiments showing the benefits of our analysis and discrepancy minimization algorithms
OWNX	In section~, we describe the learning set-up for domain adaptation and introduce the notation and Rademacher complexity concepts needed for the presentation of our results
OWNX	Section~ introduces the discrepancy distance and analyzes its properties
OWNX	Section~ presents our generalization bounds and our theoretical guarantees for regularization-based algorithms
OWNX	Section~ describes and analyzes our discrepancy minimization algorithms
OWNX	Section~ reports the results of our preliminary experiments
MISC	For a classification problem described by the joint density  SYMBOL , models of  SYMBOL  (the ``Bayesian similarity measure'') have been shown to be an optimal similarity measure for nearest neighbor classification
OWNX	This paper analyzes demonstrates several additional properties of that conditional distribution
OWNX	The paper first shows that we can reconstruct, up to class labels, the class  posterior distribution  SYMBOL  given  SYMBOL , gives a procedure for recovering the class labels, and gives an asymptotically Bayes-optimal classification procedure
MISC	It also shows, given such an optimal similarity measure, how to construct a classifier that outperforms the nearest neighbor classifier and achieves Bayes-optimal classification rates
OWNX	The paper then analyzes Bayesian similarity in a framework where a classifier faces a number of related classification tasks (multitask learning) and illustrates that reconstruction of the class posterior distribution is not possible in general
OWNX	Finally, the paper identifies a distinct class of classification problems using  SYMBOL  and shows that using  SYMBOL  to solve those problems is the Bayes optimal solution
MISC	Statistical models of similarity have become increasingly important in recent work on information retrieval  CITATION , case-based reasoning  CITATION , pattern recognition CITATION , and computer vision  CITATION
OWNX	Of particular interest is Bayesian similarity, a discriminatively trained model of  SYMBOL , which we will abbreviate as  SYMBOL
MISC	These models have been demonstrated to work well in a number of pattern recognition and visual object recognition problems  CITATION
MISC	It is easy to see that nearest neighbor classification using  SYMBOL  minimizes the risk that the class labels for  SYMBOL  and  SYMBOL  differ and therefore is optimal for 1-nearest neighbor classification  CITATION
MISC	However, beyond that observation, there have been several kinds of analysis of Bayesian similarity
MISC	The first, presented by Mahamud  CITATION  is an analysis considering a single instance of a classification problem, determined by a joint distribution  SYMBOL  of class labels  SYMBOL  and feature vectors  SYMBOL
MISC	The authors also argue for the existence of useful invariance properties of Bayesian similarity functions when those functions have a specific form  CITATION
OWNX	The second is an analysis based on a hierarchical Bayesian framework presented by Breuel  CITATION , which effectively considers Bayesian similarity in the context of a distribution of related classification tasks
OWNX	This paper analyzes the relationship between Bayesian similarity  SYMBOL  and the class posterior distribution  SYMBOL   in both the non-hierarchical and hierarchical cases and uses those results to construct an asymptotically Bayes-optimal classification procedure using Bayesian similarity
OWNX	It also presents a new statistical model for the kinds of discrimination tasks described in  CITATION  and  demonstrates that Bayesian similarity is the Bayes-optimal solution for those tasks
OWNX	The implications of these results for applications of Bayesian similarity will be discussed at the end
OWNX	There are at least two kinds of similarity
OWNX	Relational similarity  is  correspondence between relations, in contrast with  attributional similarity ,  which is correspondence between attributes
OWNX	When two words have a high  degree of attributional similarity, we call them  synonyms
MISC	When two  pairs   of words have a high degree of relational similarity, we say that their  relations are  analogous
MISC	For example, the word pair mason:stone is analogous  to the pair carpenter:wood
OWNX	This paper introduces Latent Relational Analysis (LRA),  a method for measuring relational similarity
MISC	LRA has potential applications in many  areas, including information extraction, word sense disambiguation,   and information retrieval
MISC	Recently the Vector Space Model (VSM) of information  retrieval has been adapted to measuring relational similarity,  achieving a score of 47\% on a collection of 374 college-level multiple-choice  word analogy questions
MISC	In the VSM approach, the relation between a pair of words is  characterized by a vector of frequencies of predefined patterns in a large corpus
OWNX	LRA extends the VSM approach in three ways: (1) the patterns are derived automatically  from the corpus, (2) the Singular Value Decomposition (SVD) is used to smooth the frequency  data, and (3) automatically generated synonyms are used to explore variations of the  word pairs
MISC	LRA achieves 56\% on the 374 analogy questions, statistically equivalent to the  average human score of 57\%
MISC	On the related problem of classifying semantic relations, LRA  achieves similar gains over the VSM
OWNX	There are at least two kinds of similarity
OWNX	Attributional similarity  is correspondence between attributes and  relational similarity  is correspondence between relations  CITATION
OWNX	When two words have a high degree of attributional  similarity, we call them  synonyms
OWNX	When two word  pairs  have a high  degree of relational similarity, we say they are  analogous
MISC	Verbal analogies are often written in the form  A:B::C:D\/ ,  meaning  A is to B as C is to D ; for example,  traffic:street::water:riverbed
OWNX	Traffic flows over a street;  water flows over a riverbed
OWNX	A street carries traffic;  a riverbed carries water
OWNX	There is a high degree of relational similarity between the word pair traffic:street and the word pair water:riverbed
MISC	In fact, this analogy is the basis of several mathematical theories of  traffic flow  CITATION
OWNX	In Section~, we look more closely at the connections between attributional and relational similarity
MISC	In analogies such as mason:stone::carpenter:wood, it seems that  relational similarity can be reduced to attributional similarity,  since mason and carpenter are attributionally similar, as are stone  and wood
OWNX	In general, this reduction fails
OWNX	Consider the analogy traffic:street::water:riverbed
OWNX	Traffic and water are not attributionally similar
MISC	Street and riverbed are only moderately attributionally similar
MISC	Many algorithms have been proposed for measuring the attributional  similarity between two words   CITATION
MISC	Measures of attributional similarity have been studied   extensively, due to their applications in problems such as recognizing synonyms  CITATION ,  information retrieval  CITATION , determining semantic orientation  CITATION ,  grading student essays  CITATION , measuring textual cohesion  CITATION , and word sense disambiguation  CITATION
MISC	On the other hand, since measures of relational  similarity are not as well developed as  measures of attributional similarity, the potential applications of  relational similarity are not as well known
OWNX	Many problems that involve semantic relations would benefit from an algorithm for measuring relational similarity
MISC	We discuss related problems in natural language processing, information retrieval, and information extraction in more detail in Section~
MISC	This paper builds on the Vector Space Model (VSM) of information retrieval
OWNX	Given a query, a search engine produces a ranked list of documents
OWNX	The documents are ranked in order of decreasing attributional similarity between the query and each document
OWNX	Almost all modern search engines measure attributional similarity using the VSM  CITATION  \namecite{turneylittman05} adapt the VSM approach to measuring relational similarity
MISC	They used a vector of frequencies of patterns in a corpus to represent the relation between a pair of words
OWNX	Section~ presents the VSM approach to measuring similarity
OWNX	In Section~, we present an algorithm for measuring  relational similarity, which we call Latent Relational Analysis (LRA)
MISC	The algorithm learns from a large corpus of unlabeled, unstructured  text, without supervision
AIMX	LRA extends the VSM approach of  \namecite{turneylittman05} in three ways: (1) The connecting  patterns are derived automatically from the corpus, instead of using a fixed set of patterns (2) Singular Value Decomposition  (SVD) is used to smooth the frequency data (3) Given a word pair  such as traffic:street, LRA considers transformations of the word  pair, generated by replacing one of the words by synonyms, such as  traffic:road, traffic:highway
OWNX	Section~ presents our experimental evaluation  of LRA with a collection of 374 multiple-choice word analogy questions  from the SAT college entrance exam
MISC	An example of a typical SAT question appears in Table~
MISC	In the educational testing literature, the first pair  (mason:stone) is called the  stem  of the analogy
MISC	The correct choice is called the  solution  and the incorrect choices are  distractors
MISC	We evaluate LRA by testing its ability to select the solution and avoid the distractors
OWNX	The average performance of college-bound senior high school students  on verbal SAT questions corresponds to an accuracy of  about 57\%
OWNX	LRA achieves an accuracy  of about 56\%
MISC	On these same questions, the VSM attained 47\% }  One application for relational similarity is classifying semantic  relations in noun-modifier pairs  CITATION
MISC	In Section~, we evaluate the performance of LRA  with a set of 600 noun-modifier pairs from \namecite{nastase03}
MISC	The problem is to classify a noun-modifier pair, such as ``laser printer'',  according to the semantic relation between the head noun (printer) and  the modifier (laser)
MISC	The 600 pairs have been manually labeled with 30  classes of semantic relations
OWNX	For example, ``laser printer'' is classified  as  instrument ; the printer uses the laser as an instrument for printing
MISC	We approach the task of classifying semantic relations in noun-modifier  pairs as a supervised learning problem
MISC	The 600 pairs are divided into  training and testing sets and a testing pair is classified according  to the label of its single nearest neighbour in the training set
OWNX	LRA  is used to measure distance (i e , similarity, nearness)
OWNX	LRA achieves  an accuracy of 39 8\% on the 30-class problem and 58 0\% on the 5-class  problem
OWNX	On the same 600 noun-modifier pairs, the VSM had accuracies of  27 8\% (30-class) and 45 7\% (5-class)  CITATION
OWNX	We discuss the experimental results, limitations of LRA, and future work  in Section~ and we conclude in Section~
OWNX	While statistics focusses on hypothesis testing and on estimating (properties of) the true sampling distribution, in machine learning the performance of learning algorithms on future data is the primary issue
AIMX	In this paper we bridge the gap with a general principle (PHI) that identifies hypotheses with best predictive performance
MISC	This includes predictive point and interval estimation, simple and composite hypothesis testing, (mixture) model selection, and others as special cases
OWNX	For concrete instantiations we will recover well-known methods, variations thereof, and new ones
MISC	PHI nicely justifies, reconciles, and blends (a reparametrization invariant variation of) MAP, ML, MDL, and moment estimation
MISC	One particular feature of PHI is that it can genuinely deal with nested hypotheses
OWNX	Consider data  SYMBOL  sampled from some distribution  SYMBOL  with unknown  SYMBOL
MISC	The likelihood function or the posterior contain the complete statistical information of the sample
OWNX	Often this information needs to be summarized or simplified for various reasons (comprehensibility, communication, storage, computational efficiency, mathematical tractability, etc )
MISC	Parameter estimation, hypothesis testing, and model (complexity) selection can all be regarded as ways of summarizing this information, albeit in different ways or context
CONT	The posterior might either be summarized by a single point  SYMBOL  (e g \ ML or MAP or mean or stochastic model selection), or by a convex set  SYMBOL  (e g \ confidence or credible interval), or by a finite set of points  SYMBOL  (mixture models) or a sample of points (particle filtering), or by the mean and covariance matrix (Gaussian approximation), or by more general density estimation, or in a few other ways  CITATION
MISC	I have roughly sorted the methods in increasing order of complexity
OWNX	This paper concentrates on set estimation, which includes (multiple) point estimation and hypothesis testing as special cases, henceforth jointly referred to as `` hypothesis identification '' (this nomenclature seems uncharged and naturally includes what we will do: estimation and testing of simple and complex hypotheses but not density estimation)
OWNX	We will briefly comment on generalizations beyond set estimation at the end
MISC	There are many desirable properties any hypothesis identification principle ideally should satisfy
MISC	It should \parskip=0ex\parsep=0exsep=0ex  lead to good predictions (that's what models are ultimately for),  be broadly applicable,  be analytically and computationally tractable,  be defined and make sense also for non- iid  \ and non-stationary data,  be reparametrization and representation invariant,  work for simple and composite hypotheses,  work for classes containing nested and overlapping hypotheses,  work in the estimation, testing, and model selection regime,  reduce in special cases (approximately) to existing other methods
OWNX	Here we concentrate on the first item, and will show that the resulting principle nicely satisfies many of the other items
MISC	We address the problem of identifying hypotheses (parameters/models) with good  predictive performance  head on
MISC	If  SYMBOL  is the true parameter, then  SYMBOL  is obviously the best prediction of the  SYMBOL  future observations  SYMBOL
OWNX	If we don't know  SYMBOL  but have prior belief  SYMBOL  about its distribution, the predictive distribution  SYMBOL  based on the past  SYMBOL  observations  SYMBOL  (which averages the likelihood  SYMBOL  over  SYMBOL  with posterior weight  SYMBOL ) is by definition the best Bayesian predictor Often we cannot use full Bayes (for reasons discussed above) but predict with hypothesis  SYMBOL , i e \ use  SYMBOL  as prediction
OWNX	The closer  SYMBOL  is to  SYMBOL  or  SYMBOL  the better is  SYMBOL 's prediction (by definition), where we can measure closeness with some distance function  SYMBOL
OWNX	Since  SYMBOL  and  SYMBOL  are (assumed to be) unknown, we have to sum or average over them
MISC	Predictive hypothesis identification  (PHI) minimizes the losses w r t \ some  hypothesis class   SYMBOL
MISC	Our formulation is general enough to cover point and interval estimation, simple and composite hypothesis testing, (mixture) model (complexity) selection, and others
MISC	The general idea of inference by maximizing predictive performance is not new  CITATION
OWNX	Indeed, in the context of model (complexity) selection it is prevalent in machine learning and implemented primarily by empirical cross validation procedures and variations thereof  CITATION  or by minimizing test and/or train set (generalization) bounds; see  CITATION  and references therein
OWNX	There are also a number of statistics papers on predictive inference; see  CITATION  for an overview and older references, and  CITATION  for newer references
MISC	Most of them deal with distribution free methods based on some form of cross-validation discrepancy measure, and often focus on model selection
MISC	A notable exception is MLPD  CITATION , which maximizes the predictive likelihood including future observations
MISC	The full decision-theoretic setup in which a decision based on  SYMBOL  leads to a loss depending on  SYMBOL , and minimizing the expected loss, has been studied extensively  CITATION , but scarcely in the context of hypothesis identification
MISC	On the natural progression of estimation SYMBOL prediction SYMBOL action, approximating the predictive distribution by minimizing \req{LPT} lies between traditional parameter estimation and optimal decision making
MISC	Formulation \req{LPT} is quite natural but I haven't seen it elsewhere
MISC	Indeed, besides ideological similarities the papers above bear no resemblance to this work
AIMX	The main purpose of this paper is to investigate the predictive losses above and in particular their minima, i e \ the best predictor in  SYMBOL
OWNX	Section  introduces notation, global assumptions, and illustrates PHI on a simple example
OWNX	This also shows a shortcoming of MAP and ML esimtation
OWNX	Section  formally states PHI, possible distance and loss functions, their minima, In Section , I study exact properties of PHI: invariances, sufficient statistics, and equivalences
OWNX	Sections  investigates the limit  SYMBOL  in which PHI can be related to MAP and ML
MISC	Section  derives large sample approximations  SYMBOL  for which PHI reduces to sequential moment fitting (SMF)
OWNX	The results are subsequently used for Offline PHI
OWNX	Section  contains summary, outlook and conclusions
OWNX	Throughout the paper, the Bernoulli example will illustrate the general results \paranodot{The main aim} of this paper is to introduce and motivate PHI, demonstrate how it can deal with the difficult problem of selecting composite and nested hypotheses, and show how PHI reduces to known principles in certain regimes
MISC	The latter provides additional justification and support of previous principles, and clarifies their range of applicability
MISC	In general, the treatment is exemplary, not exhaustive
MISC	T-Cell antigen Receptor repertoire is generated through rearrangements of V and J genes encoding and chains.
MISC	The quantification and frequency for every V-J combination during ontogeny and development of the immune system remain to be precisely established.
OWNX	We have addressed this issue by building a model able to account for V -J gene rearrangements during thymus development of mice.
OWNX	So we developed a numerical model on the whole TRA/TRD locus, based on experimental data, to estimate how V and J genes become accessible to rearrangements.
MISC	The progressive opening of the locus to V-J gene recombinations is modeled through windows of accessibility of different sizes and with different speeds of progression.
OWNX	Furthermore, the possibility of successive secondary V-J rearrangements was included in the modelling.
MISC	The model points out some unbalanced V-J associations resulting from a preferential access to gene rearrangements and from a non-uniform partition of the accessibility of the J genes, depending on their location in the locus.
OWNX	The model shows that 3 to 4 successive rearrangements are sufficient to explain the use of all the V and J genes of the locus.
MISC	Finally, the model provides information on both the kinetics of rearrangements and frequencies of each V-J associations.
MISC	The model accounts for the essential features of the observed rearrangements on the TRA/TRD locus and may provide a reference for the repertoire of the V-J combinatorial diversity.
OWNX	Functional antigen receptors expressed by T lymphocytes are generated during ontogeny by somatic recombination of gene segments coding for the variable, the joining, and the constant segments CITATION.
MISC	The recombination mechanism is largely dependent on both the accessibility of the loci and the RAG enzymatic complex CITATION CITATION.
OWNX	The murine TRA/TRD locus is composite, encoding TR and chains and encompassed of more than 100 functional V genes CITATION.
OWNX	In theory, each of the V genes may target one of the 49 functional J genes.
OWNX	The use of V and J genes during the process of recombination has been widely debated, and the studies support the consensus that V-J combinations are not random, with a use of J segments starting at the 5 end and proceeding to the 3 end CITATION CITATION.
OWNX	The accessibility of the J region is controlled by the TR enhancer, located at the 3 end of the C gene CITATION and by two promoters: T early, located at the 5 end of the J region and ii J49 located 15 Kb downstream of TEA.
OWNX	Both of the promoters are activated by E CITATION, CITATION, CITATION.
OWNX	E controls all the V to J associations whereas the two promoters are required for the rearrangements of the J genes situated at the 5 end of the J region.
OWNX	However, the analyses of TEA-deleted alleles and those of blockade of TEA transcription showed significant alterations in J use and support the hypothesis that the TEA promoter can regulate both positively the promoters located in the first 12 Kb of J genes and negatively the downstream promoters CITATION, CITATION CITATION .
MISC	A particularity of the TRA locus is an absence of allelic exclusion CITATION and its ability to undergo multiple cycles of secondary rearrangements CITATION, CITATION.
OWNX	The process of successive rearrangements is stopped by either positive selection, which downregulates recombinase expression CITATION or by cell death.
MISC	Therefore, the impact of secondary rearrangements on the TR gene assembly regulation remains to be defined.
OWNX	Regarding the V and J gene use, it is suggested that the first V-J association targets the secondary one into a set of J segments located near the J segment involved in the primary rearrangement CITATION, CITATION.
MISC	The rules governing the use of the V genes have not been clearly elucidated.
OWNX	Nevertheless, observations converge to a consensus: the use of V segments would progress from proximal V genes, located near the J region, towards the V genes located in the distal region CITATION, CITATION.
OWNX	At this point in time, the mechanism involved in the control of accessibility of V genes remains to debate CITATION .
MISC	The current state of the technology permits the analysis of some V-J combinations, essentially those at the extremities of the locus but still fails to establish a complete estimation of the V-J combinations.
MISC	The main obstacle comes from the fact that some V genes are duplicated in similar copies in the V region central part, making problematic their unambiguous identification by molecular methods CITATION .
MISC	Consequently, numerical modelling of the V-J recombination process may offer valuable support to overcome the difficulty for accessing to a global view of TRA repertoire.
MISC	For instance, if the J genes are chosen in a sequential way in the model, their use results unimodal, whereas it is known from experimental data that TRA/TRD locus displays two Hot Spots of recombination CITATION CITATION.
MISC	This discrepancy led us to build a mathematical model, parameterized from experimental data, on all V and J genes, including those in distal, proximal, and central positions.
MISC	Confrontation between the data obtained from experiments and from modelling makes possible an estimation of dynamical parameters, such as the accessibility to rearrangements and the frequencies of the V-J associations, giving a more accurate estimation of the TRA combinatorial diversity.
MISC	When movement outcome differs consistently from the intended movement, errors are used to correct subsequent movements by updating an internal model of motor and/or sensory systems.
MISC	Here, we examine changes to an internal model of the motor system under changes in the variance structure of movement errors lacking an overall bias.
MISC	We introduced a horizontal visuomotor perturbation to change the statistical distribution of movement errors anisotropically, while monetary gains/losses were awarded based on movement outcomes.
OWNX	We derive predictions for simulated movement planners, each differing in its internal model of the motor system.
MISC	We find that humans optimally respond to the overall change in error magnitude, but ignore the anisotropy of the error distribution.
OWNX	Through comparison with simulated movement planners, we found that aimpoints corresponded quantitatively to an ideal movement planner that updates a strictly isotropic internal model of the error distribution.
MISC	Aimpoints were planned in a manner that ignored the direction-dependence of error magnitudes, despite the continuous availability of unambiguous information regarding the anisotropic distribution of actual motor errors.
MISC	The motor system is exquisitely sensitive to perturbation.
MISC	The ability to sense a discrepancy between planned and executed movement and respond accordingly is one of the hallmarks of motor learning CITATION, CITATION, CITATION, CITATION.
OWNX	Here, we are concerned with the nature of the error signal used to update future movement plans when the result of a movement does not match the intended outcome.
MISC	Of course there is an infinite number of statistics of the error signal that the CNS might use to update future motor plans, ranging from a running average of recent errors, to n th-order moments of the distribution of past errors.
MISC	We are interested in exploring the limits of what statistics can be modeled by the nervous system.
MISC	Previous work has focused on neuromotor corrections to imposed bias, where corrective responses are found opposite to the direction of previous errors, and proportional to prior error extents CITATION, CITATION, CITATION.
MISC	This work supports motor learning models in which future motor plans incorporate an inverse of the command that would have produced the previous error.
MISC	This deterministic model of motor learning suggests that errors from past movements are subtracted off of future motor plans.
OWNX	Such models can be traced at least to Helmholtz CITATION, who used this type of model to describe perceptual constancy following eye movements.
MISC	However, these deterministic models fail to recognize that the CNS can neither simply read off a motor error from noisy sensory signals, nor can it produce identical motor outcomes with repetitions of motor commands.
MISC	The relationships between sensory signal and motor error, and between motor command and motor outcome, must be inferred; those inferences are far from certain.
MISC	Recognizing this, current research has examined the role of uncertainty in motor learning CITATION, CITATION.
MISC	For example, Sheidt et al. CITATION added a stochastic element to an average force field and found that subjects adapted to the uncertain field strength by tracking its expectation over recent errors.
OWNX	Here, we are interested in the response to changes in motor uncertainty, and ask whether these responses result from updating an internal model of motor variance; and if so, which aspects of the variance structure of the uncertain error signal are modeled.
MISC	In these studies, we increased motor noise anisotropically by stimulating a reflexive motor response known to occur when reaching in the presence of horizontal visual-field motion, or drift CITATION.
MISC	From trial to trial observers were shown leftward motion, rightward motion or a static stimulus, in random order.
OWNX	The motion, if present, began at the halfway-point of the reach, and resulted in a perturbation of the reach in the direction of the visual motion.
OWNX	Subjects could not plan in advance for any particular drift condition since these were randomly intermixed, nor could they compensate for the drift online because the timing of the reach and drift-onset insured that reaches were completed before feedback correction was possible CITATION.
MISC	Because this reflexive manual following response affects only the horizontal component of a reach, it was possible to test which aspects of the new, anisotropic distribution of motor errors was modeled by the CNS.
MISC	We test for changes in the internal representation of motor noise by monitoring changes in reach plans toward visible targets, which depend on the details of the information available to the CNS concerning motor uncertainty.
MISC	In these experiments, successful reaches to targets earn subjects a monetary bonus; reaches that instead intersect a neighboring region of the screen induce a monetary loss.
MISC	In two sessions, each beginning with reaches to targets without penalties, subjects learn their natural and perturbed noise distributions, and then respond to target-penalty pairs later in the session, allowing us to assess their internal representation of motor uncertainty.
OWNX	Our results indicate that the CNS updates a strictly circular internal model of motor variance, even when the distribution of actual errors is anisotropic.
MISC	This result is consistent with recent psychophysical and neurophysiological results CITATION, CITATION, CITATION, CITATION indicating independent encoding of the directions and extents of movement errors, because a system that updates only a circular internal representation of errors is equivalent to a system that monitors only the magnitudes of those errors, ignoring their directions.
OWNX	The threshold firing frequency of a neuron is a characterizing feature of its dynamical behaviour, in turn determining its role in the oscillatory activity of the brain.
OWNX	Two main types of dynamics have been identified in brain neurons.
OWNX	Type 1 dynamics shows a continuous relationship between frequency and stimulation current and, thus, an arbitrarily low frequency at threshold current; Type 2 shows a discontinuous f-I stim relationship and a minimum threshold frequency.
OWNX	In a previous study of a hippocampal neuron model, we demonstrated that its dynamics could be of both Type 1 and Type 2, depending on ion channel density.
OWNX	In the present study we analyse the effect of varying channel density on threshold firing frequency on two well-studied axon membranes, namely the frog myelinated axon and the squid giant axon.
OWNX	Moreover, we analyse the hippocampal neuron model in more detail.
MISC	The models are all based on voltage-clamp studies, thus comprising experimentally measurable parameters.
MISC	The choice of analysing effects of channel density modifications is due to their physiological and pharmacological relevance.
OWNX	We show, using bifurcation analysis, that both axon models display exclusively Type 2 dynamics, independently of ion channel density.
MISC	Nevertheless, both models have a region in the channel-density plane characterized by an N-shaped steady-state current-voltage relationship.
OWNX	In summary, our results suggest that the hippocampal soma and the two axon membranes represent two distinct kinds of membranes; membranes with a channel-density dependent switching between Type 1 and 2 dynamics, and membranes with a channel-density independent dynamics.
OWNX	The difference between the two membrane types suggests functional differences, compatible with a more flexible role of the soma membrane than that of the axon membrane.
MISC	It is now more than 60 years since Alan Hodgkin categorized the firing behaviour in his classical study of isolated axons from the crab Carcinus maenas CITATION.
OWNX	In many respects his experiments still form the basis for analysis of firing patterns in nervous systems.
OWNX	Using threshold dynamics and maximum frequency as parameters, he identified two major classes of repetitively firing axons : Class 1 axons start firing with very low frequency at threshold stimulation, yielding a continuous f-I stim relationship, whereas Class 2 axons start firing abruptly with a relatively high frequency at threshold, yielding a discontinuous f-I stim relationship.
OWNX	On the basis of a similar categorization mammalian cortical neurons have also been separated into main classes CITATION, CITATION, one exhibiting Class 1 characteristics and another Class 2 characteristics.
OWNX	The former class consists primarily of pyramidal neurons and the latter primarily of interneurons.
MISC	This differential classification of excitability has been shown to correlate with a differential bifurcation behaviour of corresponding dynamical models CITATION CITATION and successfully been used in analysing the coding properties of neurons CITATION CITATION.
AIMX	To avoid confusion, and in accordance with the notation of Tateno and Robinson CITATION, we in the following use the terms Type 1 and Type 2 dynamics when referring to continuous and discontinuous f-I stim relationships, respectively.
AIMX	This classification takes the threshold dynamics of the regular and fast spiking neurons, and that of the Class 1 and 2 axons, into account, but not all behavioural aspects of these classes CITATION .
MISC	The intricate interactions between the many factors involved in the dynamical regulation of neuronal firing are poorly understood CITATION.
OWNX	The dominant idea is that different combinations of ion channel types explain the different patterns CITATION.
OWNX	In a previous study we proposed a complementary explanation CITATION, CITATION.
OWNX	We showed that both Type 1 and Type 2 behaviour can be simulated in a dynamical model of a hippocampal neuron CITATION by varying the membrane density of voltage-gated Na and K channels.
OWNX	The model used was four-dimensional and based on a detailed experimental voltage-clamp study, thus comprising experimentally estimated parameters.
OWNX	The choice of ion channel densities as bifurcation parameters was due to their physiological and pharmacological relevance.
OWNX	Many drugs act by specifically blocking channels and thereby reducing ion channel density both at a somatic and at an axonal level.
MISC	Perhaps the most used local anaesthetic drug, lidocaine, acts by blocking sodium channels in axons and sensory nerve endings CITATION.
MISC	An increasing number of studies suggest a role for physiological regulation of channel densities, even at a relatively short time scale CITATION CITATION .
MISC	Each type of dynamics, i.e., Type 1 and 2, was found to be associated with distinct regions in the channel density plane or with corresponding surface areas of an oscillation volume in the FORMULA FORMULA I stim space.
OWNX	In regions with high FORMULA and low FORMULA values the model exhibits Type 1 dynamics, whereas in regions with higher FORMULA values the model generates Type 2 dynamics.
MISC	A bifurcation analysis showed that the Type 1 dynamics of the model is due to saddle-node on invariant circle bifurcations CITATION, CITATION.
MISC	Figure 3A portrays such a bifurcation in a V-I stim plot, calculated for the model using region C1 values.
MISC	The Type 2 dynamics was found to be due to either local Andronov-Hopf bifurcations and/or global double limit cycle bifurcations CITATION, CITATION.
MISC	The dynamics of the model associated with region B values is due to double limit cycle and subcritical Andronov-Hopf bifurcations, while the dynamics associated with region A2 is exclusively due to double limit cycle bifurcations.
MISC	The double limit cycle bifurcation implies an unstable limit cycle, which is part of a separating structure which separates trajectories turning to a central stable point and those approaching a stable limit cycle.
OWNX	However, preliminary calculations suggested that the bifurcation structure at the border between regions B and C1 is more complex than previously described.
MISC	When more bifurcation parameters are changed a more intricate loss of stability occurs CITATION .
OWNX	Thus, to obtain a better understanding of the processes we reanalysed the hippocampal neuron model in more detail.
OWNX	Furthermore, we extended the analysis to two other well-described excitable membranes, i.e., the myelinated axon of Xenopus laevis CITATION and the giant axon of Loligo forbesi CITATION.
OWNX	We found that oscillations associated with a subregion of region C1 of the hippocampal model show Type 2 dynamics, and that the oscillations of both axon models exclusively show Type 2 dynamics.
OWNX	We investigated the mathematical background to these findings, using techniques from bifurcation theory.
OWNX	The results suggest that the hippocampal soma and the two studied axon membranes represent two distinct types of membrane with respect to the excitability pattern; membranes with a channel-density dependent switching between Type 1 and 2 dynamics, and membranes with a channel-density independent dynamics.
OWNX	The difference between the two membrane types suggests functional differences, compatible with a more flexible role of the soma membrane than that of the axon membrane.
MISC	the objective of this paper is to measure and compare the subjective time discounting of professional athletes and non-athletes
MISC	by using a questionnaire  we found higher subjective discounting for professional athletes than for non-athletes
OWNX	we also found that the professional athletes' win-orientation positively affected their present preferences
MISC	on the other hand  professional athletes' play- orientation  which reflects their attitude towards the game itself  negatively affected their present preferences
MISC	no such effects were found in non-athletes
MISC	we argue that the  win-at-all-costs  competitive approach that leads athletes to sacrifice everything in order to win may cause or reflect their higher preference for the present
MISC	the subjective time discount rate is measured by the rate between the amount individual is willing to receive in the future  instead of a given amount in the present
MISC	this rate decreases with one's willingness to wait  meaning higher rate for an individual who is less patient and more biased to the present
MISC	the literature on time subjective discounting is extensive
MISC	it is related to psychological characteristics and cultural and demographic differences  CITATION
MISC	the socio-emotional selectivity theory suggests that the perception of time plays a fundamental role in the selection and pursuit of social goals
MISC	carstensen et al CITATION  developed this theory and suggest   when the conclusion of the appraisal process is that time is limited  the acquisitive mode associated with unlimited time is transformed into a more present-oriented state
MISC	present orientation is likely to involve goals related to feeling states  deriving emotional meaning  and experiencing emotional satisfaction  p  NUMBER 
OWNX	in the current paper  we compare time preference of professional athletes to non-athletes
OWNX	the participants in this research were  NUMBER  professional israeli athletes and  NUMBER  non-athletes
MISC	the group of professional athletes included olympic medalists  medalists from the european and world championships and members of national teams and national champions
MISC	the comparison of the psychological characteristics of athletes and non-athletes is one of the most frequently explored topics in personality studies related to sports
MISC	in the attempt to determine whether athletes differ from non-athletes  many researchers have looked at psychological  personality and perceptual-style variables
MISC	to the best of our knowledge  there are no studies that analyze professional athletes' time preference
OWNX	mccann  CITATION  analyzed decision-making among professional athletes considering contract offers
MISC	specifically  he examined why some professional athletes pursue the most lucrative offer  while others do not  and to what extent cognitive biases and heuristics influence their decision-making
MISC	he suggests that the lack of studies on influence of behavioral tendencies on professional athletes is not surprising   given the relative paucity of professional athletes among the general population  their presumptively unique modes of employment  and a general aversion among academics to the study of sports  p  NUMBER 
MISC	however  he suggests that  unlike other population groups professional athletes spontaneously furnish publishable commentary of their values  beliefs  and priorities  and they do so in real world  rather than experimental settings
OWNX	indeed  by escaping the alleged 'experimental flaw' of many behavioral law and economic studies  professional athletes offer a uniquely appealing group for further examination
MISC	for that reason  recognition of how professional athletes respond to subjective stimuli  as well as cognitive distortions  may reveal as much about us as it does about them  p  NUMBER 
OWNX	we suggest that the group of professional athletes is unique due to its  win-at-all-costs  competitive approach  CITATION
MISC	this competitive approach leads athletes to concentrate more on the present and sometimes sacrifice their future
MISC	The On-Off direction-selective ganglion cell in mammalian retinas responds most strongly to a stimulus moving in a specific direction.
OWNX	The DSGC initiates spikes in its dendritic tree, which are thought to propagate to the soma with high probability.
OWNX	Both dendritic and somatic spikes in the DSGC display strong directional tuning, whereas somatic PSPs are only weakly directional, indicating that spike generation includes marked enhancement of the directional signal.
MISC	We used a realistic computational model based on anatomical and physiological measurements to determine the source of the enhancement.
OWNX	Our results indicate that the DSGC dendritic tree is partitioned into separate electrotonic regions, each summing its local excitatory and inhibitory synaptic inputs to initiate spikes.
OWNX	Within each local region the local spike threshold nonlinearly amplifies the preferred response over the null response on the basis of PSP amplitude.
OWNX	Using inhibitory conductances previously measured in DSGCs, the simulation results showed that inhibition is only sufficient to prevent spike initiation and cannot affect spike propagation.
OWNX	Therefore, inhibition will only act locally within the dendritic arbor.
OWNX	We identified the role of three mechanisms that generate directional selectivity in the local dendritic regions.
OWNX	First, a mechanism for DS intrinsic to the dendritic structure of the DSGC enhances DS on the null side of the cell's dendritic tree and weakens it on the preferred side.
MISC	Second, spatially offset postsynaptic inhibition generates robust DS in the isolated dendritic tips but weak DS near the soma.
OWNX	Third, presynaptic DS is apparently necessary because it is more robust across the dendritic tree.
OWNX	The pre- and postsynaptic mechanisms together can overcome the local intrinsic DS.
OWNX	These local dendritic mechanisms can perform independent nonlinear computations to make a decision, and there could be analogous mechanisms within cortical circuitry.
OWNX	The On-Off direction-selective ganglion cell of the mammalian retina spikes vigorously to moving stimuli, but only weakly to stationary light spots.
MISC	It responds most strongly over a limited range of stimulus directions, and the direction producing the maximal response is called the preferred direction, while a stimulus moving in the opposite direction, called the null direction, produces little or no response CITATION.
MISC	We refer to such directionally-tuned spike responses as direction-selective.
OWNX	On-Off DSGCs are sharply bistratified neurons that respond with a transient depolarization and burst of spikes at both the onset and termination of a bright stimulus within the receptive field.
OWNX	Similarly the leading edge of a bright bar crossing the receptive field will produce a transient On-response, and, if the bar is wide relative to the dendritic extent and the speed low enough, the trailing-edge will produce a distinct, temporally separate Off-response.
MISC	In their original description of the DSGC, Barlow and Levick CITATION noted that direction-selective spike output was produced for stimuli that covered only a small fraction of the dendritic arbor.
OWNX	They proposed that the synaptic mechanism comprised subunits that were repeated in an array across the receptive field.
OWNX	In contrast to most ganglion cells, which initiate spikes in the axon initial segment, the DSGC initiates spikes in the dendritic tree CITATION.
OWNX	The dendritic spikes are thought to propagate to the soma and initiate a somatic spike, similar to neurons in other regions of the brain where dendritic spiking is important for signal processing CITATION.
OWNX	These observations suggest that some type of local dendritic processing could provide the basis for the proposed subunits.
OWNX	Evidence for dendritic spiking in the DSGC was observed in low amplitude spikelets, which appear when somatic spiking is suppressed by local application of tetrodotoxin to the soma, or by hyperpolarizing the soma CITATION.
OWNX	Dendritic spikes are hypothesized to initiate somatic spikes with high probability because they are rarely seen under normal conditions.
OWNX	Further, both somatic and dendritic spiking responses are strongly tuned to preferred-direction stimuli, whereas the somatic graded potential shows relatively weak directional tuning CITATION CITATION.
OWNX	This implies that the DSGC does not employ the mechanism used by most other ganglion cells for synaptic integration, where spikes initiated at the soma reflect the summation of synaptic inputs over the dendritic tree CITATION.
OWNX	Instead it suggests that DSGC dendrites sum synaptic inputs and generate local spikes which then propagate to the soma, in the process amplifying the responses' directional selectivity.
OWNX	In addition to dendritic spiking in the DSGC, other mechanisms are also important for generating its direction-selective response.
MISC	GABAergic inhibition is essential, and presynaptic mechanisms render both excitatory and inhibitory synaptic inputs to the DSGC directionally-tuned CITATION, CITATION.
OWNX	Both excitatory and inhibitory inputs vary in amplitude and relative timing as a function of direction.
OWNX	Further, postsynaptic integration of excitatory and inhibitory inputs has been hypothesized to contribute to DS signals CITATION CITATION.
OWNX	Postsynaptic inhibition resulting from null direction movement could produce DS signals in two ways: it could block the propagation of dendritic spikes or it could block their initiation CITATION CITATION, CITATION .
OWNX	However, the relative contributions of presynaptic and postsynaptic mechanisms to the DS spiking of the DSGC remains unclear.
OWNX	Initial theoretical studies suggested that postsynaptic mechanisms might suffice CITATION and this received some experimental support CITATION.
MISC	However, more recently, presynaptic mechanisms have appeared to be the most significant CITATION, CITATION, CITATION, CITATION.
OWNX	We wanted to revisit this issue to delineate the relative contributions of presynaptic and postsynaptic mechanisms in a calibrated model.
OWNX	To investigate how dendritic processing of synaptic PSPs could amplify DS, we constructed multi-compartment biophysical models of DSGCs, digitized from tracer-injected morphologies calibrated to physiological data obtained prior to tracer injection.
MISC	We stimulated the models with moving light bars that activated synaptic inputs.
OWNX	The goal was to explore how morphology, voltage-gated channels, and synaptic inhibition affect the initiation and propagation of dendritic spikes, and to compare these with the known physiological properties.
OWNX	Our simulations show that sub-threshold PSPs from the distal dendritic regions of the On-Off DSGC are heavily attenuated by propagation to the soma, but that spikes initiated within local dendritic regions can propagate with high probability to the soma and back-propagate to the remainder of the dendritic tree.
OWNX	Therefore active amplification of DS appears to take place during spike initiation in the dendrites.
OWNX	Fly lobula plate tangential cells are known to perform wide-field motion integration.
MISC	It is assumed that the shape of these neurons, and in particular the shape of the subclass of VS cells, is responsible for this type of computation.
MISC	We employed an inverse approach to investigate the morphology-function relationship underlying wide-field motion integration in VS cells.
OWNX	In the inverse approach detailed, model neurons are optimized to perform a predefined computation: here, wide-field motion integration.
CONT	We embedded the model neurons to be optimized in a biologically plausible model of fly motion detection to provide realistic inputs, and subsequently optimized model neuron with and without active conductances along their dendrites to perform this computation.
MISC	We found that both passive and active optimized model neurons perform well as wide-field motion integrators.
OWNX	In addition, all optimized morphologies share the same blueprint as real VS cells.
OWNX	In addition, we also found a recurring blueprint for the distribution of g K and g Na in the active models.
OWNX	Moreover, we demonstrate how this morphology and distribution of conductances contribute to wide-field motion integration.
OWNX	As such, by using the inverse approach we can predict the still unknown distribution of g K and g Na and their role in motion integration in VS cells.
OWNX	Neurons in different animals and brain regions feature a wealth of different dendritic morphologies and distributions of ionic conductances CITATION, CITATION.
CONT	While the physiological effects of these morphologies and conductance distributions are increasingly understood, how the computational functions these dendrites perform emerge from their morphologies and physiologies is still incompletely known.
MISC	Computational function is defined here as input-output transformation, resulting from the physiology and subserving the biological purpose of that neuron.
MISC	Notable exceptions to this incomplete understanding are neurons close the sensory input for which the electrophysiological dynamics are recorded during sensory stimulation, the morphology is known and both can be correlated to the neuron's sensory coding.
MISC	One such example are the fly lobula plate tangential cells, which responds to visual motion in preferred directions, and which are demonstrated to be wide-field motion detectors CITATION, CITATION .
MISC	We have recently developed an inverse approach to elucidate dendritic structure-function relationships.
MISC	The underlying assumption of the inverse is that dendritic structure parallels the computational function performed in dendrites.
OWNX	In the inverse approach, we start with a computational function of interest and optimize model neurons including dendritic morphology to perform this function.
OWNX	Here, we apply the inverse approach to investigate the neuronal morphology-function relationship in the fly LTPCs.
MISC	We focus on a particular type of LPTC, the VS cells that respond to vertical motion.
MISC	Briefly, VS cells receive motion sensitive signals from the medulla in a retinotopic organization on their dendrites.
MISC	These inputs are noisy insofar they are corrupted by spatial modulation reflecting the activity of individual inputs to the VS cell CITATION.
MISC	While the membrane potential of VS cells at the sites of synaptic input reproduces the fast input dynamics, by the time the signal reaches the axon the cells' physiology and anatomy gets rid of the temporal modulations imposed by their presynaptic local motion detectors.
OWNX	The output of the LPTCs is a smooth signal that encodes the direction of the presented moving stimulus CITATION, CITATION.
MISC	Thus the function of a single VS cell is temporal smoothing of motion sensitive inputs to produce a smooth output signal.
MISC	This computation is rewarded in the optimization performed in this work.
MISC	In line with the argument described in CITATION we assume that the dendritic morphology computes temporal smoothing.
OWNX	The aim of this study is to identify the morphological building blocks required to perform wide-field motion integration, and to investigate how physiological processes interact with the morphology to perform wide-field motion integration.
OWNX	In this work, we start by formalizing the notion of temporal smoothing and subsequently optimize different model neurons to perform this computation.
OWNX	We found that our optimized model neurons share crucial morphological features with real VS cell morphologies and that the intrinsic dynamics show remarkable similarity to the real cells.
MISC	Our results provide an alternative line of support for the hypothesis that the VS cell's morphology contributes to the computation of wide-field motion integration in these cells.
OWNX	Moreover, from our simulations we were able to identify the morphological building blocks required to perform wide-field motion integration and conclude that passive dendrites alone can account for temporal smoothing, and active ion-channels can be used to balance the responses to visual stimulation in the preferred and null-direction.
OWNX	Due to the similarity of our optimized models and real VS cells we can predict the actual -but still unknown- distribution of three ionic conductances and their role in wide-field integration in VS cells.
OWNX	We discuss the significance of our results and compare our findings to a related approach.
MISC	Observations consisting of measurements on relationships for pairs of objects arise in many settings, such as protein interaction and gene regulatory networks, collections of author-recipient email, and social networks
MISC	Analyzing such data with probabilisic models can be delicate because the simple exchangeability assumptions underlying many boilerplate models no longer hold
AIMX	In this paper, we describe a latent variable model of such data called the  mixed membership stochastic blockmodel
OWNX	This model extends blockmodels for relational data to ones which capture mixed membership latent relational structure, thus providing an object-specific low-dimensional representation
MISC	We develop a general variational inference algorithm for fast approximate posterior inference
MISC	We explore applications to social and protein interaction networks
OWNX	Keywords:   Hierarchical Bayes, Latent Variables, Mean-Field Approximation, Statistical Network Analysis, Social Networks, Protein Interaction Networks
MISC	Modeling relational information among objects, such as pairwise relations represented as graphs, is becoming an important problem in modern data analysis and machine learning
OWNX	Many data sets contain interrelated observations
MISC	For example, scientific literature connects papers by citation, the Web connects pages by links, and protein-protein interaction data connects proteins by physical interaction records
OWNX	In these settings, we often wish to infer hidden attributes of the objects from the observed measurements on pairwise properties
OWNX	For example, we might want to compute a clustering of the web-pages, predict the functions of a protein, or assess the degree of relevance of a scientific abstract to a scholar's query
MISC	Unlike traditional attribute data collected over individual objects,  relational data  violate the classical independence or exchangeability assumptions that are typically made in machine learning and statistics
OWNX	In fact, the observations are interdependent by their very nature, and this interdependence necessitates developing special-purpose statistical machinery for analysis
OWNX	There is a history of research devoted to this end
MISC	One problem that has been heavily studied is that of  clustering  the objects to uncover a group structure based on the observed patterns of interactions
MISC	Standard model-based clustering methods, eg , mixture models, are not immediately applicable to relational data because they assume that the objects are conditionally independent given their cluster assignments
MISC	The latent stochastic blockmodel~ CITATION  represents an adaptation of mixture modeling to dyadic data
MISC	In that model, each object belongs to a cluster and the relationships between objects are governed by the corresponding pair of clusters
MISC	Via posterior inference on such a model one can identify latent roles that objects possibly play, which govern their relationships with each other
MISC	This model originates from the stochastic blockmodel, where the roles of objects are known in advance~ CITATION
OWNX	A recent extension of this model relaxed the finite-cardinality assumption on the latent clusters, via a nonparametric hierarchical Bayesian formalism based on the Dirichlet process prior~ CITATION
MISC	The latent stochastic blockmodel suffers from a limitation that each object can only belong to one cluster, or in other words, play a single latent role
MISC	In real life, it is not uncommon to encounter more intriguing data on entities that are multi-facet
MISC	For example, when a protein or a social actor interacts with different partners, different functional or social contexts may apply and thus the protein or the actor may be acting according to different latent roles they can possible play
OWNX	In this paper, we relax the assumption of single-latent-role for actors, and develop a  mixed membership model  for relational data
MISC	Mixed membership models, such as latent Dirichlet allocation~ CITATION , have emerged in recent years as a flexible modeling tool for data where the single cluster assumption is violated by the heterogeneity within of a data point
MISC	They have been successfully applied in many domains, such as document analysis~ CITATION , surveys~ CITATION , image processing~ CITATION , transcriptional regulation  CITATION , and population genetics~ CITATION
OWNX	The mixed membership model associates each unit of observation with multiple clusters rather than a single cluster, via a membership probability-like vector
MISC	The concurrent membership of a data in different clusters can capture its different aspects, such as different underlying topics for words constituting each document
MISC	The mixed membership formalism is a particularly natural idea for relational data, where the objects can bear multiple latent roles or cluster-memberships that influence their relationships to others
OWNX	As we will demonstrate, a mixed membership approach to relational data lets us describe the interaction between objects playing multiple roles
MISC	For example, some of a protein's interactions may be governed by one function; other interactions may be governed by another function
MISC	Existing mixed membership models are not appropriate for relational data because they assume that the data are conditionally independent given their latent membership vectors
MISC	In relational data, where each object is described by its relationships to others, we would like to assume that the ensemble of mixed membership vectors help govern the relationships of each object
MISC	The conditional independence assumptions of modern mixed membership models do not apply
OWNX	In this paper, we develop mixed membership models for relational data, develop a fast variational inference algorithm for inference and estimation, and demonstrate the application of our technique to large scale protein interaction networks and social networks
OWNX	Our model captures the multiple roles that objects exhibit in interaction with others, and the relationships between those roles in determining the observed interaction matrix
MISC	Mixed membership and the latent block structure can be reliably recovered from relational data (Section )
MISC	The application to a friendship network among students tests the model on a real data set where a well-defined latent block structure exists (Section )
MISC	The application to a protein interaction network tests to what extent our model can reduce the dimensionality of the data, while revealing substantive information about the functionality of proteins that can be used to inform subsequent analyses (Section )
MISC	The problem of joint universal source coding and modeling, treated in the context of lossless codes by Rissanen, was recently generalized to fixed-rate lossy coding of finitely parametrized continuous-alphabet  iid 
MISC	sources
AIMX	We extend these results to variable-rate lossy block coding  of stationary ergodic sources and show that, for bounded metric distortion measures, any finitely parametrized family of stationary sources satisfying suitable mixing, smoothness and Vapnik--Chervonenkis learnability conditions admits universal schemes for joint lossy source coding and identification
MISC	We also give several explicit examples of parametric sources satisfying the regularity conditions
MISC	A universal source coding scheme is one that performs asymptotically optimally for all sources within a given class
OWNX	Intuition suggests that a good universal coder should acquire a probabilistic model of the source from a sufficiently long data sequence and operate based on this model
MISC	For lossless codes, this intuition has been made rigorous by Rissanen  CITATION : the data are encoded via a two-part code which comprises (1) a suitably quantized maximum-likelihood estimate of the source parameters, and (2) an encoding of the data with the code optimized for the acquired model
OWNX	The redundancy of this scheme converges to zero as  SYMBOL , where  SYMBOL  is the block length and  SYMBOL  is the dimension of the parameter space
OWNX	Recently we have extended Rissanen's ideas to  lossy  block coding  of finitely parametrized continuous-alphabet  iid 
MISC	sources with bounded parameter spaces  CITATION
MISC	We have shown that, under appropriate regularity conditions, there exist joint universal schemes for lossy coding and source identification whose distortion redundancy and source estimation fidelity both converge to zero as  SYMBOL  as the block length  SYMBOL  tends to infinity
MISC	The code operates by coding each block with the code matched to the parameters estimated from the preceding block
MISC	Moreover, the constant hidden in the  SYMBOL  notation increases with the ``richness" of the model class, as measured by the Vapnik--Chervonenkis (VC) dimension  CITATION  of a certain class of decision regions in the source alphabet
OWNX	The main limitation of the results of  CITATION  is the  iid 
MISC	assumption, which excludes such practically relevant model classes as autoregressive sources or Markov and hidden Markov processes
MISC	Furthermore, the assumption of a bounded parameter space may not be always justified
OWNX	In this paper we relax both of these assumptions
MISC	Because the parameter space is not bounded, we have to use variable-rate codes with countably infinite codebooks, whose performance is naturally quantified by Lagrangians  CITATION
CONT	We show that, under certain regularity conditions, there are universal schemes for joint lossy source coding and modeling such that, as the block length  SYMBOL  tends to infinity, both the Lagrangian redundancy relative to the best variable-rate code at each block length and the source estimation fidelity at the decoder converge to zero as  SYMBOL , where  SYMBOL  is the VC dimension of a certain class of decision regions induced by the collection of all  SYMBOL -dimensional marginals of the source process distributions
OWNX	The key novel feature of our scheme is that, unlike most existing schemes for universal lossy coding, which rely on implicit identification of the active source, it learns an explicit probabilistic model
OWNX	Moreover, our results clearly show that the ``price of universality" of a modeling-based compression scheme grows with the combinatorial richness of the underlying model class, as captured by the VC dimension sequence  SYMBOL
AIMX	The richer the model class, the harder it is to learn, which in turn affects the compression performance because we use the source parameters learned from past data in deciding how to encode the current block
MISC	These insights may prove useful in such settings as digital forensics or adaptive control under communication constraints, where trade-offs between the quality of parameter estimation and compression performance are of central importance
MISC	There is evidence that biological synapses have a limited number of discrete weight states.
MISC	Memory storage with such synapses behaves quite differently from synapses with unbounded, continuous weights, as old memories are automatically overwritten by new memories.
MISC	Consequently, there has been substantial discussion about how this affects learning and storage capacity.
MISC	In this paper, we calculate the storage capacity of discrete, bounded synapses in terms of Shannon information.
MISC	We use this to optimize the learning rules and investigate how the maximum information capacity depends on the number of synapses, the number of synaptic states, and the coding sparseness.
MISC	Below a certain critical number of synapses per neuron, we find that storage is similar to unbounded, continuous synapses.
MISC	Hence, discrete synapses do not necessarily have lower storage capacity.
MISC	Memory in biological neural systems is believed to be stored in the synaptic weights.
MISC	Numerous computational models of such memory systems have been constructed in order to study their properties and to explore potential hardware implementations.
MISC	Storage capacity and optimal learning rules have been studied both for single-layer associative networks CITATION, CITATION, studied here, and for auto-associative networks CITATION, CITATION.
MISC	Commonly, synaptic weights in such models are represented by unbounded, continuous real numbers.
OWNX	However, in biology, as well as in potential hardware, synaptic weights should take values between certain bounds.
MISC	Furthermore, synapses might be restricted to have a limited number of synaptic states, e.g. the synapse might be binary.
MISC	Although binary synapses might have limited storage capacity, they can be made more robust to biochemical noise than continuous synapses CITATION.
MISC	Consistent with this, experiments suggest that synaptic weight changes occur in steps.
OWNX	For example, putative single synapse experiments show that a switch-like increment or reduction to the excitatory post-synaptic current can be induced by pairing brief pre-synaptic stimulation with appropriate post-synaptic depolarization CITATION, CITATION .
MISC	Networks with bounded synapses have the palimpsest property, i.e. old memories decay automatically as they are overwritten by new ones CITATION CITATION.
MISC	In contrast, in networks with continuous, unbounded synapses, storing additional memories reduces the quality of recent and old memories equally.
MISC	Forgetting of old memories must in that case be explicitly incorporated, for instance via a weight decay mechanism CITATION, CITATION.
MISC	The automatic forgetting of discrete, bounded synapses allows one to study learning in a realistic equilibrium context, in which there can be continual storage of new information.
MISC	It is common to use the signal-to-noise ratio to quantify memory storage in neural networks CITATION, CITATION.
MISC	The SNR measures the separation between responses of the network; the higher the SNR, the more the memory stands out and the less likely it will be lost or distorted.
MISC	When weights are unbounded, each stored pattern has the same SNR.
MISC	Storage capacity can then be defined as the maximum number of patterns for which the SNR is larger than some fixed, minimum value.
MISC	However, for discrete, bounded synapses performance must be characterized by two quantities: the initial SNR, and its decay rate.
MISC	Ideally, a memory has a high SNR and a slow decay, but altering learning rules typically results in either an increase in memory lifetime but a decrease in initial SNR CITATION, or an increase in initial SNR but a decrease in memory lifetime.
MISC	Optimization of the learning rule is ambivalent because an arbitrary trade-off must be made between these two effects.
AIMX	In this paper we resolve this conflict between learning and forgetting by analyzing the capacity of synapses in terms of Shannon information.
MISC	We describe a framework for calculating the information capacity of bounded, discrete synapses, and use this to find optimal learning rules.
MISC	We model a single neuron, and investigate how information capacity depends on the number of synapses and the number of synaptic states.
MISC	We find that below a critical number of synapses, the total capacity is linear in the number of synapses, while for more synapses the capacity grows only as the square root of the number of synapses per neuron.
MISC	This critical number is dependent on the sparseness of the patterns stored, as well as on the number of synaptic states.
OWNX	Furthermore, when increasing the number of synaptic states, the information initially grows linearly with the number of states, but saturates for many states.
OWNX	Interestingly, for biologically realistic parameters, capacity is just at this critical point, suggesting that the number of synapses per neuron is limited to prevent sub-optimal learning.
MISC	Finally, the capacity measure allows direct comparison of discrete with continuous synapses, showing that under the right conditions their capacities are comparable.
MISC	The centrality-lethality rule, which notes that high-degree nodes in a protein interaction network tend to correspond to proteins that are essential, suggests that the topological prominence of a protein in a protein interaction network may be a good predictor of its biological importance.
MISC	Even though the correlation between degree and essentiality was confirmed by many independent studies, the reason for this correlation remains illusive.
OWNX	Several hypotheses about putative connections between essentiality of hubs and the topology of protein protein interaction networks have been proposed, but as we demonstrate, these explanations are not supported by the properties of protein interaction networks.
MISC	To identify the main topological determinant of essentiality and to provide a biological explanation for the connection between the network topology and essentiality, we performed a rigorous analysis of six variants of the genomewide protein interaction network for Saccharomyces cerevisiae obtained using different techniques.
MISC	We demonstrated that the majority of hubs are essential due to their involvement in Essential Complex Biological Modules, a group of densely connected proteins with shared biological function that are enriched in essential proteins.
MISC	Moreover, we rejected two previously proposed explanations for the centrality-lethality rule, one relating the essentiality of hubs to their role in the overall network connectivity and another relying on the recently published essential protein interactions model.
MISC	An intriguing question in the analysis of biological networks is whether biological characteristics of a protein, such as essentiality, can be explained by its placement in the network, i.e., whether topological prominence implies biological importance.
OWNX	One of the first connections between the two in the context of a protein interaction network, the so-called centrality-lethality rule, was observed by Jeong and colleagues CITATION, who demonstrated that high-degree nodes or hubs in a protein interaction network of Saccharomyces cerevisiae contain more essential proteins than would be expected by chance.
MISC	Since then the correlation between degree and essentiality was confirmed by other studies CITATION CITATION, but until recently there was no systematic attempt to examine the reasons for this correlation.
MISC	In particular, what is the main topological determinant of essentiality?
MISC	Is it the number of immediate neighbors or some other, more global topological property that essential proteins may have in a protein interaction network?
MISC	Jeong and colleagues CITATION suggested that overrepresentation of essential proteins among high-degree nodes can be attributed to the central role that hubs play in mediating interactions among numerous, less connected proteins.
MISC	Indeed, the removal of hubs disrupts the connectivity of the network, as measured by the network diameter or the size of the largest connected component, more than the removal of an equivalent number of random nodes CITATION, CITATION.
MISC	Therefore, under the assumption that an organism's function depends on the connectivity among various parts of its interactome, hubs would be predominantly essential because they play a central role in maintaining this connectivity.
MISC	Recently, He and colleagues challenged the hypothesis of essentiality being a function of a global network structure and proposed that the majority of proteins are essential due to their involvement in one or more essential protein protein interactions that are distributed uniformly at random along the network edges CITATION.
MISC	Under this hypothesis, hubs are proposed to be predominantly essential because they are involved in more interactions and thus are more likely to be involved in one which is essential.
OWNX	In this work we carefully evaluate each of the proposed explanations for the centrality-lethality rule.
MISC	Recently several hypotheses that linked structural properties of protein interaction networks to biological phenomena have come under scrutiny, with the main concern being that the observed properties are due to experimental artifacts and/or other biases present in the networks and as such lack any biological implication.
OWNX	To limit the impact of such biases on the results reported in our study we use six variants of the genomewide protein interaction network for Saccharomyces cerevisiae compiled from diverse sources of interaction evidence CITATION CITATION .
MISC	To assess whether the essentiality of hubs is related to their role in maintaining network connectivity we performed two tests.
MISC	First, if this were the case, then we would expect essential hubs to be more important for maintaining network connectivity than nonessential hubs.
OWNX	We found that this is not the case.
MISC	Next, in addition to node degree, we consider several other measures of topological prominence, and we demonstrate that some of them are better predictors of the role that a node plays in network connectivity than node degree.
MISC	Thus, if essentiality were related to maintaining network connectivity, then one would expect essentiality to be better correlated with these centrality measures than with the node degree.
MISC	However, we found that node degree is a better predictor of essentiality than any other measure tested.
OWNX	To reject the essential protein interaction model CITATION, we used a hypothesis testing approach.
OWNX	Namely, we observed that this model implies that the probability that a protein is essential is independent of the probability that another noninteracting protein is essential.
MISC	However, in the tested networks the essentiality of noninteracting proteins that share interaction partners is correlated.
OWNX	Thus, we reject the independence assumption and, as a result, the essential protein interaction model with high confidence.
OWNX	Motivated by our findings we propose an alternative explanation for the centrality-lethality rule.
MISC	Our explanation draws on a growing realization that phenotypic effect of gene-knockout experiments is a function of a group of functionally related genes, such as genes whose gene products are members of the same multiprotein complex CITATION.
MISC	It is well known that densely connected subnetworks are enriched in proteins that share biological function.
MISC	Therefore, one would expect that dense subnetworks of protein interaction networks should be either enriched or depleted in essential proteins.
MISC	Indeed, Hart and colleagues observed that essential proteins are not distributed evenly among the set of automatically indentified multiprotein complexes CITATION.
MISC	In this work we observe that the same phenomenon holds for potentially larger groups of densely connected and functionally related proteins, which we call COmplex BIological Modules.
OWNX	We demonstrate that due to the uneven distribution of essential proteins among COBIMs the majority of the essential proteins lie in those COBIMs that are enriched in essential proteins, which we call Essential COmplex BIological Modules .
MISC	By the very definition, ECOBIMs contain, relative to their size, more essential nodes than a random group of proteins of the same size.
MISC	But what fraction of all essential hubs are members of such ECOBIMs?
OWNX	How does this number relate to what is expected by chance?
OWNX	In fact, how does the enrichment of hubs that are members/nonmembers of ECOBIMs in essential proteins relate to the enrichment values expected by chance under a suitable randomization protocol?
OWNX	We propose that membership in ECOBIMs largely accounts for the enrichment of hubs in essential proteins.
OWNX	In support of this hypothesis, we found that the fraction of essential proteins among non-ECOBIM hubs is, depending on the network, only 13 35 percent, which is almost as low as the network average.
MISC	Furthermore the essentiality of nodes that are not members of ECOBIMs is only weakly correlated with their degree.
MISC	Finally, using a randomization experiment we demonstrated that these properties are characteristic of the protein interaction network and are unlikely in a corresponding randomized network.
OWNX	the ratio-bias phenomenon  observed by psychologist seymour epstein and colleagues  is a systematic manifestation of irrationality
MISC	when offered a choice between two lotteries  individuals consistently choose the lottery with the greater number of potential successes  even when it offers a smaller probability of success
OWNX	in the current study  we conduct experiments to confirm this phenomenon and test for the existence of bias as distinct from general irrationality
OWNX	moreover  we examine the effect of introducing a monetary incentive of varying size depending on the treatment on the extent of irrational choices within this framework
OWNX	we confirm the existence of the bias
MISC	moreover  the existence of an incentive significantly reduces the extent of irrationality exhibited  and that this effect is roughly linear in response to changes in the size of the incentive within the magnitudes investigated
OWNX	consider the following problem  you are asked to draw a red marble from either of two urns
OWNX	urn a contains  NUMBER  marbles   NUMBER  of which is red
OWNX	urn b contains  NUMBER  marbles   NUMBER  of which are red
MISC	which urn do you choose
MISC	a rational actor maximizing the probability of choosing a red marble will choose urn a
MISC	psychologist seymour epstein and colleagues  CITATION  have documented that many individuals choose urn b when presented with this choice or similar choices
MISC	epstein named this the ratio-bias phenomenon  as it appears that individuals are biased toward choices with large numbers of potential successes  rather than large probabilities of potential successes
MISC	the present investigation explores the ratio-bias phenomenon along two dimensions
OWNX	first  we test for errors within this framework in a symmetric fashion
MISC	referring to the example above  we not only present participants with decisions like that one  but also with decisions in which the urn with the larger number of marbles has the greater probability of success and is therefore the optimal choice
OWNX	if we observe similar frequencies of errors in these two circumstances  then we conclude that there is no real ratio-bias phenomenon  but rather observation of random error in both directions
OWNX	if the frequency of irrational decisions differs across these treatments  however  then we conclude that the ratio-bias phenomenon exists
MISC	the second dimension of interest is that of incentives
MISC	the participant in a ratio-bias experiment confronts a decision that is well suited to the introduction of a small monetary incentive and the testing of its marginal effect
MISC	we implement a combination within- and between-subjects design to test the effect of monetary incentives on decision making  as well as varying the size of the incentive to test for the effect of incentive magnitude on decision optimality
OWNX	We introduce a framework for filtering features that employs the Hilbert-Schmidt Independence Criterion (HSIC) as a measure of dependence between the features and the labels
MISC	The key idea is that good features should maximise such dependence
OWNX	Feature selection for various supervised learning problems (including classification and regression) is unified under this framework, and the solutions  can be approximated using a backward-elimination algorithm
OWNX	We demonstrate the usefulness of our method on both artificial and real world datasets
MISC	In supervised learning problems, we are typically given  SYMBOL  data points  SYMBOL  and their labels  SYMBOL
OWNX	The task is to find a functional dependence between  SYMBOL  and  SYMBOL ,  SYMBOL , subject to certain optimality conditions
OWNX	Representative tasks include binary classification, multi-class classification, regression and ranking
MISC	We often want to reduce the dimension of the data (the number of features) before the actual learning  CITATION ; a larger number of features  can be associated with higher data collection cost, more difficulty in model interpretation,  higher computational cost for the classifier, and decreased generalisation ability
OWNX	It is therefore important to select an informative feature subset
MISC	The problem of supervised feature selection can be cast as a combinatorial optimisation problem
MISC	We have a full set of features, denoted  SYMBOL  (whose elements correspond to the dimensions of the data)
OWNX	We use these features to predict a particular outcome, for instance the presence of cancer: clearly, only a subset  SYMBOL  of features will be relevant
OWNX	Suppose the relevance of  SYMBOL  to the outcome is quantified by  SYMBOL , and is computed by restricting the data to the dimensions in  SYMBOL
OWNX	Feature selection can then be formulated as\\[-0 5cm] \\[-0 5cm] where  SYMBOL  computes the cardinality of a set and  SYMBOL  upper bounds the number of selected features
MISC	Two important aspects of problem () are the choice of the criterion  SYMBOL  and the selection algorithm \paragraph{Feature Selection Criterion } The choice of  SYMBOL  should respect the underlying supervised learning tasks --- estimate  dependence function  SYMBOL  from training data and guarantee  SYMBOL  predicts well on test data
MISC	Therefore, good criteria should satisfy two conditions:\\[-0 5cm]  While many feature selection criteria have been explored, few take these two conditions explicitly into account
MISC	Examples include the leave-one-out error bound of SVM  CITATION  and the mutual information  CITATION
MISC	Although the latter has good theoretical justification, it requires density estimation, which is problematic for high dimensional and continuous variables
MISC	We sidestep these problems by employing a mutual-information  like  quantity --- the Hilbert Schmidt Independence Criterion (HSIC)  CITATION
MISC	HSIC uses kernels for measuring dependence and does not require density estimation
MISC	HSIC also has good uniform convergence guarantees
OWNX	As we show in section~, HSIC satisfies conditions  I  and  II , required for  SYMBOL  \paragraph{Feature Selection Algorithm } Finding a global optimum for \eq{eq:fs} is in general NP-hard  CITATION
MISC	Many algorithms transform \eq{eq:fs} into a continuous problem by introducing weights on the dimensions  CITATION
MISC	These methods perform well for linearly separable problems
MISC	For nonlinear problems, however, the optimisation usually becomes non-convex and a local optimum does not necessarily provide good features
MISC	Greedy approaches -- forward selection and backward elimination -- are often used to tackle problem () directly
OWNX	Forward selection tries to increase  SYMBOL  as much as possible for each inclusion of features, and backward elimination tries to achieve this for each deletion of features~ CITATION
MISC	Although forward selection is computationally more efficient, backward elimination provides better features in general since the features are assessed within the context of all others \paragraph{BAHSIC } In principle, HSIC can be employed using either the forwards or backwards strategy, or a mix of strategies
OWNX	However, in this paper, we will focus on a backward elimination algorithm
OWNX	Our experiments show that backward elimination outperforms forward selection for HSIC
OWNX	Backward elimination using HSIC (BAHSIC) is a filter method for feature selection
MISC	It selects features independent of a particular classifier
MISC	Such decoupling not only facilitates subsequent feature interpretation but also speeds up the computation over wrapper and embedded methods
OWNX	Furthermore, BAHSIC is directly applicable to binary, multiclass, and regression problems
OWNX	Most other feature selection methods are only formulated either for binary classification or regression
MISC	The multi-class extension of these methods is usually accomplished using a one-versus-the-rest strategy
MISC	Still fewer methods handle classification and regression cases at the same time
MISC	BAHSIC, on the other hand, accommodates all these cases in a principled way: by choosing different kernels, BAHSIC also subsumes many existing methods as special cases
MISC	The versatility of BAHSIC originates from the generality of HSIC
OWNX	Therefore, we begin our exposition with an introduction of HSIC
MISC	Structural and functional studies of the ABL and EGFR kinase domains have recently suggested a common mechanism of activation by cancer-causing mutations.
MISC	However, dynamics and mechanistic aspects of kinase activation by cancer mutations that stimulate conformational transitions and thermodynamic stabilization of the constitutively active kinase form remain elusive.
MISC	We present a large-scale computational investigation of activation mechanisms in the ABL and EGFR kinase domains by a panel of clinically important cancer mutants ABL-T315I, ABL-L387M, EGFR-T790M, and EGFR-L858R.
MISC	We have also simulated the activating effect of the gatekeeper mutation on conformational dynamics and allosteric interactions in functional states of the ABL-SH2-SH3 regulatory complexes.
OWNX	A comprehensive analysis was conducted using a hierarchy of computational approaches that included homology modeling, molecular dynamics simulations, protein stability analysis, targeted molecular dynamics, and molecular docking.
MISC	Collectively, the results of this study have revealed thermodynamic and mechanistic catalysts of kinase activation by major cancer-causing mutations in the ABL and EGFR kinase domains.
MISC	By using multiple crystallographic states of ABL and EGFR, computer simulations have allowed one to map dynamics of conformational fluctuations and transitions in the normal and oncogenic kinase forms.
AIMX	A proposed multi-stage mechanistic model of activation involves a series of cooperative transitions between different conformational states, including assembly of the hydrophobic spine, the formation of the Src-like intermediate structure, and a cooperative breakage and formation of characteristic salt bridges, which signify transition to the active kinase form.
OWNX	We suggest that molecular mechanisms of activation by cancer mutations could mimic the activation process of the normal kinase, yet exploiting conserved structural catalysts to accelerate a conformational transition and the enhanced stabilization of the active kinase form.
MISC	The results of this study reconcile current experimental data with insights from theoretical approaches, pointing to general mechanistic aspects of activating transitions in protein kinases.
OWNX	Protein kinase genes are signaling switches with a conserved catalytic domain that phosphorylate protein substrates and thereby play a critical role in cell signaling CITATION CITATION.
MISC	As a result, many protein kinases have emerged as important therapeutic targets for combating diseases caused by abnormalities in signal transduction pathways, especially various forms of cancer.
MISC	A large number of protein kinase crystal structures in the free form and complexes with various inhibitors have been determined, resulting in the growing wealth of structural information about the kinase catalytic domain CITATION CITATION.
MISC	The crystal structures have revealed considerable structural differences between closely related active and highly specific inactive kinase forms CITATION CITATION.
MISC	Conformational plasticity and diversity of crystal structures of the ABL CITATION CITATION and EGFR kinase domains CITATION CITATION have demonstrated the existence of active, inactive, Src-like inactive and intermediate conformational forms.
MISC	Conformational transitions and dynamic equilibrium between these distinct conformational states are important characteristics of the kinase regulation and recognition by other molecules CITATION CITATION.
MISC	Evolutionary analysis of the functional constraints acting on eukaryotic protein kinases demonstrated that protein kinase mechanisms may have evolved through elaboration of a simple structural component that included the HxD-motif adjoining the catalytic loop, the F-helix, an F-helix aspartate, and the catalytically critical Asp-Phe-Gly motif from the activation loop.
MISC	This computational analysis showed how distinctive structural elements of the kinase core may be linked with the conformational changes of the DFG motif in kinase regulation CITATION.
OWNX	A surface comparison of crystal structures for serine threonine and tyrosine kinases has recently identified the conserved residues that are most sensitive to activation CITATION.
MISC	According to the proposed model, critical features of the common activation mechanism may include a dynamic assembly of the hydrophobic spine motif and the formation of specific salt bridges that can collectively provide coordination of the kinase lobes during activation process CITATION, CITATION.
OWNX	These illuminating studies have demonstrated that protein kinase function may be controlled by a dynamic assembly of spatially distributed conserved residues important in regulation of allosteric signaling pathways.
AIMX	In a subsequent study, it was proposed that the F-helix of the kinase domain may act as a central scaffold in the assembly of active protein kinase forms by anchoring the hydrophobic regulatory spine and a second functional cluster termed catalytic spine CITATION .
MISC	Abnormal activation of protein kinases is among major causes of human diseases, especially various cancers.
MISC	Resequencing studies of kinase coding regions in tumors have revealed that a small number of kinase mutations contribute to tumor formation, while the majority are neutral mutational byproducts of somatic cell replication CITATION CITATION.
MISC	Mutations in protein kinases are implicated in many cancers CITATION and often exemplify the phenomenon of oncogene addiction CITATION, CITATION, whereby structural effects of oncogenic mutations confer a selective advantage for tumor formation during somatic cell replication.
OWNX	The dominant oncogenes that confer the oncogene addiction effect include ABL, EGFR, VEGFR, BRAF, RET, and MET kinase genes CITATION.
OWNX	The dependence of chronic myeloid leukemia on the translocated BCR-ABL kinase is correlated with dramatic responses to small molecule inhibitors.
MISC	A large number of diverse point mutations that impair the binding of Imatinib to ABL have been described CITATION CITATION, suggesting that some drug resistant mutations could exist before treatment, and may contribute to tumorigenesis.
MISC	The profound selectivity of Imatinib at inhibiting a small group of protein tyrosine kinases is achieved by the high precision with which this inhibitor can recognize the inactive conformation of the activation loop in ABL, KIT and PDGFR kinases CITATION, CITATION.
MISC	Structurally conserved gate-keeper mutation ABL-T315I is a dominant cancer-causing alteration, leading to the most severe Imatinib resistance by favoring the active form of the ABL kinase.
MISC	Subsequently, a series of rationally designed analogs of Imatinib based on the core scaffold were shown to recognize a broader spectrum of inactive kinase conformations and inhibit with equal potency both ABL and C-Src kinases CITATION.
MISC	Inhibitors that bind to the inactive conformation face weaker competition from cellular ATP and may act by shifting equilibrium between conformational states in a way that prevents kinase activation, rather than by inhibiting kinase activity directly.
MISC	A spectrum of lung cancer-derived EGFR mutations can induce oncogenic transformation by leading to constitutive kinase activity and confer markedly different degrees of sensitivity to EGFR inhibitors CITATION CITATION.
OWNX	Similarly, EGFR-T790M mutant could cause resistance to Gefitinib and Erlotinib drugs in the treatment of lung cancer CITATION ,.
MISC	Importantly, these mutations can promote oncogenic activation, uncontrolled cell proliferation and tumorigenesis even in the absence of the selective pressure from the kinase inhibitors.
MISC	An activating mutation in the activation loop of the EGFR kinase domain, L858R is among most frequent mutations in lung cancer, amounting to more than 40 percent of EGFR mutations in this cancer category CITATION CITATION.
MISC	While T790M has only a modest effect on EGFR function, a tandem of T790M and L858R mutations can result in a dramatic enhancement of EGFR activity CITATION.
MISC	The crystal structures of EGFR-L858R, EGFR-T790M CITATION CITATION and ABL-T315I mutants CITATION, CITATION have shown that these cancer-causing modifications could stabilize the active kinase form.
MISC	Recent structural and mutagenesis investigations have asserted a common activating nature of the gatekeeper mutations in c-ABL, c-Src, and EGFR and PDGFR kinases CITATION.
MISC	Moreover, mutations of the gatekeeper residues to smaller amino acids and pharmacological intervention by the inhibitor binding, which interfere with the structural integrity of the hydrophobic spine, could effectively abrogate the kinase activity.
MISC	Conversely, substitutions of the gatekeeper residues with bulkier modifications, that strengthen the hydrophobic spine, tend to correlate with the enhanced oncogenic activation of ABL and EGFR kinases CITATION.
OWNX	These studies have proposed a mechanism of activation in which stabilization of the hydrophobic regulatory spine may promote shift of the kinase equilibrium towards the constitutively active kinase form, and thus have a dramatic effect on the regulation of the enzyme.
OWNX	Crystallographic analysis may not capture the complete ensemble of protein kinase conformations available in solution under physiological conditions.
AIMX	NMR spectroscopy techniques can effectively complement X-ray studies by providing a more adequate characterization of conformational ensembles and dynamics of transitions between different kinase states CITATION, CITATION.
MISC	The first NMR characterization of ABL kinase in complexes with various inhibitors has been recently reported CITATION.
AIMX	This study has detected microsecond to millisecond motions of the activation loop seen in both the active and inactive states, suggesting that this mobility may be an intrinsic structural requirement for enabling conformational transitions between alternative kinase conformations.
MISC	Hydrogen exchange mass spectrometry has been applied to investigate conformational dynamics of ABL upon T315I mutation CITATION.
MISC	The effect of ABL-T315I mutation manifested not only in the local conformational disturbances near site of mutation, but also influenced protein flexibility in remote regions of the SH3 domain.
MISC	Hence, allosteric interactions and inter-domain communication of ABL regulatory complexes could be considerably perturbed by activating mutations, thereby playing a major role in the kinase regulation in solution.
MISC	Computational studies have begun to investigate a molecular basis of protein kinase function and the structural effects of activating mutations, which may ultimately control the activity signatures of cancer drugs and determine the scope of drug resistance mutations CITATION, CITATION.
MISC	A molecular mechanism of long-range, allosteric conformational activation of Src tyrosine kinases has been proposed by using a combination of experimental enzyme kinetics and nonequilibrium molecular dynamics simulations CITATION, CITATION.
MISC	Atomistic simulations of large-scale allosteric conformational transitions of adenylate kinase have suggested a population-shift mechanism upon inhibitor binding CITATION.
MISC	Coarse-grained and all-toms modeling using structural connectivity mapping have allowed to characterize a collective dynamics of conformational transitions between the inactive and active states of the Src kinase CITATION CITATION.
MISC	Atomistic dynamics of the open-to-closed movement of the cyclin-dependent kinase 5 has been recently studied using a metadynamics sampling approach, revealing a two-step molecular mechanism and the formation of functionally important intermediates CITATION.
OWNX	Molecular dynamics simulations of ABL kinase and Imatinib-binding kinetics assays have proposed that a protonation-dependent switch in the DFG motif from the activation loop may allow the kinase to access multiple conformations facilitating nucleotide binding and release cycles CITATION.
MISC	Targeted molecular dynamics simulations have attempted to explore conformational transitions in the activation loop of the c-Kit kinase domain CITATION.
MISC	Most recently, conformational dynamics of the EGFR kinase domain studied by TMD simulations has suggested that formation of the hydrophobic spine and salt bridges may be important in the activation process CITATION.
MISC	Computational studies of protein kinases have elucidated thermodynamic factors of kinase activation, suggesting that cancer mutations with the higher oncogenic activity may have the greater destabilization effect on the inactive kinase structure CITATION, CITATION .
MISC	These studies have suggested that the conserved topology of the protein kinase fold could preserve global dynamics in the normal and oncogenic forms, yet allowing for functionally important local and allosteric conformational changes caused by mutations.
OWNX	The basic mechanistic features of the protein kinase dynamics and activation mechanisms may be interpreted using a conformational selection model CITATION CITATION and the energy landscape perspective CITATION CITATION of protein folding and binding.
MISC	This theoretical framework implies an ensemble of preexisting multiple conformational states on the underlying energy landscape, with the mutations shifting the energy landscape and the relative populations of accessible states towards functionally relevant complexes CITATION CITATION.
MISC	An important role of conformational selection mechanisms has recently gained further prominence CITATION, suggesting a broad applicability of this model in explaining dynamic effects for a variety of biological systems CITATION CITATION .
MISC	It was recently proposed that evolution may have preserved protein flexibility features that retain the ability of kinases to fluctuate normally between active and inactive states.
OWNX	In contrary, cancer kinase mutations may result in the increased conformational space to be explored in the inactive state CITATION, CITATION.
MISC	Thermodynamic and mechanistic effects of cancer mutations may manifest in a preferential shifting of the landscape equilibrium and altering of the accessible conformational space for deleterious mutants through either local or allosteric-based dynamic changes.
MISC	A similar energy landscape-based framework for predicting the effects of mutations on protein dynamics and binding was successfully employed for allostery-based rescue mutant design in a tumor suppressor protein CITATION and studies of molecular evolution of affinity and flexibility in the immune system CITATION, CITATION .
MISC	Despite recent progress in computational and experimental studies of protein kinases, a quantitative understanding of thermodynamic and mechanistic catalysts of kinase activation by cancer mutations is still lacking.
OWNX	In this study, we have embarked on a detailed computational analysis of activation mechanisms in the ABL and EGFR kinase domains using homology modeling, MD simulations, protein stability analysis, TMD simulations and molecular docking.
MISC	A comparative analysis has been conducted based on computational modeling of the wild type ABL and EGFR kinase domains as well as a panel of clinically important cancer mutants ABL-T315I, ABL-L387M, EGFR-T790M, and EGFR-L858R.
MISC	We have also simulated the effect of the gatekeeper ABL-T315I mutation on conformational dynamics and allosteric interactions in the ABL-SH2-SH3 regulatory complexes.
CONT	In support of the experimental hypotheses, our results have suggested potential thermodynamic and mechanistic catalysts of the ABL and EGFR kinase activation that may collectively accelerate conformational transitions and result in the enhanced stabilization of the active kinase form.
MISC	We have also proposed a multi-stage mechanistic model of the activation process that includes a series of cooperative transitions resulting in the formation of key intermediate states that are characterized by a rapid assembly of the hydrophobic spine and subsequent stabilization of the Src-like structures.
MISC	Broadly, the results of study may reconcile current experimental data with the insights from computational approaches, pointing to general mechanistic aspects of activating transitions in protein kinases.
MISC	The major DNA constituent of primate centromeres is alpha satellite DNA.
MISC	As much as 2 percent 5 percent of sequence generated as part of primate genome sequencing projects consists of this material, which is fragmented or not assembled as part of published genome sequences due to its highly repetitive nature.
OWNX	Here, we develop computational methods to rapidly recover and categorize alpha-satellite sequences from previously uncharacterized whole-genome shotgun sequence data.
MISC	We present an algorithm to computationally predict potential higher-order array structure based on paired-end sequence data and then experimentally validate its organization and distribution by experimental analyses.
OWNX	Using whole-genome shotgun data from the human, chimpanzee, and macaque genomes, we examine the phylogenetic relationship of these sequences and provide further support for a model for their evolution and mutation over the last 25 million years.
OWNX	Our results confirm fundamental differences in the dispersal and evolution of centromeric satellites in the Old World monkey and ape lineages of evolution.
MISC	Alpha-satellite is the only functional DNA sequence associated with all naturally occurring human centromeres.
OWNX	Alpha satellite consists of tandem repetitions of a 171-bp AT-rich sequence motif.
MISC	In humans, two distinct forms of alpha-satellite are recognized based on their organization and sequence properties.
MISC	In humans, a large fraction is arranged into higher-order repeat arrays where alpha-satellite monomers are organized as multimeric repeat units ranging in size from 3 5 Mb CITATION.
MISC	While individual human alpha satellite monomer units show 20 percent 40 percent single-nucleotide variation, the sequence divergence between higher-order repeat units is typically less than 2 percent CITATION, CITATION.
MISC	The number of multimeric repeats within any centromere varies between different human individuals and, as such, is a source of considerable chromosome length polymorphism.
MISC	Unequal crossover of satellite DNA between sister chromatid pairs or between homologous chromosomes during meiosis is largely responsible for copy-number differences and is thought to be fundamental in the evolution of these HOR arrays.
MISC	The organization and unit of periodicity of these arrays are specific to each human chromosome CITATION, CITATION, with the individual monomer units classified into one of five different suprafamilies based on their sequence properties CITATION, CITATION.
MISC	Interestingly, studies of closely related primates, such as the chimpanzee and orangutan CITATION, CITATION indicate that these particular associations do not persist among the centromeres of homologous chromosome, implying that the structure and content of centromeric DNA changes very quickly over relatively short periods of evolutionary time.
MISC	In addition to higher-order arrays, large tracts of alpha-satellite DNA have more recently been described that are devoid of any HOR structure CITATION, CITATION CITATION.
OWNX	The individual repeats within these segments show extensive sequence divergence and have been classified as monomeric alpha-satellite DNA.
MISC	Such monomeric tracts are frequently located at the periphery of centromeric DNA CITATION, CITATION, CITATION.
MISC	Consequently, unlike higher-order arrays, some of these regions have been accurately sequenced and assembled because they localize in the transition regions between euchromatin and heterochromatin.
MISC	Phylogenetic and probabilistic analyses suggest that the higher-order alpha-satellite DNA emerged more recently and displaced existing monomeric repeat sequence as opposed to having arisen by unequal crossing-over of local monomeric DNA CITATION .
MISC	Centromeres and pericentromeric regions are frequently poorly assembled in primate whole-genome sequence assemblies CITATION CITATION.
MISC	These regions are generally regarded as too difficult to accurately sequence and assemble strictly from whole-genome shotgun sequence.
MISC	However, most WGS sequencing efforts include substantial amounts of alpha-satellite repeat sequence.
MISC	Indeed, as much as 2 percent 5 percent of the sequence generated from the underlying WGS consists of centromeric satellite sequences such data most often remain as unassembled in public database repositories.
OWNX	In this study, we develop computational methods to systematically identify and classify alpha-satellite sequences from primate WGS sequence.
OWNX	We predict novel HOR structures from uncharacterized primate genomes and define the phylogenetic relationship of these sequences within the context of known human HOR satellite sequences.
OWNX	Finally, we take advantage of publicly available cloned resources to experimentally validate the dispersal of these newly described alpha-satellite sequences within various primate genomes.
MISC	The data provide the first genome-wide sequence analysis of alpha-satellite DNA among primates from WGS data and a framework to identify and characterize more repeat-rich, complex regions of genomes as part of genome sequencing projects.
MISC	Computational methods for discovery of sequence elements that are enriched in a target set compared with a background set are fundamental in molecular biology research.
MISC	One example is the discovery of transcription factor binding motifs that are inferred from ChIP chip measurements.
CONT	Several major challenges in sequence motif discovery still require consideration: the need for a principled approach to partitioning the data into target and background sets; the lack of rigorous models and of an exact p-value for measuring motif enrichment; the need for an appropriate framework for accounting for motif multiplicity; the tendency, in many of the existing methods, to report presumably significant motifs even when applied to randomly generated data.
OWNX	In this paper we present a statistical framework for discovering enriched sequence elements in ranked lists that resolves these four issues.
OWNX	We demonstrate the implementation of this framework in a software application, termed DRIM, which identifies sequence motifs in lists of ranked DNA sequences.
MISC	We applied DRIM to ChIP chip and CpG methylation data and obtained the following results.
OWNX	Identification of 50 novel putative transcription factor binding sites in yeast ChIP chip data.
MISC	The biological function of some of them was further investigated to gain new insights on transcription regulation networks in yeast.
OWNX	For example, our discoveries enable the elucidation of the network of the TF ARO80.
OWNX	Another finding concerns a systematic TF binding enhancement to sequences containing CA repeats.
MISC	Discovery of novel motifs in human cancer CpG methylation data.
MISC	Remarkably, most of these motifs are similar to DNA sequence elements bound by the Polycomb complex that promotes histone methylation.
OWNX	Our findings thus support a model in which histone methylation and CpG methylation are mechanistically linked.
OWNX	Overall, we demonstrate that the statistical framework embodied in the DRIM software tool is highly effective for identifying regulatory sequence elements in a variety of applications ranging from expression and ChIP chip to CpG methylation data.
OWNX	DRIM is publicly available at LINK.
MISC	This paper examines the problem of discovering interesting sequence motifs in biological sequence data.
MISC	A widely accepted and more formal definition of this task is: given a target set and a background set of sequences, identify sequence motifs that are enriched in the target set compared with the background set.
OWNX	The purpose of this paper is to extend this formulation and to make it more flexible so as to enable the determination of the target and background set in a data driven manner.
MISC	Discovery of sequences or attributes that are enriched in a target set compared with a background set has become increasingly useful in a wide range of applications in molecular biology research.
MISC	For example, discovery of DNA sequence motifs that are overabundant in a set of promoter regions of co-expressed genes can suggest an explanation for this co-expression.
MISC	Another example is the discovery of DNA sequences that are enriched in a set of promoter regions to which a certain transcription factor binds strongly, inferred from chromatin immuno-precipitation on a microarray CITATION measurements.
MISC	The same principle may be extended to many other applications such as discovery of genomic elements enriched in a set of highly methylated CpG island sequences CITATION .
MISC	Due to its importance, this task of discovering enriched DNA subsequences and capturing their corresponding motif profile has gained much attention in the literature.
MISC	Any approach to motif discovery must address several fundamental issues.
MISC	The first issue is the way by which motifs are represented.
OWNX	There are several strategies for motif representation: using a k-mer of IUPAC symbols where each symbol represents a fixed set of possible nucleotides at a single position or using a position weight matrix, which specifies the probability of observing each nucleotide at each motif position.
MISC	Both representations assume base position independence.
MISC	Alternatively, higher order representations that capture positional dependencies have been proposed.
MISC	While these representations circumvent the position independence assumption, they are more vulnerable to overfitting and lack of data for determining model parameters.
OWNX	The method described in this paper uses the k-mer model with symbols above IUPAC.
OWNX	The second issue is devising a motif scoring scheme.
MISC	Many strategies for scoring motifs have been suggested in the literature.
OWNX	One simple yet powerful approach uses the hypergeometric distribution for identifying enriched motif kernels in a set of sequences and then expanding these motifs using an EM algorithm CITATION.
AIMX	The framework described in this paper is a natural extension of the approach of CITATION.
OWNX	YMF CITATION, CITATION is an exhaustive search algorithm which associates each motif with a z-score.
OWNX	AlignACE CITATION uses a Gibbs sampling algorithm for finding global sequence alignments and produces a MAP score.
OWNX	This score is an internal metric used to determine the significance of an alignment.
OWNX	MEME CITATION uses an expectation maximization strategy and outputs the log-likelihood and relative entropy associated with each motif.
OWNX	Once a scoring scheme is devised, a defined motif search space is scanned and motifs with significantly high scores are identified.
MISC	To determine the statistical significance of the obtained scores, many methods resort to simulations or ad hoc thresholds.
OWNX	Several excellent reviews narrate the different strategies for motif detection and use quantitative benchmarking to compare their performance CITATION CITATION.
OWNX	A related aspect of motif discovery, which is outside the scope of this paper, focuses on properties of clusters and modules of TF binding sites.
OWNX	Examples of approaches that search for combinatorial patterns and modules underlying TF binding and gene expression include CITATION CITATION .
MISC	We consider the problem of high-dimensional non-linear variable selection for supervised learning
MISC	Our approach is based on performing linear selection among exponentially many  appropriately defined  positive definite kernels that characterize non-linear interactions between the original variables
OWNX	To select efficiently from these many kernels, we use the natural hierarchical structure of the problem to extend the multiple kernel learning framework to kernels that can  be embedded in a directed acyclic graph; we show that it is then possible to perform kernel selection through a graph-adapted sparsity-inducing norm,  in polynomial time in the number of selected kernels
OWNX	Moreover, we study the consistency of variable selection  in high-dimensional settings, showing that under certain assumptions, our regularization framework allows a number of irrelevant variables which is  exponential in the number of observations
OWNX	Our simulations on synthetic datasets and datasets from the UCI repository show state-of-the-art predictive performance for non-linear regression problems
OWNX	High-dimensional problems represent a recent and important topic in machine learning, statistics and signal processing
MISC	In such settings, some notion of sparsity is a fruitful way of avoiding overfitting, for example through variable or feature selection
MISC	This has led to many  algorithmic and theoretical advances
MISC	In particular, regularization by sparsity-inducing norms such as the  SYMBOL -norm has  attracted a lot of interest in recent years
CONT	While early work has focused on efficient algorithms to solve the convex optimization problems, recent research has looked at the model selection properties and predictive performance of such methods, in the linear case~ CITATION  or within constrained non-linear settings such as the multiple kernel learning framework~ CITATION  or generalized additive models~ CITATION
CONT	However, most of the recent work dealt with  linear high-dimensional  variable selection, while the focus of much of the earlier work in machine learning and statistics was  on  non-linear low-dimensional  problems: indeed, in the last two decades,  kernel methods have been a prolific  theoretical and algorithmic machine learning framework
MISC	By using appropriate regularization by Hilbertian norms, representer theorems enable to consider large and potentially infinite-dimensional feature spaces while working within an implicit feature space no larger than the number of observations
MISC	This has led to numerous works on kernel design adapted to specific data types and generic kernel-based algorithms for many learning tasks  CITATION
MISC	However, while non-linearity is required in many domains such as computer vision or bioinformatics, most theoretical results related to non-parametric methods do not scale well with input dimensions
OWNX	In this paper, our goal is to bridge the gap between linear and non-linear methods, by tackling  high-dimensional non-linear  problems
MISC	The task of non-linear variable section is a hard problem with few approaches that have both good theoretical and algorithmic properties, in particular in high-dimensional settings
MISC	Among classical  methods, some are implicitly or explicitly based on sparsity and model selection, such as boosting~ CITATION , multivariate additive regression splines~ CITATION ,  decision trees~ CITATION , random forests~ CITATION , Cosso~ CITATION  or Gaussian process based methods~ CITATION , while some others do not rely on sparsity, such as nearest neighbors or kernel methods~ CITATION
OWNX	First attempts were made to combine non-linearity and sparsity-inducing norms by considering  generalized additive models , where the predictor function is assumed to be a sparse linear combination of non-linear functions of each variable~ CITATION
MISC	However, as shown in \mysec{universal}, higher orders of interactions are needed for universal consistency, i e , to adapt to the potential high complexity of the interactions between the relevant variables; we need to potentially allow  SYMBOL  of them for  SYMBOL  variables (for all possible subsets of the  SYMBOL  variables)
MISC	Theoretical results suggest that with appropriate assumptions,  sparse methods such as greedy methods and methods based on the  SYMBOL -norm would be able to deal correctly with  SYMBOL  features if  SYMBOL  is of the order of the number of observations  SYMBOL ~ CITATION
MISC	However, in presence of more than a few dozen variables, in order to deal with that many features, or even to simply enumerate those, a certain form of factorization or recursivity is needed
AIMX	In this paper, we propose to use a hierarchical structure based on directed acyclic graphs, which is natural in our context of non-linear variable selection
OWNX	We consider a positive definite kernel that can be expressed as a large sum of positive definite  basis  or  local kernels
OWNX	This exactly corresponds to the situation where a large feature space is the concatenation of  smaller feature spaces, and we aim to do selection among these many kernels (or equivalently feature spaces), which may be done through  multiple kernel learning~ CITATION
MISC	One major difficulty however is that the number of these smaller kernels is usually exponential in the dimension of the input space and applying multiple kernel learning directly to this decomposition would be intractable
MISC	As shown in \mysec{decompositions}, for non-linear variable selection, we consider a sum of kernels which are indexed by the set of subsets of all considered variables, or more generally by  SYMBOL , for  SYMBOL
OWNX	In order to perform selection efficiently, we make the extra assumption that these small kernels can be embedded in a  directed acyclic graph  (DAG)
OWNX	Following~ CITATION , we consider in \mysec{mkl} a specific combination of  SYMBOL -norms that is adapted to the DAG, and that will restrict the authorized sparsity patterns to certain configurations; in our specific kernel-based framework, we are able to use the DAG to design an optimization algorithm which has polynomial complexity in the number of selected kernels (\mysec{optimization})
OWNX	In simulations (\mysec{simulations}), we focus on   directed grids , where our framework allows to perform non-linear variable selection
OWNX	We provide some experimental validation of our novel regularization framework; in particular, we compare it to the regular  SYMBOL -regularization, greedy forward selection and non-kernel-based methods, and shows that it is always competitive and often leads to better performance, both on synthetic examples, and standard regression datasets from the UCI repository
OWNX	Finally, we extend in \mysec{consistency} some of the known consistency results of the Lasso and multiple kernel learning~ CITATION , and give a partial answer to the model selection capabilities of our regularization framework by giving necessary and sufficient conditions for model consistency
OWNX	In particular, we show that our framework is adapted to estimating consistently only the  hull   of the relevant variables
OWNX	Hence, by restricting the statistical power of our method, we gain computational efficiency
OWNX	Moreover, we show that we can obtain scalings between the number of variables and the number of observations which are similar to the linear case~ CITATION : indeed, we show that our regularization framework may achieve non-linear variable selection consistency even with a number of variables  SYMBOL  which is exponential in the number of observations  SYMBOL
OWNX	Since we deal with  SYMBOL  kernels, we achieve consistency with a number of kernels which is  doubly  exponential in  SYMBOL
OWNX	Moreover, for general directed acyclic graphs, we show that the total number of vertices may grow unbounded as long as the maximal out-degree (number of children) in the DAG is less than exponential in the number of observations
OWNX	This paper extends previous work~ CITATION , by providing more background on multiple kernel learning, detailing all proofs, providing new consistency results in high dimension, and comparing our non-linear predictors with non-kernel-based methods \paragraph{Notation } Throughout the paper we consider Hilbertian norms  SYMBOL  for elements  SYMBOL  of Hilbert spaces, where the specific Hilbert space can always be inferred from the context (unless otherwise stated)
MISC	For rectangular matrices  SYMBOL , we denote by  SYMBOL  its largest singular value
OWNX	We   denote by  SYMBOL  and  SYMBOL  the largest and smallest eigenvalue of a symmetric matrix  SYMBOL
MISC	These are naturally extended to compact self-adjoint operators~ CITATION
MISC	Moreover, given a vector  SYMBOL  in the product space  SYMBOL  and a subset  SYMBOL  of  SYMBOL ,  SYMBOL  denotes the vector in  SYMBOL  of elements of  SYMBOL  indexed by  SYMBOL
MISC	Similarly, for a matrix  SYMBOL  defined with  SYMBOL  blocks adapted to  SYMBOL ,  SYMBOL   denotes the submatrix of   SYMBOL  composed of blocks of  SYMBOL  whose rows are in  SYMBOL  and columns are in  SYMBOL
MISC	Moreover,  SYMBOL  denotes the cardinal of the set  SYMBOL  and  SYMBOL  denotes the dimension of the Hilbert space  SYMBOL
OWNX	We denote by  SYMBOL    the  SYMBOL -dimensional vector of ones
MISC	We denote by  SYMBOL  the positive part of a real number  SYMBOL
OWNX	Besides, given matrices  SYMBOL , and a subset  SYMBOL  of  SYMBOL ,  SYMBOL  denotes the block-diagonal matrix composed of the blocks indexed by   SYMBOL
OWNX	Finally, we let denote  SYMBOL  and  SYMBOL  general probability measures and expectations
MISC	Amplification, deletion, and loss of heterozygosity of genomic DNA are hallmarks of cancer.
MISC	In recent years a variety of studies have emerged measuring total chromosomal copy number at increasingly high resolution.
MISC	Similarly, loss-of-heterozygosity events have been finely mapped using high-throughput genotyping technologies.
MISC	We have developed a probe-level allele-specific quantitation procedure that extracts both copy number and allelotype information from single nucleotide polymorphism array data to arrive at allele-specific copy number across the genome.
OWNX	Our approach applies an expectation-maximization algorithm to a model derived from a novel classification of SNP array probes.
OWNX	This method is the first to our knowledge that is able to determine the generalized genotype of aberrant samples at each SNP site, and infer the copy number of each parental chromosome across the genome.
MISC	With this method, we are able to determine not just where amplifications and deletions occur, but also the haplotype of the region being amplified or deleted.
OWNX	The merit of our model and general approach is demonstrated by very precise genotyping of normal samples, and our allele-specific copy number inferences are validated using PCR experiments.
OWNX	Applying our method to a collection of lung cancer samples, we are able to conclude that amplification is essentially monoallelic, as would be expected under the mechanisms currently believed responsible for gene amplification.
MISC	This suggests that a specific parental chromosome may be targeted for amplification, whether because of germ line or somatic variation.
OWNX	An R software package containing the methods described in this paper is freely available at LINK.
MISC	Genomic alterations are believed to be the major underlying cause of cancer CITATION CITATION.
MISC	These alterations include various types of mutations, translocations, and copy number alterations.
OWNX	The last category involves chromosomal regions with either more than two copies, one copy, or zero copies in the cell.
MISC	Genes contained in amplified regions are natural candidates for cancer-causing oncogenes CITATION, while those in regions of deletion are potential tumor-suppressor genes CITATION.
OWNX	Thus, the localization of these alterations in cell lines and tumor samples is a central aim of cancer research.
MISC	In recent years, a variety of array-based technologies have been developed to identify and classify genomic alterations CITATION CITATION.
MISC	Studies using these technologies typically analyze the raw data to produce estimates of total copy number across the genome CITATION CITATION.
OWNX	However, these studies ignore the individual contributions to copy number from each chromosome.
MISC	Thus, for example, if a region containing a heterozygous locus undergoes amplification, the question of which allele is being amplified generally remains unanswered.
MISC	The amplified allele is of interest because it may have been selected for amplification because of its oncogenic effect.
MISC	Data from array-based platforms have also been employed to identify loss-of-heterozygosity events CITATION, CITATION.
MISC	In these studies LOH is typically inferred to have occurred where there is an allelic imbalance in a tumor sample at the same site at which the matched normal sample is heterozygous.
MISC	A complicating issue is that the imbalance may be due to the amplification of one of the alleles rather than the deletion of the other, and thus LOH may not in fact be present.
OWNX	Copy number analysis and LOH detection can both be improved by combining copy number measurement with allelotype data.
OWNX	In this paper, we present a probe-level allele-specific quantitation procedure that infers allele-specific copy numbers from 100K single nucleotide polymorphism array CITATION data.
OWNX	Our algorithm yields highly accurate genotypes at the over 100,000 SNP sites.
MISC	We are also able to infer parent-specific copy numbers across the genome, making use of the fact that PSCN is locally constant on each chromosome.
MISC	Our results also allow the distinction to be made between true LOH and apparent LOH due to the amplification of a portion of only one of the chromosomes.
OWNX	The PSCNs of 12 lung cancer samples that we initially analyzed reveal almost exclusively monoallelic amplification of genomic DNA, a result that we subsequently confirm in 89 other lung cell lines and tumors.
MISC	Monoallelic amplification has previously been noted in the literature on the single gene level CITATION CITATION, wherein mutant forms of known oncogenes are amplified, while their wild-type counterparts are left unaltered.
OWNX	To our knowledge, this phenomenon has not previously been described on a genome-wide scale, though proposed mechanisms of amplification such as unequal sister chromatid exchange CITATION would suggest monoallelic amplification as the expected result.
OWNX	In addition, our ASCNs identify the SNP haplotypes being amplified.
MISC	These haplotypes could conceivably serve as markers for deleterious germ line mutations via linkage disequilibrium.
OWNX	Indeed, the presence of monoallelic amplification makes such linkage studies statistically tractable .
OWNX	Solomonoff's central result on induction is that the prediction of a universal semimeasure  SYMBOL  converges rapidly and with probability 1 to the true sequence generating predictor  SYMBOL , if the latter is computable
OWNX	Hence,  SYMBOL  is eligible as a universal sequence predictor in case of unknown  SYMBOL
OWNX	Despite some nearby results and proofs in the literature, the stronger result of convergence for all (Martin-L{\"o}f) random sequences remained open
MISC	Such a convergence result would be particularly interesting and natural, since randomness can be defined in terms of  SYMBOL  itself
OWNX	We show that there are universal semimeasures  SYMBOL  which do not converge to  SYMBOL  on all  SYMBOL -random sequences, ie \ we give a partial negative answer to the open problem
OWNX	We also provide a positive answer for some non-universal semimeasures
MISC	We define the incomputable measure  SYMBOL  as a mixture over all computable measures and the enumerable semimeasure  SYMBOL  as a mixture over all enumerable nearly-measures
OWNX	We show that  SYMBOL  converges to  SYMBOL  and  SYMBOL  to  SYMBOL  on all random sequences
MISC	The Hellinger distance measuring closeness of two distributions plays a central role
MISC	A sequence prediction task is defined as to predict the next symbol  SYMBOL  from an observed sequence  SYMBOL
MISC	The key concept to attack general prediction problems is Occam's razor, and to a less extent Epicurus' principle of multiple explanations
MISC	The former/latter may be interpreted as to keep the simplest/all theories consistent with the observations  SYMBOL  and to use these theories to predict  SYMBOL
MISC	Solomonoff  CITATION  formalized and combined both principles in his universal a priori semimeasure  SYMBOL  which assigns high/low probability to simple/complex environments  SYMBOL , hence implementing Occam and Epicurus
MISC	Formally it can be represented as a mixture of all enumerable semimeasures
MISC	An abstract characterization of  SYMBOL  by Levin  CITATION  is that  SYMBOL  is a universal enumerable semimeasure in the sense that it multiplicatively dominates all enumerable semimeasures
MISC	Solomonoff's  CITATION  central result is that if the probability  SYMBOL  of observing  SYMBOL  at time  SYMBOL , given past observations  SYMBOL  is a computable function, then the universal predictor  SYMBOL  converges (rapidly )  with  SYMBOL -probability 1  (w p 1) for  SYMBOL  to the optimal/true/informed predictor  SYMBOL , hence  SYMBOL  represents a universal predictor in case of unknown ``true'' distribution  SYMBOL
MISC	Convergence of  SYMBOL  to  SYMBOL  w p 1 tells us that  SYMBOL  is close to  SYMBOL  for sufficiently large  SYMBOL  for almost all sequences  SYMBOL
MISC	It says nothing about whether convergence is true for any  particular  sequence (of measure 0)
MISC	Martin-L{\"o}f (M L ) randomness is the standard notion for randomness of individual sequences  CITATION
MISC	A M L -random sequence passes  all  thinkable effective randomness tests, eg \ the law of large numbers, the law of the iterated logarithm, etc
MISC	In particular, the set of all  SYMBOL -random sequences has  SYMBOL -measure 1
MISC	It is natural to ask whether  SYMBOL  converges to  SYMBOL  (in difference or ratio) individually for all M L -random sequences
MISC	Clearly, Solomonoff's result shows that convergence may at most fail for a set of sequences with  SYMBOL -measure zero
MISC	A convergence result for M L -random sequences would be particularly interesting and natural in this context, since M L -randomness can be defined in terms of  SYMBOL  itself  CITATION
MISC	Despite several attempts to solve this problem  CITATION , it remained open  CITATION
AIMX	In this paper we construct an M L -random sequence and show the existence of a universal semimeasure which does not converge on this sequence, hence answering the open question negatively for some  SYMBOL
MISC	It remains open whether there exist (other) universal semimeasures, probably with particularly interesting additional structure and properties, for which M L -convergence holds
OWNX	The main positive contribution of this work is the construction of a non-universal enumerable semimeasure  SYMBOL  which M L -converges to  SYMBOL  as desired
MISC	As an intermediate step we consider the incomputable measure  SYMBOL , defined as a mixture over all computable measures
OWNX	We show M L -convergence of predictor  SYMBOL  to  SYMBOL  and of  SYMBOL  to  SYMBOL
MISC	The Hellinger distance measuring closeness of two predictive distributions plays a central role in this work
OWNX	The paper is organized as follows: In Section~ we give basic notation and results (for strings, numbers, sets, functions, asymptotics, computability concepts, prefix Kolmogorov complexity), and define and discuss the concepts of (universal) (enumerable) (semi)measures
MISC	Section~ summarizes Solomonoff's and G\'acs' results on predictive convergence of  SYMBOL  to  SYMBOL  with probability 1
MISC	Both results can be derived from a bound on the expected Hellinger sum
MISC	We present an improved bound on the expected exponentiated Hellinger sum, which implies very strong assertions on the convergence rate
MISC	In Section~ we investigate whether convergence for all Martin-L{\"o}f random sequences hold
MISC	We construct a  SYMBOL -M L -random sequence on which some universal semimeasures  SYMBOL  do not converge to  SYMBOL
OWNX	We give a non-constructive and a constructive proof of different virtue
OWNX	In Section~ we present our main positive result
OWNX	We derive a finite bound on the Hellinger sum between  SYMBOL  and  SYMBOL , which is exponential in the randomness deficiency of the sequence and double exponential in the complexity of  SYMBOL
OWNX	This implies that the predictor  SYMBOL  M L -converges to  SYMBOL
OWNX	Finally, in Section~ we show that  SYMBOL  is non-universal and asymptotically M L -converges to  SYMBOL , and summarize the computability, measure, and dominance properties of  SYMBOL ,  SYMBOL ,  SYMBOL , and  SYMBOL
OWNX	Section~ contains discussion and outlook
MISC	Boosting is of great interest recently in the machine learning community because  of the impressive performance for classification and regression problems
MISC	The success of boosting algorithms may be interpreted in terms of the margin theory   CITATION
MISC	Recently, it has been shown that generalization error of classifiers can be obtained by explicitly taking the margin distribution of the training data into account
MISC	Most of the current boosting algorithms in practice usually optimize a convex loss function and do not make use of the margin distribution
MISC	In this work we design a new boosting algorithm, termed margin-distribution boosting (MDBoost), which directly maximizes the average margin and minimizes the margin variance at the same time
OWNX	This way the margin distribution is optimized
OWNX	A totally-corrective optimization algorithm based on column generation is proposed to implement MDBoost
OWNX	Experiments on various  datasets show that MDBoost outperforms AdaBoost and LPBoost in most cases
OWNX	Boosting offers a method for improving existing classification algorithms
OWNX	Given a training dataset, boosting builds a   strong  classifier using only a  weak  learning algorithm   CITATION
MISC	Typically, a weak (or base) classifier generated by the weak learning algorithm has a misclassification error that is slightly better than random guess
MISC	A strong classifier has a much better test error
OWNX	In this sense,  boosting algorithms can boost the weak learning algorithm to obtain a much stronger classifier
OWNX	Boosting was originally proposed as an ensemble learning method, which depends on majority voting of multiple individual classifiers
OWNX	Later, Breiman  CITATION  and Friedman  CITATION  observed that many boosting algorithms can be viewed as gradient descent optimization in functional space
MISC	Mason  CITATION  developed  AnyBoost for boosting arbitrary loss functions with a similar idea
MISC	Despite the large success in practice of these boosting algorithms, there are still open questions about why and how boosting works
MISC	Inspired by the large-margin theory in kernel methods,  Schapire   CITATION  presented a margin-based bound for AdaBoost, which tries to interpret AdaBoost's success with the margin theory
MISC	Although the margin theory provides a qualitative explanation of the effectiveness  of boosting, the bounds are quantitatively weak
MISC	A recent work  CITATION  has proffered new tighter margin bounds, which may be useful for quantitative predictions
OWNX	Arc-Gv   CITATION , a variant of the AdaBoost algorithm, was designed  by Breiman to empirically test AdaBoost's convergence properties
MISC	It   is very similar to AdaBoost (only different  in calculating the coefficient associated with each weak classifier) such that  it increases margins even more aggressively than AdaBoost
MISC	Breiman's   experiments on Arc-Gv  show contrary results to the margin theory: Arc-Gv always has a minimum margin that is provably larger than AdaBoost but Arc-Gv performs worse in terms of test error  CITATION
OWNX	Grove and Schuurmans  CITATION  observed the same phenomenon
MISC	In the literature, much work has focused on maximizing the minimum margin  CITATION
MISC	Recently, Reyzin and Schapire  CITATION  re-ran Breiman's experiments by controlling weak classifiers' complexity
MISC	They found that a better margin distribution is more important than the minimum margin
MISC	It is of importance to have a large minimum margin, but not at the expense of other factors
MISC	They thus conjectured that maximizing the average margin rather than the minimum margin may lead to improved boosting algorithms
OWNX	We try to verify this conjecture in this work
OWNX	Recently, Garg and Roth  CITATION   introduced margin distribution based complexity measure for learning classifiers and developed margin distribution based generalization bounds
MISC	Competitive classification results have been shown by optimizing this bound
MISC	Another relevant work is  CITATION
OWNX	CITATION  applies a boosting method to optimize the margin distribution based generalization bound obtained by   CITATION
OWNX	Experiments show that the new boosting methods achieve considerable improvements over AdaBoost
OWNX	The optimization of this new boosting method is based on the AnyBoost framework  CITATION
OWNX	Aligned with these attempts, we propose a new boosting algorithm through optimization of margin distribution (termed MDBoost)
OWNX	Instead of minimizing a margin distribution based generalization bound, we directly optimize the margin distribution: maximizing the average margin and at the same time minimizing the variance of the margin distribution
OWNX	The theoretical justification of the proposed MDBoost is that, approximately, AdaBoost actually maximizes the average margin and minimizes the margin variance
OWNX	The main contributions of our work are as follows
OWNX	We propose a new totally-corrective boosting algorithm, MDBoost, by optimizing the margin distribution directly
MISC	The optimization procedure of MDBoost is based on the idea of  column generation that has been widely used in large-scale linear programming
OWNX	We empirically demonstrate that MDBoost outperforms AdaBoost and LPBoost on most UCI datasets used in our experiments
MISC	The success of MDBoost verifies the conjecture in    CITATION
OWNX	Our results also show that MDBoost has achieved similar (or better) classification performance compared with AdaBoost-CG  CITATION
MISC	AdaBoost-CG  is also totally-corrective in the sense  that all the linear coefficients of the weak classifiers are updated during the training
MISC	An advantage of MDBoost is that,  at each iteration, MDBoost solves a quadratic program while AdaBoost-CG needs to solve a general convex program
OWNX	Throughout the paper, a matrix is denoted by an upper-case letter ( SYMBOL ); a column vector is denoted by a bold low-case letter ( SYMBOL )
MISC	The  SYMBOL th row of  SYMBOL  is denoted by  SYMBOL  and the  SYMBOL th column  SYMBOL
MISC	We use  SYMBOL  to denote the identity matrix
OWNX	SYMBOL  and    SYMBOL  are column vectors of  SYMBOL 's and  SYMBOL 's, respectively
MISC	Their sizes will be clear from the context
MISC	We use  SYMBOL  to denote component-wise inequalities
OWNX	The rest of the paper is structured as follows
OWNX	In Section  we present the main idea
OWNX	In Section  the dual of the MDBoost's optimization problem is derived, which enables us to design an LPBoost-like column generation based boosting algorithm
OWNX	We provide an experimental comparison of the algorithms on UCI data in Section , and conclude the paper in Section
MISC	this article presents several studies that replicate and extend previous research on maximizing
MISC	a modified scale for measuring individual maximizing tendency is introduced
MISC	the scale has adequate psychometric properties and reflects maximizers' aspirations for high standards and their preference for extensive alternative search  but not the decision difficulty aspect included in several previous studies
OWNX	based on this scale  maximizing is positively correlated with optimism  need for cognition  desire for consistency  risk aversion  intrinsic motivation  self-efficacy and perceived workload  whereas the association with regret is inconsistent
MISC	analysis of correlates of the difficulty dimension suggests that decision difficulty should be conceptualized as a separate dimension rather than as a sub-dimension of maximizing
MISC	opportunities for future research are suggested
MISC	the distinction between maximizing and satisficing approaches to decision making has long been considered important in the decision making literature  CITATION
MISC	when maximizing  decision makers hope to find the best possible solution by systematically comparing available alternatives based on well-defined preferences
MISC	when satisficing  in contrast  decision makers aspire to find a solution that meets important minimum requirements and aspirations  i e   an option that is  good enough  rather than  the best 
MISC	schwartz et al CITATION  attracted considerable attention and interest when proposing that individuals differ in their global disposition to maximize versus satisfice in decision making
MISC	a new maximizing scale that was claimed to adequately measure individual maximizing tendency was presented
MISC	based on analysis of correlates of this scale  maximizers seemed to be less happy with life  to be less optimistic and to possess lower self-esteem
MISC	maximizers also appeared to be more prone to depression  perfectionism and regret as well as more inclined to engage in upward social comparison than satisficers
MISC	accordingly  schwartz  CITATION  argued that maximizing represents a recipe for unhappiness due to overly high expectations and self-fulfilling fears of regret
MISC	increased opportunities for choice were also claimed to represent a particular burden for maximizers  who would feel compelled to explore all possible opportunities and find it increasingly difficult to make a choice
MISC	this line of reasoning corresponds to schwartz's  CITATION  previous research on problems related to increased choice and the possible tyranny of freedom  and schwartz  CITATION  recommended that decision makers should make efforts to learn to accept  good enough  rather than searching for the elusive  best  as well as stop worrying about what they are missing
MISC	subsequent research has replicated several of the key results from schwartz et al 's  CITATION  studies and identified other negative correlates
MISC	for example  findings by parker  bruine de bruin and fischoff  CITATION  suggest that maximizing is associated with worse life outcomes  less behavioral coping  greater dependence on others and more decision avoidance
MISC	parker et al CITATION  argued that  if these relationships are causal  then it is of importance to teach normative decision making skills as well as to stress the benefits of satisficing in order to obtain better outcomes
MISC	inspired by the research opportunities associated with schwartz et al 's  CITATION  maximizing scale as well as the prospects of offering practical advice to decision makers  the scale was introduced to several groups of graduate students in business administration in norway
MISC	some groups responded to the original english version of the scale while other groups rated items on a pilot version in norwegian based on preliminary translations of items
MISC	surprisingly  hardly any of the subjects seemed to be maximizers based on their scores on the original maximizing scale  regardless of whether the scale was presented in the original english version or in the pilot-version in norwegian
MISC	all but very few subjects reported satisficing approaches to most of the tasks depicted in the items on the scale
MISC	yet  based on discussions of schwartz et al 's  CITATION  theoretical underpinnings  many subjects reported that they indeed considered themselves maximizers
MISC	however  many of the items on the scale were seen as too commonplace or too inconsequential to set off maximizing efforts
MISC	subjects also argued that many items referred to situations that were irrelevant to them
MISC	this feedback indicated that many items on the scale are not sufficiently general in terms of item content and simultaneously not sufficiently relevant to measure differences in individual maximizing tendency across samples  settings and cultures
MISC	these limitations in the construct validity of the scale have also been stressed by diab  gillespie and highhouse  CITATION   among others
MISC	diab et al CITATION  argued that uni-dimensionality and internal consistency are important characteristics of the maximization attribute  and that all thirteen items of the scale should load onto one factor
MISC	however  schwartz et al 's  CITATION  scale comprises three distinct sub-dimensions and several items produce relatively weak or inconsistent factor loadings
MISC	accordingly  there has been a debate in the literature concerning the validity of the construct  the factor structure and reliability of the scale as well as the proposed correlates indicating that maximizers are less happy than satisficers
MISC	diab et al CITATION  asserted that the findings indicating that maximizers are less happy than satisficers need to be interpreted in light of inadequate definition and measurement of the core construct
MISC	based on the definition of individual maximizing tendency as the  general tendency to pursue the identification of the optimal alternative  diab et al CITATION  presented several alternative measures
MISC	as hypothesized  schwartz et al 's  CITATION  maximizing scale produced significantly higher correlations with maladaptive personality traits and dysfunctional decision making behaviors such as regret  indecisiveness  avoidance  neuroticism  and life-satisfaction than several of diab et al 's  CITATION  alternative measures  including their nine-item scale
MISC	nenkov  morrin  ward  schwartz and hulland  CITATION  also addressed the factor structure  reliability and validity of schwartz et al 's  CITATION  maximizing scale  and several short forms of the scale were tested using datasets from different populations
MISC	results replicated the three-factor solution from schwartz et al CITATION
MISC	nenkov et al CITATION  interpreted the first dimension to reflect preference for extensive alternative search  i e   the desire to continue seeking for even better options
MISC	the second dimension was interpreted to reflect decision difficulty  i e   decision makers' perceived difficulty in choosing and making decisions
MISC	the third dimension was taken to represent decision makers' tendency to hold high standards for themselves and their surroundings
MISC	nenkov et al CITATION  argued along the same lines as diab et al CITATION   stressing the need for uni-dimensionality and internal consistency in measurements of the maximizing construct
MISC	however  although several short versions of schwartz et al 's  CITATION  scale appeared equally useful when analyzing correlates  the three sub-dimensions varied in their correlation with other variables
MISC	nenkov et al CITATION  therefore argued that the three dimensions should be examined separately in future research and that there is a need to resolve whether all or perhaps only one or two of the three sub-dimensions represent inherent components of the maximizing construct
MISC	the research reported by diab et al CITATION  and nenkov et al CITATION  suggests that the measurement of individual maximizing tendency is associated with several  fundamental  methodological problems that need to be resolved in order to advance research in this area
MISC	in view of the interest in schwartz et al 's  CITATION  seminal article  relatively few studies report empirical findings based on the original scale or refined versions of the scale so far
MISC	important exceptions include carrillat  edmondson and ladik's  CITATION  study of customer loyalty  iyengar  wells and schwartz's  CITATION  investigation of job search strategies  bruine de bruin  parker and fischoff's  CITATION  investigation of individual differences in decision making competence  parker  bruine de bruin and fischoff's  CITATION  exploration of decision making styles  competence  and outcomes  chowdhury  ratneshwar and mohanty's  CITATION  investigation of maximizing versus satisficing consumers  and lewer  gerlich and gretz'  CITATION  analysis of determinants of maximizing in consumer purchase
OWNX	the ambition of the studies reported here was threefold
MISC	the first purpose  which derives from the lack of success when introducing schwartz et al 's  CITATION  scale to a new population  was to contribute to improving the measurement scale by testing original and new items across several new and large samples
MISC	the second purpose was to replicate and extend previous studies of correlates of individual maximizing tendency
MISC	improved insight into correlates may shed better light on maximizers' personality traits and the driving forces behind efforts to maximize in decision making
MISC	instrument development and testing across subjects and settings is important for practical as well as theoretical and methodological reasons
MISC	a reliable scale with adequate factor structure and discriminate validity would facilitate future research on maximizing  CITATION
MISC	efforts to develop an adequate scale may also improve our understanding of the core construct and aid in the development of a clearer definition and a better nomological net
MISC	the attention attracted to schwartz et al 's  CITATION  research also demonstrates that a reliable scale is of high interest and has high potential value for decision makers who wish to reflect on and improve their decision making
MISC	In a sensor network, in practice, the communication among sensors is subject to:  The signal-to-noise ratio~(SNR) is usually a main factor in determining the probability of error (or of communication failure) in a link
MISC	These probabilities are then a proxy for  the SNR under which the links operate
MISC	The paper studies the problem of designing the topology, ie ,   assigning the probabilities of reliable communication among sensors (or of link failures) to maximize the rate of convergence of average consensus, when the link communication costs are taken into account, and there is an overall communication budget constraint
AIMX	To consider this problem,  we address a number of preliminary issues:    With these results, we formulate topology design, subject to random link failures and to a communication cost constraint, as a constrained convex optimization problem to which we apply semidefinite programming techniques
MISC	We show by an extensive numerical study that the optimal design improves significantly the convergence speed of the consensus algorithm and can achieve the asymptotic performance of a non-random network at a fraction of the communication cost
MISC	We consider the design of the optimal topology, i e , the communication configuration of a sensor network that maximizes  the convergence rate of average consensus
MISC	Average consensus is a distributed algorithm that has been considered by Tsitsiklis in his PhD thesis,  CITATION , see also~ CITATION ,  found application recently in several areas, and is the subject of active research, e
MISC	g,,  CITATION
MISC	This topology design for sensor networks  has not received much attention in the literature
MISC	References~ CITATION  and~ CITATION  consider  restrict it to classes of random graphs,  in particular, small-world topologies
MISC	The more general question of designing the topology that maximizes the convergence rate, under a constraint on the number of network links,  was considered in our previous work,  CITATION , where we reduced to average consensus the problem of distributed inference in sensor networks; see also~ CITATION
MISC	Realistic networks operate under stress:   We model such a non-deterministic network topology as a random field
AIMX	Specifically, we assume the following:  Designing the network topology corresponds then to   The paper extends our preliminary  convergence results,  CITATION , on networks with random links
MISC	The recent paper~ CITATION  adopts a similar model and  analyzes convergence properties using ergodicity of stochastic matrices
MISC	Consensus with a randomized network also relates to gossip algorithms,  CITATION , where only a single pair of randomly selected sensors is allowed to communicate at each iteration, and the communication exchanged by the nodes is averaged
MISC	In our randomized consensus, we use multiple  randomly selected links at each iteration and, in contradistinction with~ CITATION , we design the optimal topology, i e , the optimal weight (not simple average) and the optimal probabilities of edge utilization, recognizing that communication entails costs, and that there is a communication cost constraint
MISC	Other recent work on evolving topologies includes~ CITATION  that considers continuous time consensus in networks with switching topologies and communication delays, and~ CITATION  that studies distributed consensus when the network is  a complete graph with identical link failure probabilities on all links
OWNX	We outline the paper
MISC	Section~ summarizes spectral graph theory concepts like  the graph Laplacian~ SYMBOL  and the graph algebraic connectivity   SYMBOL
MISC	% of the  Laplacian~ SYMBOL
MISC	The Section formulates the problem of distributed average consensus with random link failures
OWNX	Sections~ and  derive necessary and sufficient conditions  for convergence of the mean state, mss convergence, and a s ~convergence in terms of the average  SYMBOL  and in terms of  SYMBOL , where  SYMBOL
MISC	Section~ presents bounds on the mss convergence rate
MISC	Section~ addresses the topology design for random networks with communication cost constraints
AIMX	We formulate a first version of the problem, the randomized distributed consensus with a communication cost constraint (RCCC), and then an alternate version, which we show is a convex constrained optimization problem,  to which we apply semidefinite programming~(SDP) techniques
MISC	Section~  studies the performance of the topologies found by solving numerically the SDP optimization
MISC	We show that these designs can improve significantly the convergence rate, for example, by a factor of~ SYMBOL , when compared to geometric networks (networks where sensors communicate with every other sensor within a fixed radius) and that they can achieve practically the (asymptotic) performance of a nonrandom network at a fraction, eg , 50~\%, of the communication cost per iteration
OWNX	Section~ concludes the paper
MISC	Non-intermingling, adjacent populations of cells define compartment boundaries; such boundaries are often essential for the positioning and the maintenance of tissue-organizers during growth.
OWNX	In the developing wing primordium of Drosophila melanogaster, signaling by the secreted protein Hedgehog is required for compartment boundary maintenance.
MISC	However, the precise mechanism of Hh input remains poorly understood.
OWNX	Here, we combine experimental observations of perturbed Hh signaling with computer simulations of cellular behavior, and connect physical properties of cells to their Hh signaling status.
MISC	We find that experimental disruption of Hh signaling has observable effects on cell sorting surprisingly far from the compartment boundary, which is in contrast to a previous model that confines Hh influence to the compartment boundary itself.
MISC	We have recapitulated our experimental observations by simulations of Hh diffusion and transduction coupled to mechanical tension along cell-to-cell contact surfaces.
OWNX	Intriguingly, the best results were obtained under the assumption that Hh signaling cannot alter the overall tension force of the cell, but will merely re-distribute it locally inside the cell, relative to the signaling status of neighboring cells.
OWNX	Our results suggest a scenario in which homotypic interactions of a putative Hh target molecule at the cell surface are converted into a mechanical force.
OWNX	Such a scenario could explain why the mechanical output of Hh signaling appears to be confined to the compartment boundary, despite the longer range of the Hh molecule itself.
OWNX	Our study is the first to couple a cellular vertex model describing mechanical properties of cells in a growing tissue, to an explicit model of an entire signaling pathway, including a freely diffusible component.
MISC	We discuss potential applications and challenges of such an approach.
MISC	During embryonic development of complex multicellular organisms, spatial reference points need to be established within tissues.
MISC	These are often formed by specialized groups of cells that are capable of signaling to neighboring cells.
MISC	Such signaling centers define coordinate systems along which newly arising cells can orient themselves and make crucial decisions regarding proliferation, differentiation or migration CITATION, CITATION, CITATION, CITATION, CITATION, CITATION.
MISC	Because of their pervasive importance, tissue-organizing centers need to be precisely controlled both spatially and temporally, as well as with respect to their signaling amplitude.
MISC	One possible mechanism for spatial control of tissue organizers is to restrict the movement of cells at fixed boundary positions.
MISC	This phenomenon is indeed observed, and it involves the separation of groups of cells that have already been spatially instructed to assume distinct identities, for example at segment- or parasegment-boundaries.
OWNX	Akin to water in oil, the two cell populations are seen to establish and maintain a relatively straight interface to each other, effectively minimizing their contact area.
MISC	The minimizing force is assumed to help stabilize the interface against random perturbations that may arise from cell divisions or from arbitrary cell movements; thus, any organizing activity that is associated with the interface is likewise stabilized.
MISC	How is this separation, or sorting, of cells of distinct identities achieved?
OWNX	One line of work attributes this to differential cell adhesion CITATION, CITATION : cell populations might develop distinct adhesive properties; these affinity differences would then allow them to sort out from one another.
MISC	Another line of reasoning is based on Differential Interfacial Tension CITATION, CITATION : this hypothesis suggests that cells might actively constrict surfaces that are in contact with neighboring cells, depending on the cellular identity of neighbors and/or depending on signaling events.
OWNX	Both mechanisms would ultimately lead to physical forces that would help keep the cell populations apart.
MISC	The developing wing primordium of Drosophila is particularly well suited to study boundary formation.
MISC	It is not required for larval viability, can be manipulated experimentally through an advanced genetic toolkit, and has been well characterized.
MISC	The disc contains a compartment boundary that separates anterior from posterior cells; this boundary is inherited from specification events occurring early in the embryo.
MISC	The initial embryonic events that give rise to the boundary involve mutual signaling between stripes of cells, mediated by an extensively studied network of genes.
MISC	Once established, the cellular identities on both sides of these boundaries are stable throughout larval development and well into adult life.
MISC	The compartment boundary in the disc is strictly respected by all cells, even when cells on one side of the boundary are artificially provided with a competitive growth advantage over cells on the other side of the boundary CITATION.
OWNX	The wing disc itself is a simple, flat, epithelial sheet, and the orientations of cell divisions appear largely random CITATION.
MISC	Genetic analysis and computational modeling of this tissue is simplified by the fact that daughter cells arising from cell divisions usually remain in physical contact and do not migrate away from each other.
MISC	This has been shown experimentally by tracing descendents of single cells; in most cases such a clone of offspring cells will form a coherent patch of connected cells.
OWNX	This behavior suggests that the complicated processes of cell intercalation and migration can be neglected, to a first approximation, when studying boundary maintenance in this tissue.
MISC	Working with such wing discs, a recent, seminal study has begun to shed light on possible boundary formation mechanisms CITATION.
OWNX	The authors have directly demonstrated an increased mechanical tension at cell-to-cell interfaces located immediately at the boundary, using laser ablation experiments.
MISC	Subsequent computer simulations then revealed that collectively such local forces are sufficient to maintain a stable compartment boundary.
MISC	These results are intriguing, but they raise a number of new questions: Boundary formation in the wing disc is known to depend on the secreted and diffusible signaling protein Hedgehog, which is produced by posterior cells and specifically sensed and transduced by anterior cells CITATION, CITATION.
MISC	If diffusible Hh indeed somehow influences mechanical tension, what conditions must then be met to ensure a well-defined boundary?
OWNX	So far, all known transcriptional responses of Hh signaling are occurring several cell-diameters wide into the responding tissue.
MISC	How is the response in this case restricted to the immediate boundary region?
MISC	Furthermore, experimental suppression of Hh signaling has been shown to lead to ectopic boundary formation distant from the actual boundary CITATION.
MISC	Does this mean that the influence of Hh signaling does extend beyond the actual boundary, and if so, why does this not have a noticeable consequence in the wild type situation?
OWNX	Here, we propose a mechanistic model that can generate a localized outcome of Hh signaling with respect to physical forces and mechanical properties, despite a longer range of the molecular response in terms of target gene expression.
MISC	Furthermore, we estimate the distance from the boundary, up to which Hh signaling may be able prime cells for boundary formation; this distance is inferred using both experimental results as well as modeling results, and we estimate it to be at least 10 cell diameters.
OWNX	We approach the problem by first formulating an explicit, two-dimensional model of Hh production, diffusion and transduction, and by then coupling this setup to a physical model of the growing tissue.
MISC	In our modeling approach, cells and their contact surfaces are described as a graph of connected vertexes.
MISC	Our model essentially follows the Differential Interface Tension hypothesis; it is a modified version of a model that has been previously established for the very same tissue CITATION.
MISC	We observe good compartment boundary formation over a range of simulation parameters, and the modeling outcomes agree qualitatively with experimental perturbations specifically performed for this study.
MISC	The increasing importance of non-coding RNA in biology and medicine has led to a growing interest in the problem of RNA 3-D structure prediction.
MISC	As is the case for proteins, RNA 3-D structure prediction methods require two key ingredients: an accurate energy function and a conformational sampling procedure.
MISC	Both are only partly solved problems.
OWNX	Here, we focus on the problem of conformational sampling.
MISC	The current state of the art solution is based on fragment assembly methods, which construct plausible conformations by stringing together short fragments obtained from experimental structures.
MISC	However, the discrete nature of the fragments necessitates the use of carefully tuned, unphysical energy functions, and their non-probabilistic nature impairs unbiased sampling.
OWNX	We offer a solution to the sampling problem that removes these important limitations: a probabilistic model of RNA structure that allows efficient sampling of RNA conformations in continuous space, and with associated probabilities.
OWNX	We show that the model captures several key features of RNA structure, such as its rotameric nature and the distribution of the helix lengths.
OWNX	Furthermore, the model readily generates native-like 3-D conformations for 9 out of 10 test structures, solely using coarse-grained base-pairing information.
MISC	In conclusion, the method provides a theoretical and practical solution for a major bottleneck on the way to routine prediction and simulation of RNA structure and dynamics in atomic detail.
MISC	Non-coding RNA is of crucial importance for the functioning of the living cell, where it plays key catalytic, regulatory and structural roles CITATION, CITATION.
OWNX	Understanding the exact mechanisms behind these functions is therefore of great importance for both biology and medicine.
MISC	In many cases, this understanding requires knowledge of RNA structure in atomic detail.
MISC	However, determining the structure of an RNA molecule experimentally is typically a time consuming, expensive and difficult task CITATION.
MISC	Therefore, algorithms for RNA structure prediction have attracted much interest, initially with the main focus on predicting secondary structure.
OWNX	Many noticeable advances have been made in the area of secondary structure prediction; most recently the introduction of statistical sampling had an important impact CITATION CITATION .
MISC	In the past years, an increasing number of relevant structures have become available, and much progress has been made in the understanding of the three dimensional structure of RNA.
MISC	The conformational space of RNA has been analyzed using methods inspired by the Ramachandran plot for proteins CITATION, CITATION, the RNA base pair interactions have been accurately classified CITATION, and the conformational space of the RNA backbone has been clustered into discrete recurring conformations CITATION, CITATION CITATION.
MISC	These new insights have led to several useful tools for modeling RNA 3-D structure CITATION, CITATION and significant advances in atomic resolution prediction have recently been reported CITATION, CITATION .
MISC	However, routine prediction of RNA 3-D structure still remains an important open problem, and with the growing gap between the number of known sequences and determined structures, the problem is becoming more and more pronounced.
MISC	The two key ingredients in algorithms for RNA 3-D structure prediction, namely an accurate energy function and a conformational sampling procedure CITATION, are both only partly solved problems.
OWNX	Here, we focus on the latter problem.
MISC	The current state of the art in RNA conformational sampling is based on fragment assembly methods, which construct plausible conformations by stringing together short fragments obtained from experimental structures.
MISC	These methods have led to numerous important breakthroughs in the related fields of protein and RNA 3-D structure prediction in the last ten years CITATION CITATION.
OWNX	Nonetheless, fragment assembly methods are not a panacea.
MISC	One of the problems associated with these methods is that they inherently discretize the continuous conformational space, and hence do not cover all relevant conformations CITATION.
MISC	This is problematic since the resolution of the conformational search procedure imposes limits on the energy function; the use of fine-grained energy terms requires continuous adjustments to the RNA's dihedral degrees of freedom, which fragment assembly methods cannot provide CITATION.
MISC	In other words, the shortcomings of the conformational sampling method need to be counteracted by tweaking the energy function.
MISC	Furthermore, full conformational detail is of great importance for a complete understanding of RNA catalysis, binding CITATION and dynamics CITATION .
OWNX	Another fundamental problem with fragment assembly methods is their non-probabilistic nature, which makes their rigorous use in the framework of statistical physics problematic.
OWNX	Particularly, it is currently impossible to ensure unbiased sampling in a Markov chain Monte Carlo framework using fragment assembly as a proposal function CITATION.
OWNX	In other words, using a fragment library implies adding an inherently unknown additional term to the energy function CITATION.
OWNX	This means that the unbiased simulation of the dynamics of an RNA molecule under the control of an all-atom empirical forcefield using fragment assembly methods is currently impossible.
AIMX	For these reasons we have developed a new solution to the conformational sampling problem: a probabilistic model, called BARNACLE, that describes RNA structure in a natural, continuous space.
MISC	BARNACLE makes it possible to efficiently sample 3-D conformations that are RNA-like on a short length scale.
MISC	Such a model can be used purely as a proposal distribution, but also as an energy term enforcing realistic local conformations.
MISC	Imposing favorable long range interactions, such as hydrogen bonding between the bases, lies outside the scope of such a local model and is the task of a global energy function.
OWNX	BARNACLE combines a dynamic Bayesian network CITATION, which suits the sequential nature of the RNA molecule, with directional statistics, a branch of statistics that is concerned with the representation of angular data.
MISC	The model is not only computationally attractive, but can also be rigorously interpreted in the language of statistical physics CITATION, CITATION, making it attractive from a theoretical viewpoint as well.
OWNX	This approach is conceptually related to the probabilistic models of protein structure recently proposed by our group CITATION, CITATION.
MISC	However, the model presented here is clearly far from a trivial extension, as an RNA molecule has many more degrees of freedom than a protein; in the RNA backbone alone, there are 11 angles per residue CITATION, as opposed to two in proteins.
MISC	These many degrees of freedom combined with the limited number of experimentally determined RNA structures CITATION make this a particularly challenging statistical task for which a very different strategy was required.
OWNX	In particular, the approach we used for proteins would in the case of RNA require the use of a probability density function on the 7-dimensional hypertorus, which poses a serious statistical and computational obstacle.
OWNX	Below, we describe the probabilistic model in detail, and show that it captures the crucial aspects of local RNA structure.
OWNX	We also demonstrate its usefulness in the context of RNA 3-D prediction, and end with an outlook on possible applications.
MISC	A current challenge is to develop computational approaches to infer gene network regulatory relationships based on multiple types of large-scale functional genomic data.
MISC	We find that single-layer feed-forward artificial neural network models can effectively discover gene network structure by integrating global in vivo protein:DNA interaction data with genome-wide microarray RNA data.
MISC	We test this on the yeast cell cycle transcription network, which is composed of several hundred genes with phase-specific RNA outputs.
OWNX	These ANNs were robust to noise in data and to a variety of perturbations.
MISC	They reliably identified and ranked 10 of 12 known major cell cycle factors at the top of a set of 204, based on a sum-of-squared weights metric.
MISC	Comparative analysis of motif occurrences among multiple yeast species independently confirmed relationships inferred from ANN weights analysis.
MISC	ANN models can capitalize on properties of biological gene networks that other kinds of models do not.
MISC	ANNs naturally take advantage of patterns of absence, as well as presence, of factor binding associated with specific expression output; they are easily subjected to in silico mutation to uncover biological redundancies; and they can use the full range of factor binding values.
MISC	A prominent feature of cell cycle ANNs suggested an analogous property might exist in the biological network.
MISC	This postulated that network-local discrimination occurs when regulatory connections are explicitly disfavored in one network module, relative to others and to the class of genes outside the mitotic network.
OWNX	If correct, this predicts that MBF motifs will be significantly depleted from the discriminated class and that the discrimination will persist through evolution.
OWNX	Analysis of distantly related Schizosaccharomyces pombe confirmed this, suggesting that network-local discrimination is real and complements well-known enrichment of MBF sites in G1 class genes.
MISC	Hundreds of yeast RNAs are expressed in a cell cycle dependent, oscillating manner.
OWNX	In both budding yeast and fission yeast, these RNAs cluster into four or five groups, each corresponding roughly to a phase of the cycle CITATION CITATION.
MISC	Large sets of phase-specific RNAs are also seen in animal and plant cells CITATION CITATION, arguing that an extensive cycling transcription network is a fundamental property of Eukaryotes.
MISC	The complete composition and connectivity of the cell cycle transcription network is not yet known for any eukaryote, and many components may vary over long evolutionary distances CITATION CITATION, CITATION, but some specific regulators are paneukaryotic, as are some of their direct target genes.
OWNX	Coupled with experimental accessibility, this conservation of core components and connections make the yeast mitotic cycle an especially good test case for studies of network structure, function, and evolution.
MISC	To expose the underlying logic of this transcription network, a starting point is to decompose the cell cycle into its component phases and link the pertinent regulatory factors with their immediate regulatory output patterns, here in the form of phasic RNA expression.
MISC	One way to do this is to integrate multiple genome-wide data types that impinge on connection inference, including factor:DNA interaction data from chromatin IP studies, RNA expression patterns, and comparative genomic analysis.
MISC	This is appealing partly because these assays are genome-comprehensive and hypothesis-independent, so they can, in principle, reveal regulatory relationships not detected by classical genetics.
CONT	However, the scale and complexity of these datasets require new methods to discover and rank candidate connections, while also accommodating considerable experimental and biological noise.
OWNX	Microarray RNA expression studies in budding yeast have identified 230 to 1,100 cycling genes, the upper number encompassing nearly a fifth of all yeast genes CITATION, CITATION, CITATION, CITATION.
MISC	Specifics of experimental design and methods of analysis contribute to the wide range in the number of genes designated as cycling, but there is agreement on a core set of nearly 200.
MISC	Yeast molecular genetic studies have established that transcriptional regulation is critical for controlling phase-specific RNA expression for some of these genes, though this does not exclude modulation and additional contributions from post-transcriptional mechanisms.
MISC	About a dozen Saccharomyces transcription factors have been causally associated with direct control of cell cycle expression patterns, including repressors, activators, co-regulators, and regulators that assume both repressing and activating roles, depending on context: Ace2, Fkh1, Fkh2, Mbp1, Mcm1, Ndd1, Stb1, Swi4, Swi5, Swi6, Yhp1, and Yox1.
OWNX	These can serve as internal control true-positive connections.
OWNX	Conversely, a majority of yeast genes have no cell cycle oscillatory expression, and true negatives can be drawn from this group.
MISC	A practical consideration is how well the behavior of a network is represented in critical datasets.
MISC	In this case, cells in all cell cycle phases are present in the mixed phase, exponentially growing yeast cultures used for the largest and most complete set of global protein:DNA interaction data so far assembled in functional genomics CITATION.
MISC	These data are further supported by three smaller studies of the same basic design CITATION CITATION.
MISC	This sets the cell cycle apart from many other transcription networks whose multiple states are either partly or entirely absent from the global ChIP data.
MISC	Equally important are RNA expression data that finely parse the kinetic trajectory for every gene across the cycle of budding yeast CITATION, CITATION and also in the distantly related fission yeast, S. pombe CITATION CITATION.
MISC	This combination of highly time-resolved RNA expression data and phase-mixed ChIP/array data can be used to assign protein:DNA interactions to explicit cell cycle phases, while evolutionary comparison with S. pombe highlight exceptionally conserved and presumably fundamental network properties.
OWNX	Many prior efforts to infer yeast transcription network connections from genome-wide data CITATION CITATION, CITATION, CITATION were designed to address the global problem of finding connection patterns across the entire yeast transcriptome by using very large and diverse collections of yeast RNA, DNA, and/or chromatin immunoprecipitation data.
MISC	The present work focuses instead on a single cellular process and its underlying gene network, which represents a natural level of organization positioned between the single gene at one extreme and the entire interlocking community of networks that govern the entire cell.
OWNX	To model regulatory factor:target gene behavior, we adapted neural networks to integrate global expression and protein:DNA interaction data.
MISC	Artificial neural networks are structural computational models with a long history in pattern recognition CITATION.
OWNX	A general reason for thinking ANNs could be effective for this task is that they have some natural similarities with transcription networks, including the ability to create nonlinear sparse interactions between transcriptional regulators and target genes.
MISC	They have previously been applied to model relatively small gene circuits CITATION CITATION, though they have not, to our knowledge, been used for the problem of inferring network structure by integrating large-scale data.
MISC	We reasoned that a simple single-layer ANN would be well-suited to capture and leverage two additional known characteristics of eukaryotic gene networks.
OWNX	First, factor binding in vivo varies over a continuum of values, as reflected in ChIP data, in vivo footprinting, binding site numbers and affinity ranges, and site mutation analyses.
OWNX	These quantitative differences can have biological significance to transcription output by affecting cooperativity, background leaky expression or the lack of it, and the temporal sequencing of gene induction as factors become available or disappear.
MISC	This is quite different from a world in which binding is reduced to a simple two-state, present/absent call.
MISC	Neural networks are able to use the full range of binding probabilities in the dataset.
MISC	Second, ANNs can give weight and attention to structural features such as the persistent absence of specific factors from particular target groups of genes.
MISC	This negative image information is potentially important and not used by other methods applied to date CITATION, CITATION, CITATION, CITATION.
MISC	The inherent ability of ANNs to use these properties is a potential strength compared with algorithms that rest solely on positive evidence of factor:target binding or require discretization of binding measurements into a simplified bound/unbound call.
OWNX	ANNs have been most famously used in machine learning as black boxes to perform classification tasks, in which the goal is to build a network based on a training dataset that will subsequently be used to perform similar classifications on new data of similar structure.
OWNX	In these classical ANN applications, the weights within the network are of no particular interest, as long as the trained network performs the desired classification task successfully when extrapolating to new data.
OWNX	ANNs are used here in a substantially different way, serving as structural models CITATION.
OWNX	Specifically, we use simple feed-forward networks in which the results of interest are mainly in the weights and what they suggest about the importance of individual transcription factors or groups of factors for specifying particular expression outputs.
OWNX	Here ANNs were trained to predict the RNA expression behavior of genes during a cdc28 synchronized cell cycle, based solely on transcription factor binding pattern, as measured by ChIP/array for 204 yeast factors determined in an exponentially growing culture CITATION.
MISC	The resulting ANN model is then interrogated to identify the most important regulator-to-target gene associations, as reflected by ANN weights.
MISC	Ten of the twelve major known transcriptional regulators of cell cycle phase-specific expression ranked at the very top of the 204-regulator list in the model.
MISC	The cell cycle ANNs were remarkably robust to a series of in silico mutations, in which binding data for a specific factor was eliminated and a new family of ANN models were generated.
MISC	Additional doubly and triply mutated networks correctly identified epistasis relationships and redundancies in the biological network.
OWNX	This approach was also applied to two additional, independent cell cycle expression studies to illustrate generality across data platforms, and to probe how the networks might change under distinct modes of cell synchronization.
OWNX	Analysis of the weights matrices from the resulting models shows that the neural nets take advantage of information about specifically disfavored or disallowed connections between factors and expression patterns, together with the expected positive connections for other factors, to assign genes to their correct expression outputs.
MISC	This led us to ask if there is a corresponding bias in the biological network against binding sites for specific factors in some expression families as suggested by the ANN.
OWNX	We found that this is the case, in multiple sensu stricto yeast genomes relatively closely related to Saccharomyces cerevisiae, and also in the distantly related fission yeast S. pombe.
MISC	This appears to be a deeply conserved network architecture property, even though very few specific orthologous genes are involved.
OWNX	We develop the concept of  ABC -Boost ( A daptive  B ase  C lass Boost) for  multi-class classification and  present   ABC -MART, a concrete implementation of  ABC -Boost
MISC	The original MART ( M ultiple  A dditive  R egression  T rees) algorithm has been very successful in large-scale applications
OWNX	For binary classification, ABC-MART recovers MART
OWNX	For multi-class  classification,  ABC-MART considerably improves MART, as  evaluated on several public data sets
MISC	Classification is a basic task in machine learning
MISC	A training data set  SYMBOL  consists of  SYMBOL  feature vectors (samples)  SYMBOL , and  SYMBOL  class labels,  SYMBOL ,  SYMBOL  to  SYMBOL
OWNX	Here  SYMBOL  and  SYMBOL  is the number of classes
MISC	The  task is to predict the class labels
OWNX	This study focuses on multi-class classification ( SYMBOL )
MISC	Many classification algorithms are based on  boosting  CITATION , which is  regarded one of most significant breakthroughs in machine learning
MISC	MART CITATION  ( M ultiple  A dditive  R egression  T rees) is a successful boosting algorithm, especially for large-scale applications in industry practice
OWNX	For example, the regression-based ranking method developed in Yahoo
OWNX	CITATION  used an underlying learning algorithm based on MART
MISC	McRank  CITATION , the classification-based ranking method, also used MART as the underlying learning procedure
OWNX	This study proposes  ABC -Boost ( A daptive  B ase  C lass Boost) for  multi-class classification
OWNX	We present   ABC -MART, a concrete implementation of {ABC}-Boost
MISC	ABC-Boost  is based on the following two key ideas:   For multi-class classification, popular loss functions for  SYMBOL  classes usually assume a constraint CITATION   such that only the values for  SYMBOL  classes are needed
OWNX	Therefore, we can choose a  base class  and derive  algorithms only for   SYMBOL  classes
MISC	At each boosting step, although the base class is not explicitly trained, it will implicitly benefit from  the training on  SYMBOL  classes, due to the constraint
OWNX	Thus, we  adaptively  choose the base class which  has the ``worst'' performance
OWNX	The idea of assuming a constraint on the loss function and  using a base class  may not be at all surprising
MISC	For binary ( SYMBOL ) classification, a ``sum-to-zero'' constraint on the loss function is automatically considered so that we only need to train the algorithm for one (instead of  SYMBOL ) class
OWNX	For multi-class ( SYMBOL ) classification, the sum-to-zero constraint on the loss function is also ubiquitously adopted CITATION
OWNX	In particular, the multi-class  Logitboost  CITATION  algorithm was derived by explicitly averaging over  SYMBOL  base classes
OWNX	The loss function adopted in our ABC-MART is the same as in MART CITATION  and  Logitboost  CITATION
MISC	All three algorithms assume the ``sum-to-zero'' constraint
OWNX	However, we obtain different first and second derivatives of the loss function, from MART CITATION  and  Logitboost  CITATION
MISC	See Section  for details
OWNX	In terms of implementation, our proposed ABC-MART differs from the original MART algorithm only in a few lines of code
OWNX	Since MART is known to be a successful algorithm, much of our work is devoted to the empirical comparisons of ABC-MART with MART
OWNX	Our experiment results on publicly available data sets will demonstrate that ABC-MART could considerably improves MART
MISC	Also, ABC-MART reduces both the training and testing time by  SYMBOL , which may be quite beneficial when  SYMBOL  is small
MISC	We notice that data sets in industry applications are often quite large (e g , several million samples CITATION )
MISC	Publicly available data sets (e g , UCI repository), however, are mostly small
OWNX	In our study, the  Covertype  data set from the UCI repository is reasonably large with 581,012 observations \\   We first review the original MART algorithm and functional gradient boosting CITATION
MISC	The problem of statistical learning is to construct an accurate predictor of a random variable as a function of a correlated random variable on the basis of an  iid  \ training sample from their joint distribution
MISC	Allowable predictors are constrained to lie in some specified class, and the goal is to approach asymptotically the performance of the best predictor in the class
MISC	We consider two settings in which the learning agent only has access to rate-limited descriptions of the training data, and present information-theoretic bounds on the  predictor performance achievable in the presence of these communication constraints
MISC	Our proofs do not assume any separation structure between compression and learning and rely on a new class of operational criteria specifically tailored to joint design of encoders and learning algorithms in rate-constrained settings
MISC	Let  SYMBOL  and  SYMBOL  be jointly distributed random variables
MISC	The problem of statistical learning is to design an accurate predictor of the  output variable   SYMBOL  from the  input variable   SYMBOL  on the basis of a number of independent  training samples  drawn from their joint distribution, with very little or no prior knowledge of that distribution
MISC	The present paper focuses on the achievable performance of learning schemes when the learning agent only has access to a finite-rate description of the training samples
MISC	This problem of  learning under communication constraints  arises in a variety of contexts, such as distributed estimation using a sensor network, adaptive control, or repeated games
OWNX	In these and other scenarios, it is often the case that the agents who gather the training data are geographically separated from the agents who use these data to make inferences and decisions, and communication between these two types of agents is possible only over rate-limited channels
MISC	Hence, there is a trade-off between the communication rate and the quality of the inference, and it is of interest to characterize this trade-off mathematically
OWNX	This paper follows on our earlier work  CITATION  and presents improved bounds on the achievable performance of statistical learning schemes operating under two kinds of communication constraints: (a) the entire training sequence is delivered to the learning agent over a rate-limited noiseless digital channel, and (b) the input part of the training sequence is available to the learning agent with arbitrary precision, while the output part is delivered, as before, over a rate-limited channel
OWNX	Whereas  CITATION  has looked at schemes where the finite-rate description of the training data was obtained through vector quantization, effectively imposing a separation structure between compression and learning, here we remove this restriction
MISC	We show that, under certain regularity conditions, there is no penalty for compression of the training sequence in the setting (a)
MISC	This is due to the fact that the encoder can reliably estimate the underlying distribution (in the metric specifically tailored for the learning problem at hand) and then communicate the finite-rate description to the learning agent, who can then find the optimum predictor for the estimated distribution
MISC	The setting (b), however, is radically different: because the encoder has no access to the input part of the training sample, it cannot estimate the underlying distribution
MISC	Instead, the encoder constructs a finite-rate description of the output part using a specific kind of a vector quantizer, namely one designed to minimize the expected distance between the underlying distribution (whatever it may happen to be) and the empirical distribution of the input/quantized output pairs
OWNX	Our achievability result for the setting (b) uses a learning-theoretic generalization of recent work by Kramer and Savari  CITATION  on rate-constrained communication of probability distributions
OWNX	The problem of learning a pattern classifier under rate constraints was also treated in a recent paper by Westover and O'Sullivan  CITATION
MISC	They assumed that the underlying probability distribution is known, and the rate constraint arises from the limitations on the memory of the learning agent; then the problem is to design the best possible classifier (without any constraints on its structure)
OWNX	The motivation for the work in  CITATION  comes from biologically inspired models of learning
OWNX	The approach of the present paper is complementary to that of  CITATION
MISC	We consider a more general, decision-theoretic formulation of learning that includes regression as well as classification, but allow only vague prior knowledge of the underlying distribution and assume that the class of available predictors is constrained
MISC	Thus, while  CITATION  presents information-theoretic bounds on the performance of  any  classifier (including ones that are fully cognizant of the generative model for the data), here we are concerned with the performance of constrained learning schemes that must perform well in the presence of uncertainty about the underlying distribution
CONT	The novel element of our approach is that both the operational criteria used to design the encoders and the learning algorithm, and the regularity conditions that must hold for rate-constrained learning to be possible, involve a tight coupling between the available prior knowledge about the underlying distribution and the set of predictors available to the learning agent
OWNX	Planned future work includes obtaining converse theorems (lower bounds) and applying our formalism to specific classes of predictors used in statistical learning theory
MISC	In data analysis new forms of complex data have to be considered like for example (symbolic data, functional data, web data, trees, SQL query and multimedia data,
OWNX	
OWNX	)
OWNX	In this context classical data analysis for knowledge discovery based on calculating the center of gravity can not be used because input are not  SYMBOL  vectors
OWNX	In this paper, we present an application on real world symbolic data using the self-organizing map
OWNX	To this end, %%@ we propose an extension of the self-organizing map that can handle symbolic data \\  keywords:  Classification, Self organizing map, symbolic data, dissimilarity
MISC	The self-organizing map(SOM) introduced by Kohonen  CITATION  is an unsupervised neural network method which has both clustering and visualization %%@ properties
MISC	It can be considered as an algorithm that maps a high dimensional data space,  SYMBOL , to a lower dimension, generally 2, and which %%@ is called a map
OWNX	This projection enables the input data to be partitioned into "similar" clusters while preserving their topology
OWNX	Its most similar %%@ predecessors are the k-means algorithm  CITATION  and the dynamic clustering method  CITATION , which operate as a SOM without topology preservation %%@ and therefore without easy visualization
MISC	In data analysis, new forms of complex data have to be considered, most notably symbolic data (data with an internal structure such as interval %%@ data, distributions, functional data, etc ) and semi-structured data (trees, XML documents, SQL queries, etc )
OWNX	In this context, classical data %%@ analysis based on calculating the center of gravity can not be used because input are not  SYMBOL  vectors
MISC	In order to solve this problem, %%@ several methods can be considered depending on the type of data (for example projection operators %%@ for functional data  CITATION )
MISC	However, those methods are not fully general and an adaptation of every data analysis algorithm to the resulting %%@ data is needed
OWNX	The Kohonen's SOM is based on the center of gravity notion and unfortunately, this concept is not applicable to many kinds of complex data
OWNX	In this paper we propose an adaptation of the SOM to dissimilarity data as an alternative solution
OWNX	Our goal is to modify the SOM algorithm to allow its implementation on dissimilarity measures rather than on raw data
OWNX	To this end, we take one's inspiration from the work of Kohonen  CITATION
MISC	To apply the method, only the definition of a dissimilarity for each type of data is necessary and so complex data can be processed
MISC	We introduce a new protocol for prediction with expert advice in which each expert evaluates the learner's and his own performance using a loss function that may change over time and may be different from the loss functions used by the other experts
MISC	The learner's goal is to perform better or not much worse than each expert, as evaluated by that expert, for all experts simultaneously
MISC	If the loss functions used by the experts are all proper scoring rules and all mixable, we show that the defensive forecasting algorithm enjoys the same performance guarantee as that attainable by the Aggregating Algorithm in the standard setting and known to be optimal
OWNX	This result is also applied to the case of ``specialist'' (or ``sleeping'') experts
MISC	In this case, the defensive forecasting algorithm reduces to a simple modification of the Aggregating Algorithm
MISC	We consider the problem of online sequence prediction
MISC	A process generates outcomes  SYMBOL  step by step
MISC	At each step  SYMBOL , a learner tries to guess the next outcome announcing his prediction  SYMBOL
MISC	Then the actual outcome  SYMBOL  is revealed
MISC	The quality of the learner's prediction is measured by a loss function: the learner's loss at step  SYMBOL  is  SYMBOL
OWNX	Prediction with expert advice is a framework that does not make any assumptions about the generating process
MISC	The performance of the learner is compared to the performance of several other predictors called experts
MISC	At each step, each expert gives his prediction  SYMBOL , then the learner produces his own prediction  SYMBOL  (possibly based on the experts' predictions at the last step and the experts' predictions and outcomes at all the previous steps), and the accumulated losses are updated for the learner  and for the experts
OWNX	There are many algorithms for the learner in this framework; for a review, see~ CITATION
MISC	In practical applications of the algorithms for prediction with expert advice, choosing the loss function is often a problem
MISC	The task may have no natural measure of loss, except the vague concept that the closer the prediction to the outcome the better
MISC	Thus one can select among several common loss functions, for example, the quadratic loss (reflecting the idea of least squares methods) or the logarithmic loss (which has an information theory background)
MISC	A similar issue arises when experts themselves are prediction algorithms that optimize some losses internally
MISC	Then it is unfair to these experts when the learner competes with them according to a ``foreign'' loss function
OWNX	This paper introduces a new version of the framework of prediction with expert advice where there is no single fixed loss function but some loss function is linked to every expert
MISC	The performance of the learner is compared to the performance of each expert according to the loss function linked to that expert
MISC	Informally speaking, each expert has to be convinced that the learner performs almost as well as, or better than, that expert himself
CONT	We prove that a known algorithm for the learner, the defensive forecasting algorithm  CITATION , can be applied in the new setting and gives the same performance guarantee as that attainable in the standard setting, provided all loss functions are proper scoring rules \ifFULLThe only new requirement is that all loss functions used by the experts must be ``similar''
MISC	All strictly proper scoring rules (in particular, the quadratic and logarithmic loss functions) are similar to each other in this sense \blueend Another framework to which our methods can be fruitfully applied is that of ``specialist experts'': see, eg ,  CITATION ,  CITATION , and  CITATION
OWNX	We generalize some of the known results in the case of mixable loss functions
OWNX	To keep presentation as simple as possible, we restrict ourselves to binary outcomes  SYMBOL , predictions from  SYMBOL , and a finite number of experts
OWNX	We formulate our results for mixable loss functions only
MISC	However, these results can be easily transferred  to more general settings (non-binary outcomes, arbitrary prediction spaces, countably many experts, second-guessing experts, etc )\ where the methods of~ CITATION  work
MISC	We consider the problem of estimating the conditional probability of a label in time  SYMBOL , where  SYMBOL  is the number of possible labels
OWNX	We analyze a natural reduction of this problem to a set of binary regression problems organized in a tree structure, proving a regret bound that scales with the depth of the tree
AIMX	Motivated by this analysis, we propose the first online algorithm which provably constructs a logarithmic depth tree on the set of labels to solve this problem
OWNX	We test the algorithm empirically, showing that it works succesfully on a dataset with roughly  SYMBOL  labels
OWNX	The central question in this paper is how to efficiently estimate the conditional probability of label  SYMBOL  given an observation  SYMBOL
MISC	Virtually all approaches for solving this problem require  SYMBOL  time
MISC	A commonly used one-against-all approach, which tries to predict the probability of label  SYMBOL  versus all other labels, for each  SYMBOL ,  requires  SYMBOL  time per training example
MISC	Another common  SYMBOL  approach is to learn a scoring function  SYMBOL  and convert it into a conditional probability estimate according to  SYMBOL , where  SYMBOL  is a normalization factor
OWNX	The motivation for dealing with the computational difficulty is the usual one---we want the capability to solve otherwise unsolvable problems
OWNX	For example, one of our experiments involves a probabilistic prediction problem with roughly  SYMBOL  labels and  SYMBOL  examples, where any  SYMBOL  solution is intractable
MISC	Periplasmic binding proteins are a large family of molecular transporters that play a key role in nutrient uptake and chemotaxis in Gram-negative bacteria.
MISC	All PBPs have characteristic two-domain architecture with a central interdomain ligand-binding cleft.
MISC	Upon binding to their respective ligands, PBPs undergo a large conformational change that effectively closes the binding cleft.
MISC	This conformational change is traditionally viewed as a ligand induced-fit process; however, the intrinsic dynamics of the protein may also be crucial for ligand recognition.
MISC	Recent NMR paramagnetic relaxation enhancement experiments have shown that the maltose binding protein - a prototypical member of the PBP superfamily - exists in a rapidly exchanging mixture comprising an open state, and a minor partially closed state.
OWNX	Here we describe accelerated MD simulations that provide a detailed picture of the transition between the open and partially closed states, and confirm the existence of a dynamical equilibrium between these two states in apo MBP.
MISC	We find that a flexible part of the protein called the balancing interface motif is displaced during the transformation.
MISC	Continuum electrostatic calculations indicate that the repacking of non-polar residues near the hinge region plays an important role in driving the conformational change.
MISC	Oscillations between open and partially closed states create variations in the shape and size of the binding site.
OWNX	The study provides a detailed description of the conformational space available to ligand-free MBP, and has implications for understanding ligand recognition and allostery in related proteins.
MISC	Periplasmic Binding Proteins are major components of the bacterial cell envelope that are involved in nutrient uptake and chemotaxis CITATION, CITATION.
OWNX	Gram-negative bacteria use PBPs to transport ligands into the cytosol by association with a membrane-bound ATP-binding cassette transporter CITATION.
OWNX	Gram-positive bacteria differ in that they employ a slightly different design, in which the PBPs motif is directly attached to a membrane-anchored receptor.
MISC	In addition, several mammalian receptors contain extracellular ligand binding domains that are homologous to PBPs.
MISC	These include glutamate/glycine-gated ion channels such as the NMDA receptor; G protein-coupled receptors, including metabotropic glutamate, GABA-B, calcium sensing, and pheromone receptors; and atrial natriuretic peptide-guanylate cyclase receptors.
MISC	Many of these receptors are promising drug targets CITATION.
MISC	The structures of PBPs have been called a gold mine for studying the general mechanisms of protein-ligand recognition CITATION, as PBPs have been identified that can transport a large variety of substrates, including: carbohydrates, amino acids, vitamins, peptides, or metal ions CITATION.
MISC	The affinity of PBPs for diverse substrates also make them ideal templates for the design of diverse in vitro and in vivo biosensors with tailored properties CITATION .
MISC	Maltose binding protein is a part of the maltose/maltodextrin system of Escherichia coli, which is responsible for the uptake and efficient catabolism of maltodextrins.
MISC	MBP is the prototypical member of the PBP superfamily.
MISC	It has been the subject of extensive study due to its importance in various biological pathways CITATION, CITATION, and its utility as an affinity tag for protein expression and purification CITATION.
MISC	The protein folds into two domains of roughly equal size: the C terminal domain, and the N terminal domain.
MISC	The two domains are connected via a short helix and a two-stranded -sheet that form an interdomain hinge region.
OWNX	Like other PBPs, the binding site of MBP is located on the interdomain cleft between domains.
MISC	X-ray structures of MBP solved in the presence and absence of ligand indicate that the protein undergoes an important conformational change from an open to a closed state in the presence of the ligand, the effect of which is to better stabilize the ligand by reducing the size of the cleft CITATION.
MISC	The conformational change has been dubbed the Venus Fly-Trap Mechanism CITATION due to its resemblance to the traps on the carnivorous plant that closes only when stimulated by prey.
MISC	An induced-fit mechanism CITATION is often invoked to describe the ligand recognition process.
OWNX	In this scenario, the ligand participates in remodeling the binding site by interacting directly with the protein.
MISC	Alternatively, it is also possible that the apo protein already exists in a mixture of open and closed conformations.
MISC	In which case, the ligand would play a more passive role shifting the equilibrium toward the closed state, a mechanism traditionally described as conformational selection, or population shift CITATION.
MISC	Computer simulations and NMR studies are often needed to distinguish between the two scenarios, as X-ray structures typically do not provide detailed information about the ensemble of conformations available to the ligand-free protein CITATION .
MISC	Until recently, the bulk of our understanding of the mechanism of substrate recognition in MBP came from crystallographic studies that indicated only two possible conformations, a ligand-free open, and a ligand bound closed structure.
MISC	In 2007, Tang et al. CITATION reported the first NMR paramagnetic relaxation enhancement measurements on apo MBP.
MISC	By attaching a spin label on the NTD and CTD of the apo protein, domain hinge-bending motions could be studied.
MISC	These measurements indicated the existence of a dynamic equilibrium between a major open state, and a minor partially closed state.
OWNX	Because experimental PRE rates for MBP could not be explained either by the X-ray crystal structure of the apo-state, nor by the ligand-bound closed-state, it was possible to postulate that a partially closed structure exists.
MISC	The transition between an open, and a partially closed state, was determined to involve a rotation around the hinge region.
OWNX	The best agreement between computed and experimental PRE and Residual Dipolar Coupling data, was obtained by considering that substrate-free MBP exists in equilibrium between a major, open state and a minor, semi-closed state, populated 5 percent of the time, which corresponds to a very small energy difference between the two states.
MISC	The time-scale of the exchange between states was estimated to be between 20 ns to 20 s CITATION .
MISC	From a theoretical point of view, it is understood that a pre-existing equilibrium between different PBP conformations could play an important role in facilitating ligand recognition CITATION.
MISC	However, it remains a considerable challenge to access, using fully atomistic MD simulations, a detailed statistical analysis of slow conformational dynamics in proteins mediated by such hinge-bending motions.
CONT	In the past decade, the development of increasingly efficient simulation algorithms has led to a large number of theoretical studies using Molecular Dynamics simulations to probe the intrinsic dynamics of PBPs CITATION, CITATION, CITATION, CITATION, CITATION, CITATION, CITATION, CITATION, CITATION.
MISC	In 2003, Pang et al. CITATION studied the glutamine binding protein using 5 ns MD simulations.
MISC	They observed large vibrations in the apo protein in the direction of a closed structure, and found that the open apo structure was more flexible than the closed structure.
MISC	Subsequently, Pang et al. CITATION confirmed that this is a general result by performing a comparative study of different PBPs, which also showed that different PBPs could display slightly different dynamical properties.
MISC	The authors also observed that the opening and closure rate in the presence of a substrate could be fast, even though they also noted that obtaining converged sampling for the opening and closure events was challenging on the nanosecond time-scale.
MISC	In 2006, Kandt et al. CITATION performed longer MD simulations on BtuF, a protein involved in vitamin B 12 uptake.
MISC	Using 12 simulations of 30 50 ns each, they were able to observe the initiation of opening and closing motions in both apo and holo simulations, with larger motions in the apo simulations.
MISC	This behavior of the protein was interpreted to be compatible to the Venus Fly-trap model.
OWNX	The observation of enhanced molecular flexibility in the open state was confirmed by other groups for similar PBPs, such as the iron binding proteins FhuD CITATION, and FitE CITATION, and the heme binding proteins, ShuT, and PhuT CITATION.
MISC	In 2009, Loeffler and Kitao CITATION studied GlnBP in the open liganded form, and reported closing events occurring during the simulations.
OWNX	Taken together, these MD studies on PBPs have helped characterize the intrinsic flexibility of ligand-free PBPs on the nanosecond time-scale.
MISC	The consensus of opinion from these calculations is that the ligand recognition proceeds through a Venus flytrap mechanism, and that the apo PBPs structure is very flexible, with a tendency to oscillate along the modes that lead from the open to the closed structure.
MISC	In 2005, a simulation study of the MBP protein was carried out by Stockner et al. CITATION.
MISC	Using 4 MD simulations of 30 ns, started from both open and closed states, with and without substrate, the authors could show that the ligand-free MBP structure naturally evolves toward a closed state in the presence of a substrate.
MISC	Similarly, the closed state was found to evolve toward an open state when the substrate was removed.
MISC	The rapid time-scale of this conformational change was consistent with experimental rate constant for sugar binding 1 2 10 7 M 1 s 1 CITATION, which suggests a rate of closure around 30 50 ns.
MISC	However, the time-scale of the simulations was too short to observe any pre-existing equilibrium in apo MBP between an open and a partially closed conformer.
OWNX	This can be explained by the presumed slow exchange rate CITATION between the two conformations of apo MBP.
OWNX	In this paper, we have used accelerated Molecular Dynamics simulations CITATION of MBP to show that the apo protein exists in a dynamical equilibrium between an open and a semi-closed conformation.
MISC	A number of methods have been developed to enhance the sampling of slow conformational changes in proteins, including targeted MD CITATION, and conformational flooding CITATION.
MISC	However, within the framework of this study, a key advantage of aMD is that it allows us to study the conformational behavior and dynamics of the protein without using a pre-defined reaction coordinate.
MISC	In previous studies, aMD has been successfully employed to study slow time-scale dynamics in proteins, such as HIV-protease CITATION, ubiquitin CITATION, IKBA CITATION and H-Ras CITATION.
MISC	The enhanced conformational space sampled by aMD has also been shown to significantly improve the theoretical prediction of experimental NMR observables, such as residual dipolar couplings, scalar J-couplings CITATION and chemical shifts CITATION, which are sensitive to dynamic averaging on the micro- to millisecond time-scale.
OWNX	In this paper, we show that aMD simulations successfully allow the study of the transition from the open state of apo MBP to the hidden semi-closed conformation.
OWNX	This provides the first atomistic view of the transition between open and partially closed states in a PBP.
OWNX	NMR parameters computed from the simulations agree well with experiments.
OWNX	Free energy calculations, and continuum electrostatics calculations are used to provide new insights into the mechanism and energetics of the exchange between the open and semi-closed states of apo MBP.
MISC	Protein function is mediated by different amino acid residues, both their positions and types, in a protein sequence.
MISC	Some amino acids are responsible for the stability or overall shape of the protein, playing an indirect role in protein function.
MISC	Others play a functionally important role as part of active or binding sites of the protein.
MISC	For a given protein sequence, the residues and their degree of functional importance can be thought of as a signature representing the function of the protein.
MISC	We have developed a combination of knowledge- and biophysics-based function prediction approaches to elucidate the relationships between the structural and the functional roles of individual residues and positions.
OWNX	Such a meta-functional signature, which is a collection of continuous values representing the functional significance of each residue in a protein, may be used to study proteins of known function in greater detail and to aid in experimental characterization of proteins of unknown function.
MISC	We demonstrate the superior performance of MFS in predicting protein functional sites and also present four real-world examples to apply MFS in a wide range of settings to elucidate protein sequence structure function relationships.
MISC	Our results indicate that the MFS approach, which can combine multiple sources of information and also give biological interpretation to each component, greatly facilitates the understanding and characterization of protein function.
MISC	Vast amounts of sequence and structural data are being generated by high-throughput technologies.
MISC	Functional annotations of the uncharacterized sequences and structures are significantly lagging.
MISC	The time and cost of experimental techniques required to probe the function of all uncharacterized proteins are prohibitive.
MISC	Therefore, computational means have been increasingly useful and popular in predicting and annotating functions for the huge amount of sequence and structure data CITATION, CITATION .
MISC	However, protein function prediction is itself a difficult problem to formulate, since it is difficult to define function CITATION, CITATION.
MISC	Various functional definition schemes have been developed over the years and have addressed various aspects of protein function.
AIMX	Instead of adopting an existing functional definition scheme, we proposed to probe the role of individual amino acid residues in protein function, regardless of the functional definition schemes that are used.
MISC	In such cases, the protein function can be represented simply as a series of quantitative values, each of which indicates the functional importance of the corresponding amino acid residue in the protein sequence or structure.
MISC	To calculate the quantitative values for each residue, we used a combined approach, the meta-functional signature, which takes into account the individual scores from various function prediction algorithms and generates a composite score for each amino acid residue in a given protein.
OWNX	Currently our signature generation protocol consists of the following four types of scores for four different types of information: sequence conservation, evolutionary conservation, structural stability, and amino acid type.
MISC	All these scores are generated via conceptually simple and easily implementable algorithms, and their combined use outperforms sophisticated algorithms that use only one source of information.
MISC	Sequence conservation is one of the most utilized methods for measuring the functional importance of individual amino acids.
MISC	Amino acid residues with more conservative variation patterns are usually more important for the preservation of protein function.
OWNX	This concept is often used to identify the functional regions of proteins by building multiple alignments between the target sequence and all its sequence homologues, and then analyzing the degree of sequence conservation among each alignment site.
MISC	Various measures of sequence conservation have been proposed over the years, with differing complexity and sophistication CITATION.
OWNX	The simplest measures of sequence conservation are the entropy score and its variants CITATION CITATION.
MISC	More complicated measures CITATION CITATION incorporate other information, such as amino acid pairwise similarity, physicochemical properties, and theoretical sequence profiles, into the scoring schemes.
MISC	The AL2CO program package incorporates nine different scoring schemes, but these scores tend to correlate with each other CITATION.
OWNX	Recently it was also shown that a Jensen-Shannon divergence measure improves predicting functionally important residues, and that considering conservation in sequentially neighboring sites further improves accuracy CITATION.
MISC	We previously demonstrated that a relative entropy measure which incorporates amino acid background frequencies, can better predict functional sites than simple entropy measures CITATION.
OWNX	Furthermore, we found that incorporating the amino acid frequencies as estimated by the hidden Markov Models further improves the performance of the relative entropy measure CITATION.
AIMX	In the current study, we use a sequence conservation measure derived from HMMs as one component of our meta-functional signature generation protocol.
OWNX	In addition to sequence conservation, we also incorporate evolutionary conservation information in the meta-functional signature.
MISC	Many studies have shown that the use of phylogenetic relationships among a group of evolutionarily related sequences help accurate prediction of functional sites.
MISC	The Evolutionary Trace method, one of the first and the most successful of such methods, analyzes residue variation patterns within and between protein subfamilies from multiple alignments, maps important residues to protein structure, and quantitatively ranks residue importance CITATION, CITATION.
OWNX	A further development of the Evolutionary Trace method allows quantitative ranking of residue importance, by combining the use of evolutionary information and the entropy measures CITATION, CITATION.
OWNX	Similarly, the ConSurf method constructs phylogenetic relationships from a group of similar sequences, calculates the conservation score by a Bayesian or a maximum likelihood method, and maps the conservation information to the protein surface CITATION, CITATION.
MISC	Further, a study by Soyer et al. used site-specific evolutionary models that assumed a different substitution matrix for each site, for detecting protein functional sites CITATION.
MISC	La et al. used evolutionary relationships among sequence fragments to infer protein functional sites CITATION.
MISC	del Sol Mesa et al. presented several automated methods that divide a given protein family into subfamilies and search for residues that determine specificity CITATION.
MISC	The commonality among all these methods is that sequence relationships are analyzed based on the topology of an evolutionary tree, thus providing an additional level of information instead of relying on multiple sequence alignments alone.
OWNX	Here, we propose a novel method, called the state to step ratio score, for measuring evolutionary conservation.
MISC	Based on given multiple alignments, we construct a maximum parsimony tree, and analyze the variation patterns from the root of the tree to the leaf of the tree to create a score for each amino acid residue.
OWNX	The SSR score is a simple yet effective way of measuring evolutionary conservation.
MISC	Functional signature scores can also be derived from biophysics-based methods, using experimentally determined or computationally predicted protein structures.
MISC	For example, a recent study demonstrated that destabilizing regions in protein structures can often be used to provide valuable information for functional inference and functional site identification CITATION.
OWNX	For a given structure and a given position, we propose that we can mutate the wild-type residue to 19 other amino acids and calculate their structural stability scores, which can in turn be used to assign a score to each residue in a protein.
OWNX	Hence, these scores can also serve as a component of protein function prediction.
MISC	We previously developed a residue-specific all-atom probability discriminatory function CITATION that compiles statistics from a database of experimental structures to score and pick decoy structures that are more likely to be similar to experimentally derived structures.
MISC	The RAPDF has been optimized and enhanced in recent years for protein structure prediction CITATION CITATION.
OWNX	Here, we further expanded the RAPDF to score residue mutations on a per-residue basis.
MISC	Each residue in a given protein was mutated to one of the 19 alternative amino acids, producing new structures that were further optimized for topology and maximized for stability.
OWNX	In our current MFS generation protocol, we used two RAPDF based scoring functions, to measure how all mutated structures deviate from each other and how the experimentally determined structure differs from mutated structures, which represent the potential impact on stability for the position and for the naturally occurring residue, respectively.
OWNX	These scores separate residues conserved for structure versus function.
MISC	An additional component of the meta-functional signature is information on the type of amino acids, such as histidine and cysteine, which are more likely to be located in functional sites than other amino acids.
OWNX	However, such prior probability for a functional site is not explicitly modeled and incorporated by most current functional site prediction algorithms.
AIMX	In our MFS generation protocol, we used 19 binary variables to represent the amino acid identity for each position in a given protein.
MISC	We also examined whether the explicit use of amino acid information, as opposed to the implicit use, could provide additional information and better performance.
OWNX	Given the complexity of defining and identifying protein functional sites, clearly no single method will always work to capture all protein functional site information.
MISC	Therefore, several groups have begun to incorporate information from various sources, especially structure-derived information, to give more accurate predictions.
MISC	Work by Chelliah et al. has shown that distinguishing the structural and functional constraints for amino acid residues leads to better prediction of protein interaction sites CITATION.
MISC	We have shown that by considering both structural and functional constraints on protein evolution, we can better identify functional sites and signatures CITATION, CITATION.
OWNX	Recently, Petrova et al. showed that integration of seven selected sequence and structure features into a support vector machine framework can improve identification of catalytic sites CITATION.
BASE	Furthermore, Fischer et al. integrated sequence conservation, amino acid distribution, predicted secondary structure and relative solvent accessibility into a probability density framework, and showed that at 20 percent sensitivity the integrated method leads to a 10 percent increase in precision over non-integrated methods for predicting catalytic residues from the Catalytic Site Atlas and PDB SITE records CITATION.
MISC	Youn et al. investigated the various features for discriminating catalytic from noncatalytic residues in novel structural folds, and showed that a measure of sequence conservation, a measure of structural conservation, a degree of uniqueness of a residue's structural environment, solvent accessibility, and residue hydrophobicity are the best predictors of catalytic sites CITATION.
OWNX	Other similar studies also incorporated dozens to hundreds of features into a machine-learning framework for catalytic site identification CITATION, CITATION.
MISC	Altogether, the previous work suggests great value in using several complementary sequence and structure components for scoring catalytic sites.
AIMX	Unlike these approaches that were largely based on machine-learning algorithms, in the current study, we aim to combine several sources of information regarding the sequence, structure, evolution, and type of amino acids together via a simple logistic regression model for function prediction, including both catalytic sites and binding sites.
MISC	The major advantage of the regression model is that each component can be associated with a biologically meaningful interpretation, and that individual scores for a protein can be manually studied to gain additional insights into different aspects of protein function, which are not available when many components are thrown into a sophisticated machine-learning framework.
OWNX	We compare the MFS approach with several other functional site prediction algorithms, propose enhancements to our approach, exemplify the wide definition of function assessed by MFS, and discuss how different components of MFS can be used to understand biological function via four real-world examples.
MISC	Protein interactions play a vital part in the function of a cell.
MISC	As experimental techniques for detection and validation of protein interactions are time consuming, there is a need for computational methods for this task.
OWNX	Protein interactions appear to form a network with a relatively high degree of local clustering.
OWNX	In this paper we exploit this clustering by suggesting a score based on triplets of observed protein interactions.
MISC	The score utilises both protein characteristics and network properties.
MISC	Our score based on triplets is shown to complement existing techniques for predicting protein interactions, outperforming them on data sets which display a high degree of clustering.
OWNX	The predicted interactions score highly against test measures for accuracy.
MISC	Compared to a similar score derived from pairwise interactions only, the triplet score displays higher sensitivity and specificity.
OWNX	By looking at specific examples, we show how an experimental set of interactions can be enriched and validated.
OWNX	As part of this work we also examine the effect of different prior databases upon the accuracy of prediction and find that the interactions from the same kingdom give better results than from across kingdoms, suggesting that there may be fundamental differences between the networks.
OWNX	These results all emphasize that network structure is important and helps in the accurate prediction of protein interactions.
OWNX	The protein interaction data set and the program used in our analysis, and a list of predictions and validations, are available at LINK.
MISC	For understanding the complex activities within an organism, a complete and error-free network of protein interactions which occur in the organism would be a significant step forward.
OWNX	Experimentally, protein interactions can be detected by a number of techniques, and the data is publicly available from several databases such as DIP, Database of Interacting Proteins CITATION, and MIPS, Munich Information Center for Protein Sequences CITATION.
OWNX	Unfortunately, these experimentally detected interactions show high false negative CITATION and high false positive rates CITATION, CITATION.
OWNX	In this paper we develop a new computational approach to predict interactions and validate experimental data.
MISC	Computational methods have already been developed for these purposes.
OWNX	For interaction validation, these have mainly centered on the use of expression data CITATION, CITATION or the co-functionality or co-localisation of the proteins involved CITATION, CITATION .
MISC	For prediction of protein interactions in contrast, many methods have been suggested.
OWNX	The majority of these generate lists of proteins with a functional relationship rather than physical interactions CITATION, CITATION .
MISC	In terms of physical interaction prediction the available methods can be typified by the two approaches of Deng et al. CITATION and Jonsson et al. CITATION .
MISC	In Deng et al.'s method, a domain interaction based approach, a protein interaction is inferred on the basis of domain contacts.
MISC	If a domain pair is frequently found in observed protein interactions, it is likely that other protein pairs containing this domain pair might also interact.
MISC	From the observed protein interaction network, the probabilities of domain-domain interactions are estimated.
MISC	The expectation-maximum algorithm is employed to compute maximum likelihood estimates, assuming that protein interactions occur independently of each other.
MISC	This likelihood is then used to construct a probability score for a protein pair to interact, it is inferred based on the estimated probabilities of domain interactions within the protein pair.
MISC	Deng et al.'s prediction is based on a total of 5,719 interactions from S.cerevisiae.
MISC	However, the limited number of known domains may well not be enough to describe the variety of protein interactions.
MISC	This approach has had further extensions, such as an improved scoring for domain interactions CITATION and the inclusion of other biological information CITATION.
MISC	Liu et al.'s model CITATION is an extension of Deng et al.'s method which integrates multiple organisms.
MISC	In addition to S.cerevisiae, two other organisms, C.elegans, D.melanogaster, are included.
MISC	The second type of approach, as used by Jonsson et al. CITATION, is homology-based.
MISC	It searches for interlogs among protein interactions from other organisms.
MISC	If an interlog of a protein interaction exists in many other organisms, this protein interaction will score highly.
OWNX	In addition to searching for orthologous interlogs, Mika and Saeed CITATION, CITATION suggest that paralogous interlogs may provide even more information for inferring interacting protein pairs.
MISC	In principle, statistical clustering algorithms such as CITATION and CITATION which identify cliques in the network could be viewed as a prediction method, predicting that all proteins within a clique interact with each other.
OWNX	This interpretation is biologically questionable, and as the focus in the statistical clustering approach is on locating cliques and overlapping modules rather than on predicting individual interactions, we exclude it from our comparisons.
MISC	Neither Deng et al.'s method nor Jonsson et al.'s method make use of network structure beyond pairwise interactions; interactions are considered as isolated pairs.
MISC	However these pairs could and should be considered as a network, where the proteins are nodes and their interactions are links CITATION, CITATION.
MISC	Topological examination of these networks has revealed many interesting properties, including a clustering tendency CITATION, CITATION, see also Supporting Information.
OWNX	In our method we exploit the network structure by developing a score which considers triadic patterns of interactions rather than pairs.
OWNX	In this paper we thus take the established idea that the characteristics of a protein will affect its interactions alongside the not yet fully explored idea that its network position will also affect its interactions, in order to develop a novel predictive tool.
AIMX	Our goal is to predict protein interactions of the type x with y, where both x and y interact with a third protein z. Therefore in our approach we particularly focus on two simple three node network structures, triangles and lines.
MISC	A triangle is a subnet formed by an interacting protein pair with a common neighbour.
MISC	A line, by contrast, is a subnet formed by an non-interacting protein pair with a common neighbour.
MISC	We will show that these network structures and the protein characteristics within them help to predict protein interactions.
OWNX	We apply our method to the S.cerevisiae interaction network from the DIP database.
MISC	During the validation we assume that function and structure are known for all proteins and that the protein interaction network is known for all but one interaction.
OWNX	With triadic interacting patterns, we predict the interaction status of those protein pairs with at least one common neighbour and compare our results with those from three other published scores.
OWNX	We go on to demonstrate that the requirement to have fully annotated proteins can be relaxed to include partially annotated proteins, with a slight drop in the accuracy.
MISC	The prediction is also compared with simulated networks where all proteins are shuffled while the network structure is maintained, in order to examine whether the specific network structure, triangles and lines, keep useful information in forming protein interaction networks.
MISC	To measure the true positive rate in a set of protein pairs, Deane et al CITATION proposed the expression profile index, a measure of the true positive rate in a set of protein pairs based on biological relevance.
OWNX	We compare the EPR index to our score, showing that, with a suitable cut-off, our predictions achieve a high true positive rate.
OWNX	We also give examples of validated experimental data and predict new interactions.
OWNX	Our predictive model uses a prior interaction database and for this we use three prior databases, pooling protein interactions collected from prokaryotes, eukaryotes and all interactions.
OWNX	The results from using different prior databases show that the use of interactions from within the same kingdom rather than across kingdoms significantly improves the results, indicating as in CITATION that interaction networks may be significantly different between the kingdoms.
OWNX	Comparing our method to three other standard approaches, namely the domain-based approach by Deng et al. and an extension by Liu et al., and a homology-based approach by Jonsson et al., we find that our method outperforms the above approaches on the subset of interactions in the DIP Yeast data set which contains enough annotation and connectivity to be included in our analysis.
MISC	Our method complements the methods by Deng et al. and Liu et al., as their approaches apply to a rather different subset of potential interactions yielded from the DIP Yeast data set.
MISC	Pitch is one of the most important features of natural sounds, underlying the perception of melody in music and prosody in speech.
MISC	However, the temporal dynamics of pitch processing are still poorly understood.
MISC	Previous studies suggest that the auditory system uses a wide range of time scales to integrate pitch-related information and that the effective integration time is both task- and stimulus-dependent.
MISC	None of the existing models of pitch processing can account for such task- and stimulus-dependent variations in processing time scales.
OWNX	This study presents an idealized neurocomputational model, which provides a unified account of the multiple time scales observed in pitch perception.
MISC	The model is evaluated using a range of perceptual studies, which have not previously been accounted for by a single model, and new results from a neurophysiological experiment.
OWNX	In contrast to other approaches, the current model contains a hierarchy of integration stages and uses feedback to adapt the effective time scales of processing at each stage in response to changes in the input stimulus.
MISC	The model has features in common with a hierarchical generative process and suggests a key role for efferent connections from central to sub-cortical areas in controlling the temporal dynamics of pitch processing.
MISC	Modelling the neural processing of pitch is essential for understanding the perceptual phenomenology of music and speech.
MISC	Pitch, one of the most important features of auditory perception, is usually associated with periodicities in sounds CITATION.
MISC	Hence, a number of models of pitch perception are based upon a temporal analysis of the neural activity evoked by the stimulus CITATION CITATION.
OWNX	Most of these models compute a form of short-term autocorrelation of the simulated auditory nerve activity using an exponentially weighted integration time window CITATION CITATION.
MISC	Autocorrelation models have been able to predict the reported pitches of a wide range of complex stimuli.
MISC	However, choosing an appropriate integration time window has been problematic, and none of the previous models has been able to explain the wide range of time scales encountered in perceptual data in a unified fashion.
MISC	These data show that, in certain conditions, the auditory system is capable of integrating pitch-related information over time scales of several hundred milliseconds CITATION CITATION, while at the same time being able to follow changes in pitch or pitch strength with a resolution of only a few milliseconds CITATION, CITATION, CITATION CITATION.
MISC	Limits on the temporal resolution of pitch perception have also been explored by determining pitch detection and discrimination performance as a function of frequency modulation rate CITATION CITATION, the main conclusion being that the auditory system has a limited ability to process rapid variations in pitch.
MISC	The trade-off between temporal integration and resolution is not exclusive to pitch perception, but is a general characteristic of auditory temporal processing.
MISC	For instance, a long integration time of several hundred milliseconds is required to explain the way in which the detectability and perceived loudness of sounds increases with increasing sound duration CITATION, CITATION.
MISC	In contrast, much shorter integration times are necessary to explain the fact that the auditory system can resolve sound events separated by only a few milliseconds CITATION CITATION.
OWNX	Therefore, it appears that the integration time of auditory processing varies with the stimulus and task.
OWNX	Previously it was proposed that integration and resolution reflect processing in separate, parallel streams with different stimulus-independent integration times CITATION.
CONT	More recently, in order to reconcile perceptual data pertaining to temporal integration and resolution tasks, it was suggested that the auditory system makes its decisions based on multiple looks at the stimulus CITATION, using relatively short time windows.
OWNX	However, to our knowledge no model has yet quantitatively explained the stimulus- and task-dependency of integration time constants.
MISC	Another major challenge for pitch modelling is to relate perceptual phenomena to neurophysiological data.
MISC	Functional brain-imaging studies strongly suggest that pitch is processed in a hierarchical manner CITATION, starting in sub-cortical structures CITATION and continuing up through Heschl's Gyrus on to the planum polare and planum temporale CITATION CITATION.
MISC	Within this processing hierarchy, there is an increasing dispersion in response latency, with lower pitches eliciting longer response latencies than higher pitches CITATION.
MISC	This suggests that the time window over which the auditory system integrates pitch-related information depends on the pitch itself.
MISC	However, no attempt has yet been made to explain this latency dispersion.
OWNX	In this study, we present a unified account of the multiple time scales involved in pitch processing.
OWNX	We suggest that top-down modulation within a hierarchical processing structure is important for explaining the stimulus-dependency of the effective integration time for extracting pitch information.
OWNX	A highly idealized model, formulated in terms of interacting neural ensembles, is presented.
OWNX	The model represents a natural extension of previous autocorrelation models of pitch in a form resembling a hierarchical generative process CITATION, CITATION, in which higher levels modulate the responses in lower levels via feedback connections.
MISC	Without modification, the model can account not only for a wide range of perceptual data, but also for novel neurophysiological data on pitch processing.
MISC	the allais paradox  or common consequence effect  has been a standard challenge to normative theories of risky choice since its proposal over  NUMBER  years ago
OWNX	however  neither its causes nor the conditions necessary to create the effect are well understood
MISC	two experiments test the effects of losses and event splitting on the allais paradox
MISC	experiment  NUMBER  found that the allais paradox occurs for both gain and mixed gambles and is reflected for loss gambles produced by reflection across the origin
MISC	experiment  NUMBER  found that the allais paradox is eliminated by splitting the outcomes even when the probabilities used do not increase the salience of the common consequence
MISC	the results of experiment  NUMBER  are consistent with cumulative prospect theory  the current leading theory of risky choice
MISC	however  the results of experiment  NUMBER  are problematic for cumulative prospect theory and suggest that alternate explanations for the allais paradox must be sought
MISC	when expected utility theory eu was first proposed  CITATION  it was assumed that eu was not only the normative theory of risky decision making  but a descriptive theory as well
MISC	however it quickly became apparent that eu did not work as a descriptive theory of risky choice
MISC	one of the first and most famous challenges to eu was presented by allais in  NUMBER 
MISC	suppose one is given a choice between the following gambles       decision-makers  allais proposed  will generally choose the safer  certain gamble
MISC	however  when asked to choose between      decision-makers will generally chose the riskier gamble
MISC	closer inspection reveals that the second set of gambles are obtained from the first by removing a common consequence  an  NUMBER  percent  chance of winning   NUMBER  million  whose presence or absence should have no effect on preference
MISC	thus  subjects' preference reversals are nonnormative
MISC	the allais paradox has been demonstrated under many different conditions  CITATION
MISC	it is a real and robust phenomenon  at least when it involves a standard presentation of large monetary gains
MISC	however  the literature on the results of varying the presentation of the paradox is mixed
MISC	the present experiments investigate two circumstances in which the leading explanation of the allais paradox  cumulative prospect theory cpt  predicts an allais common consequence effect should occur  but in which the effect has not always previously been found
MISC	experiment  NUMBER  addresses the issue of the allais paradox and losses  while experiment  NUMBER  investigates the effects of event splitting on the paradox
MISC	a number of explanations for the allais paradox have been advanced
MISC	these theories include fanning-out theories  which explain the paradox via the shape of indifference curves in the unit triangle  CITATION   and expected cardinality-specific utility theories  which speculate that the utility function varies with the number of outcomes  CITATION
OWNX	however  for the present discussion i will concentrate on two particular classes of theories  probability weighting theories and configural weight theories
MISC	the most common explanation for the paradox is that decision-makers weight the probabilities of outcomes via a p function that overweights small values of p and underweights large values of p  as in original prospect theory  CITATION
MISC	in the first pair of gambles  when the common consequence cc is   NUMBER  million  cc-high  gambles  the  NUMBER  percent  greater chance of winning the safe gamble is overweighted because it falls in the very steep section of the p function near p NUMBER 
MISC	decision-makers are thus drawn to the safe gamble
MISC	when the common consequence is changed to   NUMBER   cc-low  gambles  both the  NUMBER  percent  chance of winning the riskier gamble and the  NUMBER  percent  chance of winning the safer gamble fall in a flat portion of the p function
MISC	the difference between them seems small  and decision-makers choose the more valuable  riskier gamble
MISC	under cumulative prospect theory  CITATION  the p function is not applied directly to the probability of an outcome but rather to the cumulative probabilities  the utility of the outcome is multiplied by pthe probability of obtaining an outcome at least as good as x minus pthe probability if an outcome strictly better   than x
MISC	thus  the weight given to an outcome depends not only on the probability and utility of the outcome itself  but also on how good the outcome is relative to the other possible outcomes of the gamble
MISC	rather than using cumulative probabilities  configural weight models  CITATION  directly weight the outcome according to its rank in the outcome set  with the smallest outcomes given the highest weight
MISC	by weighting smaller outcomes more heavily than larger ones  a configural weight model captures the intuition that people are more interested in avoiding the worst outcomes than they are in obtaining the best outcomes
MISC	for example  in the transfer of attentional exchange tax model  CITATION   each lower outcome  taxes  probability weight from each higher outcome
OWNX	the tax model therefore explains the allais paradox primarily via the transfer of probability weights  in the three-outcome cc-high risky gamble  the highest outcome is weighted less than its probability alone would suggest  the middle outcome weighted somewhat less  and the lowest outcome more
MISC	the decision-maker thus prefers the safe gamble in the cc-high pair  which  as a single-outcome gamble  has an unaltered probability weight
MISC	in the cc-low gambles  both gambles have two outcomes
MISC	thus  the probability weights undergo similar changes in both gambles and decision-makers simply choose the better  higher-paying risky gamble
MISC	although the allais paradox has been demonstrated for a wide variety of monetary gains  the few studies that have used losses or mixed gambles have had conflicting results
MISC	camerer  CITATION  found a reverse allais paradoxthat is  greater risk-seeking for the cc-high gambles than for the cc-low gamblesfor losses obtained by subtracting a common amount from all the outcomes of small-magnitude gains gambles
OWNX	neither probability weighting theories nor the tax model predict a reverse paradox under such conditions
MISC	however  birnbaum  CITATION  obtained an allais paradox for mixed gambles obtained in the same manner
MISC	three other studies found no paradox for either losses or similarly sized gains  CITATION
MISC	thus  the literature is conflicting on the existence of allais paradox for losses
OWNX	moreover  no studies that i am aware of have examined the effect of reflecting the paradox across the origin rather than shifting it
MISC	the question of the allais paradox for reflected loss gambles will be addressed by experiment  NUMBER 
OWNX	suppose we take the standard allais paradox cc-low gambles and split each of the gambles into three outcomes instead of two       normatively  the split gambles are identical to the standard ones
OWNX	because cpt incorporates the rank of an outcome using cumulative probability  the two sets of gambles are also identical under cpt  which therefore predicts that the paradox should be unaltered by the split
MISC	under original pt  the effects of the split depend on whether the decision-maker chooses to coalesce the gambles during the editing stage
MISC	if so  the split gambles should be treated identically to the standard ones
MISC	if not  the split should serve to increase the desirability of the safe cc-low gamble as  NUMBER  percent  and  NUMBER  percent  considered separately seem larger than  NUMBER  percent  and decrease that of the risky cc-low gamble  thus eliminating the paradox
MISC	under the tax model  the split will also serve to increase the value of the safe cc-low gamble  the outcomes with the highest payout lose less weight to the lowest outcome when split into two outcomes than when coalesced as one outcome
MISC	at the same time  the value of the cc-low risky gamble decreases when split  as the highest outcome loses more weight to the lowest outcome when the lowest outcome is split
MISC	thus the tax model predicts that such a split should reduce or eliminate the paradox
MISC	such a manipulation is known as event splitting  CITATION
MISC	several studies have found that event splitting  or presentation formats that constitute event splitting  reduce violations of eu in allais paradox
MISC	CITATION   although other studies have failed to find an effect of presentation format  CITATION
MISC	the extent to which event splitting disrupts something fundamental to the paradox is unclear
MISC	it is possible that it simply makes the common consequence more obvious by separating out the shared probability of obtaining the lowest outcome  a possibility that could tested by splitting the gambles in a fashion that does not make the common consequence more apparent
MISC	birnbaum  CITATION  partially accomplished this by examining the effects of splitting only one of the two cc-low gambles
MISC	he found that splitting only the risky gamble which makes the common consequence most evident did not eliminate the allais paradox  while splitting only the safe gamble did
OWNX	this result argues against the suggestion that event splitting makes the common consequence more evident
MISC	however  splitting one of the two cc-low gambles and not the other still means at least one of the outcomes is easily comparable across gambles
MISC	the effect of splitting the allais paradox cc-low gambles so that none of the outcomes may be easily compared is not known and will be examined in experiment  NUMBER 
MISC	all studies that have examined the allais paradox for losses or event splitting in the past have used a simple choice technique  subjects demonstrate the paradox by choosing the risky cc-high gamble and the safe cc-low gamble
MISC	however  what is important about the allais paradox is not the preference reversal itself  but rather the increase in risk seeking when the common consequence is removed
MISC	a set of two single-choice pairs can detect a shift in risk preference only if the presented gambles happen to span the shiftthat is  if the shift causes to decision-maker to prefer the safe cc-high gamble but the risky cc-low gamble
MISC	a decision-maker who chose the risky cc-high gamble might well be more risk-seeking for the cc-low gamblesand therefore be experiencing the paradoxbut be unable to demonstrate this using the single-choice technique
MISC	this limitation of the choice technique poses challenges for experimenters  if a manipulation produces a reduction in the number of subjects making the allais paradox pattern of choices  does it actually indicate a reduction in the common consequence effect  or have risk preference merely been changed overall
MISC	one aim of the present experiments was to examine the effects of sign and event splitting on the paradox using a matching technique more sensitive than the choice technique used in previous studies
MISC	% This paper proposes a method to construct an adaptive agent that is universal with respect to a given class of experts, where each expert is an agent that has been designed specifically for a particular environment
OWNX	This adaptive control problem is formalized as the problem of minimizing the relative entropy of the adaptive agent from the expert that is most suitable for the unknown environment
OWNX	If the agent is a passive observer, then the optimal solution is the well-known Bayesian predictor
MISC	However, if the agent is active, then its past actions need to be treated as causal interventions on the I/O stream rather than normal probability conditions
MISC	Here it is shown that the solution to this new variational problem is given by a stochastic controller called the Bayesian control rule, which implements adaptive behavior as a mixture of experts
OWNX	Furthermore, it is shown that under mild assumptions, the Bayesian control rule converges to the control law of the most suitable expert
MISC	When the behavior of an environment under any control signal is fully known, then the designer can choose an agent that produces the desired dynamics
MISC	Instances of this problem include hitting a target with a cannon under known weather conditions, solving a maze having its map and controlling a robotic arm in a manufacturing plant
MISC	However, when the behavior of the plant is unknown, then the designer faces the problem of  adaptive control
MISC	For example, shooting the cannon lacking the appropriate measurement equipment, finding the way out of an unknown maze and designing an autonomous robot for Martian exploration
MISC	Adaptive control turns out to be far more difficult than its non-adaptive counterpart
MISC	This is because any good policy has to carefully trade off explorative versus exploitative actions, i e actions for the identification of the environment's dynamics versus actions to control it in a desired way
MISC	Even when the environment's dynamics are known to belong to a particular class for which optimal agents are available, constructing the corresponding optimal adaptive agent is in general computationally intractable even for simple toy problems  CITATION
MISC	Thus, finding tractable approximations has been a major focus of research
OWNX	Recently, it has been proposed to reformulate the problem statement for some classes of control problems based on the minimization of a relative entropy criterion
MISC	For example, a large class of optimal control problems can be solved very efficiently if the problem statement is reformulated as the minimization of the deviation of the dynamics of a controlled system from the uncontrolled system  CITATION
MISC	In this work, a similar approach is introduced
MISC	If a class of agents is given, where each agent solves a different environment, then adaptive controllers can be derived from a minimum relative entropy principle
OWNX	In particular, one can construct an adaptive agent that is universal with respect to this class by minimizing the average relative entropy from the environment-specific agent
OWNX	However, this extension is not straightforward
MISC	There is a syntactical difference between actions and observations that has to be taken into account when formulating the variational problem
MISC	More specifically, actions have to be treated as interventions obeying the rules of causality  CITATION
MISC	If this distinction is made, the variational problem has a unique solution given by a stochastic control rule called the Bayesian control rule
MISC	This control rule is particularly interesting because it translates the adaptive control problem into an on-line inference problem that can be applied forward in time
OWNX	Furthermore, this work shows that under mild assumptions, the adaptive agent converges to the environment-specific agent
OWNX	The paper is organized as follows
OWNX	Section~ introduces notation and sets up the adaptive control problem
OWNX	Section~ formulates adaptive control as a minimum relative entropy problem
MISC	After an initial, na\"{\i}ve approach, the need for causal considerations is motivated
OWNX	Then, the Bayesian control rule is derived from a revised relative entropy criterion
OWNX	In Section~, the conditions for convergence are examined and a proof is given
OWNX	Section~ illustrates the usage of the Bayesian control rule for the multi-armed bandit problem and the undiscounted Markov decision problem
MISC	Section~ discusses properties of the Bayesian control rule and relates it to previous work in the literature
OWNX	Section~ concludes
OWNX	Information distance is a parameter-free similarity measure based on compression, used in pattern recognition, data mining, phylogeny, clustering, and classification
MISC	The notion of information distance is extended from pairs to multiples (finite lists)
OWNX	We study maximal overlap, metricity, universality,  minimal overlap, additivity, and normalized information distance in multiples
MISC	We use the theoretical notion of Kolmogorov complexity which for practical purposes is approximated by the length of the compressed version of the file involved, using a real-world compression program
OWNX	In pattern recognition, learning, and data mining one obtains information from objects containing information
OWNX	This involves an objective definition of the information in a single object, the information to go from one object to another object in a pair of objects, the information to go from one object to any other object in a multiple of objects, and the shared information between objects,   CITATION
OWNX	The classical notion of Kolmogorov complexity  CITATION  is an objective measure  for the information in an  a  single  object, and information distance measures the information  between a  pair  of objects  CITATION
MISC	This last notion has spawned research in the theoretical direction, among others   CITATION
MISC	Research in the practical direction has focused on  the  normalized  information distance, the similarity metric, which arises by normalizing the information distance in a proper manner and  approximating the Kolmogorov complexity through real-world compressors  CITATION , This normalized information distance is a parameter-free, feature-free, and alignment-free similarity measure  that has had great impact in applications
MISC	A variant of this compression distance has been tested on all time sequence databases used in the last decade in the major data mining conferences (sigkdd, sigmod, icdm, icde, ssdb, vldb, pkdd, pakdd)  CITATION
OWNX	The conclusion is that the method is competitive with all 51  other methods used and superior in  heterogenous data clustering and anomaly detection
OWNX	In  CITATION  it was shown that the method is resistant to noise
MISC	This theory  has found many applications in pattern recognition, phylogeny, clustering, and classification
MISC	For objects that are represented as computer files such applications range from weather forecasting, software, earthquake prediction, music, literature, ocr, bioinformatics, to internet  CITATION
CONT	For objects that are only represented by name,  or objects that are abstract like `red,' `Einstein,'  `three,' the normalized information distance uses background information provided by Google, or any search engine that produces aggregate page  counts
MISC	It discovers the `meaning' of words and phrases in the sense of producing a relative semantics
MISC	Applications run from ontology, semantics, tourism on the web, taxonomy, multilingual questions, to question-answer systems   CITATION
MISC	For more references on either subject see the textbook  CITATION  or Google Scholar for references to  CITATION
OWNX	However, in many applications we are interested in  shared information between many objects instead of just a pair of objects
OWNX	For example, in customer reviews of gadgets, in blogs about public happenings, in newspaper articles about the same occurrence, we are interested in the most comprehensive one or the most specialized one
OWNX	Thus, we want to extend the information distance  measure from pairs to multiples
OWNX	Retroviral insertional mutagenesis screens, which identify genes involved in tumor development in mice, have yielded a substantial number of retroviral integration sites, and this number is expected to grow substantially due to the introduction of high-throughput screening techniques.
OWNX	The data of various retroviral insertional mutagenesis screens are compiled in the publicly available Retroviral Tagged Cancer Gene Database.
MISC	Integrally analyzing these screens for the presence of common insertion sites requires an approach that corrects for the increased probability of finding false CISs as the amount of available data increases.
MISC	Moreover, significance estimates of CISs should be established taking into account both the noise, arising from the random nature of the insertion process, as well as the bias, stemming from preferential insertion sites present in the genome and the data retrieval methodology.
OWNX	We introduce a framework, the kernel convolution framework, to find CISs in a noisy and biased environment using a predefined significance level while controlling the family-wise error.
OWNX	Where previous methods use one, two, or three predetermined fixed scales, our method is capable of operating at any biologically relevant scale.
OWNX	This creates the possibility to analyze the CISs in a scale space by varying the width of the CISs, providing new insights in the behavior of CISs across multiple scales.
OWNX	Our method also features the possibility of including models for background bias.
OWNX	Using simulated data, we evaluate the KC framework using three kernel functions, the Gaussian, triangular, and rectangular kernel function.
OWNX	We applied the Gaussian KC to the data from the combined set of screens in the RTCGD and found that 53 percent of the CISs do not reach the significance threshold in this combined setting.
OWNX	Still, with the FWE under control, application of our method resulted in the discovery of eight novel CISs, which each have a probability less than 5 percent of being false detections.
MISC	In retroviral insertional mutagenesis experiments, genes involved in the development of cancer are identified by determining the loci of viral insertions from tumors induced by retroviruses in mice CITATION, CITATION.
MISC	After infecting a host cell, the retrovirus inserts its own DNA into the host cell's genome, mutating the host cell's DNA in the process.
OWNX	The mutation may alter the expression of genes in the vicinity of the insertion or, when inserted within a gene, alter the gene product.
MISC	When the affected gene is a cancer gene, activation of the proto-oncogene or inactivation of the tumor-suppressor gene can cause uncontrolled proliferation of cells.
OWNX	Eventually this may give rise to tumors.
OWNX	Throughout this text, these cancer-causing insertions are referred to as oncogenic insertions.
OWNX	A tumor develops when an accumulation of oncogenic insertions causes uncontrolled proliferation of a cell.
OWNX	As a result, the tumor tissue contains many copies of the cell bearing the oncogenic insertions that induced the proliferation, but only a few copies of cells carrying non-oncogenic insertions.
MISC	Consequently, when the DNA of the tumor is analyzed, one will encounter the insertion that induced proliferation in larger proportions than insertions that do not.
MISC	Regions in the genome that are found to carry insertions in multiple independent tumors are called common insertion sites.
OWNX	As a result, the locations of the CISs are highly correlated with the location of genes involved in tumor development.
MISC	Cloning the flanking sequences of the inserted virus to determine the insertion loci, and analyzing these data to find significant CISs, therefore enable the discovery of new candidate cancer genes.
MISC	This is summarized in Figure S1.
MISC	the current field study compares the time preferences of young adults of similar ages but in two very different environments  one more dangerous and uncertain than the other
MISC	soldiers  college students and a control group of teenagers answered questionnaires about their time preferences
MISC	during mandatory service  soldiers live in a violent atmosphere where they face great uncertainty about the near future and high risk of mortality measured by probability of survival
MISC	university students and teenagers live in much calmer environment and are tested for performance only periodically
OWNX	the soldier-subjects show relatively high subjective discount rates when compared to the other two groups
OWNX	we suggest that the higher subjective discount rate among soldiers can be the result of high perceived risk in the army as an institution  or higher mortality risk
MISC	the subjective discount rate is the rate at which individuals trade current value for future outcome
OWNX	this rate varies from person to person  depending on each one's willingness to wait
MISC	in general  an individual who values the present more than the future will have a higher subjective discount rate than a person who places more value on the future
AIMX	in the current paper  we examine how military service influences the time preference of soldiers
OWNX	we compare the time discount of soldiers in the israel defense forces idf to the time discount of university and high school students
MISC	since its establishment in  NUMBER   the state of israel has had universal conscription for all youths male and female upon completing high school at the age of  NUMBER 
MISC	by law  soldiers serve full-time for two females or three males years  and then continue serving in the reserves
OWNX	the idf plays an important part in israeli society  and is supported by a national consensus of the israel population  CITATION
MISC	the soldiers are a unique group because they are drafted at young age  prior to beginning their tertiary education  and earn similar  very low salaries
MISC	their  employer  is a harsh and total institution-where all parts of life of the individuals under its authority are subordinate to and dependent upon the hierarchy of the organization-with very clear values
MISC	the soldiers are intensively trained and tested from the first day of basic training
MISC	conversely  university students in israel usually work and have higher earnings
MISC	they live in much calmer environment and are tested for performance only periodically
MISC	a few studies have tested soldiers' decision making and compare them to civilians
OWNX	warner and pleeter  CITATION  studied the choices regarding early retirement plans of older soldiers in the us army
MISC	these soldiers were heterogenic in age  education  and earnings  and choose to join the army as a profession
MISC	in a recent article  haerem et al CITATION   compared educated  military decision makers to business students  and found that the soldiers exhibited high levels of self-efficacy that correlated with risk-seeking behavior
MISC	unlike other studies  our study is the first to test time preferences of young soldiers who did not join the army as a career choice but rather were drafted for mandatory service
OWNX	in order to ensure similar test conditions for the soldiers and other young adults  we distributed the questionnaires to both groups when they were travelling on the train
MISC	we found that the soldiers have a higher subjective discount rate when compared to similar age groups
OWNX	the rest of the paper is organized as follows  in section  NUMBER   we discuss risk  morbidity  and mortality and their relation to our research
OWNX	section  NUMBER  presents the hypothesis
OWNX	section  NUMBER  describes the experimental design
OWNX	section  NUMBER  presents the results regarding the time preferences of soldiers and students
OWNX	We consider computation of permanent of a positive  SYMBOL  non-negative matrix,  SYMBOL , or equivalently the problem of weighted counting of the perfect matchings over the complete bipartite graph  SYMBOL
MISC	The problem is known to be of likely exponential complexity
OWNX	Stated as the partition function  SYMBOL  of a graphical model, the problem allows exact Loop Calculus representation [Chertkov, Chernyak '06] in terms of an interior minimum of the Bethe Free Energy functional over non-integer doubly stochastic matrix of marginal beliefs,  SYMBOL , also correspondent to a fixed point of the iterative message-passing algorithm of the Belief Propagation (BP) type
OWNX	Our main result is an explicit expression of the exact partition function (permanent) in terms of the matrix of BP marginals,   SYMBOL , as  SYMBOL , where  SYMBOL  is the BP expression for the permanent stated explicitly in terms of  SYMBOL
OWNX	We give two derivations of the formula, a direct one based on the Bethe Free Energy and an alternative one combining the Ihara graph- SYMBOL  function and the Loop Calculus approaches
OWNX	Assuming that the matrix  SYMBOL  of the Belief Propagation marginals is calculated, we provide two lower bounds and one upper-bound to estimate the multiplicative term
MISC	Two complementary lower bounds are based on the Gurvits-van der Waerden theorem and on a relation between the modified permanent and determinant respectively
MISC	The problem of calculating the permanent of a non-negative matrix arises in many contexts in statistics,  data analysis and physics
OWNX	For example, it is intrinsic to the parameter learning of a flow used to follow particles in turbulence and to cross-correlate two subsequent images  CITATION
MISC	However, the problem is  SYMBOL -hard   CITATION ,  meaning that solving it in a time polynomial in the system size,  SYMBOL , is unlikely
OWNX	Therefore, when size of the matrix is sufficiently large, one naturally looks for ways to approximate the permanent
MISC	A very significant breakthrough  was achieved with invention of a so-called Fully-Polynomial-Randomized Algorithmic Schemes (FPRAS) for the permanent problem  CITATION : the permanent is approximated in a polynomial time, with high probability and within an arbitrarily small relative error
MISC	However, the complexity of this FPRAS is  SYMBOL , making it impractical for the majority of realistic applications
OWNX	This motivates the task of finding a lighter deterministic or probabilistic algorithm capable of evaluating the permanent more efficiently
MISC	This paper continues the thread of  CITATION  and  CITATION , where the Belief Propagation (BP) algorithm was suggested as an efficient heuristic of good (but not absolute) quality to approximate the permanent
MISC	The BP family of algorithms, originally introduced in the context of error-correction codes  CITATION  and artificial intelligence  CITATION , can generally be stated for any graphical model  CITATION
OWNX	The exactness of the BP on any graph without loops  suggests that the algorithm can be an efficient heuristic for evaluating the partition function or for finding a Maximum Likelihood (ML) solution for the Graphical Model (GM) defined on sparse graphs
MISC	However, in the general loopy cases one would normally not expect BP to work well,  thus making the heuristic results of  CITATION  somehow surprising, even though not completely unexpected in view of existence of polynomially efficient algorithms for the ML version of the problem  CITATION , also realized in  CITATION  via an iterative BP algorithm
MISC	This raises the questions of understanding the performance of BP: what it does well and what it misses
MISC	It also motivates the challenge of improving the BP heuristics
MISC	An approach potentially capable of handling the question and the challenge was recently suggested in the general framework of GM
MISC	The Loop Series/Calculus (LS) of  CITATION  expresses the ratio between the Partition Function (PF) of a binary GM and its BP estimate in terms of a finite series, in which each term is associated with the so-called generalized loop (a subgraph with all vertices of degree larger than one) of the graph
OWNX	Each term in the series,  as well as the BP estimate of the partition function, is expressed in terms of a doubly stochastic matrix of marginal probabilities,  SYMBOL , for matching pairs to contribute a perfect matching
OWNX	This matrix  SYMBOL  describes a minimum of the so-called Bethe free energy,  and it can also be understood as a fixed point of an iterative BP algorithm
OWNX	The first term in the resulting LS is equal to one
OWNX	Accounting for all the loop-corrections, one recovers the exact expression for the PF
OWNX	In other words,  the LS holds the key to understanding the gap between the approximate BP estimate for the PF and the exact result
AIMX	In section  and section , we will give a technical introduction to the variational Bethe Free Energy (BFE) formulation of BP and a brief overview of the LS approach for the permanent problem respectively {Our results } In this paper, we develop an LS-based approach to describe the quality of the BP approximation for the permanent of a non-negative matrix (i) Our natural starting point is the analysis of the BP solution itself conducted in section
OWNX	Evaluating the permanent of the non-negative matrix,  SYMBOL , dependent on the temperature parameter,  SYMBOL , we find that a non-integer BP solution is observed only at  SYMBOL , where  SYMBOL  is defined by \eq() (ii) At  SYMBOL , we derive an alternative representation for the LS in section
OWNX	The entire LS is collapsed to a product of two terms: the first term is an easy-to-calculate function of  SYMBOL , and the second term is the permanent of the matrix,  SYMBOL  (The binary operator  SYMBOL  denotes the element-wise multiplication of matrices ) This is our main result stated in theorem , and the majority of the consecutive statements of our paper follows from it
OWNX	We also present yet another, alternative, derivation of the theorem  using the multivariate Ihara-Bass formula for the graph zeta-function in subsection  (iii) Section  presents two easy-to-calculate lower bounds for the LS
MISC	The lower bound stated in the corollary  is based on the Gurvits-van der Waerden theorem applied to  SYMBOL
MISC	Interestingly enough this lower bound is invariant with respect to the BP transformation, i e it is exactly equivalent to the lower bound derived via application of the van der Waerden-Gurvits theorem to the original permanent
OWNX	Another lower bound is stated in theorem
MISC	Note,  that as follows from an example discussed in the text, the two lower bounds are complementary: the latter is stronger at sufficiently small temperatures,  while the former dominates the large  SYMBOL  region (iv) Section  discusses an upper bound on the transformed permanent based on the application of the Godzil-Gutman formula and the Hadamard inequality
OWNX	Possible future extensions of the approach are discussed in section
OWNX	We present  multiplicative updates for solving hard  and soft margin support  vector  machines  (SVM)  with non-negative  kernels
OWNX	They follow as a natural extension of the updates for non-negative matrix factorization
MISC	No additional parameter  setting, such  as choosing learning,   rate   is   required
MISC	Experiments   demonstrate   rapid convergence to good classifiers
MISC	We analyze the rates of asymptotic convergence of the updates and  establish tight bounds
MISC	We test the performance on  several datasets using  various non-negative kernels and report  equivalent generalization errors  to that of  a standard SVM
MISC	Support  vector  machines  (SVM)  are  now  routinely  used  for  many classification problems  in machine learning~ CITATION  due to their  ease of use and  ability to generalize
OWNX	In  the basic case, the input data,  corresponding to two groups, is  mapped into a higher dimensional space,  where a  maximum-margin hyperplane is  computed to separate  them
OWNX	The  ``kernel  trick''  is used  to  ensure that  the mapping into higher dimensional  space is never explicitly calculated
MISC	This can  be formulated as a non-negative  quadratic programming (NQP) problem    and    there   are    efficient    algorithms   to    solve it~ CITATION
MISC	SVM  can be  trained using  variants  of the  gradient descent  method applied   to  the   NQP
MISC	Although   these  methods   can   be  quite efficient~ CITATION , their drawback  is the requirement of setting  the   learning  rate
MISC	Subset  selection  methods   are  an alternative      approach     to      solving     the      SVM     NQP problem~ CITATION
MISC	At  a  high  level  they  work  by splitting the  arguments of the  quadratic function at  each iteration into two sets: a fixed set, where the arguments are held constant, and a  working  set  of  the  variables being  optimized  in  the  current iteration
MISC	These methods~ CITATION ,  though efficient in space  and time,  still require a  heuristic to  exchange arguments between the working and the fixed sets
MISC	An alternative algorithm for solving  the general NQP problem has been applied   to  SVM   in~ CITATION
OWNX	The  algorithm,   called M\textsuperscript{3},  uses   multiplicative  updates  to  iteratively converge to the solution
MISC	It  does not require any heuristics, such as setting the learning rate or choosing how to split the argument set
OWNX	In this  paper we reformulate the  dual SVM problem  and demonstrate a connection   to   the    non-negative   matrix   factorization   (NMF) algorithm~ CITATION
MISC	NMF employs multiplicative updates and is  very successful in practice  due to its  independence from the learning rate parameter, low  computational complexity and the ease of implementation
OWNX	The   new   formulation   allows   us   to   devise multiplicative updates for solving  SVM with non-negative kernels (the output value of the kernel function is greater or equal to zero)
MISC	The requirement  of a non-negative  kernel is  not very  restrictive since their set includes many  popular kernels, such as Gaussian, polynomial of  even  degree  etc
MISC	The  new  updates possess  all  of  the  good properties   of  the   NMF  algorithm,   such  as   independence  from hyper-parameters,  low  computational   complexity  and  the  ease  of implementation
OWNX	Furthermore, the  new algorithm converges faster than the   previous   multiplicative    solution   of   the   SVM   problem from~ CITATION  both asymptotically  (a proof is provided) and in practice
OWNX	We also  show how  to solve the  SVM problem  with soft margin using the new algorithm
OWNX	In this paper we propose a method that learns to play Pac-Man
OWNX	We define a set of high-level observation and action modules
OWNX	Actions are temporally extended, and multiple action modules may be in effect concurrently
MISC	A decision of the agent is represented as a rule-based policy
OWNX	For learning, we apply the cross-entropy method, a recent global optimization algorithm
MISC	The learned policies reached better score than the hand-crafted policy, and neared the score of average human players
MISC	We argue that learning is successful mainly because (i) the policy space includes the combination of individual actions and thus it is sufficiently rich, (ii) the search is biased towards low-complexity policies and low complexity solutions can be found quickly if they exist
OWNX	Based on these principles, we formulate a new theoretical framework, which can be found in the Appendix as supporting material
MISC	During the last two decades, reinforcement learning has reached a mature state, and has been laid on solid foundations
MISC	We have a large variety of algorithms, including value-function based, direct policy search and hybrid methods  CITATION
MISC	The basic properties of many such algorithms are relatively well understood (e g conditions for convergence, complexity, effect of various parameters etc ), although it is needless to say that there are still lots of important open questions
MISC	There are also plenty of test problems (like various maze-navigation tasks, pole-balancing, car on the hill etc ) on which the capabilities of RL algorithms have been demonstrated, and the number of successful large-scale RL applications is also growing steadily
MISC	However, there is still a sore need for more successful applications to validate the place of RL as a major branch of artificial intelligence
MISC	We think that games (including the diverse set of classical board games, card games, modern computer games etc ) are ideal test environments for reinforcement learning
MISC	Games are intended to be interesting and challenging for human intelligence and therefore, they are ideal means to explore what artificial intelligence is still missing
MISC	Furthermore, most games fit well into the RL paradigm: they are goal-oriented sequential decision problems, where each decision can have long-term effect
MISC	In many cases, hidden information, random events, unknown environment, known, or unknown players account for (part of) the difficulty of playing the game
MISC	Such circumstances are in the focus of the reinforcement learning idea
MISC	They are also attractive for testing new methods: the decision space is huge in most cases, so finding a good strategy is a challenging task
MISC	There is another great advantage of games as test problems: the rules of the games are fixed, so the danger of `tailoring the task to the algorithm' -- i e , to tweak the rules and/or the environment so that they meet the capabilities of the proposed RL algorithm -- is reduced, compared, eg , to various maze navigation tasks
MISC	RL has been tried in many classical games, including checkers  CITATION , backgammon  CITATION , and chess  CITATION
MISC	On the other hand, modern computer games got into the spotlight only recently, and there are not very many successful attempts to learn them with AI tools
OWNX	Notable exceptions are, eg ,  role-playing game  Baldur's Gate   CITATION , real-time strategy game  Wargus   CITATION ), and possibly,  Tetris   CITATION
MISC	These games are also interesting from the point of view of RL, as they catch different aspects of human intelligence: instead of deep and wide logical deduction chains, most modern computer games need short-term strategies, but many observations have to be considered in parallel, and both the observation space and the action space can be huge
OWNX	In this spirit, we decided to investigate the arcade game Pac-Man
MISC	The game is interesting on its own, as it is largely unsolved, but also imposes several important questions in RL, which we will overview in Section~
MISC	We will show that a hybrid approach is more successful than either tabula rasa learning or a hand-coded strategy alone
MISC	We will provide hand-coded high-level actions and observations, and the task of RL is to learn how to combine them into a good policy
MISC	We will apply rule-based policies because they are easy to interpret, and it is easy to include human domain-knowledge
OWNX	For learning, we will apply the cross-entropy method, a recently developed general optimization algorithm
OWNX	In the next section we overview the Pac-Man game and the related literature
MISC	We also investigate the emerging questions upon casting this game as a reinforcement learning task
OWNX	In sections  and  we give a short description of rule-based policies and the cross-entropy optimization method, respectively
OWNX	In section  we describe the details of the learning experiments, and in section  we present our results
OWNX	Finally, in section  we summarize and discuss our approach with an emphasis on its implications for other RL problems
MISC	Canonical correlation analysis is a technique to extract common features from a pair of multivariate data
MISC	In complex situations, however, it does not extract useful features because of its linearity
OWNX	On the other hand, kernel method used in support vector machine is an efficient approach to improve such a linear method
OWNX	In this paper, we investigate the effectiveness of applying kernel method to canonical correlation analysis \\ {Keyword:} multivariate analysis, multimodal data, kernel method, regularization
OWNX	This paper deals with the method to extract common features from multiple information sources
MISC	For instance, let us consider a task of learning in pattern recognition, in which an object is given by using an image and its name is given by a speech
MISC	For a newly given image, the system is required to answer its name by a speech, and for a newly given speech, the system is to answer the corresponding image
MISC	The task can be considered to be a regression problem from image to speech and vice versa
MISC	However, since the dimensionalities of images and speeches are generally very large, a regression analysis many not work effectively
MISC	In order to solve the problem, it is useful to map the inputs into low dimensional feature space and then to solve the regression problem
MISC	The canonical correlation analysis (CCA) has been used for such a purpose
OWNX	CCA finds a linear transformation of a pair of multi-variates such that the correlation coefficient is maximized
MISC	From an information theoretical point of view, the transformation maximizes the mutual information between extracted features
OWNX	However, if there is nonlinear relation between the  variates, CCA does not always extract useful features
